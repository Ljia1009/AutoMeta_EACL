{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d66fc521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1d4484d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper provides a compelling theoretical explanation for a large class of adversarial examples. While this is not new, they unify several old perspectives, and convincingly argue for genuinely new scaling relationships. This analysis only seems to work for \"well-behaved\" models. For models with gradient masking, obfuscated gradients or even non-differentiable models, it is unlikely such analysis is significant.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"flan-t5_review_out.txt.csv\")\n",
    "df.iloc[3,:][\"prediction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "edf2ebd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                            57\n",
       "gold                   This paper builds upon existing works to prove...\n",
       "prediction             The authors consider the problem of finding an...\n",
       "rouge_score                                                     0.159601\n",
       "bertscore_precision                                             0.710813\n",
       "bertscore_recall                                                0.698373\n",
       "bertscore_f1                                                    0.704538\n",
       "factCC_label                                                   INCORRECT\n",
       "factCC_score                                                    0.992199\n",
       "Name: 57, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"metrics/Bart_review_out.txt.csv\")\n",
    "df.iloc[57,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf08529",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prediction'] = df['prediction'].str.split('\\n').str[0]\n",
    "\n",
    "df.to_csv(\"bart_review_out.txt.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66cdb6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This paper describes how to use normalizing flows for selecting features in a way that controls the type-1 error by using a normalizing flow along with MCMC to sample from the null distribution. The majority of the reviewers were positive, however the most confident reviewer was negative. From taking a look at that reviewers concerns, I tend to agree with most of them.\\n\\nThe paper is titled knockoff-free, which means in the context of this paper that both 1) 1-bit p-values are not used and 2) The full knockoff property is not required, only sampling from complete conditionals are required. Most of the experiments compare knockoff methods to the proposed approach, so it\\'s not clear if 1) 1-bit p-values are not great or 2) the model-X process/complete conditional sampling process is better with normalizing flows. The former point is known and the latter point on the best way to sample from the complete conditionals is really the value. \\n\\nIf we take the paper as, \\n\\n1) complete conditionals are 1-D\\n2) MCMC can be used to sample from a 1-D unnormalized density\\n3) Simple MCMC won\\'t be bad because the problem is 1-D\\n\\n-> Any likelihood based deep generative model can be used to sample complete conditionals\\n\\nthen it\\'s a solid paper.\\n\\nOn the other hand, the belief that flows are the correct choice versus other likelihood-based deep generative models is harder to take as there\\'s only a comparison with a mixture density network used in the original HRT paper. Also from other uses of these models, different models are better in different situations. I\\'d suggest a heavy discussion in the paper on this point at the minimum. Maybe even a reframing of the paper is needed.\\n\\nFinally, for the test statistic, the HRT may not be the best choice for work like this paper that studies the problems with estimating X-distribution. The  paper \"CONTRA: Contrarian statistics for controlled variable selection\" at AISTATS 2021 shows that the HRT test statistic is more sensitive to model-X estimation errors than a simple mixture statistic that doesn\\'t give up much power. The choice of test statistic also merits some discussion in step 3.\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../DistilBart_review_out.txt.csv\")\n",
    "df.iloc[110,:][\"gold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1472a46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 549 predictions contain '\\n' (0.00%)\n"
     ]
    }
   ],
   "source": [
    "has_newline = df['prediction'].str.contains('\\n', regex=False)\n",
    "\n",
    "count_with_newline = has_newline.sum()\n",
    "total = len(df)\n",
    "\n",
    "print(f\"{count_with_newline} out of {total} predictions contain '\\\\n' ({count_with_newline / total:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf0b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"evaluation_summary_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a61ccff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Prediction-Tokens-Length</th>\n",
       "      <th>ROUGE</th>\n",
       "      <th>BERTScore-F1</th>\n",
       "      <th>BERTScore-precision</th>\n",
       "      <th>BERTScore-recall</th>\n",
       "      <th>FactCC-Score</th>\n",
       "      <th>FactCC-Label-Rate</th>\n",
       "      <th>Disco_EntityGraph</th>\n",
       "      <th>Disco_LexicalChain</th>\n",
       "      <th>Disco_RC</th>\n",
       "      <th>Disco_LC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pegasus_review</td>\n",
       "      <td>15.1166</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.6737</td>\n",
       "      <td>0.7142</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.5046</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pegasus_all</td>\n",
       "      <td>13.8215</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.6746</td>\n",
       "      <td>0.7183</td>\n",
       "      <td>0.6372</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.0169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flan-t5_review</td>\n",
       "      <td>100.3024</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.7773</td>\n",
       "      <td>0.7689</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.3297</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>1.0437</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.1838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flan-t5_all</td>\n",
       "      <td>98.5902</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.7668</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>0.4309</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.3983</td>\n",
       "      <td>0.1665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bart_review</td>\n",
       "      <td>85.2623</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>0.7797</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>2.7086</td>\n",
       "      <td>2.3403</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model  Prediction-Tokens-Length   ROUGE  BERTScore-F1  \\\n",
       "0  pegasus_review                   15.1166  0.0647        0.6737   \n",
       "1     pegasus_all                   13.8215  0.0596        0.6746   \n",
       "2  flan-t5_review                  100.3024  0.1548        0.7725   \n",
       "3     flan-t5_all                   98.5902  0.1440        0.7668   \n",
       "4     bart_review                   85.2623  0.1637        0.7797   \n",
       "\n",
       "   BERTScore-precision  BERTScore-recall  FactCC-Score  FactCC-Label-Rate  \\\n",
       "0               0.7142            0.6388        0.9316             0.5046   \n",
       "1               0.7183            0.6372        0.9442             0.5483   \n",
       "2               0.7773            0.7689        0.9519             0.3297   \n",
       "3               0.7697            0.7651        0.9531             0.2386   \n",
       "4               0.7909            0.7700        0.9518             0.4098   \n",
       "\n",
       "   Disco_EntityGraph  Disco_LexicalChain  Disco_RC  Disco_LC  \n",
       "0             0.0055              0.0089    0.0471    0.0234  \n",
       "1             0.0046              0.0061    0.0343    0.0169  \n",
       "2             0.4821              1.0437    0.4388    0.1838  \n",
       "3             0.4309              0.8730    0.3983    0.1665  \n",
       "4             0.7255              2.7086    2.3403    0.9528  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d315e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Disco_avg'] = df[[\"Disco_EntityGraph\",\"Disco_LexicalChain\",'Disco_RC','Disco_LC']].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48151500",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['model','Prediction-Tokens-Length',\"ROUGE\", 'BERTScore-F1', \"FactCC-Label-Rate\",'Disco_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf43bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('summary_show.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470624fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autometa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
