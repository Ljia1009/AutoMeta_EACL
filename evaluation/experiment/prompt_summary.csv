,gold,prediction_v0,rouge_score_v0,bertscore_precision_v0,bertscore_recall_v0,bertscore_f1_v0,factCC_label_v0,factCC_score_v0,prediction_v1,prediction_v2,rouge_score_v1,rouge_score_v2,bertscore_precision_v1,bertscore_precision_v2,bertscore_recall_v1,bertscore_recall_v2,bertscore_f1_v1,bertscore_f1_v2,factCC_label_v1,factCC_label_v2,factCC_score_v1,factCC_score_v2
0,"The paper investigates the capacity for neural language models to perform fast-mapping word acquisition using a proposed multimodal external memory architecture. Much work exists that shows that neural models are capable of following instructions whose meaning persists across episodes (i.e., slow-learning), however much less attention has been paid to instruction-following in a one-shot learning context. Using a simulated 3D navigation/manipulation domain, the paper shows that the proposed multimodal memory network is capable of both slow and one-shot word learning when trained via standard RL.

The submission was reviewed by four knowledgable referees, who read the author feedback and engaged in discussion with the authors. The paper is topical---one-shot language learning for instruction-following using neural models is of significant interest of-late. The reviewers agree that the proposed multimodal memory architecture is both interesting and technically solid. The reviewers raised concerns about the experimental evaluation and the role of embodiment. The author feedback together with discussion with reviewers were helpful in resolving some of these issues. However, the authors are encouraged to ensure that the paper clearly motivates the importance of embodiment to slow learning and fast-mapping, particularly given the large body of work in language acquisition in robotics, a truly embodied domain, which is notably missing from the related work discussion.

","The paper presents an argument for a multi-modal memory-architecture called DCEM whose key/queries and values are dependent on language and vision modalities. The proposed DCEM model outperforms baselines on various metrics and ablation. The paper only investigates generalization of object names. This is kind of a low hanging fruit for generalization in language space. The experiments on nonsense words are randomly generated characters in every episode of training and evaluation, to tease out that the new word is being memorized and associated, not that the agent is memorizing that ""dax"" per episode changes meaning. The constant references to the appendix are generally jarring, but this one is just sort of silly. It could be a single sentence maybe but not a whole subsection.",0.1494252873563218,0.7699291706085205,0.7542904615402222,0.7620295882225037,INCORRECT,0.5837467908859253,"Reviews of papers on the same paper. Please summarize the paper reviews and decide on whether the paper is accepted or rejected. The paper considers the problem of fast mapping: in a 3d environment, learning to explore an environment to learn a (new) mapping between objects and names. It seems that theDCEM model performs better than the transformer-XL model when the number of timesteps is limited. It's not quite clear how much the memory bank is learning as opposed to the LSTm hidden state (which is also something mentioned in the supplemental). It would be interesting to learn to measure when the model learns to assign an object to a name. The experiments on nonsense words are randomly generated characters in every episode of training and evaluation, to tease out that the new word is being memorized.","Multiple reviews of the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The paper considers the problem of fast mapping: in a 3d environment, learning to explore an environment to learn a (new) mapping between objects and names. It seems that theDCEM model performs better than the transformer-XL model when the number of timesteps is limited. It's not quite clear how much the memory bank is learning as opposed to the LSTm hidden state (which is also something mentioned in the supplemental) The paper is really well-written and readable, and the experiments on novel category + novel instance recognition are really convincing specifically for fast- mapping (4.1).",0.149584487534626,0.1489971346704871,0.7620476484298706,0.7713024020195007,0.747605562210083,0.7552902698516846,0.7547575831413269,0.7632123231887817,CORRECT,INCORRECT,0.9973721504211426,0.9872942566871644
1,"This paper considers the problem of (biological) sequence design and optimization. The authors made an interesting yet important case that in certain sequence design tasks, a simple evolutionary greedy algorithm could be competitive with the increasingly complex contemporary black-box optimization models.

Most reviewers appreciate the design of the open-source simulation environment in benchmarking AdaLead (and other competing algorithms) in a number of biological sequence design tasks (e.g. TF binding, RNA, and protein). However, there is a common concern that the experimental results are not fine-grained enough to explain the outperforming results of the proposed algorithm. There are also unresolved comments on missing important BO baselines in the empirical study. As a purely empirical work, these appear to be important concerns. While these results appear to be useful for the domain of biological sequence design, the reviewers are unconvinced that the proposed algorithm is significantly novel, or the results are sufficiently compelling to merit an acceptance to this venue.


","Simple evolutionary algorithm ""AdaLead"" outperformed several existing methods. There is a lack of exploration to understand why AdaLead is outperforming. Some of the figure labels can be improved. There are some acronyms likely not familiar to computer scientists with little biological background left unexplained, such as ""w.t."" in fig 1B. The paper is clearly written. It is unclear to me the ML significance of this work to the ICLR community. It might be more suitable for a specific compbio venue. What could we learn from this result? The authors have surveyed and tested many existing algorithms. They have considered many settings such as DNA, RNA, and protein as well as ""swampland"" The improvement wrt to SOTA is shaky.",0.1565836298932384,0.7861700057983398,0.7796469926834106,0.7828949093818665,INCORRECT,0.9950181245803832,"The paper is well written and motivated and previous, relevant literature is discussed. The structure of this paper is somewhat unconventional, the paper would benefit from more rigor and structure. The experimental results are unsatisfactory without a proper BO comparison. There is a lack of exploration to understand why AdaLead is outperforming. There are some acronyms likely not familiar to computer scientists with little biological background left unexplained, such as ""w.t."" in fig 1B. The paper is clearly written. It is unclear to me the ML significance of this work to the ICLR community. It might be more suitable for a specific compbio venue. What could we learn from this result? The authors have surveyed and tested many existing algorithms. They have considered many settings such as DNA, RNA, and protein.","The paper is published in the open source journal, Theoretical Computer Science (TCS) The structure of this paper is somewhat unconventional, the paper would benefit from more rigor and structure. The experimental results are unsatisfactory without a proper BO comparison. It is unclear to me the ML significance of this work to the ICLR community. It might be more suitable for a specific compbio venue. The paper is clearly written. The authors have surveyed and tested many existing algorithms. They have considered many settings such as DNA, RNA, and protein as well as ""swampland"" The authors introduce a new algorithm AdaLead to solve the problem of efficient design of biological sequences and FLEXS, an open-source simulation environment for sequence design.",0.1428571428571428,0.1696113074204947,0.7876309752464294,0.8031494617462158,0.78835529088974,0.7986137270927429,0.7879929542541504,0.8008751273155212,INCORRECT,INCORRECT,0.994487464427948,0.9994377493858336
2,"This paper presents non-trivial and novel theoretical and computational modeling that accounts for experimentally observed phenomena: the theta phase procession and precession. These phenomena are implicated in the neural representation and learning of neuronal networks involving hippocampus. Although the current manuscript does not address the learning and the presentations are limited to a linear track environment, it represents a clear advance in linking spatial and temporal information representations by extending the standard continuous attractor models that do not exhibit phase procession/precession. Furthermore, the model elegantly explains the biologically observed unimodal and bimodal cells. The authors are encouraged to improve the clarity of some parts of the writing.


","The proposed model is based on a network of recurrent connections with a Gaussian profile. The model is intended to be used in a variety of ways, not just as an example of how to use a neural network. It is not clear if the model can be applied to other areas of the brain, such as the development of new neurons, or if it can be generalized to other parts of the body. The main challenge is that the model does not provide a way of predicting how the brain will react to a change in the environment. It would be helpful to have a better idea of what is going on in the brain when a change is made, rather than relying on the model to predict it. The best way to understand the model is to look at the way the brain responds to changes in its environment, and to try and predict them.",0.1654135338345864,0.7611321210861206,0.7586920261383057,0.7599101066589355,CORRECT,0.9966914653778076,"The authors of the current submission set out to provide a biologically inspired ""neural field"" (herein a PDE model) model of the experimental data reported in Wang et al. (2020) The proposed model, unlike those previously proposed, accounts for ""phase procession"" (cf. phase precession) and ""oscillatory tracking"" The submission is devoted to deriving a particular model of place cell function without relying on statistical or machine learning methods, nor without any immediate implications for those communities. It might be an equally good if not better fit in specialized journals like PlOS CB, Neural Computation, eLife etc. The paper appears to exhibit overall high quality and clarity (though there are a few places where writing can be cleaned up and polished)","The authors of the current submission set out to provide a biologically inspired ""neural field"" (herein a PDE model) model of the experimental data reported in Wang et al. (2020) The proposed model, unlike those previously proposed, accounts for ""phase procession"" (cf. phase precession) and ""oscillatory tracking"" The submission is devoted to deriving a particular model of place cell function (ie. without relying on statistical or machine learning methods, nor without any immediate implications for those communities) It might be an equally good if not better fit in specialized journals like PlOS CB, Neural Computation, eLife etc. Regardless, it would be helpful to generalize their framework or experimental records to 2D or learning scenarios.",0.1572052401746725,0.1434977578475336,0.7745260000228882,0.7714455127716064,0.804571807384491,0.800215482711792,0.789263129234314,0.7855671644210815,INCORRECT,INCORRECT,0.9868294596672058,0.9685518145561218
3,"The proposed method introduces a method for unsupervised image-to-image mapping, using a new term into the objective function that enforces consistency in similarity between image patches across domains. Reviewers left constructive and detailed comments, which, the authors have made substantial efforts to address.

Reviewers have ranked paper as borderline, and in Area Chair's opinion, most major issued have been addressed:

- R3&R2: Novelty compared to DistanceGAN/CRF limited: authors have clarified contributions in reference to DistanceGAN/CRF and demonstrated improved performance relative to several datasets.
- R3&R1: Evaluation on additional datasets required: authors added evaluation on 4 more tasks
- R3&R1: Details missing: authors added details. 



","The paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation. The regularization is similar to imposing a CRF (Conditional Random Field) term on the network outputs. This enables the translation network to preserve edge discontinuities and variation in the output. This leads to better outputs for medical imaging, image to labels task, and horse to zebra and vice versa. The paper is lacking in technical details: what is the patch-size used for RGB-histogram? What features or conv-layers are used to get the features from VGGNet? It is not clear why RGB-Histogram would work? The current formulation can be thought as a variant of perceptual loss from Johnson et al. ECCV'16.",0.1545064377682403,0.7617600560188293,0.7620205879211426,0.7618902921676636,INCORRECT,0.9835420846939088,"The paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation. The technical novelty is very limited in my opinion. The qualitative results on the task, Horse2Zebra and Zebra2Horse, are not impressive. The current formulation can be thought as a variant of perceptual loss from Johnson et al. ECCV'16 (applied for the patches, or including pair of patches). In my opinion, implementing via perceptual loss formulation would have made the formulation cleaner and simpler. The paper is lacking in technical details: what is the patch-size used for RGB-histogram? What features or conv-layers are used to get the features from VGGNet? It is not clear why RGB-Histogram would work?","This paper proposes a method called HarmonicGAN for unpaired image-to-image translation. The key idea is to introduce a regularization term on the basis of CycleGAN, which encourages similar image patches to acquire similar transformations. The technical novelty is very limited in my opinion. The qualitative results on the task, Horse2Zebra and Zebra2Horse, are not impressive. Obvious artifacts can be observed in the results. I am not able to judge whether the comparisons are fair enough. If there is extra quota, I would recommend Accept. The paper is lacking in technical details: what is the patch-size used for RGB-histogram? What features or conv-layers are used to get the features from VGGNet? It is not clear why RGB-Histogram would work?",0.1391304347826087,0.1545064377682403,0.7555367946624756,0.7740343809127808,0.764630138874054,0.7791054248809814,0.7600563168525696,0.7765616774559021,INCORRECT,CORRECT,0.8851209282875061,0.9483098983764648
4,"The authors provide a benchmark for federated learning. 

The commonly mentioned strengths:
- there is a big need in the community for this type of work
- easily accessible code
- various levels of complexity with different granularity

Regarding the weaknesses, I see no showstoppers
- some feedback about the experiments done on the datasets -> this point comes back consistently among all reviewers, in terms of the amount, settings and reproducibility.. The authors are adviced to address this in future work, to keep momentum for the use of the community on this dataset 
- there was some discussion about tensorflow and pytorch, but based on the discussion both seem supported
- some settings / image types could be better supported

None of these weaknesses seem serious, and quite frankly, we can not expect one dataset to cover all possible settings. Since the reviewers are in agreement about the quality of this work, I recommend them for an oral presentation. 

","The paper was published in the open-source software journal, Caffeine and NLP: A Practical Guide to NLP and Machine Learning. The dataset consists in 429k images from 51k individual Flickr users. The task consists in classification, with 2 levels of granularity for the classes: 17 coarse and ~1.6k fine classes. The results show the difficulty of the task, with centralizing training getting better results than FL, which is in turn better than DP-FL. This work is really needed, providing an open gamefield to the community. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users. Proposed benchmark is only for vision tasks that do not include federated NLP tasks such as federated keyword prediction.",0.16,0.7874770164489746,0.7839187979698181,0.7856938242912292,INCORRECT,0.994379222393036,"The paper was published in the open-source software journal, Caffeine and NLP: A Practical Guide to NLP and Machine Learning. The code is lightweight and seems easily understandable. The results on DP-FL and the influence of cohort-size (for sampling) are interesting. The fine-grained classes are highly imbalanced and lead to pure classification results. The presented per-class statistics show the non-uniformity of the dataset. The proposed two levels of difﬀculty, the easier 17 coarse and the harder1,628, can meet more diverse FL settings compared to other federated datasets. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users.","The paper was published in the open-source software journal, Caffeine and NLP: A Practical Guide to NLP and Machine Learning. It was published by the Open Source Software Association (OSSA), which is a non-profit organization. Below are multiple summaries of different reviews on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users. Proposed benchmark is only for vision tasks that do not include federated NLP tasks such as federated keyword prediction. The results on DP-FL and the influence of cohort-size are interesting.",0.182509505703422,0.1623616236162361,0.7903921604156494,0.7744162082672119,0.7740175127983093,0.7651699781417847,0.78211909532547,0.7697653770446777,INCORRECT,INCORRECT,0.9903427362442015,0.9910043478012084
5,"This paper studies a timely problem and consider an interesting approach, but overall there were many concerns about technical details and the validity of the framework. The positive reviewer also mentioned concerns about the experiments, which others also found to be an insular comparison with weak baselines. Following the response period, in discussion there are additional concerns arising related to the lack of details, for instance related to possible unidentifiability of the model. As one reviewer discusses,  the authors are attempting to use RNNs to impute missing infection status labels when the missingness mechanism is assumed to be (i) not at random, (ii) playing out over time (as it is unclear whether Y^t is assumed (conditionally) independent of Y^t' with t' << t), and (iii) subject to interference (whether someone is tested is the 'treatment' here since it's a missingess problem and one person's propensity to be tested could causally affect another person's downstream infection status since apparently no Markov independence is assumed. There is also consensus that the writing quality can be greatly improved. Overall this work contains some ideas with potential in a thorough revision 

","The proposed approach formalizes an intuitive understanding of the spread of an infectious disease in (as far as I am aware) a novel way. Experimental results on a (private) real-world dataset are somewhat mixed, but show that MIINT achieves a better true positive rate at an acceptable false positive rate. It is not clear to me of the practical significance of the “isolation policy” results. Even using an oracle, Figure 1 seems to suggest that between 30-40% of the population would need to be tested to see a reduction in the infection rate. Neither the paper nor the supplement describe the features available in the real data. It seems a bit strange that the AUROC and AUPRC in Table 1 are almost perfectly negatively correlated. Is there any explanation for that?",0.1419753086419753,0.7661690711975098,0.7489691972732544,0.75747150182724,INCORRECT,0.9155428409576416,"The proposed approach formalizes an intuitive understanding of the spread of an infectious disease in (as far as I am aware) a novel way. Experimental results on a (private) real-world dataset are somewhat mixed, but show that MIINT achieves a better true positive rate at an acceptable false positive rate. It is not clear to me of the practical significance of the “isolation policy” results. Even using an oracle, Figure 1 seems to suggest that between 30-40% of the population would need to be tested to see a reduction in the infection rate. Neither the paper nor the supplement describe the features available in the real data. It seems a bit strange that the AUROC and AUPRC in Table 1 are almost perfectly negatively correlated. Is there any explanation for that?","The proposed approach formalizes an intuitive understanding of the spread of an infectious disease in (as far as I am aware) a novel way. Experimental results on a (private) real-world dataset are somewhat mixed, but show that MIINT achieves a better true positive rate at an acceptable false positive rate. It is not clear to me of the practical significance of the “isolation policy” results. Even using an oracle, Figure 1 seems to suggest that between 30-40% of the population would need to be tested to see a reduction in the infection rate. Neither the paper nor the supplement describe the features available in the real data. It seems a bit strange that the AUROC and AUPRC in Table 1 are almost perfectly negatively correlated. Is there any explanation for that?",0.1419753086419753,0.1419753086419753,0.7661690711975098,0.7661690711975098,0.7489691972732544,0.7489691972732544,0.75747150182724,0.75747150182724,INCORRECT,INCORRECT,0.9155428409576416,0.9155428409576416
6,"The paper addresses the problem of domain generalization for learning spatio-temporal dynamics. It proposes a solution where an encoder captures some characteristics of a given environment, and a forecaster autoregressively predicts future dynamics conditioned on the characteristics learned by the encoder. Said otherwise, the forecaster learns the general form of dynamics parameterized by an environment representation extracted by the encoder. The conditioning is implemented via an adaptive instance normalization mechanism. A form of padding is also introduced in order to take into account boundary conditions. The two components encoder and forecaster are trained sequentially. This approach is casted in a meta-learning framework. Theoretical results inspired by multi-task learning and domain adaptation are also demonstrated. The model is evaluated and compared to different baselines on three problems, and for two different settings: varying initial conditions with a given dynamics, and dynamics with varying parameters.

This is a borderline paper. It targets a timely and important problem of domain generalization for dynamic environments. The proposed solution is original and compares well experimentally to several baselines. It allows for better generalization performance for the two test settings considered. In the current version, the paper however suffers from different weaknesses. First there is the imprecision of the arguments and the description of the experiments. Some of the arguments and claims are vague and sometimes abusive, not backed up by evidence. For example, a central claim is that the encoder learns time invariant quantities characterizing the environment when the learned representations indeed change with a time shift in the input for any environment. The same goes for the argument developed for the padding construction. It is claimed to model boundary conditions, but this is not supported by any theoretical or empirical evidence.
As noted by the reviewers, the theoretical analysis is disconnected from the algorithmic and experimental developments and does not bring much additional value to the paper. What is more embarrassing is that some of the claims in this section are overstated and induce incorrect conclusions.  From Theorem 3.1 and proposition 3.3, the authors suggest that multitask learning leads to better generalization than learning independently, while this is not formally guaranteed by the results (this is acknowledged by the authors in a later comment). Besides, the conditions of validity are not discussed while they seem to only cover situations for which the train and the test distributions are the same. The same holds for the second theoretical results (theorem 3.4). It is claimed that this result supports the authors’ idea of training encoder and forecaster sequentially, while it does not. Besides, the bounds in this result cannot be controlled as noted by the reviewers and are not useful in practice.

Overall, the paper addresses an important topic and proposes new solutions. The results are promising and it is indeed an interesting contribution. However, inaccuracies and incorrect or exaggerated claims make it difficult to accept the current version of the article. The article would make a strong and innovative contribution if it were written as a purely experimental article with a detailed description of the experiments and comparisons.

","This work tackles the task of forecasting dynamics in different domains simultaneously. Using an encoder which is trained to determine the task, the inferred latent vector is then used to adapt a forecasting network to the task at hand. Experiments on three datasets linked to fluid dynamics are then conducted to assess the proposed model. This is a good work on a timely subject. The contribution is not groundbreaking but should be significant enough to warrant acceptance. It would be nice to see how the model deals with other families of dynamics. Especially given the fact that the contributions of this work seem geared towards practical considerations. The setting of the experiments should be more precise and additional details should be given: how are the different datasets constructed, how many domains are there in each dataset and what are the differences, how is the balance between the different domains ect.",0.1315396113602391,0.7919142246246338,0.7500964999198914,0.7704383134841919,CORRECT,0.9988892674446106,"Reviews of different papers on the same paper. Please summarize the paper reviews and decide on whether the paper is accepted or rejected. This is a good work on a timely subject. The contribution is not groundbreaking but should be significant enough to warrant acceptance. It would be nice to see how the model deals with other families of dynamics. Especially given the fact that the contributions of this work seem geared towards practical considerations. The setting of the experiments should be more precise and additional details should be given. The paper could be substantially improved by either (1) adding interpretation/predictions/validation of the theory that connect it back to the approach in the paper, or (2) removing some of the less useful parts of the Theory from the main paper.","Multiple reviews have been published on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The work tackles the task of forecasting dynamics in different domains simultaneously. Using an encoder which is trained to determine the task, the inferred latent vector is then used to adapt a forecasting network to the task at hand. This is a good work on a timely subject. The contribution is not groundbreaking but should be significant enough to warrant acceptance. The paper could be substantially improved by either (1) adding interpretation/predictions/validation of the theory that connect it back to the approach in the paper, or (2) removing some of the less useful parts of the Theory from the main paper.",0.1321044546850998,0.1437308868501529,0.7812483310699463,0.7866319417953491,0.7284637689590454,0.7442712187767029,0.753933310508728,0.764865517616272,CORRECT,CORRECT,0.9817713499069214,0.994948148727417
7,"After careful review, I believe that this paper is a useful contribution to the study of animal pose estimation and tracking. The paper received positive reviews from all the reviewers and the authors have successfully addressed the concerns regarding the lack of sufficient novelty and insufficient benchmarking. The authors also added additional low shot experiments to demonstrate the usefulness of the dataset. Based on this, I think the paper meets the bar for the track and should be accepted.

","APT-36K consists of 2,400 video clips collected and filtered from 30 animal species with 15 frames for each video, resulting in 36,000 frames in total. Three tasks are set up to evaluate several representative models. The results and analysis provide some insights which are useful for researchers in this field. The paper is well written and easy to follow. Experiments seem technically sound. My only concern is the novelty of this dataset on animal pose estimation. Since the proposed dataset contains one more animal pose tracking task, I prefer to put the rating at 'Marginally above acceptance threshold' AFAIK, the pose estimation in the animal kingdom dataset [26] consists of 33K frames, corresponding to 850 animal species, so the proposed datasets for pose estimation and tracking.",0.173076923076923,0.7734687328338623,0.8144815564155579,0.7934455871582031,INCORRECT,0.9997145533561708,"Reviews of the APT-36k dataset, consists of 2,400 video sequences, each on 16 frames of annotated video. The videos are balanced across 15 families of animals (30 species), allowing for estimation of cross-family generalization. The paper is well written and easy to follow. Experiments seem technically sound. My only concern is the novelty of this dataset on animal pose estimation. Since the proposed dataset contains one more animal pose tracking task, I prefer to put the rating at 'Marginally above acceptance threshold' AFAIK, the pose estimation in the animal kingdom dataset [26] consists of 33K frames, corresponding to 850 animal species, so the reviewer thinks theAnimal kingdom dataset is more challenging than the proposed datasets for pose estimation and tracking.","Reviews of the APT-36k dataset, consists of 2,400 video sequences, each on 16 frames of annotated video. The videos are balanced across 15 families of animals (30 species), allowing for estimation of cross-family generalization. The results and analysis provide some insights which are useful for researchers in this field. The paper is clear, the dataset and ethics are well documented, and the dataset is of good value to the community. I am voting not to accept the manuscript, but if this issue is reconciled I would consider accepting. M My main reservations are on the novelty of the dataset. It is unclear if the particular videos are licensed under the youtube standard license or a CC-BY license, which would affect whether or not they could be distributed.",0.1881188118811881,0.1809523809523809,0.7759013772010803,0.7671235799789429,0.8159704208374023,0.8101449012756348,0.7954316139221191,0.7880474925041199,INCORRECT,INCORRECT,0.9997290968894958,0.9956120252609252
8,"This paper proposes a latent point diffusion model, LION, for 3D shape generation. The model builds two denoising diffusion models in the latent spaces of a variational autoencoder. The latent spaces combine a global shape latent representation with a point-structured latent space.  Comprehensive experiments are conducted to evaluate the performance of the proposed method.  The authors address the major concerns of the reviewers and strengthen the paper by providing additional empirical results. After the rebuttal, all four reviewers reach an agreement on accepting the paper because of the novelty and the state-of-the-art performance. The AC agrees with the reviewers and recommends accepting the paper. 

","The paper proposes a hierarchical architecture for point cloud generation, which is composed of two diffusion models for shape latents and latent points. Exhaustive experiments demonstrate LION outperforms several state-of-the-art models on multiple ShapeNet benchmarks. The mapping from point- clouds to meshes is responsible for the best-looking results in the paper. The writing is clear and easy-to-read throughout; overall I found the paper enjoyable and informative to read. The technical contribution of the model itself is fairly small – DDMs on latent space have become fairly common. The paper seems to clearly improve state of the art shape generation (note this is not my area of expertise, so I have to trust the authors the metrics and datasets are meaningful)",0.2575107296137339,0.7939537763595581,0.8177897930145264,0.8056955337524414,INCORRECT,0.998964786529541,"The paper proposes a hierarchical architecture for point cloud generation, which is composed of two diffusion models for shape latents and latent points. Exhaustive experiments demonstrate LION outperforms several state-of-the-art models on multiple ShapeNet benchmarks. The writing is clear and easy-to-read throughout; overall I found the paper enjoyable and informative to read. The mapping from point- clouds to meshes is responsible for the best-looking results in the paper. There is very minimal discussion of limitations; this should be expanded. There are sufficient discussion of broader impact (which is negligible). The proposed pipeline is not particularly novel. It is more like a combination of PVCNN and the diffusion model. Combining with a surface reconstruction model like SAP enables the generation of smooth 3D meshes.","The paper proposes a hierarchical architecture for point cloud generation, which is composed of two diffusion models for shape latents and latent points. Exhaustive experiments demonstrate LION outperforms several state-of-the-art models on multiple ShapeNet benchmarks. The writing is clear and easy-to-read throughout; overall I found the paper enjoyable and informative to read. The mapping from point- clouds to meshes is responsible for the best-looking results in the paper. There is very minimal discussion of limitations; this should be expanded. There are sufficient discussion of broader impact (which is negligible). The paper seems to clearly improve state of the art shape generation (note this is not my area of expertise, so I have to trust the authors the metrics and datasets are meaningful) The evaluation seems exhaustive and the exposition of the method is clear.",0.2194092827004219,0.2419354838709677,0.7980148792266846,0.7881636023521423,0.8206216096878052,0.8206567764282227,0.8091603517532349,0.8040820360183716,INCORRECT,INCORRECT,0.9240541458129884,0.9739434719085692
9,"The paper introduces a new method to probe contextualized word embeddings for syntax and sentiment properties using hyperbolic geometry. The paper is written well and relevant to the ICLR community. Reviewers highlight that the proposed Poincaré probe offers solid results, extensive experiments that support the benefits of the approach, and proposes a new approach to analyze the geometry of BERT models. The revised version clarified various concerns of the initial reviews and improved the manuscript (comparison to Euclidean probes, low dimensional examples, new results on edge length distributions etc.). Overall, the paper makes valuable contributions to probing contextualized word embeddings and the majority of reviewers and the AC support acceptance for its contributions. Please revise your paper to take feedback from reviewers after rebuttal into account (especially to further improve clarity and discussion of the method).

","The paper is published in the Proceedings of the National Academy of Sciences of the United States of America. The authors present an extremely lightly parametrized “probe” model to determine the presence of syntactic structure in the embedding space of BERT models. They find that this distance measure, for an equivalent or lesser number of parameters, better reproduces the syntactic properties. This suggests that the BERT model may operate simply, but on a non-Euclidean manifold, in order to work with syntactic information. The name of the parsing dataset is not even mentioned, nor are the meanings of the Spearman correlation metrics (the abbreviations are not self-explanatory). There are also some open questions: for parsing, do you train a single model with both objectives?",0.1762452107279693,0.756090521812439,0.7697658538818359,0.7628669142723083,INCORRECT,0.9885502457618712,"The paper is published in the Proceedings of the National Academy of Sciences of the United States of America. It proposes probes based on hyperbolic embedding spaces, and compares them to the behaviour of Euclidean probes from recent work. The main result is that these probes allow for better recovery of syntactic properties of sentences from contextualized word embeddings compared to context-independent ones. Similar results are presented  on sentiment analysis, even though no results arePresented for context- independent wordembeddings. If thePaper is accepted, I think such an experiment would be very informative. If it is not, I was thinking is it possible to construct embedding that have known syntactic vs semantic properties. E.g. one could increase/decrease the context size, perhaps to extreme values in the case of models such as GLoVe.","This paper proposes probing BERT representations by projecting them into a Poincare subspace. The hyperbolic version of the probes consistently out-perform the Euclidean one. This suggests that the BERT model may operate simply, but on a non-Euclidean manifold, in order to work with syntactic information. The name of the parsing dataset is not even mentioned, nor are the meanings of the Spearman correlation metrics (the abbreviations are not self-explanatory). The authors provide some useful visualizations of the learned projections of the word embeddings. The paper is published in the Proceedings of the National Academy of Sciences of the United States of America. The main result is that these probes allow for better recovery of syntactic properties of sentences from contextualized word embeds compared to context-independent ones.",0.1555555555555555,0.1804511278195488,0.781927227973938,0.783517062664032,0.7867535352706909,0.7914935350418091,0.7843329310417175,0.7874851822853088,INCORRECT,INCORRECT,0.9988719820976256,0.9757128357887268
10,"This paper proposes a few-shot (untargeted) backdoor attack (FSBA) against siamese network-based visual object tracking. Contributions can be summarized as follows: First, this paper treats the attack task as an instance of multi-task learning and can be regarded as the first backdoor attack against VOT. Besides, a simple yet effective few-shot untargeted backdoor attack is proposed and achieves significant effectiveness in both digital and physical-world scenarios. This paper reveals the vulnerability of VOT to backdoor attacks caused by outsourced training or using third-party pre-trained models. One weakness is that threat model requires a very strong attacker with ability to modify the training algorithm, but only very simple defenses are considered. Overall, this is a good first attempt at showing vulnerability of VOT approaches.

","The paper introduces a variant of backdoor attacks against visual object tracking (VOT) networks. The core idea of the backdoor attach is to maximize the feature distance between poisoned frames. The proposed method is claimed to be able to operate in few-shot or one-shot mode. The paper is well organized and easy to follow. Although there are still some shortcomings in experimental analysis, this article is a good attempt on the security of the VOT and worthy of follow-up work. It is hard to tell why the main proposed defense outperforms the baseline attacks and I hope that this will be addressed. The experimental result is mainly a numerical analysis without further investigation. The rebuttal has addressed most of my concerns. Therefore, I would like to upgrade my initial recommendation.",0.2053231939163498,0.7966657876968384,0.8038292527198792,0.8002314567565918,INCORRECT,0.5999231338500977,"The paper introduces a variant of backdoor attacks against visual object tracking (VOT) networks. The proposed method is claimed to be able to operate in few- shot or one-shot mode. The paper is well organized and easy to follow. The experimental result is mainly a numerical analysis without further investigation. It is hard to tell why the main proposed defense outperforms the baseline attacks. The rebuttal has addressed most of my concerns. I would like to upgrade my initial recommendation. Although there are still some shortcomings in experimental analysis, this article is a good attempt on the security of the VOT and worthy of follow-up work. It's a good article. It’s an interesting new application of backdoor attack with good empirical results. It seems to be trivial with limiited contribution and insight.","The paper introduces a variant of backdoor attacks against visual object tracking (VOT) networks. The core idea of the backdoor attach is to maximize the feature distance between poisoned frames, which seems to be trivial. The proposed method is claimed to be able to operate in few-shot or one-shot mode. The paper is well organized and easy to follow. The experimental result is mainly a numerical analysis without further investigation. The rebuttal has addressed most of my concerns. I would like to upgrade my initial recommendation. Although there are still some shortcomings in experimental analysis, this article is a good attempt on the security of the VOT and worthy of follow-up work. It is hard to tell why the main proposed defense outperforms the baseline attacks and I hope that this will be addressed. This is an interesting new application of backdoor attack with good empirical results.",0.1954887218045113,0.1928571428571428,0.797174870967865,0.8007545471191406,0.8038862943649292,0.8077833652496338,0.8005165457725525,0.8042536377906799,INCORRECT,CORRECT,0.8015809059143066,0.8120388388633728
11,"This is a borderline paper. The scores were initially below the bar. The novelty of the work is limited and there are strong claims in the paper that should be revised. The authors can also do a better job in positioning their work with respect to the existing results. However, the authors managed to address several questions/concerns of the reviewers and convince them to raise their scores. I would strongly recommend the authors to address the rest of the reviewers' comments, especially those related to strong claims and connection to related work, and further improve their work in preparing its final draft.

","The paper proposes an exploration method for ""preference based Reinforcement Learning"" methods. The authors use an ensemle of learned reward models and add an intrinsic reward based on disagreement (or uncertainity) The idea of efficient exploration is very important for reinforcement learning, especially for cases where human feedback is used. The paper is well written and clear to understand. The evaluation is ok, but more domains should be added for allowing to derive more general conclusions. The proposed method is of interest within the domain of preference-based reinforcement learning. The novelty of the approach is limited and the claims have been shown before, but in a different framework. However, even if these issues are resolved, the degree of novelty will likely stay limited. Some suggestions: Effect of different beta values. Optimal/terminal policy in terms of preference queries.",0.165289256198347,0.7608308792114258,0.7897030115127563,0.774998128414154,CORRECT,0.9804537296295166,"The paper proposes an exploration method for ""preference based Reinforcement Learning"" methods. The authors use an ensemle of learned reward models and add an intrinsic reward based on disagreement (or uncertainity) The idea of efficient exploration is very important for reinforcement learning, especially for cases where human feedback is used. The paper is well written and clear to understand. The method can be considered sound, as it is based on established building-blocks. The evaluation is ok, but more domains should be added for allowing to derive more general conclusions. The analysis on the quality of learned rewards can be improved. Normalizing the rewards to a standard range, e.g., [0,1], can aid comparisons in Fig 5. Optimal/terminal policy in terms of preference queries.","The paper proposes an exploration method for ""preference based Reinforcement Learning"" methods. The authors use an ensemle of learned reward models and add an intrinsic reward based on disagreement (or uncertainity) The authors test the idea on robotic manipulation tasks from meta-world. It is unclear if the better performance is due to extra exploration or simply the use of a better reward estimator, i.e. the ensemble. The evaluation is ok, but more domains should be added for allowing to derive more general conclusions. The proposed method is of interest within the domain of preference-based reinforcement learning. The novelty of the approach is limited and the claims have been shown before, but in a different framework. However, even if these issues are resolved, the degree of novelty will likely stay limited.",0.148471615720524,0.1610169491525424,0.7528716325759888,0.7606105208396912,0.7819937467575073,0.7865427136421204,0.7671563625335693,0.7733592987060547,CORRECT,CORRECT,0.9028987884521484,0.9796277284622192
12,"Pros:
- Provides a practical technique which can dramatically speed up PDE solving -- this is an important and widely applicable contribution.
- Paper is simultaneously clearly written and mathematically sophisticated.
- The experimental results as impressive.

Cons:
- There were concerns that the paper lacks novelty compared to Li et al 2020b, where the underlying theoretical framework was developed. The primary novelty would seem to be:
- - using Fourier transforms as the specific neural operator
- - the strength of the experimental results

Overall, I recommend acceptance. I believe the techniques in this paper will be practically useful for future research.

","The authors proposed a novel neural Fourier operator that generalizes between different function discretization schemes. The method achieves superior performance in terms of speed and accuracy compared to learned baselines. It is also significantly faster than traditional PDE solvers. I’m assigning a score of 8 (a very good conference paper), and I think that the paper is more or less ready for publication as is. The paper itself is not self-contained. I hope that the authors are able to address my concerns. I believe that this work should be published. It’s definitely a big step-forward in neural operators. The subsequent experimentation was extremely thorough and, of course, the results were very impressive. I liked the paper a lot.",0.1851851851851851,0.7989537119865417,0.7847466468811035,0.7917864322662354,INCORRECT,0.9922826886177064,"The paper is well written, although some important details remain unclear/lacking. The distinction between training data and test data is not clearly specified. Generalization to different useful initial conditions is obviously of utmost importance. The motivation for replacing the kernel function (3) by a convolution operator is not entirely clear. The paper itself is not self-contained. I hope that the authors are able to address my concerns. I believe that this work should be published. I’m assigning a score of 8 (a very good conference paper), and I think that the paper is more or less ready for publication as is. I liked the paper a lot, and it’s definitely a big step-forward in neural operators. The subsequent experimentation was extremely thorough and, of course, the results were very impressive.","The paper is well written, although some important details remain unclear/lacking. The distinction between training data and test data is not clearly specified. The motivation for replacing the kernel function (3) by a convolution operator is not entirely clear. The paper itself is not self-contained. I hope that the authors are able to address my concerns. I believe that this work should be published. I’m assigning a score of 8 (a very good conference paper), and I think that the paper is more or less ready for publication as is. I liked the paper a lot, and it’s definitely a big step-forward in neural operators. The subsequent experimentation was extremely thorough and, of course, the results were very impressive. It is also significantly faster than traditional PDE solvers.",0.1572052401746724,0.158590308370044,0.7881821393966675,0.7871487140655518,0.7738192677497864,0.7752127051353455,0.7809346914291382,0.781135082244873,INCORRECT,INCORRECT,0.9361210465431212,0.9113935232162476
13,"This paper improves contrastive learning of sentence embedding by using unpaired examples from the image or audio modality.

Reviewers liked the significance of this work due to its simplicity and general applicability, but some questioned the amount of improvement and advocated for the inclusion of low resource languages. The authors included Chinese, which is non-European but not low resource.

","The method is simple and generalizable, i.e. not only applied to vision but also to other modalities such as audio. I’m not confident that the improvement is significant. On STS tasks, on average it improves 1% accuracy. It seems the paper is missing a comparison with MCSE [1], which is a very relevant work that augments the SimCSE with multimodal contrastive objective. It is unclear, except for the objective and hyperparameters, how other factors like pre-trained image/ audio encoder, augmentation methods, dataset, and image/audio quality could affect the final performance. The model performance improvement is relatively small. Compared to other CL sentence representationlearning work, e.g., DiffCSE, DebiasedCSE and PromptBERT, the proposed method performance with more data is not that significant.",0.1297297297297297,0.7361121773719788,0.7761998176574707,0.7556247115135193,INCORRECT,0.9421043395996094,"This paper presents a novel method to conduct multimodal contrastive learning for sentence encoders. The method is simple and generalizable, i.e. not only applied to vision but also to other modalities such as audio. The model setup is a bit unintuitive. It assumes that we can replace the embedding layer of a sentence encoder with a visual embeddinglayer to get an image encoder. On STS tasks, on average it improves 1% accuracy. In comparison, the original SimCSE paper improves more than 4% accuracy and is able to push the state-of-the-art in a supervised setting. The paper is clearly written and I could follow the motivation, experimental setup and results without really needing additional background searches.","Multiple reviews have been published on the same paper. Here are the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The method is simple and generalizable, i.e. not only applied to vision but also to other modalities such as audio. I’m not confident that the improvement is significant. On STS tasks, on average it improves 1% accuracy. In comparison, the original SimCSE paper improves more than 4% accuracy and is able to push the state-of-the-art in a supervised setting. The model setup is a bit unintuitive. It assumes that we can replace the embedding layer of a sentence encoder with a visual embeddinglayer to get an image encoder.",0.1787709497206703,0.1505376344086021,0.7589401006698608,0.746536135673523,0.7808388471603394,0.7827193737030029,0.7697337865829468,0.7641996741294861,INCORRECT,CORRECT,0.9938981533050536,0.9990854263305664
14,"The authors present a matrix factorization for the social behavior of honey bees in a hive. All the reviewers appreciated the interesting application.  However, substantial concerns were raised about the model motivation and the interpretation of the learned factors. To quote one reviewer, ""Some of these bells and whistles may not even be needed, so simplifying the model and streamlining the text would go a long way for me."" Another said, ""The paper requires more principled motivation for the choices the authors made as well as cleaning up the notation.""  The authors did address some of these concerns in discussion, but there are too many lingering concerns to recommend acceptance.  Given the unique application of this paper, the authors might also consider a journal that specializes in computational biology instead. 


","The authors present a matrix factorization model to jointly characterize the lifetime interactions of thousands of bees over generations. I think the core idea is interesting, but I have mixed feelings about the method and some of the analyses. The evaluation metrics are a bit strange. The model performs worse than the baselines on reconstruction, though this does not seem to be the primary goal of the paper. The core idea (individual-specific time courses) seems to get buried and lost with other modeling innovations like adversarial training and new terms like ""individuality basis functions"" Some of these bells and whistles may not even be needed, so simplifying the model and streamlining the text would go a long way for me. My suggestion would be to focus on qualitative / visual comparisons across the different models.",0.3471698113207547,0.8236238956451416,0.8297197222709656,0.8266605138778687,INCORRECT,0.9866509437561036,Reviews of the paper can be submitted to ICLR. Please summarize the paper reviews and decide on whether the paper is accepted or rejected. The paper proposes a NMF formulation where A and F are different types of information extracted from social datasets. The variance of AMI score is high even when the SNR = inf. Do the authors consider the model results robust given this high variance in the synthetic dataset? Is there a mismatch in the type of data of Y in the Synthetic and in the true datasets? Is Y the spatial distance like in the honey bee dataset? The authors introduce a novel method for non-negative matrix factorization for timeseries and apply it to longitudinal honey bee interaction data. The authors claim that this interpretable representation of individual bees is valuable for understanding social dynamics in the colony.,"The authors introduce a novel method for non-negative matrix factorization for timeseries and apply it to longitudinal honey bee interaction data. The core idea (individual-specific time courses) seems to get buried and lost with other modeling innovations like adversarial training and new terms like ""individuality basis functions"" Some of these bells and whistles may not even be needed, so simplifying the model and streamlining the text would go a long way for me. My suggestion would be to focus on qualitative / visual comparisons across the different models. The evaluation metrics are a bit strange. The model performs worse than the baselines on reconstruction, though this does not seem to be the primary goal of the paper. It is not clear whether their method would be useful/interesting for other areas of research.",0.1764705882352941,0.3257575757575757,0.7746766805648804,0.8156386017799377,0.7669532299041748,0.8271048069000244,0.7707955837249756,0.8213317394256592,CORRECT,INCORRECT,0.9906918406486512,0.9997040629386902
15,"The paper proposes a semi-supervised segmentation technique which uses consistency regularization via different morphological feature perturbations to increase performance with unlabelled data.  It consists of an encoder and two-head decoders. One decoder learns positive attention to the foreground regions generating dilated features using atrous convolutions. The other decoder learns negative attention to the foreground on the same image thereby generating eroded features using skip connections. A consistency regularization is then applied on these paired predictions of an unlabeled image to improve performance. The method is evaluated on two different datasets, and the authors compared the proposed method with other methods from the literature, and reported superior results. 

During the rebuttal phase the authors made significant efforts to revise their manuscript especially to improve clarity of their presentation and after rebuttal, all reviewers agreed for weak acceptance. I also agree with this decision and support publication of this paper.

","The method shows consistently good results in comparison to other approaches. The paper is long (16 pages), many figures are small and have poor quality. There seems to be confusion about what the dilation and erosion morphological operators actually do. I would suggest inserting figures in vector space rather than image space, so that it is possible to zoom and have better quality. Some Figures, like Fig.3, are very hard to appreciate and look worse than they should. I feel more explanations and better figures could give a huge boost to the paper. I see no reasons to reject the paper at this stage. It is based on convolutions and skip-connections, which seems to work well in the experiments. The method is well written, but I feel the presentation could be improved.",0.1267605633802817,0.7807567119598389,0.7650556564331055,0.7728264331817627,CORRECT,0.5407930612564087,"The paper addresses the highly relevant and important topic of learning segmentation models with limited data. The method shows consistently good results in comparison to supervised and other semi-supervised approaches. The paper is long (16 pages), many figures are small and have poor quality, it is especially hard to discern some of the plots if you are colour blind. There seems to be confusion about what the dilation and erosion morphological operators actually do. Overall, I feel more explanations and better figures could give a huge boost to the paper, but I feel the material is there, but the presentation could be improved. It is based on Atrous convolutions and skip-connections, which seems to work well in the authors' experiments. If authors solve them, I see no reasons to reject the paper at this stage.","The paper addresses the highly relevant and important topic of learning segmentation models with limited data. The method shows consistently good results in comparison to supervised and other semi-supervised approaches. The paper is long (16 pages), many figures are small and have poor quality, it is especially hard to discern some of the plots if you are colour blind. There seems to be confusion about what the dilation and erosion morphological operators actually do. Overall, I feel more explanations and better figures could give a huge boost to the paper, but I feel the material is there, but the presentation could be improved. If authors solve them, I see no reasons to reject the paper at this stage. I would suggest inserting figures in vector space rather than image space, so that it is possible to zoom and have better quality.",0.1533101045296167,0.136986301369863,0.7976857423782349,0.7831317186355591,0.7807493209838867,0.7672197222709656,0.7891266942024231,0.7750940322875977,CORRECT,CORRECT,0.9872671961784364,0.9786388874053956
16,"The paper addresses generalized zero shot learning (test data contains examples from both seen as well as unseen classes) and proposes to learn a shared representation of images and attributes via multimodal variational autoencoders. 
The reviewers and AC note the following potential weaknesses: (1) low technical contribution, i.e. the proposed multimodal VAE model is very similar to Vedantam et al (2017) as noted by R2, and to JMVAE model by Suzuki et al, 2016, as noted by R1. The authors clarified in their response that indeed VAE in Vedantam et al (2017) is similar, but it has been used for image synthesis and not classification/GZSL. (2) Empirical evaluations and setup are not convincing (R2) and not clear -- R3 has provided a very detailed review and a follow up discussion raising several important concerns such as (i) absence of a validation set to test generalization, (ii) the hyperparameters set up; (iii) not clear advantages of learning a joint model as opposed to unidirectional mappings (R1 also supports this claim). The authors partially addressed some of these concerns in their response, however more in-depth analysis and major revision is required to assess the benefits and feasibility of the proposed approach.


","The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes) The theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero- shot learning approaches but with VAEs. The contributions of the paper are mostly experimental. Most arguments in the model section are actually simply intuitions. After reading the different reviews, the replies of the authors and the updated version, my opinion that the ""explanations"" are simply intuition.",0.1739130434782608,0.8141903877258301,0.7483385801315308,0.7798768281936646,INCORRECT,0.999126136302948,"The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes) The theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero- shot learning approaches but with VAEs. The contributions of the paper are mostly experimental. Most arguments in the model section are actually simply intuitions. After reading the different reviews, the replies of the authors and the updated version, my opinion that the ""explanations"" are simply intuition.","The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes) The theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero- shot learning approaches but with VAEs. The contributions of the paper are mostly experimental. Most arguments in the model section are actually simply intuitions. After reading the different reviews, the replies of the authors and the updated version, my opinion that the ""explanations"" are simply intuition.",0.1739130434782608,0.1739130434782608,0.8141903877258301,0.8141903877258301,0.7483385801315308,0.7483385801315308,0.7798768281936646,0.7798768281936646,INCORRECT,INCORRECT,0.999126136302948,0.999126136302948
17,"This paper proposed a new algorithm to reconstruct a subset of training examples from a trained homogeneous binary classification neural network. Although there are still some limitations such as the zero training loss and homogeneity assumption, as well as limited experiments beyond MLPs, the reviewers also acknowledge that this results is very interesting and reveals an important property of deep neural networks that could potentially have far-reaching implications for privacy and security.

","The technique hinges on the fact that at the training data points, a linear combination of the derivatives of the network parameters can predict the parameters themselves. The approach produces convincing results in some of the standard computer vision datasets like MNIST and CIFAR10. This work cannot be extended to CNNs with skip connections  easily due to the homogeneity assumption. It is not clear, whether the approach would work on deep networks, i.e., is the optimization only good for fine-tuning already good prototypes? Would it fail (completely) if they did not exist? Where failure could be that only a very small fraction (I am talking 1/10^6 or so) of reconstructed images are actual training data. If they used just one sample per class, it would be quite likely that it resembles a class-average.",0.1232227488151658,0.7533693313598633,0.7928680181503296,0.7726141810417175,INCORRECT,0.8162712454795837,"This paper proposes a new method for reconstructing parts of the training data from a given trained homogeneous binary classification network. It relies on a theoretical result by Lyu and Li as well as Ji and Telgarsky. The resulting approach is tested in various contexts for a 2d toy example, a binary MNIST image classification, and a binary CIFAR-10 classification. It is not clear, whether the approach would work on deep networks, i.e., is the optimization only good for fine-tuning already good prototypes? Would it fail (completely) if they did not exist? Where failure could be that only a very small fraction (I am talking 1/10^6 or so) of reconstructed images are actual training data.","This paper proposes a new method for reconstructing parts of the training data from a given trained homogeneous binary classification network. It relies on a theoretical result by Lyu and Li as well as Ji and Telgarsky. The resulting approach is tested in various contexts for a 2d toy example, a binary MNIST image classification, and a binary CIFAR-10 classification. It is not clear, whether the approach would work on deep networks, i.e., is the optimization only good for fine-tuning already good prototypes? Would it fail (completely) if they did not exist? Where failure could be that only a very small fraction (I am talking 1/10^6 or so) of reconstructed images are actual training data.",0.238341968911917,0.238341968911917,0.7681652307510376,0.7681652307510376,0.8152021169662476,0.8152021169662476,0.7909849882125854,0.7909849882125854,INCORRECT,INCORRECT,0.9828359484672546,0.9828359484672546
18,"The paper presents a construction for deep learning on point clouds that evolve over time. The key characteristics of the data are irregular sampling in the spatial domain and regular sampling in the temporal domain. The presented construction addresses both these aspects of the data. The review by R3 was negative but was addressed by the authors and R3 did not participate in the discussion. The AC supports acceptance.

","The paper introduces point spatio-temporal convolutions, which are used for the feature extraction of point cloud sequences. A trainable kernel is used which is applied locally as a continuous convolution. The method seems to be very versatile, as it was shown in the results. The experiments are exhaustive and impressive. The novelty of this paper is still limited. There is no significant difference with MeteorNet or even PointNet++. The computation cost including stacked convolution layers, the FPS sampling, and the nearest neighbor search are all heavy. No matter the point tube or the anchor points extracted in the spatial and temporal domain, the main idea is finding a good neighbor. It is written understandably and the evaluations are sufficient, IMO, to confirm the claims given by the authors.",0.202020202020202,0.7544353604316711,0.8056822419166565,0.7792171239852905,INCORRECT,0.9973012804985046,"Proposed point spatio-temporal (PST) convolution operates on ""point tubes"" It decouples space and time through a shared spatial convolution at each timestep, followed by a temporal convolution. It also introduces a transposed PST to enable point-wise predictions in an encoder-decoder framework. The paper is, for the most part, well-written and nicely presented (e.g. Fig 2). The experiments are exhaustive and impressive. Even through the experiments results look pretty good. There is no significant difference with MeteorNet or even PointNet++. The computation cost including stacked convolution layers, the FPS sampling, and the nearest neighbor search are all heavy. No matter the point tube or the anchor points extracted in the spatial and temporal domain, the main idea is finding a good neighbor.","This paper aims to process the point cloud data in a convolution manner. The method seems to be very versatile, as it was shown in the results. The experiments are exhaustive and impressive. The novelty of this paper is still limited. There is no significant difference with MeteorNet or even PointNet++. The computation cost including stacked convolution layers, the FPS sampling, and the nearest neighbor search are all heavy. No matter the point tube or the anchor points extracted in the spatial and temporal domain, the main idea is finding a good neighbor. It is written understandably and the evaluations are sufficient, IMO, to confirm the claims given by the authors. The authors claim that in this way the network will achieve a better understanding of the dynamics of the input. Theoretically, this problem could be solved much easier without striding and transposed convolutions.",0.1538461538461538,0.1971830985915492,0.7318463325500488,0.7555612921714783,0.799964189529419,0.808133602142334,0.764390766620636,0.780963659286499,INCORRECT,INCORRECT,0.9944700002670288,0.9896005392074584
19,"The paper develops a theoretical framework (in the context of learning theory) for training overparameterized networks with label noise, and shows that, in the context of ensemble distillation, teacher networks need not be good classifiers as long as they are good conditional samplers (in the sense defined in the paper).

This is a primarily theoretical paper, with limited empirical results. All reviewers are positive about the paper: one reviewer recommends acceptance (7), the other three recommend weak acceptance (6). The reviewers are positive about the theoretical aspects of the paper, describing them as interesting and technically sound, but are less convinced about the practicality of the theory or the significance of the empirical results.

Given that the theoretical contribution of the paper seems significant and no concerns have been raised about the soundness of the theoretical arguments, I'm happy to recommend acceptance.

","This paper builds upon the observation by Nakkiran and Bansal, 2020 and proposes a theoretical framework to study conditional samplers. The authors formally define concepts of conditional sampling from a learning perspective. They also propose an algorithm for distillation using labels generated by a random teacher from a fixed pool of sampler. Finally, they show some results for classical classification algorithms. The research question of understanding data inefficient teachers is well motivated and is very meaningful. The theoretical results are concise and sound. The empirical results support the theoretical findings, but labeling a large data set significantly increases the training time. It was a solid theoretical paper that addresses an important problem. I didn't find a discussion of limitations, but I did find the paper interesting and interesting to read in its own right.",0.2014388489208633,0.8116394281387329,0.7891929745674133,0.8002588152885437,INCORRECT,0.7795447707176208,"The paper builds upon the observation by Nakkiran and Bansal, 2020 and proposes a theoretical framework to study conditional samplers. The empirical side of the work is relatively weak, as the practical implementation of the proposed method is costly, and the empirical study in the paper is limited. The research question of understanding data inefficient teachers is well motivated and is very meaningful. The theoretical results are concise and sound. It was a solid theoretical paper that addresses an important problem. I didn't find a discussion of limitations, but I did find the paper interesting and interesting to read in its own right. The paper also shows that some well known algorithms are teachers under some conditions over the underlying distribution of the data. In practice, distillation is done by training a much larger teacher model to train a small student model.","The paper builds upon the observation by Nakkiran and Bansal, 2020 and proposes a theoretical framework to study conditional samplers. The authors formally define concepts of conditional sampling from a learning perspective. They also propose an algorithm for distillation using labels generated by a random teacher from a fixed pool of sampler. Finally, they show some results for classical classification algorithms.Below are multiple summaries of different reviews on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. See the above for more details on the paper. The research question of understanding data inefficient teachers is well motivated and is very meaningful. The paper also shows that some well known algorithms are teachers under some conditions.",0.2097902097902098,0.2101449275362319,0.8107541799545288,0.7991079688072205,0.7939220666885376,0.786192774772644,0.8022498488426208,0.7925978302955627,INCORRECT,CORRECT,0.922174036502838,0.9103012681007384
20,"Three experts reviewed this paper and all recommended rejection. The rebuttal did not change the reviewers' recommendations. The reviewers was not excited by the proposed probabilistic framework and raised many concerns regarding the comparison with baselines and competing methods, limited size of datasets, and limited scope of one dataset for one task. Considering the reviewers' concerns, we regret that the paper cannot be recommended for acceptance at this time.  The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere.

","This is a look at some of the events that took place over the course of the past week. This is not a complete list of all the events, but a list of the main ones. This includes the events of the week, as well as the events in the past few months. These videos will go on for the next few days, until the next set of videos will be shown. These will include the events from the first week of school and the second week of the summer vacation. The events of this week include: the first day of school, the last day of summer vacation, and the beginning of the new year. The end-to-end nature of this framework makes it more efficient than previous works. The results suggest that the proposed approach outperforms these compared methods. The claims in the paper are largely unsubstantiated due to the lack of comparison to baselines.",0.1487603305785124,0.7232604026794434,0.7656850814819336,0.7438682913780212,INCORRECT,0.9858763813972472,"This is a look at some of the events that took place over the course of the past week. This is not a complete list of all the events, but a list of the main ones. This includes the events of the week, as well as the events in the past few months. This will be the first of a series of videos that will show how these events took place. These videos will go on for the next few days, until the next set of videos will be shown. These will include the events from the first week of school and the second week of the summer vacation. These are just a few of the many events that happened over the last few weeks. The events of this week include: the first day of school, the last day of summer vacation, and the beginning of the new year.","This is a look at some of the events that took place over the course of the past week. This is not a complete list of all the events, but a list of the main ones. This includes the events of the week, as well as the events in the past few months. This will be the first of a series of videos that will show how these events took place. These videos will go on for the next few days, until the next set of videos will be shown. These will include the events from the first week of school and the second week of the summer vacation. These are just a few of the many events that happened over the last few weeks. The events of this week include: the first day of school, the last day of summer vacation, and the beginning of the new year.",0.1452991452991453,0.1452991452991453,0.692033052444458,0.692033052444458,0.7038468718528748,0.7038468718528748,0.6978899836540222,0.6978899836540222,INCORRECT,INCORRECT,0.9979361295700072,0.9979361295700072
21,"I agree with the concerns raised by the reviewers. In particular, the issues of novelty and experimental evaluation (mentioned in the revision summary) remain the major weak points of the paper. My impression is that the changes made in the revision represent a significant experimental addition to the paper, one which might merit a full pass through peer review, and one which in any event did not alter the reviewers' scores. While I think this paper has something to contribute (and the empirical results suggest the method may outperform competitors), I think it would be improved by a rewrite (and possibly a restructure) that makes the part that is your contribution much more clear. For example, in the abstract, it's only in the sentence ""We show both theoretically
and empirically that potential vanishing/exploding gradients problems can be mitigated by enforcing orthogonality to the shared filter bases"" that we actually get to the part that is really novel about this contribution (the ""enforcing orthogonality""): that would ideally be much earlier in the abstract.

","The method reduces 10.01M parameters of ResNet-34 with almost the same error rate. A classic problem, exploding/vanishing gradients, is alleviated by keeping a variable W_basis close to orthogonal. The strategy of convolution decomposing (as shown in Equation 3) in this paper is similar with separable convolution used in MobileNet. For weight sharing, the authors propose to share weight across layers which is also similar with previous weight sharing papers. The novelty/contribution is not quite sufficient. The results are not fair enough, for example, in the ImageNet experiments, MobileNetV2-Shared model is trained for 300 epochs but the baseline is only trained for 140 epochs.",0.1554770318021201,0.7679364681243896,0.7523958683013916,0.760086715221405,INCORRECT,0.9990333318710328,"This paper addresses the problem of obtaining more compact CNNs by a parameter sharing method. The results against ResNet/MobileNet are indeed promising and good to see. The presentation of the results (Table 1 and Table 2) is cumbersome. There is a typo in in the sentence above Equation (5) ; reusrive --> recursive. How does orthogonality regularisation work on a 1x1 conv? The work of Ioannou et al. (https://arxiv.org/abs/1605.06489) might be of interest as this seeks structured sparsity in ConvNets to decrease computation without loss of performance. In Section Experiments, the proposed method is only compared with classic Res net-34 and MobileNet-V2.","This paper addresses the problem of obtaining more compact CNNs by a parameter sharing method. The results against ResNet/MobileNet are indeed promising and good to see. The presentation of the results (Table 1 and Table 2) is cumbersome. There is a typo in in the sentence above Equation (5) ; reusrive --> recursive. How does orthogonality regularisation work on a 1x1 conv? The work of Ioannou et al. (https://arxiv.org/abs/1605.06489) might be of interest as this seeks structured sparsity in ConvNets. The author should, I suggest, focus more on the actual performance such as memory and time overheads during network training and deployment inference.",0.1418439716312056,0.1423487544483985,0.7304168343544006,0.7352125644683838,0.7520924210548401,0.7533836364746094,0.7410961389541626,0.7441872358322144,INCORRECT,INCORRECT,0.957489013671875,0.9674786925315856
22,"This paper studied imitation learning in the classification setting. The paper shows that using proper online learning algorithms is not sufficient to obtain sublinear regret, and devises an improper learning framework that relies on online linear optimization resulting in provably efficient algorithms. 

All the reviewers appreciated the theoretical novelty and are unanimous in their decision to accept the paper. Please incorporate the reviewers' feedback and the resulting discussion. Adding in some basic experimental results (outlined in the ""Experimental plan"" comment) would strengthen the paper. 

","This paper shows that any proper algorithm is unlikely to achieve a sublinear regret. Inspired by this observation, the paper propose an improper online learning framework that is equivalent to online linear optimization with the help of a mixed policy class. This framework allows us to design oracle0efficient algorithms with different sample/interaction round complexities. It would be very helpful if there are some experimental results (at least on some toy settings) to demonstrate the practical value as well as to make the key insights easier to understand. The direct reduction of BC to supervised learning yields a loose bound, as shown in [1]. The expert annotation complexity of BC should be \widetilde{O}(H^2/\epsilon) rather than \widenilde(O) (H^4/\epsilon)",0.2403846153846153,0.771974503993988,0.8347251415252686,0.8021244406700134,INCORRECT,0.9993667006492616,"Reviews of the paper on online imitation learning. Please summarize the paper reviews and decide on whether the paper is accepted or rejected. The main contributions include: Theoretical guarantee for drawbacks of proper online learning. An improper online learning algorithmic framework. Efficient algorithms to deal with computational hardness. Theorem 13 to show that all problems in PPAD are solvable in randomized polynomial time under some specific circumstances in COIL setting. It also gives a general online convex optimization formulation for online IL, so it seems that linear optimization is covered. The use of ""separator sets"" by the authors seemingly opens up a couple fun algorithmic questions that can take advantage of existing research from support vector machines and active sets. The direct reduction of BC to supervised learning yields a loose bound.","This paper studies the problem of classification-based online imitation learning. It shows a negative result that any proper learning fails to achieve sublinear regret. The main contributions include: Theoretical guarantee for drawbacks of proper online learning. An improper online learning algorithmic framework. Efficient algorithms to deal with computational hardness. The use of ""separator sets"" by the authors seemingly opens up a couple fun algorithmic questions. It would be very helpful if there are some experimental results (at least on some toy settings) to demonstrate the practical value as well as to make the key insights easier to understand. It seems that they are not fundamental issues. The direct reduction of BC to supervised learning yields a loose bound, as shown in [1]. The expert annotation complexity of BC should be \widetilde{O}(H^2/\epsilon) rather than \widenilde(O) (H^4/\epsilon)",0.2037037037037036,0.2290748898678414,0.7967401742935181,0.7720928192138672,0.8198472857475281,0.8368577361106873,0.8081285953521729,0.8031718134880066,CORRECT,INCORRECT,0.9992258548736572,0.9710889458656312
23,"The paper makes a novel contribution to methods for generating novel molecules from scratch. The core idea is to generate a shape that fits the molecular pocket without looking at the protein structure.

Two out of three reviewers recommended acceptance. Reviewers emphasize that the method is innovative and interesting, and the empirical performance appealing (especially given that only the shape information is provided to the model). Strong performance is enabled by good design choices made across the paper, such as including the pretraining stage.

The reviewer that recommend rejection raised issues related to the novelty and clarity of the paper. However, I believe the paper is sufficiently clear and novel to meet the bar for acceptance.

Overall, it is my pleasure to recommend acceptance of the paper.

","This paper proposes a zero-shot drug design method based on sketch. Using only information about the shape of the protein pocket avoids some of the limitations of the data set and binding simulations. However, the model is limited by ignoring the different interaction forces (hydrogen bonding, π-Stacking, etc.) that occur when molecules bind to proteins. The connecting step based entirely on greedy algorithms may lead to unreasonable results. The model is still similar to the transformer-based sequence generation model used in machine translation tasks. The tree-like structure is less expressive for molecules with complex structures. It would be beneficial to the community if authors consider publishing the codes if the paper is accepted. It is quite different from the other line of work which leverages the atoms of both proteins and ligands for generative design.",0.2188679245283019,0.7861536741256714,0.7961655855178833,0.7911279201507568,CORRECT,0.987138330936432,"This paper proposes a zero-shot drug design method based on sketch. Using only information about the shape of the protein pocket avoids some of the limitations of the data set and binding simulations. However, the model is limited by ignoring the different interaction forces (hydrogen bonding, π-Stacking, etc.) that occur when molecules bind to proteins. The connecting step based entirely on greedy algorithms may lead to unreasonable results. The paper is not clear enough in the method description, only the design of the encoding and decoding method and the paper citation of the model used are given. It would be beneficial to the community if authors consider publishing the codes if the paper is accepted. It is quite different from the other line of work which leverages the atoms of both proteins and ligands for generative design.","This paper proposes a zero-shot drug design method based on sketch. Using only information about the shape of the protein pocket avoids some of the limitations of the data set and binding simulations. However, the model is limited by ignoring the different interaction forces (hydrogen bonding, π-Stacking, etc.) that occur when molecules bind to proteins. The connecting step based entirely on greedy algorithms may lead to unreasonable results. The model is still similar to the transformer-based sequence generation model used in machine translation tasks. The tree-like structure is less expressive for molecules with complex structures. It is quite different from the other line of work which leverages the atoms of both proteins and ligands for generative design. It would be beneficial to the community if authors consider publishing the codes if the paper is accepted.",0.2264150943396226,0.2113207547169811,0.7964100241661072,0.7871547341346741,0.8003849983215332,0.7971832752227783,0.7983925938606262,0.7921373248100281,CORRECT,CORRECT,0.9650222063064576,0.995171844959259
24,"The paper considers a collaborative decision-making setting in which one agent can suggest actions for a listening agent to execute. The listening agent is not bound to take these suggested actions. The paper models the listening agent's decision-making process as a POMDP, treating the suggestions provided by other agents as observations (i.e., dependent only on the state) that are used to update the belief state. The paper describes two representations of the suggested actions and presents empirical results on simulated domains that demonstrate that the listening agent's performance improves when following the suggestions of a perfect oracle, while it degrades given imperfect suggestions in proportion to the level of noise.

The paper was reviewed by three researchers who read the author response and discussed the paper together with the AC. The reviewers largely agree that the collaborative decision-making problem as formulated is interesting. The reviewers find that the idea of formulating suggestion-following as a POMDP with suggestions modeled as observations is clever, and that the description of the proposed formulation is clear and easy to follow. The two formulations of the observation function are reasonable, albeit very simple initial models, though the paper does not provide much insight into when one should be used over the other. A primary concern with the paper is that it only provides empirical results. The work would have significantly benefited from theoretical results, which would help to understand how the method would generalize to other domains.

","The paper looks at the problem of designing a framework to support collaboration between an autonomous system and a human supervisor. Simulated experiments on a discrete state problem with an offline generated policy show some improvement using suggestions from a human with an omniscient view. The core idea seems to be a useful one, although the demonstration here is on small, discrete, 2-agent environments without catastrophic failures, brittle behavior, or clear inconsistencies. This work seems theoretical enough to not have significant societal impacts (beyond, perhaps, the use of computational agents, but here they have human supervisors!) The idea of treating recommended actions as observations is a clever way to adapt single-agent POMDPs to incorporate advice from another agent (human or artificial) The experiments and empirical results were also extensive and used reasonable benchmark problems and baselines.",0.1291989664082687,0.7910740375518799,0.7825077772140503,0.7867676019668579,INCORRECT,0.9964597821235656,"The paper looks at the problem of designing a framework to support collaboration between an autonomous system and a human supervisor. The method proposes to use the action suggestions, by using the human policy as part of the observation model of the underlying POMDP. This approximate method is then tested on two benchmark domains (under various conditions), where the paper demonstrates that the human suggestions does make a positive impact on the system performance. The core idea seems to be a useful one, although the demonstration here is on small, discrete, 2-agent environments without catastrophic failures, brittle behavior, or clear inconsistencies. This work seems theoretical enough to not have significant societal impacts (beyond, perhaps, the use of computational agents, but here they have human supervisors!) The details of computation of the scaled rational and noisy rational approaches are a bit unclear, but the authors claim to provide code.","The paper looks at the problem of designing a framework to support collaboration between an autonomous system and a human supervisor. The idea of treating recommended actions as observations is a clever way to adapt single-agent POMDPs to incorporate advice from another agent (human or artificial) The experiments and empirical results were also extensive and used reasonable benchmark problems and baselines. This work seems theoretical enough to not have significant societal impacts (beyond, perhaps, the use of computational agents, but here they have human supervisors!) The details of computation of the scaled rational and noisy rational approaches are a bit unclear. The core idea seems to be a useful one, although the demonstration here is on small, discrete, 2-agent environments without catastrophic failures, brittle behavior, or clear inconsistencies.",0.1708542713567839,0.1424802110817942,0.7967211008071899,0.7963666915893555,0.7865664958953857,0.783553421497345,0.7916111946105957,0.7899081110954285,INCORRECT,INCORRECT,0.905781090259552,0.9927785992622375
25,"This paper had mixed reviews. 

One very positive expert reviewer (8) pointed out this paper used a rigorous approach to showing than FP8 can outperform INT8 in inference, which I agree is very interesting and useful.

 Another reviewer gave borderline acceptance (5), and I did not find any remaining concerns following the authors' response.

One reviewer gave borderline reject (4), but I did not find any remaining coherent major concerns following the authors' rebuttal. Also, this reviewer seemed less experienced, so I down-weighted this reviewer's score. 

Another reviewer gave borderline reject (4) with the following remaining concerns:

(1) ""I think this scheme does not show advantages over the existing work. ""
But I don't think this is true, since as far as I know previous work did not show such an advantage of FP over INT.

(2) ""The practical application of the algorithm in this paper will bring extra overhead. ""
I agree the authors should give more details here (especially for flexible), but at least for the flex bias method, the extra overhead seems quite reasonable (as this is similar to the standard method used for INT), so I'm not sure what is the issue.  

(3) ""it is a very intuitive view that we should adopt a format with more exponent bits on the data with a large distribution range"". 
But the authors' response correctly said this is not true (as a uniform distribution would be better represented using INT, no matter what it's range), and is not what they are saying. 

Therefore, I think the reviewer had some errors in understanding here, and so I down-weighted this reviewer's score.

Also, the following paper seems relevant:
A Block Minifloat Representation for Training Deep Neural Networks, ICLR 2022

","The paper was published in the Journal of Computer Science and Engineering (JCE&E) in 2012. It is published by Oxford University Press on behalf of the Association for Computing Machinery (ACM) (http://www.acm.org/acm/2012/01/07/acM/article.html#storylink=cpy) The scheme in this paper might make the hardware design more complex, because it needs to support different m/e/b, which is mentioned in [3] (see the ref section in ""Strengths and Weakness""). I recommend the authors to discuss on the implication for actual hardware implementation. Please see the question section for more detailed discussion. Back to Mail Online home. Back To The page you were from.",0.1083743842364532,0.6966038346290588,0.7194353938102722,0.7078355550765991,INCORRECT,0.970776379108429,"The paper was published in the Journal of Computer Science and Engineering (JCE&E) in 2012. It is published by Oxford University Press on behalf of the Association for Computing Machinery (ACM) (http://www.acm.org/acm/2012/01/07/acM/article.html#storylink=cpy) The main conclusion from this work is that FP8format is more suitable thanINT8 in terms of the accuracy. The proposed method is only tailored to an efficient quantization procedure. The inference performance is hard to benefit from the concluded 5M2E and 4M3E: Minifloats are commonly used in embedded devices, which need to be emulated in software.","The paper was published in the Journal of Computer Science and Engineering (JCE&E) in 2012. It is published by Oxford University Press on behalf of the Association for Computing Machinery (ACM) (http://www.acm.org/acm/2012/01/07/acM/article.html#storylink=cpy) The main conclusion from this work is that FP8format is more suitable thanINT8 in terms of the accuracy. The proposed method is only tailored to an efficient quantization procedure. The inference performance is hard to benefit from the concluded 5M2E and 4M3E: Minifloats are commonly used in embedded devices, which need to be emulated in software.",0.1015228426395939,0.1015228426395939,0.712306797504425,0.712306797504425,0.7190909385681152,0.7190909385681152,0.7156828045845032,0.7156828045845032,INCORRECT,INCORRECT,0.9584497213363647,0.9584497213363647
26,"Reviewers generally agree that the main result of the paper, which generalizes the classical Wigner-Eckart Theorem and provides a  basis for the space of G-steerable kernels for any compact group G, is a significant result. There are also several concerns
that need to be addressed. R4 notes that the use of the Dirac delta function (e.g. Theorem C.7) is informal and mathematically imprecise and needs to be fixed. R1 notes that it would be helpful to at least describe how this general formulation can be applied in machine learning.

Presentation and accessibility: the current version of the paper will be accessible to only  a small part of the machine learning audience, i.e. those already with advanced knowledge in mathematics and/or theoretical physics, in particular in representation theory. If the authors aim to make it more accessible, the writing would need to be substantially improved.

","The paper considers Group Equivariant Convulation Neural Networks (GCNNs) which are convolutional neural networks that are equivariant wrt group symmetries of the underlying space. The authors prove a theorem (thm 4.1) which describes a basis for the space of kernels in a G-steerableCNN for any compact group G. Any steerable kernel is then a linear combination of this basis and the network can then be trained by learning the coefficients. The appendix is quite verbose and the language is more casual than I am accustomed to in a mathematical text or research paper, but it serves the goal of being didactic and approachable. The results obtained here are significant for any learning problem where there are inherent natural symmetry.",0.2361623616236162,0.7925262451171875,0.7680649757385254,0.7801039218902588,INCORRECT,0.9425902962684632,"The paper considers Group Equivariant Convulation Neural Networks (GCNNs) which are convolutional neural networks that are equivariant wrt group symmetries of the underlying space. The application section of the paper is in general way too Sketchy. The language of physics does not add to the paper. It would be better to use something more standard. The explicit results of appendix E would be rather more useful if implemented in a ML package, and I hope that is on the author's to-do list. The results obtained here are significant for any learning problem where there are inherent natural symmetry. The authors point out this could be especially beneficial for data arising from physical processes, and the mathematical methods could be of independent interest.","The paper considers Group Equivariant Convulation Neural Networks (GCNNs) which are convolutional neural networks that are equivariant wrt group symmetries of the underlying space. The results obtained here are significant for any learning problem where there are inherent natural symmetry. The appendix is quite verbose and the language is more casual than I am accustomed to in a mathematical text or research paper, but it serves the goal of being didactic and approachable. This paper is a significant contribution to the field. The language of physics does not add to the paper. It would be better to use something more standard. The explicit results of appendix E would be rather more useful if implemented in a ML package, and I hope that is on the author's to-do list.",0.1824817518248175,0.1928571428571428,0.7924089431762695,0.7875707745552063,0.7668026685714722,0.766993522644043,0.779395580291748,0.7771459817886353,CORRECT,CORRECT,0.9412274956703186,0.9834089279174804
27,"There is a clear consensus to accept this manuscript.  The results are impressive, and have a nice theoretical orientation that will allow the results to have continued impact as the field advances.  There are some minor errors by the authors in the discussions, which are worth the authors being aware of before submitting their final version.  In particular, they state that:

""The authors of [2,3] considered a bounded activation function in the infinite-width limit with large depth, in which case their variance 
V
ℓ
α
α
 always converged to a finite fixed point when depth is large [2, eq. 3]. Their chaotic and ordered phases are then defined by the behaviour of the correlation fixed point [2, eq. 5], which in turn determines the behaviour of the gradient [2, eq. 16].

In our case, shaping the activation leads to an unbounded function, and consequently the variance 
V
ℓ
α
α
 is not always bounded - even if we take the same limit as [2] (but shaping depends on depth instead like the DKS/TAT papers), in which case we get an ODE with finite time explosion. Intuitively, if we drop the Brownian motion from eq. 18 and consider

d
X
t
=
b
X
t
(
X
t
−
1
)
,
d
t
,
,

which is the logistic ODE, and has a finite time explosion if 
X
0
>
1
 and 
b
>
0
. At the same time, due to shaping, our correlation 
ρ
t
α
β
 will actually be able to avoid the fixed point (i.e., non-degenerate). So the gradient will be well behaved from the perspective of correlations (we are in the critical regime defined by [2]), but it may still explode due to variances exploding.

References
Novak, R., Xiao, L., Lee, J., Bahri, Y., Yang, G., Hron, J., Abolafia, D.A., Pennington, J. and Sohl-Dickstein, J., 2018. Bayesian deep convolutional networks with many channels are gaussian processes. arXiv preprint arXiv:1810.05148. https://arxiv.org/pdf/1810.05148.pdf
Schoenholz, S.S., Gilmer, J., Ganguli, S. and Sohl-Dickstein, J., 2016. Deep information propagation. arXiv preprint arXiv:1611.01232. https://arxiv.org/pdf/1611.01232.pdf
Yang, G. and Schoenholz, S., 2017. Mean field residual networks: On the edge of chaos. Advances in neural information processing systems, 30. https://arxiv.org/pdf/1712.08969.pdf
""

And while [2] states they consider bounded activations, it is not used or necessary and is not used in [3] or subsequent more recent work that discusses the edge of chaos further; see for instance: Activation function design for deep networks: linearity and effective initialisation by Murray et al. and On the impact of the activation function on deep neural networks training by Hayou et al.  


","The paper studies the random covariance matrix of infinite depth and width limit of deep neural networks. Using recent work on deep kernel shaping, the authors show that shaping activation function leads to non-trivial stochastic differential equations (SDE) Authors show that simulation of finite networks match the distribution predicted by the SDE. The only weakness I can find is in the presentation, which is mainly down to personal preference. In my opinion the paper feels very math heavy, and possibly not as accessible as it could be. However, this is a theoretical paper and a broader impact statement is not required (though it is always appreciated). The paper provides a creative theoretical contribution. Furthering our understanding of large neural networks, from a novel angle using SDEs.",0.1124780316344464,0.7873409986495972,0.6817803978919983,0.7307682633399963,INCORRECT,0.9994909763336182,"The paper studies the random covariance matrix of infinite depth and width limit of deep neural networks. Using recent work on deep kernel shaping, the authors show that shaping activation function leads to non-trivial stochastic differential equations (SDE) Authors show that simulation of finite networks match the distribution predicted by the SDE. The results are difficult to parse as is. The only weakness I can find is in the presentation, which is mainly down to personal preference. In my opinion the paper feels very math heavy, and possibly not as accessible as it could be. The societal impact is not addressed. However, this is a theoretical paper and a broader impact statement is not required. The paper provides a creative theoretical contribution. Furthering our understanding of large neural networks, from a novel angle using SDEs.","The paper studies the random covariance matrix of infinite depth and width limit of deep neural networks. Using recent work on deep kernel shaping, the authors show that shaping activation function leads to non-trivial stochastic differential equations (SDE) Authors show that simulation of finite networks match the distribution predicted by the SDE. The only weakness I can find is in the presentation, which is mainly down to personal preference. In my opinion the paper feels very math heavy, and possibly not as accessible as it could be. The societal impact is not addressed. However, this is a theoretical paper and a broader impact statement is not required. The paper provides a creative theoretical contribution. Furthering our understanding of large neural networks, from a novel angle using SDEs.",0.1176470588235294,0.1157894736842105,0.7855265140533447,0.7857552170753479,0.6824327707290649,0.6785256266593933,0.7303595542907715,0.7282141447067261,INCORRECT,INCORRECT,0.9993709921836852,0.9996507167816162
28,"The paper adds a new level of complexity to neural networks, by modulating activation functions of a layer as a function of the previous layer activations.  The method is evaluated on relatively simple vision and language tasks.

The idea is nice, but seems to be a special case of previously published work; and the results are not convincing.  Four of five reviewers agree that the work would benefit from: improving comparisons with existing approaches, but also improving its theoretical framework, in light of competing approaches.

","The proposed modulator is easy to implement and applicable to (almost) all network architectures. It is unclear whether the modulator weights are shared along the depth of a CNN layer, i.e. between feature maps. When comparing the test accuracy of CNNs in Fig. 4 the result is questionable. Some experiments show nice results (eg. modulated densenet-lite outperforming densenET) but the overall paper needs further improvements. The paper is published in the open-source journal Brain, Cognition and Machine Learning (BBM) (http://www.brain,cognition and machine learning.org/blog/2013/01/28/brain-cognitions-and-machine-learning-bcm.html).",0.1397849462365591,0.7045754790306091,0.7939215898513794,0.746584951877594,INCORRECT,0.9476855397224426,"The proposed modulator is easy to implement and applicable to (almost) all network architectures. It is unclear whether the modulator weights are shared along the depth of a CNN layer, i.e. between feature maps. The idea is demonstrated on basic vision and NLP tasks, showing improvements over the baselines. Some experiments show nice results (eg. modulated densenet-lite outperforming densenET) but the overall paper needs further improvements. The discussion at the end adds little value and rather seems to be a motivation of the model than a discussion of the results. The paper is published in the open-source journal Brain, Cognition and Machine Learning (BBM) (http://www.brain,cognition and machine learning.org/blog/2013/01/28/brain-cognitions-and-machine-learning-bcm)","The paper is published in the open-source journal Brain, Cognition and Machine Learning (BBM) (http://www.brain,cognition and machine learning.org/blog/2013/01/28/brain-cognitions-and-machine-learning-bcm.html) The idea is to multiply the output of the linear combination by a ""modulator"", prior to feeding it into the activation function. Some experiments show nice results (eg. modulated densenet-lite outperforming densenET) but the overall paper needs further improvements. It is unclear whether the modulator weights are shared along the depth of a CNN layer. The discussion at the end adds little value and rather seems to be a motivation of the model than a discussion of the results.",0.219047619047619,0.1909547738693467,0.7262721061706543,0.7236392498016357,0.8103866577148438,0.7932436466217041,0.7660272121429443,0.7568445205688477,INCORRECT,INCORRECT,0.9894731640815736,0.9994508624076844
29,"This work proposed a new HPO surrogate benchmark for 14 scenarios and filled the gap of benchmarks in the multi-objective and multi-fidelity setting. The paper is clearly written and conducted experiments to demonstrate its usefulness. It also provided analysis on several interesting questions such as tabular vs surrogate; multi-fidelity vs full-fidelity. It is open sourced and being integrated into a larger benchmarking framework (HPOBench). I think it will make a good contribution to the HPO community.



","The benchmarks are surrogate-based, provided using the ONNX format, and have low memory requirements. The paper is not very clear. Namely, there are alot of missing references, the authors rely on their publicly available work, for most of the information. This is a very strong HPO benchmarking system covering all relevant aspects of the HPO problem, and provides a more faithful yet more efficient (in terms of time and memory overhead) comparison between HPO algorithms. For this reason, I strongly recommend the acceptance of this paper. It has a big potential impact on the field of AutoML, because a general framework for mutli- objective and mutli/fidelity optimization is currently not available. It will be a potentially impactful project to describe why we need this benchmark and how it will be used.",0.1502347417840375,0.7864280939102173,0.8272354602813721,0.8063157796859741,INCORRECT,0.9998475313186646,"The benchmarks are surrogate-based, provided using the ONNX format, and have low memory requirements. In general, the paper is clear and well written. However, something went wrong with the references which are all cited as '??' (both papers, sections, etc. The benchmarks are listed mainly, e.g., in a table in a quantitative way. The diversity of the instances for each benchmark collection is not studied. One suggestion would be to visualize the empirical cumulative distribution of the underlying tabular datasets. The writing of the paper seems correct and proper references are cited. The paper is correctly written and specific details are given. The utility of the framework is illustrated with several experiments. Overall I think that this is an interesting paper that proposes a tool that the community will most likely find useful.","The benchmarks are surrogate-based, provided using the ONNX format, and have low memory requirements. As far as I can see the results are technically sound, but I was not able to run the experiments myself for further analysis. In general, the paper is clear and well written. However, something went wrong with the references which are all cited as '??' (both papers, sections, etc. The benchmarks are listed mainly, e.g., in a table in a quantitative way. It is not clear how different the answer would be if we used some of the other benchmarks (such as HPOBench and HPO-B) with some level of parity. The writing of the paper seems correct and proper references are cited. Overall I think that this is an interesting paper that proposes a tool that the community will most likely find useful.",0.1682242990654205,0.1545454545454545,0.7765349745750427,0.7651860117912292,0.7988125681877136,0.8105106949806213,0.7875162363052368,0.7871964573860168,CORRECT,INCORRECT,0.9484721422195436,0.9974952936172484
30,"The paper proposed a two-stage method to select instances from a set, involving candidate selection (learning a function  to determine a Bernoulli probability for each input) and AutoRegressive subset selection (learning a function  to generate probabilities for sampling elements from a reduced set); both stages use the Concrete distribution to ensure differentiability. The experiments show the performance of the proposed method on several use-cases, including reconstruction of an image from a subset of its pixels, selecting sparse features for a classification task, and dataset distillation for few-shot classification. I read the paper and I agree with the reviewers that in its current format the paper is hard to follow. I strongly encourage the authors to add more discussion and intuition on the proposed method and extend the experiments with more baseline comparison and ablation studies in the revised version. 

","Stochastic subset selection (SSS) is a method to learn to compress a set $D$ by selecting a subset $D_s$ such that the loss of a task is as close as possible to the loss if the task had been performed on the original $D$. The paper show how this general method can be applied to several tasks. SSS is motivated by the need to reduce bandwidth, computation and memory footprint of deep learning in edge devices. The paper is very dense, which makes it hard to follow. The experiments, while good to show the strength of the approach, do not cover usefullness for the mobile use case. I think the proposed approach has some potential and will be interesting for the community. I am on the fence with this paper.",0.227106227106227,0.7816123962402344,0.7891292572021484,0.7853528261184692,INCORRECT,0.9596965909004213,"The authors present a stochastic algorithm for selecting a subset of a large dataset, while trying to preserve statistics from the original dataset. The algorithm is a two-step process, first selecting a set of ""candidates"" based on individual features, then filtering to a final subset which may account for interactions between candidate items. The paper provides experimental evidence that the proposed method outperforms other subset selection baselines, such as Learning to Select (LTS) and random selection (RS) The authors need to explain the motivation behind the proposed algorithm. The writing and figures lack clarity and are often difficult to follow. The experiments, while good to show the strength of the approach, do not cover usefullness for the mobile use case. I think the proposed approach has some potential and will be interesting for the community.","Stochastic subset selection (SSS) is a method to learn to compress a set $D$ by selecting a subset $D_s$ such that the loss of a task is as close as possible to the loss if the task had been performed on the original $D$. The paper show how this general method can be applied to several tasks. SSS is motivated by the need to reduce bandwidth, computation and memory footprint of deep learning in edge devices. The paper is very dense, which makes it hard to follow. The experiments, while good to show the strength of the approach, do not cover usefullness for the mobile use case. I think the proposed approach has some potential and will be interesting for the community. I am on the fence with this paper.",0.2086330935251798,0.227106227106227,0.822708249092102,0.7816123962402344,0.8135221004486084,0.7891292572021484,0.8180893659591675,0.7853528261184692,INCORRECT,INCORRECT,0.96358460187912,0.9596965909004213
31,"Dear authors,

Your proposition of adding a noise scaling with the diagonal of the gradient covariance to the updates as a middle-ground between the identity and the full covariance is interesting and tackles the timely question of the links between optimization and generalization.

However, the reviewers had concerns about the experiments that did not reveal to which extent each trick had an influence.
I would like to add that, even though the term Fisher is used for both the true Fisher and tne empirical one, these two matrices encore very different kind of information. In particular, the latter is only defined when there is a dataset. Hence, your case study  (section 3.2) which uses the true Fisher does not apply to the empirical Fisher.

I encourage the authors to pursue in this direction but to update the experimental section in order to highlight the impact of each technique used.

","The method is shown empirically to achieve both comparable generalization and the training speedup compared to small batch. The intuition of using diagonal fisher for faster convergence in generalization performance is still missing from my perspective. The experiments are conducted on MNIST and CIFAR10 and 100, which I feel is a bit insufficient for a paper that deals with generalization gaps in large batches. There is a typo in the next line of Eq. (2) in which the notation ""l_i"" is not defined at this time. In addition, the notation ‘l’ is not clearly defined in the paper. It is not clear if the ‘’ in ‘L’ means ‘let’ or ‘len’",0.1908396946564886,0.7736464738845825,0.7709918022155762,0.7723168134689331,INCORRECT,0.9951027631759644,"Reviews of the paper can be done by clicking here. Please summarize the paper reviews and decide on whether the paper is accepted or rejected. The paper proposes a method to close the generalization gap that arises in training DNNs with large batch. The experiments are conducted on MNIST and CIFAR10 and 100, which I feel is a bit insufficient for a paper that deals with generalization gaps in large batches. The intuition of using diagonal fisher for faster convergence in generalization performance is still missing from my perspective. The algorithm derivation seems to be reasonable and the derived algorithm is executable. There is a typo in the next line of Eq. (2) in which the notation ""l_i"" is not defined at this time.","This paper proposes a method to close the generalization gap that arises in training DNNs with large batch. The intuition of using diagonal fisher for faster convergence in generalization performance is still missing from my perspective. The experiments are conducted on MNIST and CIFAR10 and 100, which I feel is a bit insufficient for a paper that deals with generalization gaps in large batches. The algorithm derivation seems to be reasonable and the derived algorithm is executable. There is a typo in the next line of Eq. (2) in which the notation ""l_i"" is not defined at this time. It is not clear if the ‘’ in ‘L’ means ‘let’ or ‘len’",0.2101449275362319,0.1977186311787072,0.7703394293785095,0.7687551379203796,0.7654321789741516,0.7664721012115479,0.7678779363632202,0.7676118612289429,INCORRECT,INCORRECT,0.9887431859970092,0.9667806625366212
32,"This work proposes algorithms for solving ERM with continuous losses satisfying the PL condition. The first algorithm achieves that by using a chainging noise variance and thus the paper frames the contribution in terms of the advantages of non-constant noise rate.

The problem is a well-studied one and the result is a nice if relatively modest improvement over Wang et al. However, as pointed out in reviews, in the context of convex optimization the same rate has already been established (Feldman,Koren,Talwar STOC 2020). This work is cited and briefly discussed but the discussion only includes one of the algorithms in the paper (that does have an additional log N factor). The overall assumptions in this paper are not comparable (weaker in some ways and stronger since they only require PL instead of strong convexity) but still the overall the contribution appears to be incremental.

","The study was published in the Journal of Applied Mathematics and Statistics (JAMAS) on November 14, 2013. The paper studies private gradient descent when the noise added to each of the iteration is dynamically scheduled. The results hold only under PL condition (which is a more general condition than strong convexity) and smoothness. The authors do a good job engaging with prior work, identifying gaps in related work and putting their contributions in that context. The analysis seems technically correct and pretty strong, although I did not check this closely. There are some typos that I found. There might be some interesting idea in this paper, especially, looking at the dynamic schedule for PPML. But I fail to see the strength of the result in the view of prior work as the comparison done in thePaper is between apples and oranges.",0.1937716262975778,0.777184009552002,0.7861302495002747,0.781631588935852,INCORRECT,0.8537988662719727,"The study was published in the Journal of Applied Mathematics and Statistics (JAMAS) on November 14, 2013. The paper studies private gradient descent when the noise added to each of the iteration is dynamically scheduled. The authors do a good job engaging with prior work, identifying gaps in related work and putting their contributions in that context. There are some typos that I found. There might be some interesting idea in this paper, especially, looking at the dynamic schedule for PPML. However, I fail to see the strength of the result in the view of prior work as the comparison done in thePaper is between apples and oranges. I will keep my reviews limited to the current submission of the paper. The results look correct. My current scores are because I see limited value/interest in these results.","The study was published in the Journal of Applied Mathematics and Statistics (JAMAS) on November 14, 2013. It is published by Oxford University Press on behalf of the American Mathematical Society (AMAS). The paper studies private gradient descent when the noise added to each of the iteration is dynamically scheduled. Below are multiple summaries of different reviews on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The main contribution is a theoretical analysis of aDynamic privacy schedule which helps reduce the utility upper bound ofprivate gradient descent (with or without momentum) The results look correct. My current scores are because I see limited value/interest in these results.",0.1818181818181818,0.1532846715328467,0.7679120898246765,0.7484487891197205,0.7684246301651001,0.7569965720176697,0.7681683301925659,0.7526983618736267,INCORRECT,INCORRECT,0.9642767310142516,0.987684726715088
33,"This paper considers the task of training policies for human-robot collaborative tasks and observes the need for out of distribution generalisation for human policies as a pre-requisite for training. The authors present an approach for learning a latent representation for human policies that may be adapted online. 

Reviewers consider the motivation compelling and highly relevant for assistive robotics applications. In particular, reviewers consider the idea of learning a latent space for human policies as elegant. Further, thorough comparisons with related efforts strengthen the paper’s arguments. 

The primary weakness of the paper is that the tasks used to evaluate the approach are relatively simple (reaching and itch scratching). This raises the question of whether and to what extent the method can scale to more realistic tasks. Any experiments to suggest that the approach can bridge the sim2real gap have been suggested since the current results are purely in simulation. A better technical exposition of the test time adaptation has also been suggested. 

During the rebuttal phase,  the authors provided additional clarification/results for key reviewer questions such as mechanism for generalisation, overfitting, choice/training of encoders and their inclusion strengthens the overall paper. The major quantitative evaluation is on moderately complex tasks (e.g., itch scratching) supplemented by a user study. The user study is conducted in lab scenario (not with real users) and the setup bears resemblance to human studies in other human-collaborative domains (such as driving, collaborative assembly etc.). 

Overall, the paper contributes an approach for learning latent representations from interaction data that can be adapted online based on distribution shifts observed online. The manuscript can be strengthened by a clearer exposition on the mechanism/nature of generalisation attained, mechanisms for preventing overfitting and and an analysis of potential scalability to complex scenarios. Further, since the learning problem is scoped towards the specific domain of assistive tasks (as opposed to general robot tasks), a clearer setup of the problem context and a statement on the scalability of the results to end-users may also be considered by the authors. 


","This paper tackles the problem of generalizing to out-of-distribution human behavior when using sim2real methods to develop assistive robotics capabilities. The authors propose the Prediction-based Assistive Latent eMbedding (PALM) framework, which involves learning a latent space by predicting future human actions from a history of observations and actions. The paper can be significantly improved by being more cohesive about the motivation, the claims, and the assumptions of the methods. It is unclear how PALM would scale to more complex settings. Can the authors provide some discussion around how the method scales? As stated above, it would be helpful to clarify how the test time adaptation was performed in the experiments. The regularization term (eq. 3) is motivated by VAE formulation and helps in grouping similar humans closer.",0.1772151898734177,0.8160426020622253,0.7755717635154724,0.7952926158905029,INCORRECT,0.9889400601387024,"The paper focuses on learning latent representations for generalization in assistive tasks such as reaching and itch-scratching. The latent space is learned directly from the history of interactions by predicting partner actions during training. During testing, the learned space is adapted by observing the partner actions to account for OOD partner policies. The paper can be significantly improved by being more cohesive about the motivation, the claims, and the assumptions of the methods. The assumptions need to be very clearly specified in the paper and the claims should be carefully considered and re-worded. The regularization term (eq. 3) is motivated by VAE formulation and helps in grouping similar humans closer. By similar humans, the paper probably means similar itch locations and history of actions ( a clarification would be helpful).","This paper tackles the problem of generalizing to out-of-distribution human behavior when using sim2real methods to develop assistive robotics capabilities. The work is done entirely in simulation with synthesized human behavior. The paper can be significantly improved by being more cohesive about the motivation, the claims, and the assumptions of the methods. The assumptions need to be very clearly specified in the paper and the claims should be carefully considered and re-worded. It is unclear how PALM would scale to more complex settings. Can the authors provide some discussion around how the method scales? As stated above, it would be helpful to clarify how the test time adaptation was performed in the experiments. The regularization term (eq. 3) is motivated by VAE formulation and helps in grouping similar humans closer.",0.16,0.1635220125786163,0.8168033361434937,0.8146900534629822,0.7727522850036621,0.7685402631759644,0.7941674590110779,0.7909426093101501,INCORRECT,INCORRECT,0.9934788942337036,0.9983574748039246
34,"The paper gives high probability bounds on excess risk for differentially private learning algorithms, in the setting where the loss is assumed to be Lipschitz, smooth, and assumed to satisfy the Polyak-Łojasiewicz (PL) condition. The key idea in the paper is to leverage the curvature in the loss (PL condition) and the generalized Bernstein condition. 

Authors show that they get sharper bounds of the order \sqrt{p}/(n\epsilon) when the loss is assumed to satisfy the PL condition besides being convex Lipschitz/smooth. Without using some curvature information about the loss function, the best upper bounds we can get are in the order of \sqrt{p}/(n\epsilon) + 1/\sqrt{n} — and this is tight at least in terms of the dependence on n given the nearly matching lower bounds — in fact, the dependence on n is tight as it matches the non-private settings.  

So, I find it a bit misleading when authors say that they improve over the existing results. That statement is not true in its generality — it is true that we can leverage the PL condition to give faster rates but that is not the setting of prior work. Again, the bounds that authors compare against are for smooth/Lipschitz convex loss functions and without any assumption on the curvature of the loss. 

If we do look at the literature for when and/or how can curvature help, we can compare against the existing bounds for strongly convex losses. The best-known result in the setting that is most closely related is that of Feldman et al. (STOC 2020): https://dl.acm.org/doi/pdf/10.1145/3357713.3384335. As we can check from Theorem 4.9 in that paper, the bounds we get are in the order of 1/n + d/n^2 which is actually better — not surprising since PL condition is a weaker condition. There is merit to the results in this paper but the current narrative is quite misleading and a more careful comparison with the existing literature is needed. The bounds are hard to parse — for example, what is the dependence on the strong convexity parameter (\mu)? It would also help to instantiate specific loss functions so that we can fix some of the parameters in the bound to have a clear comparison with the existing bounds.

","The paper achieves high probability excess risk bound with rate O(1/n) w.r.t n for DP models via uniform stability by using Generalized Bernstein condition under G-Lipschitz, L-smooth, and PL condition. The paper overall read clearly, though the proof sketches should be more clear. Although the understandability of the current manuscript is acceptable, I encourage the authors to correct the typos and the grammatical errors in future versions of this paper by giving the correct results by this are clear by this is not given by this. Theorem 2&3 have more novelty, but are less important than Theorem 1 in my opinion. The presentation of results and proof sketches is clear. The authors should check carefully whether the results are given by the current version of the paper by this author.",0.1638095238095238,0.8009207844734192,0.7328155040740967,0.7653560638427734,INCORRECT,0.9996464252471924,"The paper gives a high probability excess population risk bound for differentially private optimization algorithm under $G$-Lipschitz, $L$-smooth and PL condition with gradient perturbation. It seems that mNGP is proposed solely for the sake of bypassing Young’s inequality. Theorem 2&3 have more novelty, but are less important than Theorem 1 in my opinion. The presentation of results and proof sketches is clear. The paper overall read clearly, though the proof sketches should be more clear. Although the understandability of the current manuscript is acceptable, I encourage the authors to correct the typos and the grammatical errors in future versions of this paper by giving the correct results by this are clear.","Multiple reviews have been published on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The paper overall read clearly, though the proof sketches should be more clear. It seems that mNGP is proposed solely for the sake of bypassing Young’s inequality. Theorem 2&3 have more novelty, but are less important than Theorem 1 in my opinion. The presentation of results and proof sketches is clear. Although the understandability of the current manuscript is acceptable, I encourage the authors to correct the typos and the grammatical errors in future versions of this paper by giving the correct results by this are clear by this is not given by this.",0.1669980119284294,0.1395348837209302,0.7930209636688232,0.7724902629852295,0.7197102308273315,0.6897094249725342,0.7545892000198364,0.7287566065788269,INCORRECT,INCORRECT,0.9854159951210022,0.9927513599395752
35,"This paper goes beyond the NTK setting in analyzing optimization and generalization in ReLU networks. It nicely generalizes NTK by showing that generalization depends on a family of kernels rather than the single NTK. The reviewers appreciated the results. One thing that is missing is a clear separation between NTK results and the ones proposed here. Although it is ok to defer this to future work, a discussion of this point in the paper would be helpful.

","Theoretical Computer Science is published in the open-access journal, Theoretical. Computer Science. This paper studies the optimization and generalization of a three-layer neural network trained by a projected SGD algorithm. In this setting, the network runs beyond the NTK regime. It can achieve feature learning, and better generalization performance than NTK. The paper is meaningful because it provides an approach to analyze the feature learning effect of neural networks. The model and the algorithm are close to commonly used ones, while there are components specially designed for the theoretical analysis. While it is generally well written, it is not very accessible for a casual ICLR reader with no background in theoretical computer science. It would be better if the authors can provide further comments on the key difference between the data- dependent complexity measure bound and the function-norm based bound.",0.2,0.7825941443443298,0.8246699571609497,0.8030813336372375,INCORRECT,0.9999810457229614,"Theoretical Computer Science is published in the open-access journal, Theoretical. Computer Science. The paper presents a theoretical analysis of a 3 layer neural network with ReLU activations. The main result is introduction of adaptive generalization bounds that are defined for a modified SGD algorithm. The model and the algorithm are close to commonly used ones, while there are components specially designed for the theoretical analysis. In this setting, the network runs beyond the NTK regime. It can achieve feature learning, and better generalization performance than NTK. It is meaningful because it provides an approach to analyze the feature learning effect of neural networks. The reviewer hope the authors can make it clearer why the studied setting is different from NTK and why the network is less wide than required by NTK?","Theoretical Computer Science is published in the open-access journal, Theoretical. Computer Science. The paper presents a theoretical analysis of a 3 layer neural network with ReLU activations. The main result is introduction of adaptive generalization bounds that are defined for a modified SGD algorithm. In this setting, the network runs beyond the NTK regime. It can achieve feature learning, and better generalization performance than NTK. It is meaningful because it provides an approach to analyze the feature learning effect of neural networks. It packs a lot of material in 9 page of main text and 101 pages of Appendix material. While it is generally well written, it is not very accessible for a casual ICLR reader with no background in theoretical computer science. Since I'm not an expert in this, I'll defer to the other reviewers to check the significance and correctness of this paper.",0.1531100478468899,0.16,0.7863244414329529,0.775063157081604,0.8175905346870422,0.8227423429489136,0.801652729511261,0.7981913089752197,CORRECT,INCORRECT,0.8516747355461121,0.9999818801879884
36,"The paper proposes a framework for classification of whole slides images, where the DNN essentially relies on patch processing (as is the norm). The paper proposes an aggregation module that relies on a DNN to perform a weighted average of the patch representations (Section 3.2). The paper claims end-to-end learning, but this involves a sampling step that hasn't been shown to be suitable for the purpose. 


","MIL with defined costs seem to perform better than the state of the art. Vanilla C2C is inferior to Campanella baseline results. The results are promising, a good application study is needed. It is not clear if the results will be applied to other diseases. All symbols used in the equation should be explained. The maximum number of patches was established as 64. How this value was established? It is useful to present an average time of single slide classified for each method. It would be very nice to see that the representations indeed get closer in each case, numerically. Is it always binary classification, both in the celiac disease task and in CAMELYON? I believe this could maybe verified with some experiment. If not, why not try it on the Celiac Disease task?",0.1372549019607843,0.7310671806335449,0.7624566555023193,0.7464320659637451,CORRECT,0.9639006853103638,"MIL with defined costs seem to perform better than the state of the art. Vanilla C2C is inferior to Campanella baseline results. The study does not show the benefit of attention aggregation. The results are promising, a good application study is needed. It is not clear if the results will be applied to other diseases. The main weakness of the paper is the lack of details about the processing time. How is this method impacting on time of model training and single slide Classification? Is single slide classification faster ?Other comments include: All symbols used in the equation should be explained. The maximum number of patches was established as 64. How this value was established? It is useful to present an average time of single slide classified for each method (Table 1)","MIL with defined costs seem to perform better than the state of the art. Vanilla C2C is inferior to Campanella baseline results. The results are promising, a good application study is needed. It is not clear if the results will be applied to other diseases. The authors should clearly show the difference between their method and the CLAM method (preprint in April 2020, https://arxiv.org/abs/2004.09666), which also uses clustering + attention methods. The main weakness of the paper is the lack of details about the processing time. How is this method impacting on time of model training and single slide Classification? Is single slide classification faster ?Other comments include: All symbols used in the equation should be explained.",0.1485148514851485,0.1256544502617801,0.7416421175003052,0.7181165218353271,0.7767798900604248,0.7734875679016113,0.758804440498352,0.7447742819786072,CORRECT,INCORRECT,0.951886773109436,0.9650420546531676
37,"The reviewers agree that from a decision tree induction point of view, this paper provides a solid methodological approach in contrast to prior heuristics-based approaches. They found the author feedback satisfying, specifically, the additional experiments showcase that the proposed method generalizes most likely beyond development datasets.

We ask the authors that in the final version, please make a pass over the paper to incorporate the author-reviewer discussions.

","A splitting criterion for fitting decision trees is proposed based on multi-armed bandits as to improve training efficiency. The paper has a solid theoretical background and a novel algorithmic contribution, but lacks a thorough experimental evaluation. It is unclear why an artificial dataset was generated instead of using real-world data, e.g., from OpenML. How come that the performs degrades that much for ExtraTrees? Limitations are not discussed in the paper. Theoretical results offer some guarantees on the computational complexity. The experiments use reimplemented variants of the baseline algorithms. It would have been useful to replicate the results on different datasets. It should be clear that you have better empirical results than the standard that is implemented in Scikit-learn/Weka etc.",0.1450777202072538,0.7739686965942383,0.7920674085617065,0.7829134464263916,INCORRECT,0.9996373653411864,"A splitting criterion for fitting decision trees is proposed based on multi-armed bandits as to improve training efficiency. Empirical evaluation on the MNIST dataset show that the proposed selection technique results in much faster tree algorithms. The paper has a solid theoretical background and a novel algorithmic contribution, but lacks a thorough experimental evaluation. Theoretical results offer some guarantees on the computational complexity. The experiments use reimplemented variants of the baseline algorithms. It would have been useful to replicate the results on different datasets. It is unclear why an artificial dataset was generated instead of using real-world data, e.g., from OpenML. How come that the performs degrades that much for ExtraTrees? Limitations are not discussed in the paper. The theoretical guarantees seem fairly straightforward. The proposed technique might be more difficult to implement/optimize effiently.","A splitting criterion for fitting decision trees is proposed based on multi-armed bandits as to improve training efficiency. While the general idea is quite interesting and the tackled problem is an important one, the paper falls short in terms of the scope of contribution. It is unclear why an artificial dataset was generated instead of using real-world data, e.g., from OpenML. The performance degradation in Table 2 was not addressed at all. How come that the performs degrades that much for ExtraTrees? Limitations are not discussed in the paper. Theoretical results offer some guarantees on the computational complexity. The proposed technique might be more difficult to implement/optimize effiently. It should be clear that you have better empirical results than the standard that is implemented in Scikit-learn/Weka.",0.1642512077294685,0.1393034825870646,0.7725216150283813,0.7639734148979187,0.7911590337753296,0.7864192724227905,0.7817292809486389,0.7750338912010193,INCORRECT,INCORRECT,0.9987564086914062,0.9999397993087769
38,"Summary of discussion: Three reviewers rated the paper Good (7) while Reviewer2 disagreed. R2's criticism was focussed on how this work is placed within existing/related literature, and no technical problem was identified. The authors have addressed some of R2's comments/concerns, R2 has not participated in the discussion.

Novelty and contributions: Overall the reviews seem consistent with an incremental paper which is technically valid, improves the state of the art on a reasonably difficult task. However, it does not appear from the reviews that the paper substantially advances our understanding of machine learning more broadly beyond this specific application.

Experiments: There is some disagreement among reviewers on the adequacy of the experiments, with at least two reviewers calling for experiments involving 'natural photos'. I believe the author's responses adequately address these concerns: they pointed out that the key selling point of their paper is the ability to model structured noise which is less relevant in natural photos.

On the balance of things, I think this paper should be accepted, but I wouldn't argue if it did not make the cut due to its narrow scope. For this reason, I recommended poster presentation.

","A paper proposed a new method for blind image denoising using a ""GAN2GAN"" network. Different from previous work noise2noise, the proposed method only needs single noisy images to train the network, without noisy pairs. The idea of refining the noisy image iteratively is reasonable, which makes the image content for training progressively better. The experiments were done with extensive datasets and baselines. The motivation of using the proposed network design is not clear. Using more generators will lead to larger capacity models than existing methods. More analyses are needed in Sec. 4.4 for ablation study. If the authors can provide comparisons or discussion, analysis on these algorithms and comparison, it would be helpful. It is notclear whether the performance gains are due to use such largercapacity models. If so, the contribution of the paper is limited.",0.1377245508982036,0.7688024044036865,0.7543050050735474,0.7614847421646118,INCORRECT,0.9981654286384584,"This paper proposed a new method for blind image denoising using a ""GAN2GAN"" network. Different from previous work noise2noise, the proposed method only needs single noisy images to train the network, without noisy pairs. The idea of refining the noisy image iteratively is reasonable, which makes the image content for training progressively better. The final results on synthetic and real data showed improvements over the baselines. It would be great to have natural images in the experiments to validate the idea. It is not clear the described dataset for Table 3 for training or testing. More analyses are needed in Sec. 4.4 for ablation study. If the authors can provide comparisons or discussion, analysis on these algorithms and comparison, it would be helpful.","This paper proposed a new method for blind image denoising using a ""GAN2GAN"" network. Different from previous work noise2noise, the proposed method only needs single noisy images to train the network, without noisy pairs. The idea of refining the noisy image iteratively is reasonable, which makes the image content for training progressively better. It would be great to have natural images in the experiments to validate the idea. The motivation of using the proposed network design is not clear. Using more generators will lead to larger capacity models than existing methods. More analyses are needed in Sec. 4.4 for ablation study. This paper is solid, I am not sure how this work compares to well known algorithms forblind image Denoising. If the authors can provide comparisons or discussion, analysis on these algorithms and comparison, it would be helpful.",0.1183800623052959,0.1309523809523809,0.7705973386764526,0.7691863775253296,0.7505584359169006,0.7576857805252075,0.7604458332061768,0.7633927464485168,INCORRECT,INCORRECT,0.7803992033004761,0.9574179649353028
39,"This paper proposes a federated learning (FL) scheme that is suitable for clients/devices with heterogeneous resources. The scheme Split-Mix trains multiple models of different sizes and adversarial-robustness levels, which are tailored to the budgets of the individual device. Empirical results show encouraging results.

It is clear that FL will have to work with clients with diverse resources, a point that is appreciated. Indeed, it is anticipated that widely-dispersed inference will have to deal with a highly-heterogeneous mix of clients. The study is quite thorough. One aspect that is not convincing in the experiments is the budgets being exponentially distributed: having a strong concentration around a mean (with something like a Gaussian tail), or a power-law distribution, would be more suitable.

","Split-Max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness. With customisation, the models are smaller and more robust under budget constraints. The idea of BN layer-wise mixing is kind of confusing. The reason of sharing all parameters except the batch-normalisation requires further elaboration. The assumption about the computational resources of clients would be better clarified. The evaluation results are heavily based on the assumption of exponentially distributed budgets. There is a large number of typos (mainly after Section 4). A sample: x1 net SHeteroFL seems to converge faster than slimmer nets till around round 50. The authors conclude that the widest model may not be a good candidate model but don’t provide any intuition behind this.",0.1417322834645669,0.7911147475242615,0.7862445116043091,0.788672149181366,INCORRECT,0.999724805355072,"The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device. Empirical results demonstrate the efficacy of the method against the main competitor. Weaknesses: The evaluation results are heavily based on the assumption of exponentially distributed budgets. There is a large number of typos (mainly after Section 4). A sample: x1 net SHeteroFL seems to converge faster than slimmer nets till around round 50. The authors conclude that the widest model may not be a good candidate model but don’t provide any intuition behind this. After reading further the reason, behind this seems to be the less amount of data.","The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device. Empirical results demonstrate the efficacy of the method against the main competitor. The evaluation results are heavily based on the assumption of exponentially distributed budgets. There is a large number of typos (mainly after Section 4). A sample: x1 net SHeteroFL seems to converge faster than slimmer nets till around round 50. The authors conclude that the widest model may not be a good candidate model but don’t provide any intuition behind this. After reading further the reason, behind this seems to be the less amount of data.",0.3464566929133858,0.3478260869565218,0.8319174647331238,0.8344038724899292,0.8395538926124573,0.8406141400337219,0.8357182145118713,0.8374974131584167,INCORRECT,INCORRECT,0.9998125433921814,0.999786913394928
40,"The paper shows convergence results for RMSprop in certain regimes. The reviews are uniformly positive about this paper and I recommend acceptance.

","The results of the study show that if the RSPP is chosen high enough, it will converge to a fixed point. The results show that this is not always the case. The study was published in the open-source journal, Theoretical Algorithms, which is open to anyone. The authors hope that the results will help other researchers in the field to improve their understanding of the theory and practice of RSPPs. For more information on the study, go to: http://www.cnn.com/2013/01/29/science/features/topics/topical-algorithms-reconciliation.html#storylink=cpy. The article was originally published in The New York Times, which has since changed its mind.",0.075187969924812,0.6775264739990234,0.789137601852417,0.7290852665901184,INCORRECT,0.9989421963691713,"The paper studies one of the most popular algorithms in machine learning: RMSprop. By proving the convergence without using ""bounded gradient"" assumption, the authors establish a phase transition from divergence to non-divergence for RMSProp. The results provide basic guidelines for tuning hyper-parameters of the algorithms in practice. The experiments supporting the theoretical results are comprehensible, but the authors need to provide a figure with x-axis to be epochs and y- axis to be accuracy so that the readers can have better idea upon how SGD andRMSProp behave during training.Overall, this is a nice, well-written and relevant paper that clears the bar for publication in its current version. It could be improved on a couple of things: if beta2 = 1, the algorithm degenerates to SGD.","This work revisits a famous counterexample on the convergence of Adam (originally presented in Reddi 2018). The authors show that, if the EMA parameter beta2 in RMSprop and Adam is chosen high enough, then both methods converge to a bounded region in the stochastic setting. Crucially, and differently from many other papers on the topic, the gradients are not assumed to be bounded and the beta2 hyperparameter is not chosen to increase to 1. The paper is well written and the logic of it is convincing. It truly does merge the gap between theory and practice in non-convex Stochastic optimization. It could be improved on a couple of things: if beta2 = 1, the algorithm degenerates to SGD.",0.1324503311258278,0.1142857142857143,0.7314499616622925,0.7212403416633606,0.8237320184707642,0.823083221912384,0.7748530507087708,0.7688036561012268,INCORRECT,CORRECT,0.9465672969818116,0.8020921945571899
41,"All four reviewers enjoyed this paper and were particularly impressed by the videos provided in the supplementary material. The results are very impressive indeed. The reviewers also agreed that using a multi stage approach was interesting and effective. The two new datasets were deemed useful to the generation community and the proposed metrics and human evaluations were appreciated by the reviewers. A few smaller concerns included a missing failure analysis and some clarifications questions which were addressed in the rebuttal. Given the above, I recommend acceptance.

","The paper discusses a method for generating long videos in which new content is introduced as the camera moves forwards. It has been shown that training at high res both in space and time is prohibitively expensive. While this method focuses on the temporal part of videos, it's not clear what's the resolution upper bound. Although the method works better for high dynamics, it may not handle low dynamics. Videos with longer sequence length tend to exacerbate the issue of overfitting and therefore some strong augmentations might be required. The main challenge is modeling the temporal dynamics. But we can still (wisely) select shorter videos but with enough frames change. We need better structures to model the temporal Dynamics. The two contributed datasets on mountain biking and horseback riding could be useful for future research especially to evaluate temporal consistency.",0.1228070175438596,0.7423621416091919,0.7795364856719971,0.7604953050613403,INCORRECT,0.9555850625038148,"The paper discusses a method for generating long videos in which new content is introduced as the camera moves forwards. It has been shown that training at high res both in space and time is prohibitively expensive. The proposed framework is reasonable and seems to be working well on the proposed datasets. The paper fails to report UCF, FaceForensics and others from stylegan-v & tats, arguing that these datasets contain less new content and camera movements. While this method focuses on the temporal part of videos, it's not clear what's the resolution upper bound. The main challenge is modeling the temporal dynamics. But we can still (wisely) select shorter videos but with enough frames change. We need better structures to model the temporal Dynamics.","The paper discusses a method for generating long videos in which new content is introduced as the camera moves forwards. It has been shown that training at high res both in space and time is prohibitively expensive. The paper fails to report UCF, FaceForensics and others from stylegan-v & tats, arguing that these datasets contain less new content and camera movements. While this method focuses on the temporal part of videos, it's not clear what's the resolution upper bound of the proposed framework. The proposed model outperforms prior methods especially qualitatively on aspects including generating plausible dynamics and object persistence. It may not handle low dynamics. Although the method works better for high dynamics, it may not handling low dynamics, as the main reason for low dynamics in video generation models is data.",0.1320754716981132,0.1357466063348416,0.756446123123169,0.7490997314453125,0.7858142852783203,0.7733660936355591,0.7708505392074585,0.7610395550727844,INCORRECT,INCORRECT,0.996531069278717,0.9972049593925476
42,"The reviewers were generally split on this paper. On the one hand, reviewers generally appreciated the clear presentation, discussion, and explanations, and the experiments. On the other hand, most reviewers commented on the lack of comparative evaluation to other works, including works that are related conceptually. While the authors have a potentially reasonable argument for omitting such comparisons, in the balance I do not believe that the reviewers were actually convinced by this. Particularly when the novelty of the contribution is not crystal clear, such comparisons are important, so I am inclined to not recommend acceptance at this point (though I acknowledge that the paper is clear borderline and could be accepted).

","Reviews of papers on deep learning and neural networks. Please provide confidence intervals on your results. If you have the compute, please make your code available in an anonymous repository, and publicly available at the end of the review session. The code is not available (as far as I can see). I think this is interesting research and highlights a general and contemporary challenge when training deep neural Networks. The problem is well motivated and the implementation well described. I would like to see how this holds up against state-of-the-art in sparsity. The experiments are extensive, however, as this is not compared against any other model in the field. More results and explanations are required. It would be better to compare the proposed method with model compression methods.",0.1646090534979424,0.7537288665771484,0.7681865692138672,0.7608890533447266,INCORRECT,0.9398958683013916,"Reviews of papers on the same topic are published on the arXiv.org site. Please share your summaries of the reviews to help us understand the paper better. For example, please share your results on how the paper compares to other models. For more information on the ArXiv site, please visit: http://www.arxiv.com/2013/01061/arXiv-Reviews-of-Deep-Learning-Paper-2.html. The Arxiv site also offers the option of posting your own reviews of the same paper, which you can do by clicking on the link at the bottom of the page. To see more reviews of this paper, please go to: www.arXI.org/2012/01071/ArXI-Review-Of-Deep Learning Paper- 2.","Reviews of the paper are published on the arXiv.org website. The reviews are meant to help readers understand the paper's main points and weaknesses. This article includes summaries of all the reviews on the paper. For more information on the reviews, see the arxiv.com/2013/01/07/arXiv-Reviews-Paper- summaries-Report-Report.html. The ArXiv version of this article includes the summaries from the other reviews. We are happy to clarify any differences between these reviews and those of our own. For the full list of reviews, please see the Arxiv site here. The arXIV version ofthis article also includes the full version of the ArXIV- Reviewer's Report, which can be found on the ARXiv site.",0.1826086956521739,0.1802575107296137,0.6390900611877441,0.6859186291694641,0.7209643721580505,0.7440863847732544,0.6775627732276917,0.7138194441795349,INCORRECT,INCORRECT,0.66628497838974,0.8255179524421692
43,"All reviewers agree that the author's response has addressed their primary concerns. Reviewer frMM had two reservations that resulted in a borderline rating 1) concerns about how the adversarial samples were generated and 2) a request for evaluation on AntMaze. The author's followup response and further experiments address 1 and partially 2. It would be great to see RORL results on AntMaze in the final version.

Overall, the performance of RORL is competitive with state-of-the-art methods on Mujoco and Adroit tasks with fewer ensemble elements needed. The main benefit is on improved performance against adversarial attack, where RORL significantly improves over existing methods. I think the paper makes a nice contribution that the community will find valuable.

I encourage the authors to think carefully about how to integrate the additional experiments into the paper to resolve the questions raised by reviewers.




","Theoretical Algorithms is published in the open-source journal, TheoreticalAlgorithms. The paper investigates the problem of training robust RL agents with offline datasets. It claims that regularizing policy and value networks to have similar values against adversarial perturbations can achieve state-of-the-art performance in both standard and adversarial settings. The proposed method achieved strong results on mujoco tasks from D4RL datasets. The authors handled my major concerns on approximation and experiments by providing additional responses and adding more experiments. It would be nice if the authors can evaluate on more challenging tasks such as AntMaze or Atari. Because of that, I'd like to suggest ""weak reject"" but I'm also willing to change my score based on other reviews and author responses.",0.1476014760147601,0.7975001335144043,0.7935425043106079,0.7955163717269897,INCORRECT,0.999990463256836,"Theoretical Algorithms is published in the open-source journal, Theoretical. Algorithm employs the ensemble Q functions. The proposed method achieved strong results on mujoco tasks from D4RL datasets. It would be nice if the authors can evaluate on more challenging tasks such as AntMaze or Atari. Because of that, I'd like to suggest ""weak reject"" but I'm also willing to change my score based on other reviews and author responses. It is unclear whether or not the ensemble Technique brings the main contribution to robustness. Theoretically, the proposed framework (RORL) enjoys a tighter suboptimality bound that PBRL. It will be interesting to see the actual effect on the compute time as a percentage of the total training time.","Theoretical Algorithms is published in the open-source journal, TheoreticalAlgorithms. The paper investigates the problem of training robust RL agents with offline datasets. It claims that regularizing policy and value networks to have similar values against adversarial perturbations can achieve state-of-the-art performance on the D4RL benchmarks in both standard and adversarial settings. Below are multiple summaries of different reviews on the same paper. Summarize the main content, strengths, weaknesses of the paper based on the reviews, and decide on whether the paper is accepted or rejected. The proposed RORL is also very close to the ensemble baseline EDAC. The authors handled my major concerns on approximation and experiments by providing additional responses and adding more experiments.",0.1654135338345864,0.1735849056603773,0.7815257906913757,0.7839127779006958,0.7735159397125244,0.7784631848335266,0.7775002121925354,0.7811784744262695,INCORRECT,INCORRECT,0.9999077320098876,0.9999916553497314
44,"Three out of four reviewers are positive about the paper after the author response and during the discussion.

Strengths include
* The proposed method for parameter reduction in transformers allows end-2-end learning cross-modal representations especially on long videos, which has not been possible before
* Good performance on audio and video understanding
* Extensive set of ablations

Concerns include a somewhat incremental nature of the paper and the still large computational resources to run the experiments.
I think, both, the ideas and results are interesting to the community and recommend accept.

","The authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. The AV representations are learned by training the network to solve two self-supervised pertaining tasks, and subsequently evaluated on various audio/visual downstream tasks. The authors imply that using a partially fixed model (as has been done with multimodal vision/language tasks) is inferior to end-to-end training, which is the major technical contribution of this work, as presented by the authors. The paper is a nice read. It builds on a line of research on multi-modal video understanding that utilises transformers where these works: 1) fix one of the transformer models (e.g. BERT) and 2) utilise tokens and thus do not train the approach in an end- to-end fashion.",0.1428571428571428,0.7657951712608337,0.7746636271476746,0.7702038288116455,INCORRECT,0.9911888837814332,"The paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio-visual representation learning. The models are pretrained on Kinetics-700 and AudioSet and evaluated on UCF101, ESC-50, and Kinectics-Sounds. It proposes ablations for which weights/layers to share across modalities, when/where to fuse/join both modalities,. and other modeling details (that matter) The authors imply that using a partially fixed model (as has been done with multimodal vision/language tasks) is inferior to end-to-end training. The authors claim that the proposed model is more effective in handling long videos. But, only results on Charades and KS are shown without extensive comparisons.","The authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. The AV representations are learned by training the network to solve two self-supervised pertaining tasks, and subsequently evaluated on various audio/visual downstream tasks. The authors imply that using a partially fixed model (as has been done with multimodal vision/language tasks) is inferior to end-to-end training, which is the major technical contribution of this work, as presented by the authors. The paper is a nice read. It builds on a line of research on multi-modal video understanding that utilises transformers. It's true that the number of parameters has dropped significantly, but in any forward/backward pass, the memory requirements of multiple slow-fast (ResNet-50) with all transformers in memory.",0.1553398058252427,0.1244444444444444,0.7757155895233154,0.7720762491226196,0.7779855132102966,0.7756298184394836,0.7768488526344299,0.7738489508628845,INCORRECT,INCORRECT,0.8668009042739868,0.9487356543540956
45,"This paper proposes a method for inspecting and interpreting the visual representations learned by self-supervised methods. 
The method is conceptually simple and intuititive, the authors assume that concept labels for the images are available, and then go on to learn a mapping between the learned image vectors and the human-provided descriptions of the images. The key insight is to learn a reverse mapping, i.e., to map label vectors to representation vectors. Specifically, feature vectors are quantized using k-means to obtain clusters;  images are labeled (automatically) with a diverse set of concepts from expert models trained with supervision on
external data sources, and  a linear model is trained  to map concepts to clusters, measuring the mutual information between the representation and human-interpretable concepts.

Reviewers raised some questions regarding the relation of the approach to topic models, the difference between reverse probing and linear probing, implementation details and computation. The authors addressed reviewers comments convincingly with additional experiments and/or explanations.

","The paper aims to measure the interpretability of the visual representations learned by the recent self-supervised models. It proposes reverse linear probing, a post-hoc method that aims at predicting a quantized version of the internal representation (as observed in specific examples) from semantic label. While the problem studied in the paper is very interesting, at this moment, I don't see any obvious advantages of the proposed method over a simple linear probing. It is not clear how the quantized representation $f_K(x)$ is actually computed. The idea of having the proposed probing in reverse order is, to best of my knowledge novel to me. It might be good to provide some details on the proposed linear probe. The paper is not yet ready for publication at ICLR.",0.1966101694915254,0.7885891795158386,0.7841152548789978,0.7863458395004272,INCORRECT,0.9854889512062072,"The paper aims to measure the interpretability of the visual representations learned by the recent self-supervised models. It proposes reverse linear probing, a post-hoc method that aims at predicting a quantized version of the internal representation (as observed in specific examples) from semantic label. The paper finds that models trained on ImageNet images capture more than just semantic class labels. They capture information about textures, scenes, objects, etc. They also identified that OBoW, does really well even with only 200 epochs (though the reasons for why is still left to be investigated). Clustering-based approaches generally produce more interpretable representations. It is not clear how the quantized representation $f_K(x)$ is actually computed. It might be good to provide some details on the proposed linear probing.","The paper aims to measure the interpretability of the visual representations learned by the recent self-supervised models. It proposes reverse linear probing, a post-hoc method that aims at predicting a quantized version of the internal representation (as observed in specific examples) from semantic label. Code related to the paper will be released upon the publication of the manuscript. In the current state I believe the paper is not yet ready for publication at ICLR. It is not clear how the quantized representation $f_K(x)$ is actually computed. The idea of having the proposed probing in reverse order is, to best of my knowledge novel to me. It might be good to provide some details on the proposed linear probing. I enjoyed reading the paper - it is well written and the proposed approach is simple. There are also issues that relate to 1) positioning with respect to related work, and 2) the ability for the reader to draw insights from the analysis.",0.1774744027303754,0.1951219512195122,0.7976370453834534,0.7784399390220642,0.792328953742981,0.7913915514945984,0.7949740886688232,0.7848622798919678,CORRECT,INCORRECT,0.7183845639228821,0.971699059009552
46,"The reviews are generally positive (though somewhat short), and a large pre-training corpus for legal text will likely be useful for NLP research. One reviewer gave a reject score (5) with the following two weaknesses:

A) The dataset comes from a wide spectrum of law-related data sources, which may differ substantially and hence limit the usefulness of the dataset.

B) Privacy


I am not too worried about Point A because large language models seem to be able to learn from diverse data sources.

Regarding Point B, the separate ethics review mentions the privacy concerns as well but finds that the submission sufficiently discusses this concern and sees no serious ethical issues.

Hence overall I recommend accepting the paper.


","The paper presents a dataset of open-source English-language legal and administrative data. It covers court opinions, contracts, administrative rules, and legislative records. Unfortunately, it contains mainly US/Canada legal domain. The accompanying PoL-BERT language models do not seem to be trained optimally and their usefulness may be limited. The paper is well written and the issue is timely. The released corpus is comprehensive and will be useful for studying legal AI. For confidential support call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit http://www.suicidepreventionlifeline.org/. The paper was published by the Open Data Institute (ODI) in the U.S. and is available on the ODI website.",0.1531914893617021,0.7474038600921631,0.7661488652229309,0.7566602826118469,INCORRECT,0.9955822825431824,"The paper presents a dataset of open-source English-language legal and administrative data. It covers court opinions, contracts, administrative rules, and legislative records. Unfortunately, it contains mainly US/Canada legal domain. The accompanying PoL-BERT language models do not seem to be trained optimally and their usefulness may be limited. The paper is well written and the issue is timely. The released corpus is comprehensive and will be useful for studying legal AI. For confidential support call the National Suicide Prevention Lifeline at 1-800-273-8255 or visit http://www.suicidepreventionlifeline.org/. The paper was published by the Open Data Institute (ODI) in the U.S. and is available on the ODI website.","The paper compiles a dataset from various sources into one unified format for use in downstream research. This dataset can be used for pre-training (since it is not labelled for any specific purpose) and can provide useful insights into various social issues. Unfortunately, it contains mainly US/Canada legal domain. The accompanying PoL-BERT language models do not seem to be trained optimally and their usefulness may be limited. The paper was published by the Open Data Institute (ODI) in the U.S. and is available on the ODI website. For confidential support call the National Suicide Prevention Lifeline at 1-800-273-TALK (8255) or visit www.suicidepreventionlifeline.org.",0.1531914893617021,0.1471861471861471,0.7474038600921631,0.7656207084655762,0.7661488652229309,0.7727616429328918,0.7566602826118469,0.7691746354103088,INCORRECT,INCORRECT,0.9955822825431824,0.9916040301322936
47,"The paper presents a new problem: open-set single domain generalization, where only one source domain is available and unknown classes and unseen target domains increase the difficulty of the task. To tackle this challenging problem, this paper designs a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. Then, the paper proposes a cross-classifier consistency regularization that minimizes the multi-binary classifier's output and one-vs-all multi-class classifier's output. 

The proposed OS-SDG is an interesting and realistic problem. However, since it is way more challenging, the optimal solution to it remains elusive. Some reviewers think the method might be heuristic and lack theoretical guarantees. Nevertheless, the results are promising and the paper makes a first step toward the challenging OS-SDG problem. Another concern is that the CCR loss needs more ablation studies to further analyze its role. Though the authors have added more explanation of this part, I suggest the authors put more ablation studies in the final supplementary document. 

Overall, the paper is novel and interesting.  I would recommend acceptance of this paper given its novelty and impressive performance, but I highly suggest the authors add more ablation studies in the final supplementary, as suggested by the reviewers.

","The paper presents a new task: open-set single domain generalization, where only one source domain is available and unknown classes and unseen target domains increase the difficulty of the task. The experiments show the proposed method could largely improve the accuracy for unknown classes in the target domain. The paper is well-written and is technically sound and the proposed problem makes sense. However, some theoretical analysis should be addressed in the revision of the paper. I increase my score from 6 to 8, and increase the number of points on the scorecard from 5 to 8. The authors have also published a new version of this article. The study was published in the journal IEEE Trans on KDE, 2009, and can be downloaded for free from the site. It is available for download in the U.S., Canada, and the UK, with prices starting at $3.99 each.",0.3237597911227153,0.8042850494384766,0.7963771224021912,0.8003115057945251,INCORRECT,0.9997645020484924,"This paper proposes a new method called CrossMatch for open-set single domain generalization where only one source domain is available to train the model. CrossMatch designs a new strategy to generate auxiliary samples for unknown classes and develops a novel consistency regularization to help identify samples from unknown classes in target domains. Results on several datasets verify that the proposed method achieves impressive results on three widely-used datasets. However, CrossMatch is mainly built on several previous methods, e.g., the multi-binary classifier (Liu et al., 2019; Saito & Saenko, 2021) and adversarial data augmentation, making the overall novelty incremental for ICLR. I vote for ""weak reject"" for the proposed CrossMatch scheme. The study was published in the journal IEEE Trans on KDE, 2009, and can be downloaded for free from the site.","This paper proposes a new method called CrossMatch for open-set single domain generalization. CrossMatch designs a new strategy to generate auxiliary samples for unknown classes. It also develops a novel consistency regularization to help identify samples from unknown classes in target domains. The study was published in the journal IEEE Trans. on KDE, 2009, and can be downloaded for free from the site. The paper is available for download in the U.S., Canada, and the UK, with prices starting at $3.99 per download. The authors have also published a new version of this article. For more information on the study, visit the IEEE Trans on KDE website or go to: http://www.iclr.org/doi/abs/10.1145/ICLR.2009/09/08/07/0737/0837/0937/0736/0738/0739/0740/0760/0770/0720/0780/0710/0700/0750/0790/07100/07000/07600/071000/07200/07400/072000/07300/07 1900/073000/071900/0730/07700/07900/070000/071200/0719/071500/0715/071600/071800/071300/0620/0820/062000/063000/06300/061000/06100/082000/083000/08 1900/06 1900/081000/081900/061900/08300/0805/0709/071960/07 1700/08200/081500/0819/081600/0815/082020/071700/0920",0.2125340599455041,0.1545667447306791,0.8103172183036804,0.602922797203064,0.7916278839111328,0.7654862403869629,0.80086350440979,0.6745484471321106,INCORRECT,CORRECT,0.9943673014640808,0.5958397388458252
48,"Overall, this paper achieves strong and interesting results regarding the query complexity of submodular maximization. One reviewer was concerned that the lower bound result was maybe a folklore result that is easy to prove. However, sufficient evidence to justify that claim was not provided and other reviewers did not share the same concern.

","The paper studies the problem of submodular maximization under cardinality/knapsack constraints. The goal is to maximize the function value, for cardinality constraints, the algorithm is allowed to select up to k elements. The approximation ratio is optimal, but the stochastic greedy algorithm (a randomized algorithm) has better oracle complexity of $O(n\log(1/\epsilon)$. A nearly lower bound is also proved in the paper (but I am not sure whether these are folklores...) The paper is fairly well written and clear. The related work section is very rich. The experiments are clearly not the main focus of the submission and I would rather see them as a proof of concept that the algorithm works.",0.1538461538461538,0.7607387900352478,0.8114296197891235,0.7852669954299927,INCORRECT,0.9933059811592102,"The paper studies the problem of submodular maximization under cardinality/knapsack constraints. The goal is to maximize the function value, for cardinality constraints, the algorithm is allowed to select up to k elements. The approximation ratio is optimal, but the stochastic greedy algorithm (a randomized algorithm) has better oracle complexity of $O(n\log(1/\epsilon)$. A nearly lower bound is also proved in the paper (but I am not sure whether these are folklores...) There is no reason one restricts to deterministic instead of randomize algorithm, this decreases the value of the paper a lot. no no no, I believe I convince the author that my main concern is (1) the significance of lower bound (I still believe it is more like a folklore result, but nice effort to write it down)","The paper studies (mainly monotone) submodular maximization subject to various types of constraints. The authors conduct experiments on real-world datasets to show the practical advantages of the proposed algorithm to SOTA algorithms. The algorithm is very clean and natural and the proof of the approximation guarantee is easy to follow. A nearly lower bound is also proved in the paper (but I am not sure whether these are folklores...) The paper is fairly well written and clear. The related work section is very rich. I would just mention that the authors might want to spend some words on the case of non-monotone objectives, for cardinality constraint see e.g. Kuhnle AAAI21, while for knapsack see Amanatidis et al. NeurIPS 20.",0.1505376344086021,0.1257142857142857,0.740327000617981,0.7532947063446045,0.8090957403182983,0.8251667022705078,0.7731853127479553,0.7875944375991821,CORRECT,INCORRECT,0.6694293022155762,0.988962471485138
49,"This paper tackles the problem of feature interactions identification in black-box models, which is an important problem towards achieving explainable AI/ML. The authors formulate the problem under the multi-armed bandit setting and propose a solution based on the UCB algorithm. This simplification of the problem leads to a computationally feasible solution, for which the authors provide several theoretical analyses. The importance of the learned interactions is showcased in a new deep learning model leveraging these interactions, leading to a reduction in model size (thereby competing against pruning methods) as well as an improvement in accuracy (thereby competing against generalization methods). Although the proposed approach essentially builds on the specific UCB algorithm, it could likely be extended/modified to other (potentially more efficient) bandit strategies. A drawback of this work resides in the experiments being entirely synthetics. In order to close the gap with practice, experiments on real datasets of higher dimensionality should be conducted.
","The authors propose two key ideas. The first is the idea of using the UCB algorithm to identify strong feature interactions in a computationally efficient way. The second is using the identified pairwise interactions to build a lightweight GAM-like model that they call ParaACE. In experiments, the authors show theUCB approach is effective at identifying feature interactions compared to alternative methods. They demonstrate that Para ACE offers strong gains in model compression compared to other competing approaches, and often improves performance relative to its overparameterized teacher model. The paper is thoroughly written with sound technical backing - especially the code sharing and the content will help in improving the state of art in explainableDeep learning approaches. This paper is recommended for acceptance at ICLR.",0.1850533807829181,0.7977973818778992,0.7902376055717468,0.7939994931221008,CORRECT,0.843977689743042,"The paper uses the UCB algorithm to identify strong feature interactions in a computationally efficient way. The second is using the identified pairwise interactions to build a lightweight GAM-like model that they call ParaACE. In experiments, the authors show theUCB approach is effective at identifying feature interactions compared to alternative methods. They demonstrate that Para ACE offers strong gains in model compression compared to other competing approaches, and often improves performance relative to its overparameterized teacher model. The paper is thoroughly written with sound technical backing - especially the code sharing and the content will help in improving the state of the art in explainableDeep learning approaches. This paper is recommended for acceptance at ICLR. Please summarize the paper reviews and decide on whether the paper is accepted or rejected.","The authors propose two key ideas. The first is the idea of using the UCB algorithm to identify strong feature interactions in a computationally efficient way. The second is using the identified pairwise interactions to build a lightweight GAM-like model that they call ParaACE. In experiments, the authors show theUCB approach is effective at identifying feature interactions compared to alternative methods. They demonstrate that Para ACE offers strong gains in model compression compared to other competing approaches, and often improves performance relative to its overparameterized teacher model. The paper is thoroughly written with sound technical backing - especially the code sharing and the content will help in improving the state of art in recent advances in explainableDeep learning approaches. This paper is recommended for acceptance at ICLR.",0.1742160278745644,0.1830985915492957,0.7928285598754883,0.796970784664154,0.7871184349060059,0.7903579473495483,0.7899631857872009,0.7936505675315857,CORRECT,CORRECT,0.9945399165153505,0.8604899048805237
