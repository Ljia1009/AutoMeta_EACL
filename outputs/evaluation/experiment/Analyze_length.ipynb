{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bedecfe6-b2e0-4c32-bc13-9e891cb22a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# compare length\n",
    "df = pd.read_csv(\"length_summary.csv\")\n",
    "\n",
    "df_filtered = df[(df['rouge_score_'] < df['rouge_score_v1']) | (df['rouge_score_'] < df['rouge_score_v2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0c78b1c-5cd3-4e19-adbe-67395339b9fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean for min_length = 40 and 90 is 0.1639564005212592\n",
      "mean for min_length = 100 is 0.1713935948854972\n",
      "mean for min_length = 150 and dynamic max length is 0.17092215904345745\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean for min_length = 40 and 90 is {df['rouge_score_'].mean()}\")\n",
    "print(f\"mean for min_length = 100 is {df['rouge_score_v1'].mean()}\")\n",
    "# max_length = dynamic (the min length of the same input batch, so that the output will not be longer than the input).\n",
    "print(f\"mean for min_length = 150 and dynamic max length is {df['rouge_score_v2'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f716851-9e32-4dc2-b6af-21e99f535a03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gold</th>\n",
       "      <th>prediction_</th>\n",
       "      <th>rouge_score_</th>\n",
       "      <th>bertscore_precision_</th>\n",
       "      <th>bertscore_recall_</th>\n",
       "      <th>bertscore_f1_</th>\n",
       "      <th>factCC_label_</th>\n",
       "      <th>factCC_score_</th>\n",
       "      <th>prediction_v1</th>\n",
       "      <th>...</th>\n",
       "      <th>bertscore_precision_v1</th>\n",
       "      <th>bertscore_precision_v2</th>\n",
       "      <th>bertscore_recall_v1</th>\n",
       "      <th>bertscore_recall_v2</th>\n",
       "      <th>bertscore_f1_v1</th>\n",
       "      <th>bertscore_f1_v2</th>\n",
       "      <th>factCC_label_v1</th>\n",
       "      <th>factCC_label_v2</th>\n",
       "      <th>factCC_score_v1</th>\n",
       "      <th>factCC_score_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The paper investigates the capacity for neural...</td>\n",
       "      <td>The authors use a 3D world to explore grounded...</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.809728</td>\n",
       "      <td>0.764374</td>\n",
       "      <td>0.786398</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.927479</td>\n",
       "      <td>The authors use a 3D world to explore grounded...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803796</td>\n",
       "      <td>0.769929</td>\n",
       "      <td>0.754871</td>\n",
       "      <td>0.754290</td>\n",
       "      <td>0.778566</td>\n",
       "      <td>0.762030</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.710058</td>\n",
       "      <td>0.583747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This paper considers the problem of (biologica...</td>\n",
       "      <td>The authors implement an open-source simulatio...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.811689</td>\n",
       "      <td>0.770215</td>\n",
       "      <td>0.790408</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.998772</td>\n",
       "      <td>The authors implement an open-source simulatio...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798175</td>\n",
       "      <td>0.786170</td>\n",
       "      <td>0.757699</td>\n",
       "      <td>0.779647</td>\n",
       "      <td>0.777411</td>\n",
       "      <td>0.782895</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998167</td>\n",
       "      <td>0.995018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The authors provide a benchmark for federated ...</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>0.773782</td>\n",
       "      <td>0.744870</td>\n",
       "      <td>0.759050</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.880897</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778559</td>\n",
       "      <td>0.787477</td>\n",
       "      <td>0.753572</td>\n",
       "      <td>0.783919</td>\n",
       "      <td>0.765862</td>\n",
       "      <td>0.785694</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.994379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>This paper studies a timely problem and consid...</td>\n",
       "      <td>The proposed approach formalizes an intuitive ...</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>0.796270</td>\n",
       "      <td>0.736958</td>\n",
       "      <td>0.765467</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>The proposed approach formalizes an intuitive ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774090</td>\n",
       "      <td>0.766169</td>\n",
       "      <td>0.738067</td>\n",
       "      <td>0.748969</td>\n",
       "      <td>0.755650</td>\n",
       "      <td>0.757472</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999886</td>\n",
       "      <td>0.915543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>The paper addresses the problem of domain gene...</td>\n",
       "      <td>This work tackles the task of forecasting dyna...</td>\n",
       "      <td>0.093489</td>\n",
       "      <td>0.810253</td>\n",
       "      <td>0.723361</td>\n",
       "      <td>0.764346</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.999429</td>\n",
       "      <td>Reviews of a paper on deep learning for foreca...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810620</td>\n",
       "      <td>0.791914</td>\n",
       "      <td>0.736875</td>\n",
       "      <td>0.750096</td>\n",
       "      <td>0.771990</td>\n",
       "      <td>0.770438</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.989380</td>\n",
       "      <td>0.998889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>After careful review, I believe that this pape...</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>0.172185</td>\n",
       "      <td>0.775010</td>\n",
       "      <td>0.791754</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.966194</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.776609</td>\n",
       "      <td>0.773469</td>\n",
       "      <td>0.799102</td>\n",
       "      <td>0.814482</td>\n",
       "      <td>0.787695</td>\n",
       "      <td>0.793446</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.599852</td>\n",
       "      <td>0.999715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>This paper proposes a few-shot (untargeted) ba...</td>\n",
       "      <td>The paper introduces a variant of backdoor att...</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.853242</td>\n",
       "      <td>0.795741</td>\n",
       "      <td>0.823489</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.998917</td>\n",
       "      <td>The paper introduces a variant of backdoor att...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842248</td>\n",
       "      <td>0.796666</td>\n",
       "      <td>0.798380</td>\n",
       "      <td>0.803829</td>\n",
       "      <td>0.819727</td>\n",
       "      <td>0.800231</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.979119</td>\n",
       "      <td>0.599923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>This is a borderline paper. The scores were in...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>0.124294</td>\n",
       "      <td>0.766519</td>\n",
       "      <td>0.771293</td>\n",
       "      <td>0.768899</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.988653</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.756070</td>\n",
       "      <td>0.760831</td>\n",
       "      <td>0.767380</td>\n",
       "      <td>0.789703</td>\n",
       "      <td>0.761683</td>\n",
       "      <td>0.774998</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.998538</td>\n",
       "      <td>0.980454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Pros:\\n- Provides a practical technique which ...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.773293</td>\n",
       "      <td>0.731262</td>\n",
       "      <td>0.751691</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.899950</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800622</td>\n",
       "      <td>0.798954</td>\n",
       "      <td>0.771599</td>\n",
       "      <td>0.784747</td>\n",
       "      <td>0.785843</td>\n",
       "      <td>0.791786</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.995916</td>\n",
       "      <td>0.992283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>The authors present a matrix factorization for...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.838688</td>\n",
       "      <td>0.808128</td>\n",
       "      <td>0.823125</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.997411</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.886838</td>\n",
       "      <td>0.823624</td>\n",
       "      <td>0.858465</td>\n",
       "      <td>0.829720</td>\n",
       "      <td>0.872421</td>\n",
       "      <td>0.826661</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.986336</td>\n",
       "      <td>0.986651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>The paper proposes a semi-supervised segmentat...</td>\n",
       "      <td>The paper is generally well written, only has ...</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.773700</td>\n",
       "      <td>0.744869</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.938079</td>\n",
       "      <td>The paper addresses the highly relevant and im...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791646</td>\n",
       "      <td>0.780757</td>\n",
       "      <td>0.755816</td>\n",
       "      <td>0.765056</td>\n",
       "      <td>0.773316</td>\n",
       "      <td>0.772826</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.671082</td>\n",
       "      <td>0.540793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>The paper addresses generalized zero shot lear...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>0.138686</td>\n",
       "      <td>0.830301</td>\n",
       "      <td>0.723330</td>\n",
       "      <td>0.773133</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.940214</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827128</td>\n",
       "      <td>0.814190</td>\n",
       "      <td>0.728936</td>\n",
       "      <td>0.748339</td>\n",
       "      <td>0.774934</td>\n",
       "      <td>0.779877</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.979197</td>\n",
       "      <td>0.999126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>The paper presents a construction for deep lea...</td>\n",
       "      <td>Proposed point spatio-temporal (PST) convoluti...</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.753125</td>\n",
       "      <td>0.780204</td>\n",
       "      <td>0.766425</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.999006</td>\n",
       "      <td>The paper is, for the most part, well-written ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.753234</td>\n",
       "      <td>0.754435</td>\n",
       "      <td>0.780765</td>\n",
       "      <td>0.805682</td>\n",
       "      <td>0.766752</td>\n",
       "      <td>0.779217</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.846436</td>\n",
       "      <td>0.997301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>The paper develops a theoretical framework (in...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.800900</td>\n",
       "      <td>0.743929</td>\n",
       "      <td>0.771364</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.966229</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802893</td>\n",
       "      <td>0.811639</td>\n",
       "      <td>0.770139</td>\n",
       "      <td>0.789193</td>\n",
       "      <td>0.786175</td>\n",
       "      <td>0.800259</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.531630</td>\n",
       "      <td>0.779545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Three experts reviewed this paper and all reco...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.705821</td>\n",
       "      <td>0.711631</td>\n",
       "      <td>0.708714</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.997675</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.691064</td>\n",
       "      <td>0.723260</td>\n",
       "      <td>0.693671</td>\n",
       "      <td>0.765685</td>\n",
       "      <td>0.692365</td>\n",
       "      <td>0.743868</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.995368</td>\n",
       "      <td>0.985876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>I agree with the concerns raised by the review...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>0.154472</td>\n",
       "      <td>0.788292</td>\n",
       "      <td>0.727108</td>\n",
       "      <td>0.756465</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998909</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750898</td>\n",
       "      <td>0.767936</td>\n",
       "      <td>0.729662</td>\n",
       "      <td>0.752396</td>\n",
       "      <td>0.740128</td>\n",
       "      <td>0.760087</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999629</td>\n",
       "      <td>0.999033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>This paper studied imitation learning in the c...</td>\n",
       "      <td>The authors provide (1) an impossibility resul...</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.810672</td>\n",
       "      <td>0.813940</td>\n",
       "      <td>0.812303</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.997016</td>\n",
       "      <td>The main contributions include: Theoretical gu...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793149</td>\n",
       "      <td>0.771975</td>\n",
       "      <td>0.801371</td>\n",
       "      <td>0.834725</td>\n",
       "      <td>0.797239</td>\n",
       "      <td>0.802124</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998262</td>\n",
       "      <td>0.999367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>The paper makes a novel contribution to method...</td>\n",
       "      <td>This paper proposes a zero-shot drug design me...</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.796861</td>\n",
       "      <td>0.772002</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999077</td>\n",
       "      <td>The method involves two stages: first sketchin...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798664</td>\n",
       "      <td>0.786154</td>\n",
       "      <td>0.770831</td>\n",
       "      <td>0.796166</td>\n",
       "      <td>0.784501</td>\n",
       "      <td>0.791128</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.719019</td>\n",
       "      <td>0.987138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>The paper considers a collaborative decision-m...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.806592</td>\n",
       "      <td>0.757089</td>\n",
       "      <td>0.781057</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.999731</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813369</td>\n",
       "      <td>0.791074</td>\n",
       "      <td>0.779136</td>\n",
       "      <td>0.782508</td>\n",
       "      <td>0.795884</td>\n",
       "      <td>0.786768</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999607</td>\n",
       "      <td>0.996460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>Reviewers generally agree that the main result...</td>\n",
       "      <td>The application section is in particular way t...</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.791248</td>\n",
       "      <td>0.755582</td>\n",
       "      <td>0.773004</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.954507</td>\n",
       "      <td>The paper considers Group Equivariant Convulat...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767727</td>\n",
       "      <td>0.792526</td>\n",
       "      <td>0.746845</td>\n",
       "      <td>0.768065</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.780104</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.962826</td>\n",
       "      <td>0.942590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>There is a clear consensus to accept this manu...</td>\n",
       "      <td>Theory analysis is extensive, and the presenta...</td>\n",
       "      <td>0.096712</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.664364</td>\n",
       "      <td>0.722764</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>The paper studies the random covariance matrix...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785577</td>\n",
       "      <td>0.787341</td>\n",
       "      <td>0.672480</td>\n",
       "      <td>0.681780</td>\n",
       "      <td>0.724643</td>\n",
       "      <td>0.730768</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.935718</td>\n",
       "      <td>0.999491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>The paper proposed a two-stage method to selec...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.754809</td>\n",
       "      <td>0.746819</td>\n",
       "      <td>0.750793</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.991421</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764340</td>\n",
       "      <td>0.781612</td>\n",
       "      <td>0.753822</td>\n",
       "      <td>0.789129</td>\n",
       "      <td>0.759044</td>\n",
       "      <td>0.785353</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.985589</td>\n",
       "      <td>0.959697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>Dear authors,\\n\\nYour proposition of adding a ...</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.796850</td>\n",
       "      <td>0.748646</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.857080</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787452</td>\n",
       "      <td>0.773646</td>\n",
       "      <td>0.761351</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.774181</td>\n",
       "      <td>0.772317</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.990498</td>\n",
       "      <td>0.995103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>This work proposes algorithms for solving ERM ...</td>\n",
       "      <td>Private gradient descent is an important mecha...</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>0.792490</td>\n",
       "      <td>0.766700</td>\n",
       "      <td>0.779382</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.995834</td>\n",
       "      <td>The problem studied is interesting and importa...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797088</td>\n",
       "      <td>0.777184</td>\n",
       "      <td>0.775010</td>\n",
       "      <td>0.786130</td>\n",
       "      <td>0.785894</td>\n",
       "      <td>0.781632</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.997362</td>\n",
       "      <td>0.853799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>This paper considers the task of training poli...</td>\n",
       "      <td>This paper tackles the problem of generalizing...</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.821843</td>\n",
       "      <td>0.737514</td>\n",
       "      <td>0.777398</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.931981</td>\n",
       "      <td>The paper focuses on learning latent represent...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.812512</td>\n",
       "      <td>0.816043</td>\n",
       "      <td>0.754181</td>\n",
       "      <td>0.775572</td>\n",
       "      <td>0.782260</td>\n",
       "      <td>0.795293</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.997291</td>\n",
       "      <td>0.988940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>The paper gives high probability bounds on exc...</td>\n",
       "      <td>The paper gives a high probability excess popu...</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.787597</td>\n",
       "      <td>0.689652</td>\n",
       "      <td>0.735377</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.999744</td>\n",
       "      <td>The paper achieves high probability excess ris...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.802888</td>\n",
       "      <td>0.800921</td>\n",
       "      <td>0.725820</td>\n",
       "      <td>0.732816</td>\n",
       "      <td>0.762412</td>\n",
       "      <td>0.765356</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.999646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>This paper goes beyond the NTK setting in anal...</td>\n",
       "      <td>Theoretical paper presents a theoretical analy...</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.793907</td>\n",
       "      <td>0.807321</td>\n",
       "      <td>0.800558</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999230</td>\n",
       "      <td>Reviewers give their verdict on a paper on opt...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800666</td>\n",
       "      <td>0.782594</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.824670</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.803081</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.999981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>37</td>\n",
       "      <td>The reviewers agree that from a decision tree ...</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.769897</td>\n",
       "      <td>0.782054</td>\n",
       "      <td>0.775928</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.792801</td>\n",
       "      <td>0.773969</td>\n",
       "      <td>0.787328</td>\n",
       "      <td>0.792067</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.782913</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998852</td>\n",
       "      <td>0.999637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>Summary of discussion: Three reviewers rated t...</td>\n",
       "      <td>The motivation of using the proposed network d...</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.780669</td>\n",
       "      <td>0.737170</td>\n",
       "      <td>0.758296</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.963947</td>\n",
       "      <td>A paper proposed a new method for blind image ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765604</td>\n",
       "      <td>0.768802</td>\n",
       "      <td>0.732391</td>\n",
       "      <td>0.754305</td>\n",
       "      <td>0.748630</td>\n",
       "      <td>0.761485</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.996367</td>\n",
       "      <td>0.998165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>This paper proposes a federated learning (FL) ...</td>\n",
       "      <td>A paper proposes a customisation strategy name...</td>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.826874</td>\n",
       "      <td>0.779806</td>\n",
       "      <td>0.802651</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.534821</td>\n",
       "      <td>The paper proposes a new federated learning sc...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862258</td>\n",
       "      <td>0.791115</td>\n",
       "      <td>0.824932</td>\n",
       "      <td>0.786245</td>\n",
       "      <td>0.843182</td>\n",
       "      <td>0.788672</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999357</td>\n",
       "      <td>0.999725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>40</td>\n",
       "      <td>The paper shows convergence results for RMSpro...</td>\n",
       "      <td>This work truly does merge the gap between the...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.758290</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.789796</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.996747</td>\n",
       "      <td>The paper studies one of the most popular algo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760586</td>\n",
       "      <td>0.677526</td>\n",
       "      <td>0.833760</td>\n",
       "      <td>0.789138</td>\n",
       "      <td>0.795494</td>\n",
       "      <td>0.729085</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.985983</td>\n",
       "      <td>0.998942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>All four reviewers enjoyed this paper and were...</td>\n",
       "      <td>The paper discusses a method for generating lo...</td>\n",
       "      <td>0.131737</td>\n",
       "      <td>0.755997</td>\n",
       "      <td>0.770373</td>\n",
       "      <td>0.763117</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>The paper addresses the problem of video gener...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755409</td>\n",
       "      <td>0.742362</td>\n",
       "      <td>0.760782</td>\n",
       "      <td>0.779536</td>\n",
       "      <td>0.758086</td>\n",
       "      <td>0.760495</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.955585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>43</td>\n",
       "      <td>All reviewers agree that the author's response...</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.798766</td>\n",
       "      <td>0.771712</td>\n",
       "      <td>0.785006</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784966</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.759474</td>\n",
       "      <td>0.793543</td>\n",
       "      <td>0.772010</td>\n",
       "      <td>0.795516</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>0.999990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>46</td>\n",
       "      <td>The reviews are generally positive (though som...</td>\n",
       "      <td>The paper compiles a dataset from various sour...</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>0.821731</td>\n",
       "      <td>0.767014</td>\n",
       "      <td>0.793430</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998710</td>\n",
       "      <td>The paper presents a dataset of open-source En...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.788670</td>\n",
       "      <td>0.747404</td>\n",
       "      <td>0.753319</td>\n",
       "      <td>0.766149</td>\n",
       "      <td>0.770589</td>\n",
       "      <td>0.756660</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.997772</td>\n",
       "      <td>0.995582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>47</td>\n",
       "      <td>The paper presents a new problem: open-set sin...</td>\n",
       "      <td>The paper presents a new task: open-set single...</td>\n",
       "      <td>0.261981</td>\n",
       "      <td>0.902086</td>\n",
       "      <td>0.769552</td>\n",
       "      <td>0.830565</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.998644</td>\n",
       "      <td>The paper presents a new task: open-set single...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.873434</td>\n",
       "      <td>0.804285</td>\n",
       "      <td>0.787560</td>\n",
       "      <td>0.796377</td>\n",
       "      <td>0.828277</td>\n",
       "      <td>0.800312</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.999531</td>\n",
       "      <td>0.999765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>Overall, this paper achieves strong and intere...</td>\n",
       "      <td>The paper studies (mainly monotone) submodular...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.773860</td>\n",
       "      <td>0.777355</td>\n",
       "      <td>0.775603</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.998548</td>\n",
       "      <td>The paper studies the problem of submodular ma...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770240</td>\n",
       "      <td>0.760739</td>\n",
       "      <td>0.800516</td>\n",
       "      <td>0.811430</td>\n",
       "      <td>0.785086</td>\n",
       "      <td>0.785267</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>0.867829</td>\n",
       "      <td>0.993306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>49</td>\n",
       "      <td>This paper tackles the problem of feature inte...</td>\n",
       "      <td>The authors propose two key ideas. The first i...</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.797096</td>\n",
       "      <td>0.773511</td>\n",
       "      <td>0.785126</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.803807</td>\n",
       "      <td>ParaACE is an algorithm that uses the UCB algo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804724</td>\n",
       "      <td>0.797797</td>\n",
       "      <td>0.772060</td>\n",
       "      <td>0.790238</td>\n",
       "      <td>0.788053</td>\n",
       "      <td>0.793999</td>\n",
       "      <td>INCORRECT</td>\n",
       "      <td>CORRECT</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.843978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                               gold  \\\n",
       "0            0  The paper investigates the capacity for neural...   \n",
       "1            1  This paper considers the problem of (biologica...   \n",
       "4            4  The authors provide a benchmark for federated ...   \n",
       "5            5  This paper studies a timely problem and consid...   \n",
       "6            6  The paper addresses the problem of domain gene...   \n",
       "7            7  After careful review, I believe that this pape...   \n",
       "10          10  This paper proposes a few-shot (untargeted) ba...   \n",
       "11          11  This is a borderline paper. The scores were in...   \n",
       "12          12  Pros:\\n- Provides a practical technique which ...   \n",
       "14          14  The authors present a matrix factorization for...   \n",
       "15          15  The paper proposes a semi-supervised segmentat...   \n",
       "16          16  The paper addresses generalized zero shot lear...   \n",
       "18          18  The paper presents a construction for deep lea...   \n",
       "19          19  The paper develops a theoretical framework (in...   \n",
       "20          20  Three experts reviewed this paper and all reco...   \n",
       "21          21  I agree with the concerns raised by the review...   \n",
       "22          22  This paper studied imitation learning in the c...   \n",
       "23          23  The paper makes a novel contribution to method...   \n",
       "24          24  The paper considers a collaborative decision-m...   \n",
       "26          26  Reviewers generally agree that the main result...   \n",
       "27          27  There is a clear consensus to accept this manu...   \n",
       "30          30  The paper proposed a two-stage method to selec...   \n",
       "31          31  Dear authors,\\n\\nYour proposition of adding a ...   \n",
       "32          32  This work proposes algorithms for solving ERM ...   \n",
       "33          33  This paper considers the task of training poli...   \n",
       "34          34  The paper gives high probability bounds on exc...   \n",
       "35          35  This paper goes beyond the NTK setting in anal...   \n",
       "37          37  The reviewers agree that from a decision tree ...   \n",
       "38          38  Summary of discussion: Three reviewers rated t...   \n",
       "39          39  This paper proposes a federated learning (FL) ...   \n",
       "40          40  The paper shows convergence results for RMSpro...   \n",
       "41          41  All four reviewers enjoyed this paper and were...   \n",
       "43          43  All reviewers agree that the author's response...   \n",
       "46          46  The reviews are generally positive (though som...   \n",
       "47          47  The paper presents a new problem: open-set sin...   \n",
       "48          48  Overall, this paper achieves strong and intere...   \n",
       "49          49  This paper tackles the problem of feature inte...   \n",
       "\n",
       "                                          prediction_  rouge_score_  \\\n",
       "0   The authors use a 3D world to explore grounded...      0.144737   \n",
       "1   The authors implement an open-source simulatio...      0.142857   \n",
       "4   The paper presents FLAIR, a large-scale image ...      0.151786   \n",
       "5   The proposed approach formalizes an intuitive ...      0.112782   \n",
       "6   This work tackles the task of forecasting dyna...      0.093489   \n",
       "7   The APT-36k dataset consists of 2,400 video se...      0.172185   \n",
       "10  The paper introduces a variant of backdoor att...      0.211538   \n",
       "11  The paper proposes an exploration method for \"...      0.124294   \n",
       "12  The authors proposed a novel neural Fourier op...      0.119048   \n",
       "14  The authors present a matrix factorization mod...      0.336449   \n",
       "15  The paper is generally well written, only has ...      0.136752   \n",
       "16  The paper considers the problem of (Generalize...      0.138686   \n",
       "18  Proposed point spatio-temporal (PST) convoluti...      0.178082   \n",
       "19  This paper builds upon the observation by Nakk...      0.109589   \n",
       "20  This is a look at some of the events that took...      0.177515   \n",
       "21  The method reduces 10.01M parameters of ResNet...      0.154472   \n",
       "22  The authors provide (1) an impossibility resul...      0.177515   \n",
       "23  This paper proposes a zero-shot drug design me...      0.211009   \n",
       "24  The paper looks at the problem of designing a ...      0.137313   \n",
       "26  The application section is in particular way t...      0.145455   \n",
       "27  Theory analysis is extensive, and the presenta...      0.096712   \n",
       "30  Stochastic subset selection (SSS) is a method ...      0.200000   \n",
       "31  This paper proposes the method which improves ...      0.155844   \n",
       "32  Private gradient descent is an important mecha...      0.107623   \n",
       "33  This paper tackles the problem of generalizing...      0.120482   \n",
       "34  The paper gives a high probability excess popu...      0.137168   \n",
       "35  Theoretical paper presents a theoretical analy...      0.136646   \n",
       "37  The paper \"MABSplit: Faster Forest Training Us...      0.173333   \n",
       "38  The motivation of using the proposed network d...      0.134276   \n",
       "39  A paper proposes a customisation strategy name...      0.163462   \n",
       "40  This work truly does merge the gap between the...      0.136364   \n",
       "41  The paper discusses a method for generating lo...      0.131737   \n",
       "43  The paper investigates the problem of training...      0.135135   \n",
       "46  The paper compiles a dataset from various sour...      0.157635   \n",
       "47  The paper presents a new task: open-set single...      0.261981   \n",
       "48  The paper studies (mainly monotone) submodular...      0.133333   \n",
       "49  The authors propose two key ideas. The first i...      0.184739   \n",
       "\n",
       "    bertscore_precision_  bertscore_recall_  bertscore_f1_ factCC_label_  \\\n",
       "0               0.809728           0.764374       0.786398       CORRECT   \n",
       "1               0.811689           0.770215       0.790408       CORRECT   \n",
       "4               0.773782           0.744870       0.759050     INCORRECT   \n",
       "5               0.796270           0.736958       0.765467     INCORRECT   \n",
       "6               0.810253           0.723361       0.764346       CORRECT   \n",
       "7               0.775010           0.791754       0.783293     INCORRECT   \n",
       "10              0.853242           0.795741       0.823489       CORRECT   \n",
       "11              0.766519           0.771293       0.768899       CORRECT   \n",
       "12              0.773293           0.731262       0.751691     INCORRECT   \n",
       "14              0.838688           0.808128       0.823125     INCORRECT   \n",
       "15              0.773700           0.744869       0.759011       CORRECT   \n",
       "16              0.830301           0.723330       0.773133     INCORRECT   \n",
       "18              0.753125           0.780204       0.766425       CORRECT   \n",
       "19              0.800900           0.743929       0.771364     INCORRECT   \n",
       "20              0.705821           0.711631       0.708714     INCORRECT   \n",
       "21              0.788292           0.727108       0.756465     INCORRECT   \n",
       "22              0.810672           0.813940       0.812303       CORRECT   \n",
       "23              0.796861           0.772002       0.784235     INCORRECT   \n",
       "24              0.806592           0.757089       0.781057       CORRECT   \n",
       "26              0.791248           0.755582       0.773004       CORRECT   \n",
       "27              0.792422           0.664364       0.722764     INCORRECT   \n",
       "30              0.754809           0.746819       0.750793     INCORRECT   \n",
       "31              0.796850           0.748646       0.771997       CORRECT   \n",
       "32              0.792490           0.766700       0.779382     INCORRECT   \n",
       "33              0.821843           0.737514       0.777398     INCORRECT   \n",
       "34              0.787597           0.689652       0.735377       CORRECT   \n",
       "35              0.793907           0.807321       0.800558     INCORRECT   \n",
       "37              0.769897           0.782054       0.775928       CORRECT   \n",
       "38              0.780669           0.737170       0.758296       CORRECT   \n",
       "39              0.826874           0.779806       0.802651       CORRECT   \n",
       "40              0.758290           0.824034       0.789796     INCORRECT   \n",
       "41              0.755997           0.770373       0.763117       CORRECT   \n",
       "43              0.798766           0.771712       0.785006     INCORRECT   \n",
       "46              0.821731           0.767014       0.793430     INCORRECT   \n",
       "47              0.902086           0.769552       0.830565       CORRECT   \n",
       "48              0.773860           0.777355       0.775603     INCORRECT   \n",
       "49              0.797096           0.773511       0.785126       CORRECT   \n",
       "\n",
       "    factCC_score_                                      prediction_v1  ...  \\\n",
       "0        0.927479  The authors use a 3D world to explore grounded...  ...   \n",
       "1        0.998772  The authors implement an open-source simulatio...  ...   \n",
       "4        0.880897  The paper presents FLAIR, a large-scale image ...  ...   \n",
       "5        0.999987  The proposed approach formalizes an intuitive ...  ...   \n",
       "6        0.999429  Reviews of a paper on deep learning for foreca...  ...   \n",
       "7        0.966194  The APT-36k dataset consists of 2,400 video se...  ...   \n",
       "10       0.998917  The paper introduces a variant of backdoor att...  ...   \n",
       "11       0.988653  The paper proposes an exploration method for \"...  ...   \n",
       "12       0.899950  The authors proposed a novel neural Fourier op...  ...   \n",
       "14       0.997411  The authors present a matrix factorization mod...  ...   \n",
       "15       0.938079  The paper addresses the highly relevant and im...  ...   \n",
       "16       0.940214  The paper considers the problem of (Generalize...  ...   \n",
       "18       0.999006  The paper is, for the most part, well-written ...  ...   \n",
       "19       0.966229  This paper builds upon the observation by Nakk...  ...   \n",
       "20       0.997675  This is a look at some of the events that took...  ...   \n",
       "21       0.998909  The method reduces 10.01M parameters of ResNet...  ...   \n",
       "22       0.997016  The main contributions include: Theoretical gu...  ...   \n",
       "23       0.999077  The method involves two stages: first sketchin...  ...   \n",
       "24       0.999731  The paper looks at the problem of designing a ...  ...   \n",
       "26       0.954507  The paper considers Group Equivariant Convulat...  ...   \n",
       "27       0.999987  The paper studies the random covariance matrix...  ...   \n",
       "30       0.991421  Stochastic subset selection (SSS) is a method ...  ...   \n",
       "31       0.857080  This paper proposes the method which improves ...  ...   \n",
       "32       0.995834  The problem studied is interesting and importa...  ...   \n",
       "33       0.931981  The paper focuses on learning latent represent...  ...   \n",
       "34       0.999744  The paper achieves high probability excess ris...  ...   \n",
       "35       0.999230  Reviewers give their verdict on a paper on opt...  ...   \n",
       "37       0.974574  The paper \"MABSplit: Faster Forest Training Us...  ...   \n",
       "38       0.963947  A paper proposed a new method for blind image ...  ...   \n",
       "39       0.534821  The paper proposes a new federated learning sc...  ...   \n",
       "40       0.996747  The paper studies one of the most popular algo...  ...   \n",
       "41       0.999022  The paper addresses the problem of video gener...  ...   \n",
       "43       0.999992  The paper investigates the problem of training...  ...   \n",
       "46       0.998710  The paper presents a dataset of open-source En...  ...   \n",
       "47       0.998644  The paper presents a new task: open-set single...  ...   \n",
       "48       0.998548  The paper studies the problem of submodular ma...  ...   \n",
       "49       0.803807  ParaACE is an algorithm that uses the UCB algo...  ...   \n",
       "\n",
       "   bertscore_precision_v1  bertscore_precision_v2  bertscore_recall_v1  \\\n",
       "0                0.803796                0.769929             0.754871   \n",
       "1                0.798175                0.786170             0.757699   \n",
       "4                0.778559                0.787477             0.753572   \n",
       "5                0.774090                0.766169             0.738067   \n",
       "6                0.810620                0.791914             0.736875   \n",
       "7                0.776609                0.773469             0.799102   \n",
       "10               0.842248                0.796666             0.798380   \n",
       "11               0.756070                0.760831             0.767380   \n",
       "12               0.800622                0.798954             0.771599   \n",
       "14               0.886838                0.823624             0.858465   \n",
       "15               0.791646                0.780757             0.755816   \n",
       "16               0.827128                0.814190             0.728936   \n",
       "18               0.753234                0.754435             0.780765   \n",
       "19               0.802893                0.811639             0.770139   \n",
       "20               0.691064                0.723260             0.693671   \n",
       "21               0.750898                0.767936             0.729662   \n",
       "22               0.793149                0.771975             0.801371   \n",
       "23               0.798664                0.786154             0.770831   \n",
       "24               0.813369                0.791074             0.779136   \n",
       "26               0.767727                0.792526             0.746845   \n",
       "27               0.785577                0.787341             0.672480   \n",
       "30               0.764340                0.781612             0.753822   \n",
       "31               0.787452                0.773646             0.761351   \n",
       "32               0.797088                0.777184             0.775010   \n",
       "33               0.812512                0.816043             0.754181   \n",
       "34               0.802888                0.800921             0.725820   \n",
       "35               0.800666                0.782594             0.802139   \n",
       "37               0.792801                0.773969             0.787328   \n",
       "38               0.765604                0.768802             0.732391   \n",
       "39               0.862258                0.791115             0.824932   \n",
       "40               0.760586                0.677526             0.833760   \n",
       "41               0.755409                0.742362             0.760782   \n",
       "43               0.784966                0.797500             0.759474   \n",
       "46               0.788670                0.747404             0.753319   \n",
       "47               0.873434                0.804285             0.787560   \n",
       "48               0.770240                0.760739             0.800516   \n",
       "49               0.804724                0.797797             0.772060   \n",
       "\n",
       "    bertscore_recall_v2  bertscore_f1_v1  bertscore_f1_v2  factCC_label_v1  \\\n",
       "0              0.754290         0.778566         0.762030        INCORRECT   \n",
       "1              0.779647         0.777411         0.782895        INCORRECT   \n",
       "4              0.783919         0.765862         0.785694        INCORRECT   \n",
       "5              0.748969         0.755650         0.757472          CORRECT   \n",
       "6              0.750096         0.771990         0.770438          CORRECT   \n",
       "7              0.814482         0.787695         0.793446          CORRECT   \n",
       "10             0.803829         0.819727         0.800231          CORRECT   \n",
       "11             0.789703         0.761683         0.774998          CORRECT   \n",
       "12             0.784747         0.785843         0.791786        INCORRECT   \n",
       "14             0.829720         0.872421         0.826661        INCORRECT   \n",
       "15             0.765056         0.773316         0.772826          CORRECT   \n",
       "16             0.748339         0.774934         0.779877        INCORRECT   \n",
       "18             0.805682         0.766752         0.779217        INCORRECT   \n",
       "19             0.789193         0.786175         0.800259          CORRECT   \n",
       "20             0.765685         0.692365         0.743868        INCORRECT   \n",
       "21             0.752396         0.740128         0.760087        INCORRECT   \n",
       "22             0.834725         0.797239         0.802124          CORRECT   \n",
       "23             0.796166         0.784501         0.791128          CORRECT   \n",
       "24             0.782508         0.795884         0.786768          CORRECT   \n",
       "26             0.768065         0.757142         0.780104        INCORRECT   \n",
       "27             0.681780         0.724643         0.730768        INCORRECT   \n",
       "30             0.789129         0.759044         0.785353        INCORRECT   \n",
       "31             0.770992         0.774181         0.772317        INCORRECT   \n",
       "32             0.786130         0.785894         0.781632        INCORRECT   \n",
       "33             0.775572         0.782260         0.795293        INCORRECT   \n",
       "34             0.732816         0.762412         0.765356        INCORRECT   \n",
       "35             0.824670         0.801402         0.803081        INCORRECT   \n",
       "37             0.792067         0.790055         0.782913          CORRECT   \n",
       "38             0.754305         0.748630         0.761485          CORRECT   \n",
       "39             0.786245         0.843182         0.788672        INCORRECT   \n",
       "40             0.789138         0.795494         0.729085        INCORRECT   \n",
       "41             0.779536         0.758086         0.760495        INCORRECT   \n",
       "43             0.793543         0.772010         0.795516        INCORRECT   \n",
       "46             0.766149         0.770589         0.756660        INCORRECT   \n",
       "47             0.796377         0.828277         0.800312          CORRECT   \n",
       "48             0.811430         0.785086         0.785267        INCORRECT   \n",
       "49             0.790238         0.788053         0.793999        INCORRECT   \n",
       "\n",
       "    factCC_label_v2  factCC_score_v1 factCC_score_v2  \n",
       "0         INCORRECT         0.710058        0.583747  \n",
       "1         INCORRECT         0.998167        0.995018  \n",
       "4         INCORRECT         0.994043        0.994379  \n",
       "5         INCORRECT         0.999886        0.915543  \n",
       "6           CORRECT         0.989380        0.998889  \n",
       "7         INCORRECT         0.599852        0.999715  \n",
       "10        INCORRECT         0.979119        0.599923  \n",
       "11          CORRECT         0.998538        0.980454  \n",
       "12        INCORRECT         0.995916        0.992283  \n",
       "14        INCORRECT         0.986336        0.986651  \n",
       "15          CORRECT         0.671082        0.540793  \n",
       "16        INCORRECT         0.979197        0.999126  \n",
       "18        INCORRECT         0.846436        0.997301  \n",
       "19        INCORRECT         0.531630        0.779545  \n",
       "20        INCORRECT         0.995368        0.985876  \n",
       "21        INCORRECT         0.999629        0.999033  \n",
       "22        INCORRECT         0.998262        0.999367  \n",
       "23          CORRECT         0.719019        0.987138  \n",
       "24        INCORRECT         0.999607        0.996460  \n",
       "26        INCORRECT         0.962826        0.942590  \n",
       "27        INCORRECT         0.935718        0.999491  \n",
       "30        INCORRECT         0.985589        0.959697  \n",
       "31        INCORRECT         0.990498        0.995103  \n",
       "32        INCORRECT         0.997362        0.853799  \n",
       "33        INCORRECT         0.997291        0.988940  \n",
       "34        INCORRECT         0.999900        0.999646  \n",
       "35        INCORRECT         0.999993        0.999981  \n",
       "37        INCORRECT         0.998852        0.999637  \n",
       "38        INCORRECT         0.996367        0.998165  \n",
       "39        INCORRECT         0.999357        0.999725  \n",
       "40        INCORRECT         0.985983        0.998942  \n",
       "41        INCORRECT         0.999655        0.955585  \n",
       "43        INCORRECT         0.978745        0.999990  \n",
       "46        INCORRECT         0.997772        0.995582  \n",
       "47        INCORRECT         0.999531        0.999765  \n",
       "48        INCORRECT         0.867829        0.993306  \n",
       "49          CORRECT         0.997190        0.843978  \n",
       "\n",
       "[37 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3938c701-d84c-4c4f-bc0f-6a96e2dd4754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>prediction_</th>\n",
       "      <th>prediction_v1</th>\n",
       "      <th>prediction_v2</th>\n",
       "      <th>rouge_score_</th>\n",
       "      <th>rouge_score_v1</th>\n",
       "      <th>rouge_score_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The paper investigates the capacity for neural...</td>\n",
       "      <td>The authors use a 3D world to explore grounded...</td>\n",
       "      <td>The authors use a 3D world to explore grounded...</td>\n",
       "      <td>The paper presents an argument for a multi-mod...</td>\n",
       "      <td>0.144737</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.149425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This paper considers the problem of (biologica...</td>\n",
       "      <td>The authors implement an open-source simulatio...</td>\n",
       "      <td>The authors implement an open-source simulatio...</td>\n",
       "      <td>Simple evolutionary algorithm \"AdaLead\" outper...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.164609</td>\n",
       "      <td>0.156584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The authors provide a benchmark for federated ...</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>The paper was published in the open-source sof...</td>\n",
       "      <td>0.151786</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>This paper studies a timely problem and consid...</td>\n",
       "      <td>The proposed approach formalizes an intuitive ...</td>\n",
       "      <td>The proposed approach formalizes an intuitive ...</td>\n",
       "      <td>The proposed approach formalizes an intuitive ...</td>\n",
       "      <td>0.112782</td>\n",
       "      <td>0.118881</td>\n",
       "      <td>0.141975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The paper addresses the problem of domain gene...</td>\n",
       "      <td>This work tackles the task of forecasting dyna...</td>\n",
       "      <td>Reviews of a paper on deep learning for foreca...</td>\n",
       "      <td>This work tackles the task of forecasting dyna...</td>\n",
       "      <td>0.093489</td>\n",
       "      <td>0.113269</td>\n",
       "      <td>0.131540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>After careful review, I believe that this pape...</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>APT-36K consists of 2,400 video clips collecte...</td>\n",
       "      <td>0.172185</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.173077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>This paper proposes a few-shot (untargeted) ba...</td>\n",
       "      <td>The paper introduces a variant of backdoor att...</td>\n",
       "      <td>The paper introduces a variant of backdoor att...</td>\n",
       "      <td>The paper introduces a variant of backdoor att...</td>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.239631</td>\n",
       "      <td>0.205323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is a borderline paper. The scores were in...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>0.124294</td>\n",
       "      <td>0.154639</td>\n",
       "      <td>0.165289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pros:\\n- Provides a practical technique which ...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.151351</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The authors present a matrix factorization for...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>0.336449</td>\n",
       "      <td>0.393162</td>\n",
       "      <td>0.347170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The paper proposes a semi-supervised segmentat...</td>\n",
       "      <td>The paper is generally well written, only has ...</td>\n",
       "      <td>The paper addresses the highly relevant and im...</td>\n",
       "      <td>The method shows consistently good results in ...</td>\n",
       "      <td>0.136752</td>\n",
       "      <td>0.141079</td>\n",
       "      <td>0.126761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The paper addresses generalized zero shot lear...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>0.138686</td>\n",
       "      <td>0.141844</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The paper presents a construction for deep lea...</td>\n",
       "      <td>Proposed point spatio-temporal (PST) convoluti...</td>\n",
       "      <td>The paper is, for the most part, well-written ...</td>\n",
       "      <td>The paper introduces point spatio-temporal con...</td>\n",
       "      <td>0.178082</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.202020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The paper develops a theoretical framework (in...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.167401</td>\n",
       "      <td>0.201439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Three experts reviewed this paper and all reco...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.179775</td>\n",
       "      <td>0.148760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I agree with the concerns raised by the review...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>0.154472</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.155477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>This paper studied imitation learning in the c...</td>\n",
       "      <td>The authors provide (1) an impossibility resul...</td>\n",
       "      <td>The main contributions include: Theoretical gu...</td>\n",
       "      <td>This paper shows that any proper algorithm is ...</td>\n",
       "      <td>0.177515</td>\n",
       "      <td>0.168539</td>\n",
       "      <td>0.240385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The paper makes a novel contribution to method...</td>\n",
       "      <td>This paper proposes a zero-shot drug design me...</td>\n",
       "      <td>The method involves two stages: first sketchin...</td>\n",
       "      <td>This paper proposes a zero-shot drug design me...</td>\n",
       "      <td>0.211009</td>\n",
       "      <td>0.203883</td>\n",
       "      <td>0.218868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The paper considers a collaborative decision-m...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>0.137313</td>\n",
       "      <td>0.178674</td>\n",
       "      <td>0.129199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reviewers generally agree that the main result...</td>\n",
       "      <td>The application section is in particular way t...</td>\n",
       "      <td>The paper considers Group Equivariant Convulat...</td>\n",
       "      <td>The paper considers Group Equivariant Convulat...</td>\n",
       "      <td>0.145455</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.236162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>There is a clear consensus to accept this manu...</td>\n",
       "      <td>Theory analysis is extensive, and the presenta...</td>\n",
       "      <td>The paper studies the random covariance matrix...</td>\n",
       "      <td>The paper studies the random covariance matrix...</td>\n",
       "      <td>0.096712</td>\n",
       "      <td>0.097015</td>\n",
       "      <td>0.112478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The paper proposed a two-stage method to selec...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.201754</td>\n",
       "      <td>0.227106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dear authors,\\n\\nYour proposition of adding a ...</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>The method is shown empirically to achieve bot...</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.191235</td>\n",
       "      <td>0.190840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>This work proposes algorithms for solving ERM ...</td>\n",
       "      <td>Private gradient descent is an important mecha...</td>\n",
       "      <td>The problem studied is interesting and importa...</td>\n",
       "      <td>The study was published in the Journal of Appl...</td>\n",
       "      <td>0.107623</td>\n",
       "      <td>0.147541</td>\n",
       "      <td>0.193772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>This paper considers the task of training poli...</td>\n",
       "      <td>This paper tackles the problem of generalizing...</td>\n",
       "      <td>The paper focuses on learning latent represent...</td>\n",
       "      <td>This paper tackles the problem of generalizing...</td>\n",
       "      <td>0.120482</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.177215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The paper gives high probability bounds on exc...</td>\n",
       "      <td>The paper gives a high probability excess popu...</td>\n",
       "      <td>The paper achieves high probability excess ris...</td>\n",
       "      <td>The paper achieves high probability excess ris...</td>\n",
       "      <td>0.137168</td>\n",
       "      <td>0.130252</td>\n",
       "      <td>0.163810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>This paper goes beyond the NTK setting in anal...</td>\n",
       "      <td>Theoretical paper presents a theoretical analy...</td>\n",
       "      <td>Reviewers give their verdict on a paper on opt...</td>\n",
       "      <td>Theoretical Computer Science is published in t...</td>\n",
       "      <td>0.136646</td>\n",
       "      <td>0.169697</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The reviewers agree that from a decision tree ...</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>A splitting criterion for fitting decision tre...</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.145078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Summary of discussion: Three reviewers rated t...</td>\n",
       "      <td>The motivation of using the proposed network d...</td>\n",
       "      <td>A paper proposed a new method for blind image ...</td>\n",
       "      <td>A paper proposed a new method for blind image ...</td>\n",
       "      <td>0.134276</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.137725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>This paper proposes a federated learning (FL) ...</td>\n",
       "      <td>A paper proposes a customisation strategy name...</td>\n",
       "      <td>The paper proposes a new federated learning sc...</td>\n",
       "      <td>Split-Max can adjust the model size according ...</td>\n",
       "      <td>0.163462</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.141732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The paper shows convergence results for RMSpro...</td>\n",
       "      <td>This work truly does merge the gap between the...</td>\n",
       "      <td>The paper studies one of the most popular algo...</td>\n",
       "      <td>The results of the study show that if the RSPP...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.075188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>All four reviewers enjoyed this paper and were...</td>\n",
       "      <td>The paper discusses a method for generating lo...</td>\n",
       "      <td>The paper addresses the problem of video gener...</td>\n",
       "      <td>The paper discusses a method for generating lo...</td>\n",
       "      <td>0.131737</td>\n",
       "      <td>0.148571</td>\n",
       "      <td>0.122807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>All reviewers agree that the author's response...</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>Theoretical Algorithms is published in the ope...</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.145299</td>\n",
       "      <td>0.147601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The reviews are generally positive (though som...</td>\n",
       "      <td>The paper compiles a dataset from various sour...</td>\n",
       "      <td>The paper presents a dataset of open-source En...</td>\n",
       "      <td>The paper presents a dataset of open-source En...</td>\n",
       "      <td>0.157635</td>\n",
       "      <td>0.162437</td>\n",
       "      <td>0.153191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>The paper presents a new problem: open-set sin...</td>\n",
       "      <td>The paper presents a new task: open-set single...</td>\n",
       "      <td>The paper presents a new task: open-set single...</td>\n",
       "      <td>The paper presents a new task: open-set single...</td>\n",
       "      <td>0.261981</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.323760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Overall, this paper achieves strong and intere...</td>\n",
       "      <td>The paper studies (mainly monotone) submodular...</td>\n",
       "      <td>The paper studies the problem of submodular ma...</td>\n",
       "      <td>The paper studies the problem of submodular ma...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.156250</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This paper tackles the problem of feature inte...</td>\n",
       "      <td>The authors propose two key ideas. The first i...</td>\n",
       "      <td>ParaACE is an algorithm that uses the UCB algo...</td>\n",
       "      <td>The authors propose two key ideas. The first i...</td>\n",
       "      <td>0.184739</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.185053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 gold  \\\n",
       "0   The paper investigates the capacity for neural...   \n",
       "1   This paper considers the problem of (biologica...   \n",
       "4   The authors provide a benchmark for federated ...   \n",
       "5   This paper studies a timely problem and consid...   \n",
       "6   The paper addresses the problem of domain gene...   \n",
       "7   After careful review, I believe that this pape...   \n",
       "10  This paper proposes a few-shot (untargeted) ba...   \n",
       "11  This is a borderline paper. The scores were in...   \n",
       "12  Pros:\\n- Provides a practical technique which ...   \n",
       "14  The authors present a matrix factorization for...   \n",
       "15  The paper proposes a semi-supervised segmentat...   \n",
       "16  The paper addresses generalized zero shot lear...   \n",
       "18  The paper presents a construction for deep lea...   \n",
       "19  The paper develops a theoretical framework (in...   \n",
       "20  Three experts reviewed this paper and all reco...   \n",
       "21  I agree with the concerns raised by the review...   \n",
       "22  This paper studied imitation learning in the c...   \n",
       "23  The paper makes a novel contribution to method...   \n",
       "24  The paper considers a collaborative decision-m...   \n",
       "26  Reviewers generally agree that the main result...   \n",
       "27  There is a clear consensus to accept this manu...   \n",
       "30  The paper proposed a two-stage method to selec...   \n",
       "31  Dear authors,\\n\\nYour proposition of adding a ...   \n",
       "32  This work proposes algorithms for solving ERM ...   \n",
       "33  This paper considers the task of training poli...   \n",
       "34  The paper gives high probability bounds on exc...   \n",
       "35  This paper goes beyond the NTK setting in anal...   \n",
       "37  The reviewers agree that from a decision tree ...   \n",
       "38  Summary of discussion: Three reviewers rated t...   \n",
       "39  This paper proposes a federated learning (FL) ...   \n",
       "40  The paper shows convergence results for RMSpro...   \n",
       "41  All four reviewers enjoyed this paper and were...   \n",
       "43  All reviewers agree that the author's response...   \n",
       "46  The reviews are generally positive (though som...   \n",
       "47  The paper presents a new problem: open-set sin...   \n",
       "48  Overall, this paper achieves strong and intere...   \n",
       "49  This paper tackles the problem of feature inte...   \n",
       "\n",
       "                                          prediction_  \\\n",
       "0   The authors use a 3D world to explore grounded...   \n",
       "1   The authors implement an open-source simulatio...   \n",
       "4   The paper presents FLAIR, a large-scale image ...   \n",
       "5   The proposed approach formalizes an intuitive ...   \n",
       "6   This work tackles the task of forecasting dyna...   \n",
       "7   The APT-36k dataset consists of 2,400 video se...   \n",
       "10  The paper introduces a variant of backdoor att...   \n",
       "11  The paper proposes an exploration method for \"...   \n",
       "12  The authors proposed a novel neural Fourier op...   \n",
       "14  The authors present a matrix factorization mod...   \n",
       "15  The paper is generally well written, only has ...   \n",
       "16  The paper considers the problem of (Generalize...   \n",
       "18  Proposed point spatio-temporal (PST) convoluti...   \n",
       "19  This paper builds upon the observation by Nakk...   \n",
       "20  This is a look at some of the events that took...   \n",
       "21  The method reduces 10.01M parameters of ResNet...   \n",
       "22  The authors provide (1) an impossibility resul...   \n",
       "23  This paper proposes a zero-shot drug design me...   \n",
       "24  The paper looks at the problem of designing a ...   \n",
       "26  The application section is in particular way t...   \n",
       "27  Theory analysis is extensive, and the presenta...   \n",
       "30  Stochastic subset selection (SSS) is a method ...   \n",
       "31  This paper proposes the method which improves ...   \n",
       "32  Private gradient descent is an important mecha...   \n",
       "33  This paper tackles the problem of generalizing...   \n",
       "34  The paper gives a high probability excess popu...   \n",
       "35  Theoretical paper presents a theoretical analy...   \n",
       "37  The paper \"MABSplit: Faster Forest Training Us...   \n",
       "38  The motivation of using the proposed network d...   \n",
       "39  A paper proposes a customisation strategy name...   \n",
       "40  This work truly does merge the gap between the...   \n",
       "41  The paper discusses a method for generating lo...   \n",
       "43  The paper investigates the problem of training...   \n",
       "46  The paper compiles a dataset from various sour...   \n",
       "47  The paper presents a new task: open-set single...   \n",
       "48  The paper studies (mainly monotone) submodular...   \n",
       "49  The authors propose two key ideas. The first i...   \n",
       "\n",
       "                                        prediction_v1  \\\n",
       "0   The authors use a 3D world to explore grounded...   \n",
       "1   The authors implement an open-source simulatio...   \n",
       "4   The paper presents FLAIR, a large-scale image ...   \n",
       "5   The proposed approach formalizes an intuitive ...   \n",
       "6   Reviews of a paper on deep learning for foreca...   \n",
       "7   The APT-36k dataset consists of 2,400 video se...   \n",
       "10  The paper introduces a variant of backdoor att...   \n",
       "11  The paper proposes an exploration method for \"...   \n",
       "12  The authors proposed a novel neural Fourier op...   \n",
       "14  The authors present a matrix factorization mod...   \n",
       "15  The paper addresses the highly relevant and im...   \n",
       "16  The paper considers the problem of (Generalize...   \n",
       "18  The paper is, for the most part, well-written ...   \n",
       "19  This paper builds upon the observation by Nakk...   \n",
       "20  This is a look at some of the events that took...   \n",
       "21  The method reduces 10.01M parameters of ResNet...   \n",
       "22  The main contributions include: Theoretical gu...   \n",
       "23  The method involves two stages: first sketchin...   \n",
       "24  The paper looks at the problem of designing a ...   \n",
       "26  The paper considers Group Equivariant Convulat...   \n",
       "27  The paper studies the random covariance matrix...   \n",
       "30  Stochastic subset selection (SSS) is a method ...   \n",
       "31  This paper proposes the method which improves ...   \n",
       "32  The problem studied is interesting and importa...   \n",
       "33  The paper focuses on learning latent represent...   \n",
       "34  The paper achieves high probability excess ris...   \n",
       "35  Reviewers give their verdict on a paper on opt...   \n",
       "37  The paper \"MABSplit: Faster Forest Training Us...   \n",
       "38  A paper proposed a new method for blind image ...   \n",
       "39  The paper proposes a new federated learning sc...   \n",
       "40  The paper studies one of the most popular algo...   \n",
       "41  The paper addresses the problem of video gener...   \n",
       "43  The paper investigates the problem of training...   \n",
       "46  The paper presents a dataset of open-source En...   \n",
       "47  The paper presents a new task: open-set single...   \n",
       "48  The paper studies the problem of submodular ma...   \n",
       "49  ParaACE is an algorithm that uses the UCB algo...   \n",
       "\n",
       "                                        prediction_v2  rouge_score_  \\\n",
       "0   The paper presents an argument for a multi-mod...      0.144737   \n",
       "1   Simple evolutionary algorithm \"AdaLead\" outper...      0.142857   \n",
       "4   The paper was published in the open-source sof...      0.151786   \n",
       "5   The proposed approach formalizes an intuitive ...      0.112782   \n",
       "6   This work tackles the task of forecasting dyna...      0.093489   \n",
       "7   APT-36K consists of 2,400 video clips collecte...      0.172185   \n",
       "10  The paper introduces a variant of backdoor att...      0.211538   \n",
       "11  The paper proposes an exploration method for \"...      0.124294   \n",
       "12  The authors proposed a novel neural Fourier op...      0.119048   \n",
       "14  The authors present a matrix factorization mod...      0.336449   \n",
       "15  The method shows consistently good results in ...      0.136752   \n",
       "16  The paper considers the problem of (Generalize...      0.138686   \n",
       "18  The paper introduces point spatio-temporal con...      0.178082   \n",
       "19  This paper builds upon the observation by Nakk...      0.109589   \n",
       "20  This is a look at some of the events that took...      0.177515   \n",
       "21  The method reduces 10.01M parameters of ResNet...      0.154472   \n",
       "22  This paper shows that any proper algorithm is ...      0.177515   \n",
       "23  This paper proposes a zero-shot drug design me...      0.211009   \n",
       "24  The paper looks at the problem of designing a ...      0.137313   \n",
       "26  The paper considers Group Equivariant Convulat...      0.145455   \n",
       "27  The paper studies the random covariance matrix...      0.096712   \n",
       "30  Stochastic subset selection (SSS) is a method ...      0.200000   \n",
       "31  The method is shown empirically to achieve bot...      0.155844   \n",
       "32  The study was published in the Journal of Appl...      0.107623   \n",
       "33  This paper tackles the problem of generalizing...      0.120482   \n",
       "34  The paper achieves high probability excess ris...      0.137168   \n",
       "35  Theoretical Computer Science is published in t...      0.136646   \n",
       "37  A splitting criterion for fitting decision tre...      0.173333   \n",
       "38  A paper proposed a new method for blind image ...      0.134276   \n",
       "39  Split-Max can adjust the model size according ...      0.163462   \n",
       "40  The results of the study show that if the RSPP...      0.136364   \n",
       "41  The paper discusses a method for generating lo...      0.131737   \n",
       "43  Theoretical Algorithms is published in the ope...      0.135135   \n",
       "46  The paper presents a dataset of open-source En...      0.157635   \n",
       "47  The paper presents a new task: open-set single...      0.261981   \n",
       "48  The paper studies the problem of submodular ma...      0.133333   \n",
       "49  The authors propose two key ideas. The first i...      0.184739   \n",
       "\n",
       "    rouge_score_v1  rouge_score_v2  \n",
       "0         0.131579        0.149425  \n",
       "1         0.164609        0.156584  \n",
       "4         0.133929        0.160000  \n",
       "5         0.118881        0.141975  \n",
       "6         0.113269        0.131540  \n",
       "7         0.166667        0.173077  \n",
       "10        0.239631        0.205323  \n",
       "11        0.154639        0.165289  \n",
       "12        0.151351        0.185185  \n",
       "14        0.393162        0.347170  \n",
       "15        0.141079        0.126761  \n",
       "16        0.141844        0.173913  \n",
       "18        0.200000        0.202020  \n",
       "19        0.167401        0.201439  \n",
       "20        0.179775        0.148760  \n",
       "21        0.122449        0.155477  \n",
       "22        0.168539        0.240385  \n",
       "23        0.203883        0.218868  \n",
       "24        0.178674        0.129199  \n",
       "26        0.151261        0.236162  \n",
       "27        0.097015        0.112478  \n",
       "30        0.201754        0.227106  \n",
       "31        0.191235        0.190840  \n",
       "32        0.147541        0.193772  \n",
       "33        0.138889        0.177215  \n",
       "34        0.130252        0.163810  \n",
       "35        0.169697        0.200000  \n",
       "37        0.187500        0.145078  \n",
       "38        0.108696        0.137725  \n",
       "39        0.346154        0.141732  \n",
       "40        0.192308        0.075188  \n",
       "41        0.148571        0.122807  \n",
       "43        0.145299        0.147601  \n",
       "46        0.162437        0.153191  \n",
       "47        0.307692        0.323760  \n",
       "48        0.156250        0.153846  \n",
       "49        0.161290        0.185053  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eecfeaac-36f2-41bc-be76-6b039751b561",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]].iloc[4, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620239e9-7f05-438e-920b-3ec40bc4e1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The authors provide a benchmark for federated learning. \n",
      "\n",
      "The commonly mentioned strengths:\n",
      "- there is a big need in the community for this type of work\n",
      "- easily accessible code\n",
      "- various levels of complexity with different granularity\n",
      "\n",
      "Regarding the weaknesses, I see no showstoppers\n",
      "- some feedback about the experiments done on the datasets -> this point comes back consistently among all reviewers, in terms of the amount, settings and reproducibility.. The authors are adviced to address this in future work, to keep momentum for the use of the community on this dataset \n",
      "- there was some discussion about tensorflow and pytorch, but based on the discussion both seem supported\n",
      "- some settings / image types could be better supported\n",
      "\n",
      "None of these weaknesses seem serious, and quite frankly, we can not expect one dataset to cover all possible settings. Since the reviewers are in agreement about the quality of this work, I recommend them for an oral presentation. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(row['gold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "749c7932-153c-4b2f-bd37-8551f57314b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper presents FLAIR, a large-scale image dataset for federated learning. FLAIR includes 429,078 images from 51,414 users, with 17 coarse-grained labels and 1,628 ï¬ne- grained labels. The images in the dataset are gathered and filtered in such a fashion that no faces are present to avoid any personally identifiable information. The authors do not provide the NeurIPS checklist in the main article nor in the supplementary.\n"
     ]
    }
   ],
   "source": [
    "print(row[\"prediction_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28c2747f-8543-4ef4-b037-db9c8c03d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper presents FLAIR, a large-scale image dataset for federated learning. FLAIR includes 429,078 images from 51,414 users, with 17 coarse-grained labels and 1,628 ï¬ne- grained labels. The results show the difficulty of the task, with centralizing training getting better results than FL, which is in turn better than DP-FL. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users.\n"
     ]
    }
   ],
   "source": [
    "print(row[\"prediction_v1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d7e1a2ef-27e4-470f-afba-88199ec29447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper was published in the open-source software journal, Caffeine and NLP: A Practical Guide to NLP and Machine Learning. The dataset consists in 429k images from 51k individual Flickr users. The task consists in classification, with 2 levels of granularity for the classes: 17 coarse and ~1.6k fine classes. The results show the difficulty of the task, with centralizing training getting better results than FL, which is in turn better than DP-FL. This work is really needed, providing an open gamefield to the community. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users. Proposed benchmark is only for vision tasks that do not include federated NLP tasks such as federated keyword prediction.\n"
     ]
    }
   ],
   "source": [
    "print(row[\"prediction_v2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6f177843-cf5b-4cf2-802a-bab796ef9cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper addresses the problem of domain generalization for learning spatio-temporal dynamics. It proposes a solution where an encoder captures some characteristics of a given environment, and a forecaster autoregressively predicts future dynamics conditioned on the characteristics learned by the encoder. Said otherwise, the forecaster learns the general form of dynamics parameterized by an environment representation extracted by the encoder. The conditioning is implemented via an adaptive instance normalization mechanism. A form of padding is also introduced in order to take into account boundary conditions. The two components encoder and forecaster are trained sequentially. This approach is casted in a meta-learning framework. Theoretical results inspired by multi-task learning and domain adaptation are also demonstrated. The model is evaluated and compared to different baselines on three problems, and for two different settings: varying initial conditions with a given dynamics, and dynamics with varying parameters.\n",
      "\n",
      "This is a borderline paper. It targets a timely and important problem of domain generalization for dynamic environments. The proposed solution is original and compares well experimentally to several baselines. It allows for better generalization performance for the two test settings considered. In the current version, the paper however suffers from different weaknesses. First there is the imprecision of the arguments and the description of the experiments. Some of the arguments and claims are vague and sometimes abusive, not backed up by evidence. For example, a central claim is that the encoder learns time invariant quantities characterizing the environment when the learned representations indeed change with a time shift in the input for any environment. The same goes for the argument developed for the padding construction. It is claimed to model boundary conditions, but this is not supported by any theoretical or empirical evidence.\n",
      "As noted by the reviewers, the theoretical analysis is disconnected from the algorithmic and experimental developments and does not bring much additional value to the paper. What is more embarrassing is that some of the claims in this section are overstated and induce incorrect conclusions.  From Theorem 3.1 and proposition 3.3, the authors suggest that multitask learning leads to better generalization than learning independently, while this is not formally guaranteed by the results (this is acknowledged by the authors in a later comment). Besides, the conditions of validity are not discussed while they seem to only cover situations for which the train and the test distributions are the same. The same holds for the second theoretical results (theorem 3.4). It is claimed that this result supports the authorsâ€™ idea of training encoder and forecaster sequentially, while it does not. Besides, the bounds in this result cannot be controlled as noted by the reviewers and are not useful in practice.\n",
      "\n",
      "Overall, the paper addresses an important topic and proposes new solutions. The results are promising and it is indeed an interesting contribution. However, inaccuracies and incorrect or exaggerated claims make it difficult to accept the current version of the article. The article would make a strong and innovative contribution if it were written as a purely experimental article with a detailed description of the experiments and comparisons.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "This work tackles the task of forecasting dynamics in different domains simultaneously. Using an encoder which is trained to determine the task, the inferred latent vector is then used to adapt a forecasting network to the task. Experiments on three datasets linked to fluid dynamics are then conducted to assess the proposed model. This is framed as a meta-learning approach, and is shown to substantially outperform single-task approaches and off-the-shell meta- learning approaches across multiple datasets.\n",
      "\n",
      "\n",
      "Reviews of a paper on deep learning for forecasting dynamics. The work tackles the task of forecasting dynamics in different domains simultaneously. This is a good work on a timely subject. The contribution is not groundbreaking but should be significant enough to warrant acceptance. Especially given the fact that the contributions of this work seem geared towards practical considerations. The paper shows that learning shared models across domains is an important and fruitful way forward for modeling physical processes with machine learning. It is framed as a meta-learning approach, and is shown to substantially outperform single task approaches.\n",
      "\n",
      "\n",
      "This work tackles the task of forecasting dynamics in different domains simultaneously. Using an encoder which is trained to determine the task, the inferred latent vector is then used to adapt a forecasting network to the task at hand. Experiments on three datasets linked to fluid dynamics are then conducted to assess the proposed model. This is a good work on a timely subject. The contribution is not groundbreaking but should be significant enough to warrant acceptance. It would be nice to see how the model deals with other families of dynamics. Especially given the fact that the contributions of this work seem geared towards practical considerations. The setting of the experiments should be more precise and additional details should be given: how are the different datasets constructed, how many domains are there in each dataset and what are the differences, how is the balance between the different domains ect.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = df[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]].iloc[6, :]\n",
    "print(row['gold']+\"\\n\\n\")\n",
    "print(row[\"prediction_\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v1\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v2\"]+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca12f6ad-512b-4361-98b1-0949b886e7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pros:\n",
      "- Provides a practical technique which can dramatically speed up PDE solving -- this is an important and widely applicable contribution.\n",
      "- Paper is simultaneously clearly written and mathematically sophisticated.\n",
      "- The experimental results as impressive.\n",
      "\n",
      "Cons:\n",
      "- There were concerns that the paper lacks novelty compared to Li et al 2020b, where the underlying theoretical framework was developed. The primary novelty would seem to be:\n",
      "- - using Fourier transforms as the specific neural operator\n",
      "- - the strength of the experimental results\n",
      "\n",
      "Overall, I recommend acceptance. I believe the techniques in this paper will be practically useful for future research.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The authors proposed a novel neural Fourier operator that generalizes between different function discretization schemes. It achieves superior performance in terms of speed and accuracy compared to learned baselines. It is also significantly faster than traditional PDE solvers. The motivation for replacing the kernel function (3) by a convolution operator is not entirely clear. This is performed by a supervised learning of a mapping between the PDE coefficients (a) and a PDE solution (u)\n",
      "\n",
      "\n",
      "The authors proposed a novel neural Fourier operator that generalizes between different function discretization schemes. The method achieves superior performance in terms of speed and accuracy compared to learned baselines. It is also significantly faster than traditional PDE solvers. The motivation for replacing the kernel function (3) by a convolution operator is not entirely clear. The paper itself is not self-contained. I hope that the authors are able to address my concerns. I believe that this work should be published. It's definitely a big step-forward in neural operators.\n",
      "\n",
      "\n",
      "The authors proposed a novel neural Fourier operator that generalizes between different function discretization schemes. The method achieves superior performance in terms of speed and accuracy compared to learned baselines. It is also significantly faster than traditional PDE solvers. Iâ€™m assigning a score of 8 (a very good conference paper), and I think that the paper is more or less ready for publication as is. The paper itself is not self-contained. I hope that the authors are able to address my concerns. I believe that this work should be published. Itâ€™s definitely a big step-forward in neural operators. The subsequent experimentation was extremely thorough and, of course, the results were very impressive. I liked the paper a lot.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = df[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]].iloc[12, :]\n",
    "print(row['gold']+\"\\n\\n\")\n",
    "print(row[\"prediction_\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v1\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v2\"]+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbb2020e-581a-4012-8634-5bed607acba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The paper addresses generalized zero shot learning (test data contains examples from both seen as well as unseen classes) and proposes to learn a shared representation of images and attributes via multimodal variational autoencoders. \n",
      "The reviewers and AC note the following potential weaknesses: (1) low technical contribution, i.e. the proposed multimodal VAE model is very similar to Vedantam et al (2017) as noted by R2, and to JMVAE model by Suzuki et al, 2016, as noted by R1. The authors clarified in their response that indeed VAE in Vedantam et al (2017) is similar, but it has been used for image synthesis and not classification/GZSL. (2) Empirical evaluations and setup are not convincing (R2) and not clear -- R3 has provided a very detailed review and a follow up discussion raising several important concerns such as (i) absence of a validation set to test generalization, (ii) the hyperparameters set up; (iii) not clear advantages of learning a joint model as opposed to unidirectional mappings (R1 also supports this claim). The authors partially addressed some of these concerns in their response, however more in-depth analysis and major revision is required to assess the benefits and feasibility of the proposed approach.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input. The authors propose â€˜modality invariant variational autoencodersâ€™ which allows one to perform shared manifold learning by training VAEs with both images and attributes as inputs.\n",
      "\n",
      "\n",
      "The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/ attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes) The theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero- shot learning approaches but with VAEs.\n",
      "\n",
      "\n",
      "The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input (images and attributes) The theoretical aspect of the method is then limited since the proposed loss function actually corresponds to optimize the same problem as most zero- shot learning approaches but with VAEs. The contributions of the paper are mostly experimental. Most arguments in the model section are actually simply intuitions. After reading the different reviews, the replies of the authors and the updated version, my opinion that the \"explanations\" are simply intuition.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = df[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]].iloc[16, :]\n",
    "print(row['gold']+\"\\n\\n\")\n",
    "print(row[\"prediction_\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v1\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v2\"]+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d24d890-bcca-49e9-b584-6ac771825cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This paper proposes a federated learning (FL) scheme that is suitable for clients/devices with heterogeneous resources. The scheme Split-Mix trains multiple models of different sizes and adversarial-robustness levels, which are tailored to the budgets of the individual device. Empirical results show encouraging results.\n",
      "\n",
      "It is clear that FL will have to work with clients with diverse resources, a point that is appreciated. Indeed, it is anticipated that widely-dispersed inference will have to deal with a highly-heterogeneous mix of clients. The study is quite thorough. One aspect that is not convincing in the experiments is the budgets being exponentially distributed: having a strong concentration around a mean (with something like a Gaussian tail), or a power-law distribution, would be more suitable.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "A paper proposes a customisation strategy named \"Split-Max\" for federated learning. Split-Max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness. The proposed approach can train both accurate and robust models in a joint fashion, where all but batch-norm layers are shared for efficiency. It's not perfectly clear how the split and aggregation are done in the proposed approach. The assumption about the computational resources of clients would be better clarified.\n",
      "\n",
      "\n",
      "The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device. The proposed approach can train both accurate and robust models in a joint fashion, where all but batch-norm layers are shared for efficiency. Experimental results on multiple datasets (CIFAR10, Digits, DomainNet) demonstrate the effectiveness of the proposed approach compared to FedAvg and HeteroFL.\n",
      "\n",
      "\n",
      "Split-Max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness. With customisation, the models are smaller and more robust under budget constraints. The idea of BN layer-wise mixing is kind of confusing. The reason of sharing all parameters except the batch-normalisation requires further elaboration. The assumption about the computational resources of clients would be better clarified. The evaluation results are heavily based on the assumption of exponentially distributed budgets. There is a large number of typos (mainly after Section 4). A sample: x1 net SHeteroFL seems to converge faster than slimmer nets till around round 50. The authors conclude that the widest model may not be a good candidate model but donâ€™t provide any intuition behind this.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = df[[\"gold\",\"prediction_\",\"prediction_v1\",\"prediction_v2\",\"rouge_score_\", \"rouge_score_v1\",\"rouge_score_v2\"]].iloc[39, :]\n",
    "print(row['gold']+\"\\n\\n\")\n",
    "print(row[\"prediction_\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v1\"]+\"\\n\\n\")\n",
    "print(row[\"prediction_v2\"]+\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc292719-26ed-48fe-ac35-62bfaf8ef640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert = df[(df['bertscore_f1_'] < df['bertscore_f1_v1']) | (df['bertscore_f1_'] < df['bertscore_f1_v2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c03e33ad-d763-4e8c-975e-db681c92b8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df_bert[[\"gold\", \"prediction_\", \"prediction_v1\", \"prediction_v2\", \"bertscore_f1_\", \"bertscore_f1_v1\", \"bertscore_f1_v2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79155c73-f3db-493c-a17c-93078abe3133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gold</th>\n",
       "      <th>prediction_</th>\n",
       "      <th>prediction_v1</th>\n",
       "      <th>prediction_v2</th>\n",
       "      <th>bertscore_f1_</th>\n",
       "      <th>bertscore_f1_v1</th>\n",
       "      <th>bertscore_f1_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The proposed method introduces a method for un...</td>\n",
       "      <td>The paper adds a spatial regularization loss t...</td>\n",
       "      <td>The paper adds a spatial regularization loss t...</td>\n",
       "      <td>The paper adds a spatial regularization loss t...</td>\n",
       "      <td>0.769009</td>\n",
       "      <td>0.774916</td>\n",
       "      <td>0.761890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The authors provide a benchmark for federated ...</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>The paper presents FLAIR, a large-scale image ...</td>\n",
       "      <td>The paper was published in the open-source sof...</td>\n",
       "      <td>0.759050</td>\n",
       "      <td>0.765862</td>\n",
       "      <td>0.785694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The paper addresses the problem of domain gene...</td>\n",
       "      <td>This work tackles the task of forecasting dyna...</td>\n",
       "      <td>Reviews of a paper on deep learning for foreca...</td>\n",
       "      <td>This work tackles the task of forecasting dyna...</td>\n",
       "      <td>0.764346</td>\n",
       "      <td>0.771990</td>\n",
       "      <td>0.770438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>After careful review, I believe that this pape...</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>The APT-36k dataset consists of 2,400 video se...</td>\n",
       "      <td>APT-36K consists of 2,400 video clips collecte...</td>\n",
       "      <td>0.783293</td>\n",
       "      <td>0.787695</td>\n",
       "      <td>0.793446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>This is a borderline paper. The scores were in...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>The paper proposes an exploration method for \"...</td>\n",
       "      <td>0.768899</td>\n",
       "      <td>0.761683</td>\n",
       "      <td>0.774998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Pros:\\n- Provides a practical technique which ...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>The authors proposed a novel neural Fourier op...</td>\n",
       "      <td>0.751691</td>\n",
       "      <td>0.785843</td>\n",
       "      <td>0.791786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The authors present a matrix factorization for...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>The authors present a matrix factorization mod...</td>\n",
       "      <td>0.823125</td>\n",
       "      <td>0.872421</td>\n",
       "      <td>0.826661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The paper proposes a semi-supervised segmentat...</td>\n",
       "      <td>The paper is generally well written, only has ...</td>\n",
       "      <td>The paper addresses the highly relevant and im...</td>\n",
       "      <td>The method shows consistently good results in ...</td>\n",
       "      <td>0.759011</td>\n",
       "      <td>0.773316</td>\n",
       "      <td>0.772826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The paper addresses generalized zero shot lear...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>The paper considers the problem of (Generalize...</td>\n",
       "      <td>0.773133</td>\n",
       "      <td>0.774934</td>\n",
       "      <td>0.779877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The paper presents a construction for deep lea...</td>\n",
       "      <td>Proposed point spatio-temporal (PST) convoluti...</td>\n",
       "      <td>The paper is, for the most part, well-written ...</td>\n",
       "      <td>The paper introduces point spatio-temporal con...</td>\n",
       "      <td>0.766425</td>\n",
       "      <td>0.766752</td>\n",
       "      <td>0.779217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The paper develops a theoretical framework (in...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>This paper builds upon the observation by Nakk...</td>\n",
       "      <td>0.771364</td>\n",
       "      <td>0.786175</td>\n",
       "      <td>0.800259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Three experts reviewed this paper and all reco...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>This is a look at some of the events that took...</td>\n",
       "      <td>0.708714</td>\n",
       "      <td>0.692365</td>\n",
       "      <td>0.743868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I agree with the concerns raised by the review...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>The method reduces 10.01M parameters of ResNet...</td>\n",
       "      <td>0.756465</td>\n",
       "      <td>0.740128</td>\n",
       "      <td>0.760087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The paper makes a novel contribution to method...</td>\n",
       "      <td>This paper proposes a zero-shot drug design me...</td>\n",
       "      <td>The method involves two stages: first sketchin...</td>\n",
       "      <td>This paper proposes a zero-shot drug design me...</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>0.784501</td>\n",
       "      <td>0.791128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The paper considers a collaborative decision-m...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>The paper looks at the problem of designing a ...</td>\n",
       "      <td>0.781057</td>\n",
       "      <td>0.795884</td>\n",
       "      <td>0.786768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reviewers generally agree that the main result...</td>\n",
       "      <td>The application section is in particular way t...</td>\n",
       "      <td>The paper considers Group Equivariant Convulat...</td>\n",
       "      <td>The paper considers Group Equivariant Convulat...</td>\n",
       "      <td>0.773004</td>\n",
       "      <td>0.757142</td>\n",
       "      <td>0.780104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>There is a clear consensus to accept this manu...</td>\n",
       "      <td>Theory analysis is extensive, and the presenta...</td>\n",
       "      <td>The paper studies the random covariance matrix...</td>\n",
       "      <td>The paper studies the random covariance matrix...</td>\n",
       "      <td>0.722764</td>\n",
       "      <td>0.724643</td>\n",
       "      <td>0.730768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This work proposed a new HPO surrogate benchma...</td>\n",
       "      <td>The benchmarks are surrogate-based, provided u...</td>\n",
       "      <td>The benchmarks are surrogate-based, provided u...</td>\n",
       "      <td>The benchmarks are surrogate-based, provided u...</td>\n",
       "      <td>0.796257</td>\n",
       "      <td>0.768666</td>\n",
       "      <td>0.806316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The paper proposed a two-stage method to selec...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>Stochastic subset selection (SSS) is a method ...</td>\n",
       "      <td>0.750793</td>\n",
       "      <td>0.759044</td>\n",
       "      <td>0.785353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Dear authors,\\n\\nYour proposition of adding a ...</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>This paper proposes the method which improves ...</td>\n",
       "      <td>The method is shown empirically to achieve bot...</td>\n",
       "      <td>0.771997</td>\n",
       "      <td>0.774181</td>\n",
       "      <td>0.772317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>This work proposes algorithms for solving ERM ...</td>\n",
       "      <td>Private gradient descent is an important mecha...</td>\n",
       "      <td>The problem studied is interesting and importa...</td>\n",
       "      <td>The study was published in the Journal of Appl...</td>\n",
       "      <td>0.779382</td>\n",
       "      <td>0.785894</td>\n",
       "      <td>0.781632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>This paper considers the task of training poli...</td>\n",
       "      <td>This paper tackles the problem of generalizing...</td>\n",
       "      <td>The paper focuses on learning latent represent...</td>\n",
       "      <td>This paper tackles the problem of generalizing...</td>\n",
       "      <td>0.777398</td>\n",
       "      <td>0.782260</td>\n",
       "      <td>0.795293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The paper gives high probability bounds on exc...</td>\n",
       "      <td>The paper gives a high probability excess popu...</td>\n",
       "      <td>The paper achieves high probability excess ris...</td>\n",
       "      <td>The paper achieves high probability excess ris...</td>\n",
       "      <td>0.735377</td>\n",
       "      <td>0.762412</td>\n",
       "      <td>0.765356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>This paper goes beyond the NTK setting in anal...</td>\n",
       "      <td>Theoretical paper presents a theoretical analy...</td>\n",
       "      <td>Reviewers give their verdict on a paper on opt...</td>\n",
       "      <td>Theoretical Computer Science is published in t...</td>\n",
       "      <td>0.800558</td>\n",
       "      <td>0.801402</td>\n",
       "      <td>0.803081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The reviewers agree that from a decision tree ...</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>The paper \"MABSplit: Faster Forest Training Us...</td>\n",
       "      <td>A splitting criterion for fitting decision tre...</td>\n",
       "      <td>0.775928</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.782913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Summary of discussion: Three reviewers rated t...</td>\n",
       "      <td>The motivation of using the proposed network d...</td>\n",
       "      <td>A paper proposed a new method for blind image ...</td>\n",
       "      <td>A paper proposed a new method for blind image ...</td>\n",
       "      <td>0.758296</td>\n",
       "      <td>0.748630</td>\n",
       "      <td>0.761485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>This paper proposes a federated learning (FL) ...</td>\n",
       "      <td>A paper proposes a customisation strategy name...</td>\n",
       "      <td>The paper proposes a new federated learning sc...</td>\n",
       "      <td>Split-Max can adjust the model size according ...</td>\n",
       "      <td>0.802651</td>\n",
       "      <td>0.843182</td>\n",
       "      <td>0.788672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>The paper shows convergence results for RMSpro...</td>\n",
       "      <td>This work truly does merge the gap between the...</td>\n",
       "      <td>The paper studies one of the most popular algo...</td>\n",
       "      <td>The results of the study show that if the RSPP...</td>\n",
       "      <td>0.789796</td>\n",
       "      <td>0.795494</td>\n",
       "      <td>0.729085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The reviewers were generally split on this pap...</td>\n",
       "      <td>The idea of pruning is to improve the performa...</td>\n",
       "      <td>Reviews of papers on deep learning are now ope...</td>\n",
       "      <td>Reviews of papers on deep learning and neural ...</td>\n",
       "      <td>0.724636</td>\n",
       "      <td>0.729288</td>\n",
       "      <td>0.760889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>All reviewers agree that the author's response...</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>The paper investigates the problem of training...</td>\n",
       "      <td>Theoretical Algorithms is published in the ope...</td>\n",
       "      <td>0.785006</td>\n",
       "      <td>0.772010</td>\n",
       "      <td>0.795516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Three out of four reviewers are positive about...</td>\n",
       "      <td>The authors present a method for learning audi...</td>\n",
       "      <td>The proposed model indeed has some merits (e.g...</td>\n",
       "      <td>The authors present a method for learning audi...</td>\n",
       "      <td>0.780417</td>\n",
       "      <td>0.783390</td>\n",
       "      <td>0.770204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Overall, this paper achieves strong and intere...</td>\n",
       "      <td>The paper studies (mainly monotone) submodular...</td>\n",
       "      <td>The paper studies the problem of submodular ma...</td>\n",
       "      <td>The paper studies the problem of submodular ma...</td>\n",
       "      <td>0.775603</td>\n",
       "      <td>0.785086</td>\n",
       "      <td>0.785267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>This paper tackles the problem of feature inte...</td>\n",
       "      <td>The authors propose two key ideas. The first i...</td>\n",
       "      <td>ParaACE is an algorithm that uses the UCB algo...</td>\n",
       "      <td>The authors propose two key ideas. The first i...</td>\n",
       "      <td>0.785126</td>\n",
       "      <td>0.788053</td>\n",
       "      <td>0.793999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 gold  \\\n",
       "3   The proposed method introduces a method for un...   \n",
       "4   The authors provide a benchmark for federated ...   \n",
       "6   The paper addresses the problem of domain gene...   \n",
       "7   After careful review, I believe that this pape...   \n",
       "11  This is a borderline paper. The scores were in...   \n",
       "12  Pros:\\n- Provides a practical technique which ...   \n",
       "14  The authors present a matrix factorization for...   \n",
       "15  The paper proposes a semi-supervised segmentat...   \n",
       "16  The paper addresses generalized zero shot lear...   \n",
       "18  The paper presents a construction for deep lea...   \n",
       "19  The paper develops a theoretical framework (in...   \n",
       "20  Three experts reviewed this paper and all reco...   \n",
       "21  I agree with the concerns raised by the review...   \n",
       "23  The paper makes a novel contribution to method...   \n",
       "24  The paper considers a collaborative decision-m...   \n",
       "26  Reviewers generally agree that the main result...   \n",
       "27  There is a clear consensus to accept this manu...   \n",
       "29  This work proposed a new HPO surrogate benchma...   \n",
       "30  The paper proposed a two-stage method to selec...   \n",
       "31  Dear authors,\\n\\nYour proposition of adding a ...   \n",
       "32  This work proposes algorithms for solving ERM ...   \n",
       "33  This paper considers the task of training poli...   \n",
       "34  The paper gives high probability bounds on exc...   \n",
       "35  This paper goes beyond the NTK setting in anal...   \n",
       "37  The reviewers agree that from a decision tree ...   \n",
       "38  Summary of discussion: Three reviewers rated t...   \n",
       "39  This paper proposes a federated learning (FL) ...   \n",
       "40  The paper shows convergence results for RMSpro...   \n",
       "42  The reviewers were generally split on this pap...   \n",
       "43  All reviewers agree that the author's response...   \n",
       "44  Three out of four reviewers are positive about...   \n",
       "48  Overall, this paper achieves strong and intere...   \n",
       "49  This paper tackles the problem of feature inte...   \n",
       "\n",
       "                                          prediction_  \\\n",
       "3   The paper adds a spatial regularization loss t...   \n",
       "4   The paper presents FLAIR, a large-scale image ...   \n",
       "6   This work tackles the task of forecasting dyna...   \n",
       "7   The APT-36k dataset consists of 2,400 video se...   \n",
       "11  The paper proposes an exploration method for \"...   \n",
       "12  The authors proposed a novel neural Fourier op...   \n",
       "14  The authors present a matrix factorization mod...   \n",
       "15  The paper is generally well written, only has ...   \n",
       "16  The paper considers the problem of (Generalize...   \n",
       "18  Proposed point spatio-temporal (PST) convoluti...   \n",
       "19  This paper builds upon the observation by Nakk...   \n",
       "20  This is a look at some of the events that took...   \n",
       "21  The method reduces 10.01M parameters of ResNet...   \n",
       "23  This paper proposes a zero-shot drug design me...   \n",
       "24  The paper looks at the problem of designing a ...   \n",
       "26  The application section is in particular way t...   \n",
       "27  Theory analysis is extensive, and the presenta...   \n",
       "29  The benchmarks are surrogate-based, provided u...   \n",
       "30  Stochastic subset selection (SSS) is a method ...   \n",
       "31  This paper proposes the method which improves ...   \n",
       "32  Private gradient descent is an important mecha...   \n",
       "33  This paper tackles the problem of generalizing...   \n",
       "34  The paper gives a high probability excess popu...   \n",
       "35  Theoretical paper presents a theoretical analy...   \n",
       "37  The paper \"MABSplit: Faster Forest Training Us...   \n",
       "38  The motivation of using the proposed network d...   \n",
       "39  A paper proposes a customisation strategy name...   \n",
       "40  This work truly does merge the gap between the...   \n",
       "42  The idea of pruning is to improve the performa...   \n",
       "43  The paper investigates the problem of training...   \n",
       "44  The authors present a method for learning audi...   \n",
       "48  The paper studies (mainly monotone) submodular...   \n",
       "49  The authors propose two key ideas. The first i...   \n",
       "\n",
       "                                        prediction_v1  \\\n",
       "3   The paper adds a spatial regularization loss t...   \n",
       "4   The paper presents FLAIR, a large-scale image ...   \n",
       "6   Reviews of a paper on deep learning for foreca...   \n",
       "7   The APT-36k dataset consists of 2,400 video se...   \n",
       "11  The paper proposes an exploration method for \"...   \n",
       "12  The authors proposed a novel neural Fourier op...   \n",
       "14  The authors present a matrix factorization mod...   \n",
       "15  The paper addresses the highly relevant and im...   \n",
       "16  The paper considers the problem of (Generalize...   \n",
       "18  The paper is, for the most part, well-written ...   \n",
       "19  This paper builds upon the observation by Nakk...   \n",
       "20  This is a look at some of the events that took...   \n",
       "21  The method reduces 10.01M parameters of ResNet...   \n",
       "23  The method involves two stages: first sketchin...   \n",
       "24  The paper looks at the problem of designing a ...   \n",
       "26  The paper considers Group Equivariant Convulat...   \n",
       "27  The paper studies the random covariance matrix...   \n",
       "29  The benchmarks are surrogate-based, provided u...   \n",
       "30  Stochastic subset selection (SSS) is a method ...   \n",
       "31  This paper proposes the method which improves ...   \n",
       "32  The problem studied is interesting and importa...   \n",
       "33  The paper focuses on learning latent represent...   \n",
       "34  The paper achieves high probability excess ris...   \n",
       "35  Reviewers give their verdict on a paper on opt...   \n",
       "37  The paper \"MABSplit: Faster Forest Training Us...   \n",
       "38  A paper proposed a new method for blind image ...   \n",
       "39  The paper proposes a new federated learning sc...   \n",
       "40  The paper studies one of the most popular algo...   \n",
       "42  Reviews of papers on deep learning are now ope...   \n",
       "43  The paper investigates the problem of training...   \n",
       "44  The proposed model indeed has some merits (e.g...   \n",
       "48  The paper studies the problem of submodular ma...   \n",
       "49  ParaACE is an algorithm that uses the UCB algo...   \n",
       "\n",
       "                                        prediction_v2  bertscore_f1_  \\\n",
       "3   The paper adds a spatial regularization loss t...       0.769009   \n",
       "4   The paper was published in the open-source sof...       0.759050   \n",
       "6   This work tackles the task of forecasting dyna...       0.764346   \n",
       "7   APT-36K consists of 2,400 video clips collecte...       0.783293   \n",
       "11  The paper proposes an exploration method for \"...       0.768899   \n",
       "12  The authors proposed a novel neural Fourier op...       0.751691   \n",
       "14  The authors present a matrix factorization mod...       0.823125   \n",
       "15  The method shows consistently good results in ...       0.759011   \n",
       "16  The paper considers the problem of (Generalize...       0.773133   \n",
       "18  The paper introduces point spatio-temporal con...       0.766425   \n",
       "19  This paper builds upon the observation by Nakk...       0.771364   \n",
       "20  This is a look at some of the events that took...       0.708714   \n",
       "21  The method reduces 10.01M parameters of ResNet...       0.756465   \n",
       "23  This paper proposes a zero-shot drug design me...       0.784235   \n",
       "24  The paper looks at the problem of designing a ...       0.781057   \n",
       "26  The paper considers Group Equivariant Convulat...       0.773004   \n",
       "27  The paper studies the random covariance matrix...       0.722764   \n",
       "29  The benchmarks are surrogate-based, provided u...       0.796257   \n",
       "30  Stochastic subset selection (SSS) is a method ...       0.750793   \n",
       "31  The method is shown empirically to achieve bot...       0.771997   \n",
       "32  The study was published in the Journal of Appl...       0.779382   \n",
       "33  This paper tackles the problem of generalizing...       0.777398   \n",
       "34  The paper achieves high probability excess ris...       0.735377   \n",
       "35  Theoretical Computer Science is published in t...       0.800558   \n",
       "37  A splitting criterion for fitting decision tre...       0.775928   \n",
       "38  A paper proposed a new method for blind image ...       0.758296   \n",
       "39  Split-Max can adjust the model size according ...       0.802651   \n",
       "40  The results of the study show that if the RSPP...       0.789796   \n",
       "42  Reviews of papers on deep learning and neural ...       0.724636   \n",
       "43  Theoretical Algorithms is published in the ope...       0.785006   \n",
       "44  The authors present a method for learning audi...       0.780417   \n",
       "48  The paper studies the problem of submodular ma...       0.775603   \n",
       "49  The authors propose two key ideas. The first i...       0.785126   \n",
       "\n",
       "    bertscore_f1_v1  bertscore_f1_v2  \n",
       "3          0.774916         0.761890  \n",
       "4          0.765862         0.785694  \n",
       "6          0.771990         0.770438  \n",
       "7          0.787695         0.793446  \n",
       "11         0.761683         0.774998  \n",
       "12         0.785843         0.791786  \n",
       "14         0.872421         0.826661  \n",
       "15         0.773316         0.772826  \n",
       "16         0.774934         0.779877  \n",
       "18         0.766752         0.779217  \n",
       "19         0.786175         0.800259  \n",
       "20         0.692365         0.743868  \n",
       "21         0.740128         0.760087  \n",
       "23         0.784501         0.791128  \n",
       "24         0.795884         0.786768  \n",
       "26         0.757142         0.780104  \n",
       "27         0.724643         0.730768  \n",
       "29         0.768666         0.806316  \n",
       "30         0.759044         0.785353  \n",
       "31         0.774181         0.772317  \n",
       "32         0.785894         0.781632  \n",
       "33         0.782260         0.795293  \n",
       "34         0.762412         0.765356  \n",
       "35         0.801402         0.803081  \n",
       "37         0.790055         0.782913  \n",
       "38         0.748630         0.761485  \n",
       "39         0.843182         0.788672  \n",
       "40         0.795494         0.729085  \n",
       "42         0.729288         0.760889  \n",
       "43         0.772010         0.795516  \n",
       "44         0.783390         0.770204  \n",
       "48         0.785086         0.785267  \n",
       "49         0.788053         0.793999  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b0237bb-b036-4289-bccb-ded372538d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7698425740906687\n",
      "0.7753120155045481\n",
      "0.7790058598373876\n"
     ]
    }
   ],
   "source": [
    "print(subset[\"bertscore_f1_\"].mean())\n",
    "print(subset[\"bertscore_f1_v1\"].mean())\n",
    "print(subset[\"bertscore_f1_v2\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc34480-e331-4c24-9bbd-3ecb047d9e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
