[
    [
        "This paper proposes variants of neural process models that can model correlation in the input (and in the output for multi-ouput regression) using invertible transformations, in particular the use of aussian copula to handle the non-Gaussian output distribution. The reviewers found the idea interesting and novel, and the experiments comprehensive and convincing, both on artificial and real data. The author rebuttals were effective in answering key questions and concerns of the reviewers, and overall the paper is recommended for acceptance.",
        "This paper proposes a class of neural processes that lifts the limitations of conditional neural processes (CNPs) and produces dependent/correlated outputs but that, as CNPs, is inherently scalable and it is easy to train via maximum likelihood. The proposed model is extended to multi-output regression and to capture non-Gaussian output distributions. Results are presented on synthetic data, an electroencephalogram dataset and on a climate modeling problem. The paper parameterizes the prediction map as a Gaussian, where the mean and covariance are determined using neural networks. Non-Gaussian prediction maps are obtained using copulas.   Technically speaking, the reviewers found the approach to be incremental and only marginally significant and I agree with them. Issues such as estimates of computational cost, using fixed lengthscales for the covariances and relationships/using normalizing flows have been addressed by the authors satisfactorily. Empirically, the contribution of the paper is somewhat significant, as it provides similar flexibility to other more computationally expensive processes and more general assumptions than conditional neural processes."
    ],
    [
        "This paper investigates when to switch between exploitation and exploration modes in reinforcement learning. granularities for the timing of the switches as well as different switching mechanisms are investigated.  The paper is overall well-motivated, well-written and empirically sound. It proposes new ways to explore the subject, especially with intra-episodic exploration variants.  Reviewers had a high variance in their evaluation of the paper. R2 and R3 voted weak accept, R1 and R4 voted for reject, and R2 voted for borderline reject. Most of the concerns were with clarifying details of the experiments and improving the exposition. From my own look into the paper, I tend to agree with the reviewers: the empirical analysis is interesting, it presents a large body of study results, and concludes with very thought-provoking suggestions and discussions.  On the other hand, R4 and R5 voted for rejection. The main concern for me is not so much the",
        "Exploration can happen at various levels of granularity and at different times during an episode,  and this work performs a study of the problem of exploration (when to explore/when to switch between exploring and exploitation, at what time-scale to do so, and what signals would be good triggers to switch). The study is performed on atari games.  Strenghts: ------------ The study is well motivated and the manuscript is overall well written Studies a new problem area, and proposes an initial novel method for this problem extensive study on atari problems  Weaknesses -------------- some clarity issues as pointed out by the reviewers no illustrative task is given to give a more intuitive exposition of the \"when to explore\" problem comparison to some extra baselines like GoExplore would have been insightful  Rebuttal: ---------- Most clarity issues have been addressed satisfactorily. It has been explained why some requests for extra baselines would be challenging/or not relevant enough. While the authors agree that GoExplore would be an interesting baseline, they seem to have not added it. An illustrative task was not provided.  Summary: ------------ All reviewers agree that this manuscript opens up and tackles a novel direction in exploration, and provides an extensive empirical study on atari games (a standard benchmark for such problem settings). While I agree with the reviewers that point out that this paper could have been made stronger by adding an illustrative task and additional baselines like GoExplore, there is a general consensus that the provided empirical study on this novel problem setting is a good contribution in itself. Because of this I recommend accept."
    ],
    [
        "This paper proposes a self-distillation based graph augmentation mechanism to alleviate the drawbacks of existing MI based models. The reviewers have noted that the proposed approach shares the high dependency towards negative sampling with the existing graph representation learning approaches. The major concern is that the designed of the proposed method encourages the closeness of augmented views from the same graph instances. This could be problematic for applications where we want to preserve the semantic similarity across graphs. The approach partially builds upon contrastive self-supervised learning which contrasts pairs of augmented graphs.  The authors performed evaluation in graph classification and regression tasks. Quantitatively the proposed model achieves encouraging results. However, most of the reviewers believe that the experimental results are not significant enough to support the claims of the paper. It would have been better if the system designs and significant difference of IGSD from existing work are discussed.   We encourage the authors to revise the paper based on the reviewer's comments and resubmit it to a future",
        "This paper proposes an unsupervised graph learning method [Iterative Graph Self-Distillation (IGSD)] by iteratively performing self-distillation to contrast graph pairs under different augmented views. This idea is then extended to semi-supervised setting where via a supervised contrastive loss and self-training. The method is empirically evaluated on some semi-supervised graph classification and molecular property prediction tasks, and has achieved promising results.  Reviewers agree that the method is interesting and the paper is well-written. The biggest concern from reviewers related to experimental evaluations of the method. The authors responded to this and included additional experiments. Although the reviewers appreciate the provided results and explanations, at the end they were not convinced about the empirical assessments. In particular, R1's post rebuttal comment indicates concerns about the reported performance of GCKN, which is different from the published one in Table 1 of GCKN paper. I encourage authors to improve on these experimental discrepancies and resubmit."
    ],
    [
        "This paper studies the relationship between adversarial vulnerability and input dimensionality of neural networks. While the reviewers found the results interesting, they do not see clear implications of the theoretical results in terms of improving our understanding of adversarial perturbation phenomena, especially since the authors do not cover the adversarially-augmented training based iterative attacks. Given that the experimental results are also not particularly novel, and the paper does not provide a clear breakout on new insights, I recommend rejection at this time.",
        "This paper suggests that adversarial vulnerability scales with the dimension of the input of neural networks, and support this hypothesis theoretically and experimentally.   The work is well-written, and all of the reviewers appreciated the easy-to-read and clear nature of the theoretical results, including the assumptions and limitations. (The AC did not consider the criticisms raised by Reviewer 3 justified. The norm-bound perturbations considered here are a sufficiently interesting unsolved problem in the community and a clear prerequisite to solving the broader network robustness problem.)   However, many of the reviewers also agreed that the theoretical assumptions - and, in particular, the random initialization of the weights - greatly oversimplify the problem. Reviewers point out that the lack of data dependence and only considering the norm of the gradient considerably limit the significance of the corresponding theoretical results, and also does not properly address the issue of gradient masking."
    ],
    [
        "This paper provides a characterization of policy optimization algorithms that provably converge to a Nash equilibrium at a sublinear rate for a class of two-player zero sum Markov games where each player adopts an entropy-regularized policy optimization method (which the authors call as smooth Fictitious Self Play). The paper also provides a lower bound on the attained Nash equilibrium. The main algorithm is a version of the classic fictitious play algorithm that operates on the Q-values but a key novelty is the use of a particular form of regularization: a Lipschitz regularity term that enforces consistency of the policy gradient. The paper makes a nice contribution to the literature by introducing a new characterization of self-play under this regularization term.  The reviewers and AC note the following potential weaknesses: (1) the reviewers found the different assumptions made in the paper a bit ad hoc and thus it is hard to assess if the provided bound is relevant or a trivial consequence of the assumptions",
        "The paper shows that a form of Fictitious Self-Play converges to the Nash equilibria in Markov games. Understanding the theoretical properties of Fictitious Self-Play is important, however the paper in its current form is not ready for publication. The paper needs a more thorough discussion on related works, the assumptions made, and as pointed out by Reviewer3, the convergence argument needs to be expanded and explained in more detail. Further, I encourage authors to add experiments and compare their algorithm with other methods."
    ],
    [
        "This paper proposes a source-free unsupervised domain adaptation technique which, when the source data is not available at the time of adaptation, divides the target data into source-like and target-specific samples for adaptation. The philosophy behind sounds quite interesting to me, namely, divide and contrast adaptive contrastive learning (DaC) strategy to achieve class-wise adaptation and local consistency. The proposed method is supported by both theoretical arguments and numerical results that demonstrate the superiority of DaC. The authors have addressed the reviewers' concerns in the rebuttal period, and at the end of the discussion phase, most reviewers are in favor of accepting the paper (with the remaining one only marking a marginal score). I agree with the reviewers and recommend accepting this paper.",
        "This paper proposes a relatively complicated method for source-free unsupervised domain adaptation, which integrates several techniques into a divide and contrast framework. The idea of dividing the target data into source-like subset and target-specific subset and employing global alignment and feature consistency for each subset is novel when the source data is inaccessible. The contrastive learning and memory-based MMD are novel in the context of source-free domain adaptation and introduce theoretical benefits in terms of the expansion theory and domain alignment theory, respectively. Reviewers were on the positive side while holding some concerns on the marginal improvement over the SoTA methods, which were addressed in the author rebuttal. AC generally agreed that the paper has introduced a novel and solid contribution to the field, with a nice connection between algorithmic methods and theoretical insights, and  recommended the paper for acceptance. Authors are suggested to incorporate all rebuttal material in the revision and if possible, to work out a recipe for easing the adoption of their relatively complicated framework that comes with many modules and loss terms."
    ],
    [
        "This paper introduces a variant of partial rejection control (SMC) for variational inference in sequential latent variable models.  The basic idea is to learn a variational representation of the posterior distribution of the latent variable by sampling from the SMC loss, and then using the variational posterior sampling to recover an upper bound on the joint distribution between the positive and negative logits.  Convergence analysis is then done with a differentiable approximation to the original SMC bound.  Pros:  - The paper is clearly written and easy to follow.  Cons: - The proposed approach is a bit complicated and the presentation can be improved. - It is not obvious that one can obtain unbiased estimators of the normalizing constant. - The experiments include a mix of toy and more realistic examples.  Overall, the reviewers felt that the paper was not quite ready for publication.  I encourage the authors to improve the presentation further.",
        "This paper explores the use of partial rejection control (PRC) for improved SMC-based variational bounds. While an unbiased SMC variant with PRC has been previously introduced by Kudlicka et al. (2020), this work introduces innovations that can help apply such ideas to variational inference. These bounds result in improvements in empirical performance.   This paper was heavily discussed, with significant engagement by both the authors and the reviewers. Most reviewers recommended acceptance of this paper, with one reviewer (R4) recommending against acceptance. R4's central concerns regard the novelty of the proposed approach and its positioning relative to the existing SMC literature. The authors argued vigorously in the comments that this paper should be judged as a contribution to the VI literature and not the SMC literature.  Unfortunately, I will recommend that this paper is rejected. It is my opinion that R4's concerns were not fully addressed.  On the one hand, I agree with the authors that there is significant value to be had in exploring variants of SMC for VI. Indeed, some prior art, like FIVO and IWAE, contributed little to the Monte Carlo literature. I believe that these were good contributions.  On the other hand, I am concerned that the current draft does not clearly circumscribe its contributions. I read the sections that disuss the works of Schmon et al. (2019) and Kudlicka et al. (2020), and the writing did not leave me with a clear enough sense of the differences. I also read the abstract and introduction of the paper. The introduction of the paper positions this work clearly within the VI literature, but does not clearly discuss prior SMC art, e.g., it does not cite Kudlicka et al. (2020). Despite citing rejection control for SMC, the writing of the abstract and introduction left me with the impression that this work was the first to introduce *unbiased, partial* rejection control for SMC. I believe that impressions matter and that the machine learning community should be generous to adjacent communities when assigning credit.  I realize that my decision is a matter of taste. I also want to say that I am confident that the authors have a clear sense of where their contribution sits, and I suspect that it is a valuable contribution. However, I cannot recommend the draft in its current form. If this is a contribution to the VI literature, as the authors argue, then the authors should not hesitate to give full credit to prior SMC art. My reading of the current draft still leaves me confused about which aspects of the SMC estimator are actual contributions."
    ],
    [
        "The paper presents a new approach to meta-learning motivated by an analysis of the impact of unrolling the optimization process in the meta-optimization phase on the learning process. The proposed algorithm, Bootstrapped Meta-Learning (BMG), optimizes a target with respect to a set of unrolled meta-gradients for task-tuning meta-parameters. Empirically, the proposed algorithm achieved a new state-of-the art for model-free agents on the Atari ALE benchmark.  The paper received unanimously positive reviews. Reviewers agree that the paper is well-motivated, well-written, and that the empirical results show considerable improvement w.r.t. well-performing baselines. The paper is also well-organized and clearly presented.  I recommend the paper for acceptance.",
        "This paper addresses a meta-learning method which involves bilevel optimization. It is claimed that two limitations (myopia of MG and restricted consideration of geometry of search space) that most of existing methods have can be resolved by the MBG with a properly chosen pseudo-metric. The algorithm first bootstraps a target from the meta- learner, then optimizes the meta-learner by minimizing the distance to that target under a chosen pseudo-metric. The authors also establish conditions that guarantee performance improvements and show that metric can be sued to control meta-optimization. All the reviewers agree that the idea is interesting and experiments well support it. Authors did a good job in the rebuttal phase, resolving most of concerns raised by reviewers, leading that two of reviewers raised their score. While the current theoretical results are limited to a simple case where L=1$, the method is attractive for meta-learning community. All reviewers agree to champion this paper. Congratulations on a nice work."
    ],
    [
        "The authors present a nice approach to bin-packing heuristic. However, reviewers point out that the related work section and the write-up need significant improvement. The limited set of experiments also needs improvement. Overall, the paper is not suitable for publication at ICLR in its current form, but the authors are encouraged to submit a revised version to a future conference, once these issues are addressed.  PS: The bin packing algorithm provided is a nice contribution to the community, as bagel-packing algorithms have not been evaluated in the context of PDB heuristics before. Hope the authors will improve the paper accordingly.",
        "Dear Authors, thank you very much for your submission. We are happy to inform you that we have decided to accept it and we look forward to your talk in the workshop. Please, go over the feedback in the reviews and correct or update your papers in time for the camera ready date (May 24). In particular, please address the comments raised by both reviewers regarding clarity, discussion of related work, and additional experimental results, by making use of the additional space (9 pages)  allowed by HSDIP. Best regards HSDIP organizers"
    ],
    [
        "This paper presents an interesting approach to infer environment labels that can be used for environment invariant learning, which is an important and challenging problem. The paper is well written and easy to follow. The problem setting is interesting and the experiments are sufficient. The comments from the reviewers are sufficient but the presentation should be improved (see below for specific suggestions). I recommend acceptance.  PS1: The title and abstract of the paper are misleading. The authors assume that training data originate from multiple “environments”, each with particular distribution. The environments are inferred from the unlabeled training data. It would be great if the authors can explain more clearly how the proposed approach is different from prior work (e.g. how the clustering is done), how the datasets come from different environments, etc.",
        "This work presents a novel environment-free invariant learning method that uses an auxiliary network to learn environment-specific features, from which environment inferences can be derived. The method is composed of two jointly learned models, that take care of the environment identification, the learning of the invariant representations, and the label predictions, produced by a multi-headed neural network. The proposed model is compared to different alternative models from the literature of the field, in different challenging benchmarks, and the results show that it closely achieves the best possible invariant learning performance.  After some initial discussions, all reviewers agreed that this work is ready for publication, as the work addresses an important problem, presents good empirical results, and will be of significant interest to the community."
    ],
    [
        "This paper introduces a no-derivatives benchmark for traffic control algorithms using the SUMO traffic simulation package. The paper provides evaluation of different RL algorithms under realistic traffic control scenarios. The authors have done a good job in the rebuttal phase in addressing most of the reviewers' comments. Traffic control is an important topic that is likely to be of great interest at the interface of AI and real-world traffic control. The benchmark can be an important tool for the community to benefit from. I recommend an accept.",
        "All the reviewers appreciate the value of the proposed benchmarks. The remaining concerns seem addressable. I recommend accepting the paper while asking the authors to incorporate the review feedback into the camera-ready paper."
    ],
    [
        "This paper has been widely discussed between reviewers and authors. Unfortunately, even after the reviewers updated their scores, the paper was still in the borderline range. Several concerns were raised, including the incremental nature of this work, the correctness of some of the theoretical results, and the limited experimental evaluation. I want to commend the authors for their persistence in working through the review process and engaging with the reviewers. They were able to address many of the concerns, and in the end the reviewers were split on whether to accept or reject the paper.   Overall, I think this paper is interesting and well-written. It is a continuation in a line of work that combines logical composition with goal-based reinforcement learning to achieve good generalization. I think it is a good paper for the conference and recommend acceptance.",
        "I thank the authors for their submission and active participation in the discussions. This papers is borderline. On the positive side, reviewers emphasized this is a well written [ovqB,1zPe] and sound paper [BUDa] with good theoretical [td5N,ovqB,1zPe] and empirical [BUDa,td5N,ovqB] results. On the negative side, reviewers remarked clarity [KyZj,AVki], incremental with respect to Tasse et al (2020) [KyZj], relatively restricted Boolean task algebra [td5N], toyish nature of the environments considered [ovqB], and some missing details [1zPe]. During discussion, the sentiment seems to be somewhat lukewarm with none of the reviewers strongly favoring acceptance or rejection. It seems the main remaining concern is around the toyish nature of the environments used in this paper. I acknowledge that and I believe the authors could include experiments on more complex environments. However, I also give the authors credit for addressing most of the reviewer's concerns during rebuttal and for presenting a solid empirical and theoretical result that the research community can build upon in the future. I am therefore recommending acceptance of this paper and highly encourage the authors to further improve their paper based on the reviewer feedback."
    ],
    [
        "This paper applies RL methods to the one-sided feedback setting and thus customizes Q-learning to solve inventory control. The major contribution of the paper is a new algorithm leveraging the model structure, so that the regret no longer depends on size of state and action space. In this setting, the proposed algorithm improves the regret bounds over existing methods.  The major concern of this paper still remains after the rebuttal phase. The reviewers are not totally convinced that the assumptions made in this paper are general and realistic. There are also some concerns about the soundness of the algorithm. More importantly, it is not clear whether the proposed approach is a good fit for the full feedback setting, where the episode length and the horizon are long.",
        "This paper explores the performance of Q-learning in the presence of either one-sided feedback or full feedback. Such feedbacks play an important role in improving the resulting regret bounds, which are (almost) not affected by the dimension of the state and action space. The motivation of such feedback settings stems from problems like inventory control. However, the assumptions underlying the theory herein are often quite strong, which might limit the applicability of the theory. The dependency on the length per episode H can also be improved."
    ],
    [
        "This work provides evaluations on serveral backdoor attacks and defenses on NLP data. The evaluation can be further improved by discussing related defenses, maintaining high quality and clear documentation, and discussing the stealthiness of the attacks. The OpenBackdoor framework is open-sourced and the authors can further improve the documentation with additional details and metrics. Overall, all reviewers are positive about the contribution of the work for the community to appreciate the detailed discussion and standardization of evaluation.",
        "This work provides evaluations on serveral backdoor attacks and defenses on NLP data. The evaluation can be further improved by discussing related defenses, maintaining high quality and clear documentation, and discussing the stealthiness of the attacks."
    ],
    [
        "This paper uses low-degree polynomials to identify problems for which average-case reconstruction is impossible in deep learning.  The reviewers found this to be a relevant and interesting problem, and that the polynomial modeling of tree roots is a useful and interesting tool for identifying such problems.  However, the reviewers found that the paper could be improved in a number of respects, including better linking the problem of reconstruction to the general problem of complexity analysis of deep learning, and clearer presentation of the technical contributions.",
        "This paper studies using low-degree polynomials for analyzing statistical/computational gaps for high-dimensional inference problems and identify average-case settings that exhibit this gap.  This is a nice paper and above the bar, though it perhaps appeal to only a theoretical audience."
    ],
    [
        "The paper combines decision-time planning with imitation learning to obtain better performance in non-transferant environments.  The proposed approach, IMPLANT, uses the learned policy to generate candidates for a search process that maximizes the reward.  Overall, all reviewers agree that the contribution is novel and significant, and the experimental results are strong. The paper is well-written and easy to follow.  During the rebuttal, the authors have addressed most of the questions/concerns raised by the reviewers. The authors are encouraged to include the additional experiments and discussions in the revised version.",
        "The reviewers highly appreciated the replies and the additional experiments. We also had a private discussion on the paper. To summarize: the replies alleviated quite a few concerns, however the consensus was that the paper still does not meet the bar for a highly competitive conference like ICLR.  The idea of combining MPC (on a 'wrong' model)  with a learned cost function is very interesting and a promising direction. On the downside the reviewers are still not entirely convinced about the contribution and believe that the paper requires a significant re-write to incorporate the discussed points as well as an additional round of reviews."
    ],
    [
        "The paper presents an interesting approach of combining a generative model and a classifier, both of which are trained under differential privacy to generate samples that are differentially private. The paper is well written and the authors have addressed many of the reviewers' concerns. However, the reviewers still think that the paper could be improved in several aspects, including more clearly presenting the contributions of the paper, and in making it more accessible to a broader audience.",
        "The paper surveys existing differentially private data synthesis methods, and introduces an algorithm that learns both a generator and a classifier in a differentially private mode.  The problem is highly timely and important. Results are promising.  Main remaining concerns after discussion between the reviewers and the authors are:  - reason why the proposed scheme can give better classification accuracy, should be clarified more  - unclarity on conclusions that can be drawn from the experiments. The revised version has improved on this somewhat.  One explanation for the problems was suggested to be that the paper tries, at the same time, to both present a new method and be a survey. Is hard to do in a short paper, and as a result, the paper lacks focus. At the very least, more work is needed.  The authors are encouraged to continue their work on this important problem, and the review comments hopefully help in that."
    ],
    [
        "The paper compared RNN and CNN based methods for time series outlier detection. The reviewers have raised several concerns about the paper, including the lack of clear performance gains from any method, the limited novelty of the considered approaches, and the incomplete evaluation. The authors did not provide a rebuttal. Hence, I cannot suggest this paper for presentation at ICLR as it is not ready for such an important topic. I encourage the authors to address the concerns raised by the reviewers in future iterations of the paper.",
        "This paper has been reviewed by four experts. Their independent evaluations were consistent, all recommended rejection. I agree with that assessment as this paper is not ready for publication at ICLR in its current form. The reviewers have provided the authors with ample constructive feedback and the authors have been encouraged to consider this feedback if they choose to continue the work on this topic."
    ],
    [
        "This paper studies the performance of FedAvg with local fine-tuning for multi-task linear regression. Its main theorem shows FedAvg can achieve linear convergence, whereas distributed SGD and FedAvg diverge for representation learning. Empirical results are provided to verify the theory.  The reviewers appreciated the theoretical results of this paper. However, they also raised several concerns: 1) The assumptions are strong. In particular, in Theorem 1, FedAvg and distributed GD converge to the same solution, but they differ in the choice of representations. It would be nice to compare more deeply with the previous work by Collins et al. (ICML 2021) on shared representations. 2) The novelty is limited. The connection between the results in this paper and those in Collins et el. (ICLR 2021) is not very clear. 3) There are many typos in the paper. We hope the reviewers' comments can help to improve the paper for a strong publication",
        "This work provides an analysis explaining why FedAvg can produce more generalizable representations than distributed SGD. Theoretical guarantees are presented for a multi-task linear regression setting and further empirical results demonstrate the effectiveness of learning representations with image classification tasks. The theoretical analysis presented can be an important building block for the study of more complex settings in federated optimization. All reviewers recommend acceptance.  Please take the (few) suggestions by the reviewer into account, and also incorporate the explanations and clarifications provided during the rebuttal in the camera ready version."
    ],
    [
        "The paper proposes a novel Lipschitz filtering method to increase the robustness of quantized networks. The method is validated both experimentally and through theory. Reviewers find the paper addresses a confusing point in the current literature, clarifies some issues, and provides a novel and useful approach to mitigate those issues. During the discussion phase authors addressed the concerns of most reviewers. All reviewers agree that the paper would add value to the research community through thorough experimental study as well as in industry. Therefore, I recommend acceptance.",
        "The reviewers agree the paper brings a novel perspective by controlling the conditioning of the model when performing quantization.  The experiments are convincing experiments. We encourage the authors to incorporate additional references suggested in the reviews. We recommend acceptance."
    ],
    [
        "The paper proposes a factor learning method by learning one factor at a time, in an unsupervised manner, via a variational auto-encoder style framework.  The authors conducted experiments to demonstrate the effectiveness of the proposed method. However, the reviewers think the paper is not ready for publication at ICLR, since it lacks technical novelty. In particular, the paper lacks detailed comparisons with previous work, and there are also concerns about the quality of some of the writing.",
        "This paper presents a method for unsupervised learning of disentangled representations by first training a VAE with a tangled set of latents, and then sequentially learning disentangled latent variables one at a time from the entangled initial VAE latent space. On several toy disentanglement benchmarks, the method is shown to perform competitively with previous VAE and GAN approaches.   There were several concerns from reviewers around the clarity and description of the proposed one-factor-at a time (OAT) training procedure. While the updated draft addressed several typos and some clarity issues, multiple reviewers continued to find the method description problematic. There were additional concerns around the viability of the method on real-world datasets where the number of factors are not known, and as the authors stated the proposed method can also result in one factor of variation encoded into mulitple latent variables, which hurts on many of the disentanglement metrics.  The addition of CelebA downstream task evaluation begins to address this concern of real-world data, but more rigorous experiments (including more description of how models were selected) and discussion of the limtiations of the proposed method are needed. There is also no theoretical motivation as to why the proposed intervention-based factor learning algorithm should recover the ground truth factors.  Given the concerns over experimental results, clarity, and lack of theoretical motivation, I suggest rejecting this paper in the current form."
    ],
    [
        "This paper presents a rich dataset aimed at creating supervision for 2D cartoon tasks. The dataset is created by procedurally converting open source 3D computer graphics movies/shorts into \"flattened\" 2D frames. Care is taken in describing both the motivation and limitations of this approach. In an area with a dearth of good data, this paper's contributions are warmly welcomed. Reviews appreciated these aspects of the paper while highlighting potential weaknesses that appear addressed in the revisions. I recommend accepting this paper to the NeurIPS 2022 Datasets and Benchmarks program.",
        "This paper presents a rich dataset aimed at creating supervision for 2D cartoon tasks. The dataset is created by procedurally converting open source 3D computer graphics movies/shorts into \"flattened\" 2D frames. Care is taken in describing both the motivation and limitations of this approach. In an area with a dearth of good data, this paper's contributions are warmly welcomed. Reviews appreciated these aspects of the paper while highlighting potential weaknesses that appear addressed in the revisions. I recommend accepting this paper to the NeurIPS 2022 Datasets and Benchmarks program."
    ],
    [
        "This paper considers combinatorial semi-bandits problems with multiple trigger arms and significantly improves the dependence on batch size from linear to logarithmic in many practical applications. The trigger probability and variance modulation smoothness conditions significantly improve the O(K) factor that appears in the previous regret bounds. The reviewers, including myself, find the paper well-written, with clear intuition behind various ideas/assumptions. During the rebuttal/discussion phase, the author(s) addressed most of the questions/concerns raised by the reviewers. In my opinion, the paper is a solid contribution to the literature, and I recommend acceptance.",
        "Thank the authors for their submission.  The paper studies combinatorial multi-armed bandit with probabilistically triggered arms. That is an MAB setting in which, at each round, the learner chooses a subset of the arms and obtains a reward that is some function of expected rewards of the chosen arms. In addition, the learner only observes feedback on a random subset of her chosen arms (triggered arms).   The paper relaxes a smoothness assumption laid by a previous work, and further improves the dependence on K in the regret bound, where K is the batch size (maximum number of triggered arms) The authors provide computationally-efficient algorithms that are based on Bernstein concentration inequality, facilitating the improved bounds.  The paper is well-written and organized, and the theoretical results are sound."
    ],
    [
        "The paper proposes a method for out-of-distribution (OOD) detection by ensembling multiple models and setting the disagreement high enough with respect to the OOD samples in the unlabeled set so that the labeled samples in that set can be used as input to another ensemble.   **Strengths**   * The paper is generally well-written. * The proposed method is novel and interesting. * Ensemble methods have been shown to outperform MCD and SOTA for OOD detection.  **Weaknesses**  * Although the proposed method outperforms MCD on OOD data, the experimental results show that it is not competitive with SOTA on other datasets that have OOD components. This is likely due to the smaller training size of ensembles used for this task. * Limited technical novelty as the paper mostly combines known techniques without significant new insights.  Despite the limited technical novelty, the paper is well written and easy to follow",
        "The authors propose a semi-supervised novelty detection method which tries to identify out-of-distribution samples in the unlabeled data (consisting of in- and out-distribution samples) using a disagreement score of an ensemble. The ensemble is generated by fine-tuning the trained classiifer on the labeled training data plus the unlabeled data which all get a fixed label (which is repeated several times to generate the ensemble). The main idea is that one uses early stopping based on an in-distribution validation set in order to avoid overfitting on the unlabeled points which allows then identification of the out-distribution points via the disagreement score.  The reviewers appreciated the simplicity of the approach and the extensive experimental results. The authors did a good job in trying to answer all questions and concerns of the reviewers.   However, some concerns remained: - the setting assumes that the OOD data is fixed which was considered as partially unrealistic and thus evaluation of the OOD detection performance on unseen OOD distributions was requested in order to understand the limitations of the method (this was only partially done by the authors).  - the theoretical result is for a two-layer network and completely based on previous work. As the authors use much deeper networks later on in the experiments, this result cannot be used to theoretically justify the approach.  - there remained concerns about the necessary diversity of the ensemble and the early stopping procedure  While I think that the paper has its merits, it is not yet ready for publication. I encourage the authors to to take into account the above points and other remaining concerns of the reviewers in a revised version."
    ],
    [
        "The paper studies the dimensional collapse problem of contrastive learning and attempts to attribute the collapsing phenomena to strong augmentation and implicit regularization, using simple linear network models. They identify two underlying causes for this problem, i.e too strong data augmentation  and implicit low-rank regularization. Their theoretical analyses are proved on simple networks in the ResNet family, and simplified settings of shallow, linear networks (e.g. linear layer, additive noise). The authors then present a new algorithm called DirectCLR as a simple sub- vector based CL method. The experimental results are convincing. The paper is well written and the authors have added more experimental results during the rebuttal phase. Overall, the paper is an interesting contribution.",
        "The theory and results presented in this paper provide a new method to avoid collapse in contrastive learning.  All but one reviewer recommend acceptance.  The lone negative reviewer is concerned with the limited experiments, but the other reviewers, and the AC, find the experimentation convincing enough to warrant acceptance."
    ],
    [
        "This paper proposes an ensemble of autoencoders of varying depths and widths called RobOD for outlier detection. Compared to a single model, RobOD is able to simultaneously reduce the compute cost of hyperparameter selection while increasing sensitivity to the HPs. Although rarely used in deep OD models, the ensemble idea is widely used in OD tasks and the authors demonstrated that it can be effective against a competitive set of baselines. The paper is well-written and easy to follow.  However, there are some concerns that the paper could be improved by better discussing the limitations of the proposed method. In particular, it is not clear how to determine the optimal combination of models (or ensemble) for a given task. The authors are encouraged to add discussions on these limitations in the revision.",
        "This paper empirically demonstrates the sensitivity of unsupervised OD methods to hyperparameters and proposes ensembles of models with differing hyperparameters along with training techniques based on weight sharing to do so efficiently.   The authors provided additional experiments to answer some reviewer's major concerns regarding the (meta-)HP robustness of the ensemble methods. While there are natural fluctuations with respect to the (meta) hyperparameters, a larger number of hyperparameters included usually resulted in a close to optimal AUROC.  Another concern for two reviewers was the extendability of the efficient ensemble training techniques to other models such as GANs etc. As the authors replied, even though skip connections might not be adaptable to other techniques, e.g. for ensembling various widths, zero-masked layers with BatchEnsemble would also be broadly applicable to ensemble-learn other unsupervised representation learning models. Perhaps in the final version, the authors further discuss with a short experiment how the AE-specific scaling techniques add to the performance.  A further concern was the lack of theoretical underpinning about the (meta)HP-robustness. Given that the reviewers agree that this paper provides ample empirical evidence and praise the experimental value, we think theoretical work (providing HP sensitivity results is highly nontrivial in general, let alone for neural networks) can be part of future work but the lack of it in the current manuscript should not prevent the publication of this work."
    ],
    [
        "This paper analyzes the last-iterate convergence of extra-gradient or optimistic gradient algorithms to smooth monotone games with continuous action sets using a new proximity measure called the tangent residual. Without making strong uniqueness assumptions, this is one of the first papers that provide rates of convergence for these algorithms to non-convex games. While there are some concerns regarding the limited novelty of the approach, the authors have addressed most of them well in their rebuttal. All the reviewers concur that this is a solid paper worth accepting.",
        "This paper studies the last iterate rate of convergence of the well-known extragradient and optimistic gradient algorithms in smooth monotone games with continuous convex action sets. The main result of the paper is to show that both algorithms (with constant step size) enjoy tight last-iterate convergence rates for setting (previous papers either 1) only applied to unconstrained domains 2) were asymptotic, or 3) required dependence on arbitrarily large problem-dependent constants).  This paper resolves a well-known open problem within the min-max optimization community, and is likely to have significant impact. The reviewers agree that the paper is well-written, and the the techniques (using the \"tangent residual\" as a potential function) are novel. For the final version, the authors are encouraged to incorporate the reviewers' suggestions to improve the presentation."
    ],
    [
        "**Strengths**: The paper presents a systematic study of “reward hacking” in the environments with the misspecified rewards. The authors present a set of experiments with 4 environments, several types of reward misspecification in each of them and several agents of different expressivity. They notice that often the agents that are more capable end up obtaining high proxy reward, but low real reward. This is an interesting phenomenon and an understudied phenomenon, so this study is significant.  **Weaknesses**: While the reviewers generally appreciated the systematic way in which the problem has been studied, some concerns were raised about the reproducibility of the results due to the lack of a clear champion for the problem. Nevertheless, this paper is a significant contribution to the field and I think it will be of interest to the community.   **Post-rebuttal updates:** The authors have carefully addressed the concerns raised by the reviewers. In particular, they added",
        "I thank the authors for their submission and active participation in the discussions. All reviewers are unanimously leaning towards acceptance of this paper. Reviewers in particular liked that the paper is presenting an interesting and systematic study of reward hacking [GVMn] that is useful to the research community [bfGN] and targets an important problem [uYeb] in a rigorous way [16uL]. I thus recommend accepting the paper, but I strongly encourage the authors to further improve their paper based on the reviewer feedback, in particular in regards to improving positioning with respect to related work and a better formalization of their work."
    ],
    [
        "The paper proposes an accelerated method for distributed sparse regression in high dimensions. It combines accelerated Nesterov’s proximal gradient with consensus and gradient tracking mechanisms, and shows it converges globally at a linear rate, achieving both optimal iteration complexity and communication complexity.  This method can estimate locally the gradient of the empirical loss while enforcing agreement on the local estimates. While there is sufficient contribution from the paper, the reviewers raised some concerns that were not addressed well in the rebuttal phase. In particular, one reviewer pointed out that the theoretical results are incremental over Zhong et al. (2021). Another reviewer was concerned that the empirical results do not provide strong evidence for the superiority of the proposed method.  Based on the above concerns, the paper is not yet ready for publication. I hope the authors will take the reviewers' feedback into account when revising the paper.",
        "The paper provides novel guarantees for the well-studied distributed sparse regression problem. Their theoretical results improve upon the state of the art and extend to settings that many previous results could not handle. From a technical perspective, their result builds upon previous frameworks, but also requires a number new, novel ideas. The paper does have some downsides; as mentioned previously, some of their ideas do build quite strongly off of previous work, and the presentation of the paper is quite dense, as several reviewers noted. However, the consensus of the reviewers overall is that the technical contribution of the paper is above the bar for acceptance, and would be of interest to the distributed optimization community."
    ],
    [
        "This paper proposes a new method to construct conformal prediction sets in an adversarial setting. Specifically, it uses randomized smoothing to construct a robust conformity score. All the reviewers agree that the paper is well-written and reach the acceptance bar of ICLR.  Strength: - New method for robust conformity prediction under adversarial perturbations - Generative approach for adversarial attack setting - Extensive experiments  Weakness: - More extensive experiments are needed to justify the use of post-hoc methods and the assumptions made - More discussions can be added on the decision boundary and the decision criteria  This paper received unanimously accept scores. Therefore, I recommend acceptance. I encourage the authors to take the reviewers' comments into account when preparing the camera ready version.",
        "This paper studies the problem of producing distribution-free prediction sets using conformal prediction that are robust to test-time adversarial perturbations of the input data. The authors point out that these perturbations could be label and covariate dependent, and hence different from covariate-shift handled in Tibshirani et al 19, the label-shift handled in Podkopaev and Ramdas 21, and the f-divergence shifts of Cauchois et al 2021.   The authors propose a relatively simple idea that has appeared in other literatures like optimization but appears to be new to the conformal literature: (i) use a smoothed (using Gaussian noise on X, and inverse Gaussian CDF) nonconformity score function, in order to control its Lipschitz constant, (ii) utilize a larger score cutoff than the standard 1-alpha quantile of calibration scores employed in conformal prediction. The observation that point (i) alone lends some robustness to adversarial perturbations of the data is interesting. As several experiments in the paper and responses to reviewers show, this comes at the (apparently necessary) price of larger prediction sets.   I read through all the comments and also the supplement. The authors have responded very well to all the reviewers questions/concerns, adding significant sections to their supplement as a result. Three reviewers are convinced, but one remaining reviewer requested additional experiments to compare with Cauchois et al (in addition to all the others already produced by the authors originally and in response to reviewers). However, the authors point out that the code in the aforementioned paper was not public, but they were able to privately get the code from the authors during the rebuttal period. At this point, I recommend acceptance of the paper even without those additional experiments, since it is not the authors' fault that the original code was not public. Nevertheless, I suggest to the authors that, if possible, they could add some comparisons to the camera-ready since they now have the code.  I congratulate the authors on a nice work, a very solid rebuttal, and also the astute reviewers on pointing out various aspects that could be improved.   Minor point for the authors (for the camera-ready): I would like to comment on the Rebuttal point 4.4 in the supplement, which then got further discussed in the thread. The reviewer points out four references [R1-R4]. I will add one more to the list [R5] https://arxiv.org/pdf/1905.10634.pdf (Kivaranovic et al, appeared in 2019, published in 2020). I think the literature reviews in this area are starting to be messy, and all authors need to do a better job. Clearly, the original paper of Vovk et al already establishes various types of conditional validity (and calls it PAC-style guarantee), produces guarantees that others in this area produce, and it appears that much recreation of the wheel is occurring. For eg, [R2, R4] do not cite [R5], despite [R5] appearing earlier and being published earlier, and having PAC-style guarantees and experiments with neural nets, etc. However, in turn, [R5] do not cite Vovk [R1], but [R2, R4] do cite [R1]. (And [R3] does not seem to be relevant to this discussion of conditional validity?) In any case, I am not sure any of these papers need citing since the current paper does not deal with conditional validity. If at all, just one sentence like \"Conditional validity guarantees, of the styles suggested by Vovk [2012], would be an interesting avenue for future work\"."
    ],
    [
        "Reviewers found this to be an interesting and clearly-written paper with good results. There were some concerns about fitting the contribution within the scope of ICLR, so we encourage the authors to take those comments into account and clarify their contribution in the final version.   There were also some requests for additional experiments, some of which the authors were able to address during the response period. There is now a consensus among reviewers that this is a good enough contribution to be accepted.",
        "The authors present Neural Acoustic Fields (NAF), which render sounds for arbitrary emitter and listener positions in a scene. Overall, the reviewers are very positive (8-8-8-5). The authors addressed many of the reviewers' questions about previous related work and rendering spatial binaural audio."
    ],
    [
        "This paper presents hinge policy optimization, a new theoretical framework for interpreting policy gradient algorithms as classification problems to be solved with a hinge loss. The paper shows the equivalence between such a formulation and the popular PPO-clip objective and provides global converge guarantees.  The idea is interesting and novel. The theoretical analysis is useful and the empirical results can be improved.  We encourage the author(s) to incorporate the comments from the reviewers to make it more interesting for the ML audience.",
        "All reviewers agreed that analysis of PPO is interesting.  During the discussion, however, there was an agreement that the current work is too thin in novelty and contribution: it provides only convergence analysis under very strong assumptions, and heavily builds on techniques from prior works. Meanwhile, for conventional policy gradient, recent works provided convergence rates. As one reviewer pointed out - this work does not further our theoretical understanding on why PPO is better than vanilla policy gradient, as all the established results hold for policy gradient, even with less assumptions. I encourage the authors to strengthen their paper by relaxing Assumption 4 (perhaps based on the robust classification idea raised in the discussion), and by further providing rate results."
    ],
    [
        "This paper proposes a fully Bayesian approach to learn an intuitive physics model by combining symbolic regression and statistical learning. Using symbolic regression has a long history, especially in material science, and a good method for successfully applying it to physical science is well known. The paper however, does not make a sufficiently clear case on the advantages of using it in the context of symbolic physics, neither in the method nor in the experiments. It is a borderline paper and could be improved in various aspects such as (1) using better hyperparameter search, (2) using a better description of the symbolic regression algorithm, (3) better comparison with the state-of-the-art, and (4) making clear how the method compares to the state of the art in symbolic physics.",
        "This paper proposes a method for learning physics combining symbolic computation and learning in an interesting way, targeting sample efficiency. At the initial evaluation, it was on the fence but leaning towards acceptance, with 3 slightly positive and one slightly negative review.   The strengths lie in the combination between symbolic reasoning and statistical ML with a formulation around the classical EM framework. On the other hand, an important issue of the paper is its quite simplistic evaluation on now very easy problems and benchmarks. While benchmarks tend to be simple in the field of learning physics, current work does address more difficult problems than the problems tackled in this paper.  Another issue discussed was the simple trade-off in injecting hand-crafted inductive bias into a system leading to increased sample efficiency, which was perceived as unsurprising by some reviewers. While this is common in ML, and even strongly more so in learning physics from data synthetically generated with known physical laws, it was perceived to be particularly unsurprising in this paper where the benchmarks are indeed very simple and the laws directly encoded.  The AC discussed this paper with the PCs, and it was judged that the weaknesses in evaluation, in particular the simplicity of the tasks, cannot compensate for the interesting hybrid symbolic/ML formulation, and decided to reject the paper."
    ],
    [
        "This paper provides an acceleration strategy for parameter tuning using data subset selection to reduce the cost of HPO. Reviewers all agreed that the proposed methodology is novel and provides significant speedups over the competitive baselines. While there were some concerns on the significance of the performance improvements, the strength of the paper outweighs these. I recommend acceptance.  BTW, I would like to ask the authors to include a citation to https://arxiv.org/abs/1908.08729, which actually conducted a similar analysis and achieved similar speedups using a very similar methodology, and which can be used as a baseline for future works.",
        "This paper proposes AUTOMATA, an approach that uses GradMatch to select subsets of data in order to accelerate hyperparameter tuning. The reviewers all found the approach to be practical and empirically effective. There were concerns about the robustness to different subset sizes, particularly across different datasets, but the authors demonstrated that AUTOMATA works well across a number of settings during the rebuttal period. The remaining criticism largely revolves around the novelty of the approach, but the majority of the reviewers believe that this is a useful application of gradient-based subset selection."
    ],
    [
        "This paper studies the important problem of tail-label representation learning in extreme extreme multi-label learning setting. As the reviewers mentioned, the main contribution of the paper is proposing methods for re-ranking which encourages precedence of tail labels and avoiding skew by using augmentation of the rarer labels. However, the theoretical properties of the proposal have not been proved experimentally which makes the significance of the contribution of this paper quite unclear. Although the authors provided some experimental results on some benchmark datasets, it is still unclear whether the results would extend to more realistic datasets.",
        "The paper presents some interesting insights, but all reviewers have agreed that it does not meet the bar of ICLR. The theoretical results require revision as several issues have been indicated in the reviews. The authors have tried to correct them during the rebuttal, but the reviewers remain unconvinced.  Also the novelty is limited as re-ranking is a well-known concept and decoupling of head and tail labels is an approach often used in practice across many applications.  The authors should also clarify the way the RankNet method is used and implemented to clarify the issue raised by Reviewer 1. Finally, let me notice that adjusting thresholds for labels has been considered in the XMLC literature, in the context of optimization of the macro F-measure (Extreme F-measure Maximization using Sparse Probability Estimates, ICML 2016)."
    ],
    [
        "The paper studies the problem of so-called churn prediction, where as many as possible changes to a predictive model can be made without being properly validated. The paper proposes a way to control the churn rate, which is based on a distillation of the model parameters and solving a convex optimization problem with an associated loss function. The authors validate empirically their approach on 12 OpenML datasets.   The reviewers agree that the paper studies an interesting problem, proposes a novel solution, and has the potential to inspire further research. The primary limitation of this study is that, while the underlying problem framework is intriguing, the empirical study does not appear to make a significant impact. As a result, it is hard to determine whether the proposed method has the expected impact.  Given the potential interest for the research community, we encourage the authors to keep improving the study and resubmit to another venue.",
        "The paper introduces a procedure to control the churn (i.e. differences in the predictive model due o retraining) using distillation.  This is a strong paper, with novel technique which is clearly presented, and is backed by sound theory. The experimental results were also deemed extremely convincing by reviewers TJ4g and pZBb.   Reviewer nqfu raised a question about the similarities between churn reduction and domain adaptation. The authors have addressed this by pointing out similarities to their work but also noting that, in the settings mentioned by the reviewer, alternative approaches such as completely retraining the model might be more appropriate. This part of the rebuttal is convincing.  Reviewer TJ4g has pointed out several points of improvement, to which the authors have responded adequately.  All in all, this paper is ready for and deserving of acceptance."
    ],
    [
        "This paper generalizes the results of Pilanci and Ergen (2020) showing that the non-convex optimization problem corresponding to the training of a one-hidden-layer muti-output ReLU nework can be solved using convex programming. The authors give the first algorithm that finds the global min of the network training Problem. However in the general case the complexity is exponential in the rank of the data matrix. The paper does not have a very clear message and is hard to follow. The notation in some critical parts of the paper is not clear and makes reading difficult. We encourage the authors to take the reviewers' comments into account and improve the paper.",
        "This paper extends an earlier work with scalar output to vector output. It establish a relationship of two-layer ReLu network and convex program. The result can be used to design training algorithms for ReLu networks with provably computational complexity. Overall, this is an interesting idea, leading to better theoretical insights to computational issues of two-layer ReLu networks."
    ],
    [
        "This paper proposes a principle component analysis based framework for missing data imputation, which is based on PCA and PIC, and allows for more efficient and accurate imputation. The paper is well written and easy to follow. The idea of separating the features in fully observed vs. missing features is a good idea. The originality of the paper is limited, mainly because the paper only compared with PCA-based methods, but the authors added experiments with methods that use PCA on top of the standard PCA methods, and showed that their method can achieve better performance. The reviewers think that this is an interesting idea and an important direction. However, there are a few issues that the reviewers raised, and the authors did not address them in the rebuttal phase.   1. Novelty: The term \"Principal component analysis\" should be more precisely PCA or PCA. There are many papers in the literature that apply PCA to the principle components analysis",
        "This paper proposes a framework based on principle components analysis (PCA) to speed up the missing data imputation. It divides the feature sets into two partitions -- the fully observed one and the one that contains missing values. The proposed method applies PCA to the fully observed partition to do dimensionality reduction, followed by the existing imputation methods. The authors further propose to apply PCA to the imputed data to speed up the downstream classification task.  The major weakness is that the methodological contribution is quite limited. Projecting data into lower dimensional spaces to speed up downstream tasks is not new. In particular, the main assumption of random missingness has been considered before 10-20 years ago and the more challenging setting of non-random missingness was not considered. Overall the reviewers mostly agree that the contribution is limited."
    ],
    [
        "This paper focuses on the information maximization problem in self-supervised learning (SSL), specifically the collapse problem. It considers a second-order statistics-based mutual information measure, log-determinant mutual information (LDMI), which is equivalent to Shannon mutual information under Gaussian distribution and has been widely used in previous SSL works. The main contribution of this paper is to develop a framework for SSL using such a measure. The paper is well-written, accompanied by a detailed theoretical analysis. Empirical results demonstrate the advantage of the proposed method on several benchmark tasks.  The paper receives mixed ratings initially. Reviewers have raised various concerns, some of which have been successfully addressed by the authors. For example, one reviewer pointed out that the presented experiments aren't sufficient to show the strength of the work, as only small scale benchmark datasets are used. The authors have added one large scale experiment, which partially addressed the concern. Another reviewer raised the concern that the",
        "The paper describes a self-supervised learning method based on an information maximization criterion that naturally prevents dimensional collapse. The authors consider the Shannon mutual information under the assumption that the data is Gaussian. A first-order approximation to the log-determinant of the sum of two matrices is used to simplify the final objective. Experiments on 4 image datasets show that the proposed approach gives better results than contrastive and non-contrastive methods.  Strengths:  1 - The paper is well written and easy to follow. 2 - The paper is theoretically grounded on correlative information measure of representation. 3 - Strong results on some downstream classification problems. 4 - Initially the experiments included only one downstream task regarding classification, but the paper has been updated to include also results for object segmentation and detection task. 5 - Novel and well motivated. 6 - state-of-the-art SSL performance.  Weaknesses:  - Some weaknesses are pointed out by reviewer GZwK, but these are not well justified.  Decision:  A majority of reviewers vote for acceptance. The only reviewer voting slightly towards rejection is GZwK, with a reasoning that is not well justified. For example, the main criticisms mentioned by reviewer GZwK  - The paper directly generalizes the earlier proposed log-determinant mutual information to the field of self-supervised learning.  - this paper does not give a deep-going analysis that why the second-order statistics can play a important role in self-supervised learning  are not mentioned by any of the other reviewers.  Because of this, I have decided to accept the paper."
    ],
    [
        "The paper presents a method for reaching the distance between any start position and any goal subject to obstacle avoidance with a neural network.  The reviewers and AC note the critical limitation of novelty of this work which is an application of GANs to the domain of navigation. Also, all reviewers agree that the paper is not well written and lacks detail on all required detail such as architecture, training regime, cost function regularization, biases induced due to the discretization nature of the training data, etc. There is also no comparison with state-of-the-art methods for 2D navigation, but rather experiments in 3D. Overall, AC decided that this work is not ready for publication at ICLR in its current form.",
        "This paper proposes environment fields, a representation that models reaching distances within a scene. Dense environment fields are learnt using a neural network, and the effectiveness of this representation is shown on 2D maze environments and 3D indoor environments. This paper received hugely contrasting reviews, with two reviewers being very supportive and one reviewer providing the lowest score of 1. In light of this, I'll start with providing my takeaways on the review and discussion with reviewer z3Y4 (rating of 1) and then proceed to the remaining discussion.  Reviewer z3Y4 has provided the score of 1 and has made strong remarks that include: \"what is proposed in this paper is simply not comprehensible\", \"description of the method itself is simply devoid of all required detail\", \"The main claims of the paper are incorrect or not at all supported by theory or empirical results.\" and \" what is being proposed in this paper is simply too unclear and vague to be assessed\". **Such dismissive remarks, in my opinion, are completely unnecessary and create a toxic discussion and review environment.**  Reviewer z3Y4 has many criticisms of the submission, but the primary ones include: (a) the lack of details throughout the paper (b) the positioning of the paper in the abstract and introduction, and (c) the lack of experiments in continuous environments. Re (a): It is well understood in our research community that providing every last detail in the main submission is nearly impossible due to the restriction on the number of pages. Providing excess details in the main paper also often reduces the readability of the paper. Such details are better addressed in the appendix and crucially, the code. The authors have provided some details in the appendix and have indicated that they will release a code base.  I also agree with the authors that justifying every last detail in the network architecture such as choice of an activation function is not necessary for this submission. The same goes with describing methods in past works in detail vs referring the reader to the appropriate citation. As a result, I believe that the authors have addressed (a) well. Re (b): This has also been addressed by the authors, by pointing out relevant parts of the paper that had the necessary details. Re (c): In this regard, the paper clearly contains a well laid out experiment in 3D indoor scenes, so as far as I am concerned, this has been addressed in the main submission.  Reviewers AhgQ and fAEP have supported this submission but also laid out some concerns that include: (1) Are the gradients suboptimal ? (2) Positioning the paper with regards to past works (3) Motivation behind using the VAE (4) Qualitative analysis and failures The authors have addressed these 4 concerns well using the rebuttal as well as via a revision of the appendix. The reviewers, post discussion have indicated their satisfaction with the revised submission.  I think this paper is interesting and proposes a novel scene representation which can be useful for others in the Embodied AI community. I am in agreement with reviewers AhgQ and fAEP, and in spite of the strong reject score by z3Y4, I recommend accepting this paper."
    ],
    [
        "This paper presents an approach for learning to factor face attributes using a latent VAE and GAN, trained in a self-supervised manner to decouple the identity information from the attribute information, and then uses adversarial information factorization to separate the two representations in latent space. Experiments on a face dataset show that the proposed approach can learn to factor attributes from identity on the face dataset.   The paper is well written and the motivation is clear. The experimental results also show the effectiveness of the proposed model. The reviewers and AC note the following potential weaknesses: (1) limited novelty as the considered approach is a direct application of conditional VAE given Boa et al (2017), (2) lack of ablations to demonstrate the importance of the learned factorization for disentangling identity from identity and face attribute factorization, and (3) limited comparison to prior work on attribute generation and disentanglement.  The authors have addressed most of the concerns",
        "The paper proposes a supervised adversarial method for disentangling the latent space of a VAE into two groups: latents z which are independent of the given attribute y, and \\hat{y} which contains information about y. Since the encoder also predicts \\hat{y} it can be used for classification and the paper shows competitive results on this task, apart from the attribute manipulation task. Reviewers had raised points about model complexity and connections to prior works which the authors have addressed and the paper is on the borderline based on the scores.   Though none of the reviewers explicitly pointed out the similarity of the paper with Fader networks (Lample et al., 2017), the adversarial setup for getting attribute invariant 'z' is exactly same as in Fader networks, as also pointed out in an anonymous comment. The only difference is that encoder in the current paper also predicts the attribute itself (\\hat{y}), which is not the case in Fader n/w, and hence the encoder can be used as a classifier as well (authors have also mentioned and discussed this difference in their response). However, the core idea of the paper as outlined in the title of the paper, ie, using adversarial loss for information factorization, is very similar to this earlier work, which diminishes the originality of the work.   With the borderline review scores, the paper can go in either of the half-spaces (accept/reject) but I am hesitant to recommend an \"accept\" due to limited originality of the approach. However, if there is space in the program, the paper can be accepted."
    ],
    [
        "The paper presents a GAN approach, Surreal-GAN, that aims to create fake pathological data (with a latent variable that is distinguishable from real data) based on the correlation between the two inputs, and uses an inverse function to predict the latent variable from a fake/real pathological data and a healthy input. The paper shows that it can outperform several state-of-the-art methods based on semi-supervised learning, and has shown great performance on the task of creating a representation of disease-related patterns from structural MRI images.  The reviewers agree that the paper tackles an important problem, and the idea of using GANs to learn representations of multiple dimensions imposed on a normal brain is very interesting. However, they also agree that it is unclear how realistic the proposed approach is, given that it relies on the \"inverse\" GAN formulation and that performance results are not significantly better than baselines. Furthermore, the paper would benefit from a",
        "The authors present a GAN for learning a continuous representation of disease-related image patterns from regional volume information generated from structural MRI images. The reviewers find the problem relevant and appreciate the proposed solution. They find the paper well-written and find the empirical results on Alzheimer brain MRIs relevant for the neuroscience community.   The overall objective function includes several hyper-parameters. As pointed out as the main weak point by multiple reviewers this may hint at overengineering/overfitting to a data set. However, the reviewers also mention that the regularizers are all sufficiently well-motivated in the paper and the author response.  Reviewers highlight comparisons on the real data as a strong result demonstrating that Surreal GAN was able to isolate two major sources/locations of atrophy in Alzheimer’s disease. Overall, the reviews are positive in majority."
    ],
    [
        "The paper proposes a physical system simulation benchmark to evaluate the integration of simulation methods with respect to physical models. The paper is well-written and easy to follow, and the authors have done a good job motivating the four representative benchmark physical systems. The flexibility of the benchmark allows for the integration with other learning tasks or machine learning methods. Even though the paper focuses on the simplest physical models, the conclusion of the paper is that even data-driven pipelines, while providing qualitatively acceptable solutions, are quantitatively far from integrating physical models with meaningful integration. This is an important conclusion to support future work in this direction.   One weakness is that the paper does not provide much discussion on how to apply the proposed approach to more complex systems, beyond the simplest ones. The authors are encouraged to provide a more in-depth discussion on these issues in future revisions.  Overall, all reviewers are enthusiastic about the paper, and we recommend acceptance.",
        "This paper introduces a physical evaluation dataset framework for scientific computing pipelines that map one high-dim state space into another high- or low-dim one, providing a suite of simple representative physics problems.  Reviewers appreciated for motivation, clarity, comprehensiveness, and overall contribution to the space."
    ],
    [
        "This paper presents a large corpus of Korean legal documents, paired with labels corresponding to two classification tasks, two legal judgment prediction tasks, and one summarization task. Reviewers praised the uniqueness of the new resource.  However, there were concerns about the domain specific training of the GPT-2 model, which was found to be important by the authors but not sufficiently well justified by the empirical study presented.  Reviewers also found value in the release of the dataset but not convinced that it represents a significant advance over existing resources.  I agree with these objections. Large-scale corpora, benchmark datasets, and language models in the legal domain are lacking. This work does not provide one single large-scale corpus or benchmark for the domain. But it does provide six smaller-scale datasets that can be helpful for the research community to understand the legal discourse and make progress in this area.  In its current form, the paper is not ready for publication but I believe it has",
        "This paper presents a large corpus of Korean legal documents, paired with labels corresponding to two classification tasks, two legal judgment prediction tasks, and one summarization task. Reviewers praised the uniqueness of the new resource.  However, there is some criticism of the results section, with several reviewers bringing up possible comparisons to other models and wondering whether the performance of this model has been analyzed thoroughly.  The authors argue in particular that mT5 and KoGPT-2 can benefit from continued pre-training this corpus, which seems satisfactory, although there is the question raised by 7fpy that this is essentially pre-training on the test tasks and may be too generous when assessing the performance on other legal-domain tasks that arise down the road.  Reviewer 7fpy brings up some valid critiques of the dataset construction: several points about filtering were unclear, as was the strength of the automatic pipeline used to construct the dataset.  There are a few ethical concerns raised by the ethics reviewer, which I believe are serious. Point [1] is resolved. Point [2] about misuse seems valid and harder to argue against.  The data does have value for use in the kind of more benign studies the authors report in the response there. But its very existence could encourage the construction of certain kinds of automated tools for legal judgment prediction, which has been a hotly-debated issue in the NLP community before. Ultimately I will defer to the ethics reviewer on this one, who seems satisfied.  Overall this paper seems like a well-done effort. The main question is whether its utility (modulated by issues with the results) outweighs the risks of putting it out there. Reviewers seem to lean positive on this and I would lean positive as well."
    ],
    [
        "This paper introduces the first NAS benchmarks on graphs. Ratings were quite diverse, with scores of 4,5,6,7,8,8. The many positive reviewers highlighted that GraphNAS is very relevant and that a benchmark for them would be very useful for the community. The benchmark includes comprehensive evaluations on as many as 9 different datasets, which may also help facilitate research on meta-learning for (Graph)NAS. Initially, the code for creating the benchmark and analysis was not available, which is a no-go for tabular NAS benchmarks, but the authors fixed this in the rebuttal period. The most negative reviewer, 8asK7, appears to not be familiar with tabular benchmarks and their usefulness, and did not react to the discussion about it, as well as to the modification of the paper to highlight it. The other borderline negative review, by reviewer LkTe, had as their main ciriticism that NAS methods should be benchmarked on many",
        "This paper introduces the first NAS benchmarks on graphs. Ratings were quite diverse, with scores of 4,5,6,7,7,8. The many positive reviewers highlighted that GraphNAS is very relevant and that a benchmark for them would be very useful for the community. The benchmark includes comprehensive evaluations on as many as 9 different datasets, which may also help facilitate research on meta-learning for (Graph)NAS. Initially, the code for creating the benchmark and analysis was not available, which is a no-go for tabular NAS benchmarks, but the authors fixed this in the rebuttal period. The most negative reviewer, 8asK, appears to not be familiar with tabular NAS benchmarks and their usefulness, and did not react to the discussion about it, as well as to the modification of the paper to highlight it. The other borderline negative review, by reviewer LkTe, had as their main ciriticism that NAS methods should be benchmarked on many spaces, but the point of tabular NAS benchmarks is *not* to provide a conclusive assessment of the performance of NAS methods that holds in general across search spaces (as a \"horserace\" paper might try to achieve), but rather to facilitate the cheap evaluation of current and future NAS methods on a single search space. For these reasons, I do agree more with the positive reviewers and recommend acceptance of this work as a poster."
    ],
    [
        "This paper proposes a novel CNN-based portfolio policy network that has permutation invariance (equivariance) properties when treating multiple assets’ information via transfer. Experimental results demonstrate the superior performance over state-of-the-art portfolio methods in terms of Sharpe ratios, stability, and expected return.  All the reviewers agree that this is an interesting paper worth publishing at NeurIPS. I would like to encourage the authors to consider the issues raised by the reviewers and further improve the paper in the camera-ready version.",
        "This paper proposes an architecture of a policy network (WaveCorr) that is particularly effective for portfolio management tasks.  A key observation that leads to the design of WaveCorr is that the dependency across asset should be treated differently from the dependency across time.  The proposed WaveCorr has the property that it is \"permutation invariant\" with respect to assets, which means that the class of functions that can be represented by WaveCorr is invariant to permutation of assets.  WaveCorr is shown to achieve the state-of-the-art performance in a portfolio management task.  A major point of discussion was the definition of \"permutation invariance\".  The reviewers and AC understood the difference between the permutation invariance defined in this paper and that studied in the prior work (the output of a network is insensitive to the permutation of the particular values of the input).  With the definition in this paper, however, a fully connected layer is permutation invariant, but the Corr layer proposed in the paper appears to have more structure.  It is unclear exactly what properties of the Corr layer leads to the performance improvement."
    ],
    [
        "This paper proposes a new graph rewiring approach that utilizes a discrete notion of Ricci curvature in graph convolutional neural networks (GCNs). This is motivated by a link between negatively curved edges and graph bottlenecks, i.e., a decrease in the curvature of the graph. Theory provides an analytical explanation for the over-squashing and GNN bottleneck phenomena. While the theoretical contribution is strong, some concerns have been raised regarding the lack of strong empirical evidence. In particular, some reviewers have questioned the robustness of the empirical results, which do not clearly support the claim of the paper. We hope the author(s) could address these concerns and improve the paper for the final version.",
        "The paper proposes a new technique to handle oversquashing in GNNs by introducing a novel rewiring technique. The reviewers are quite positive about the paper and the rebuttal phase greatly helped clarify the method and it's impact."
    ],
    [
        "The paper presents an empirical study on quantization and distillation of BERT models. The authors find out that the previous approaches for quantization are significantly undertrained and hence need more training resources. They propose a new method XtrmC to achieve much higher quantization ratio using much less training resources and achieve better results. All reviewers agree that the paper contains valuable engineering insights, yet its presentation is largely hampered by the careless writing and lack of basic proofreading. The paper lacks a detailed analysis of the computational complexity of the various methods in the experimental setting. Although it provides a thorough understanding of the low-bit (1-bit and 2-bit) quantization for pre-trained BERT. It needs a thorough comparison with the recent works on TinyBERT, TenaryBERT and BinaryBERT. The major concern is that the contribution is incremental since it mainly discusses the effectiveness of the strategies proposed in the previous works and does not discuss the differences and how",
        "Reviewers agree that this paper presents a systematic study on the impact of hyper-parameters and training strategies of previous works. Based on those empirical observations, they propose a simplified model with layer reduction and single-stage distillation, which do not rely on a complicated and ad-hoc training strategy. Extensive experiments are conducted with thorough comparison with existing works. Authors also clearly point-out their current limitations.  The major concern is that this paper is more focused on discussion of the effectiveness of training strategies in previous methods, while the theoretical contribution is somehow limited. It would be much better if authors could explain their observations (more training epochs is needed while additional distillation stages can be discarded) from a theoretical perspective, although this may be far out of the scope of this work. Nonetheless, this paper presents valuable empirical study over existing Transformer compression methods and may inspire following research; therefore, AC recommends acceptance."
    ],
    [
        "This paper studies the group disentanglement properties of contrastive approaches to representation learning using BYOL (difference of low-rank latent representations via normalization transformations), an approach that produces disentangled representations by using a different normalization method each time a new layer is added to the representation. The authors show that BYOL can induce better representations than some other methods at learning to disentangle multiple groups. This is an interesting, previously-unreported finding, and it motivates future work in this direction.   The reviewers had split opinions on this paper. While some reviewers found the work interesting and worthy of acceptance, others raised concerns about the limited nature of the results, in particular the fact that only one dataset is used to show these results, and that these results are only shown on low-dimensional data. While I agree with the authors that some of these concerns were partially addressed in the rebuttal, and I think there are no major flaws remaining,",
        "The paper provides additional empirical evidence that self-supervised learning methods can help disentangling factors of variation in a dataset. That said, the paper can benefit from better framing and perhaps comparison with existing work (e.g., https://arxiv.org/abs/2102.08850 and https://arxiv.org/abs/2007.00810). Furthermore, the authors acknowledge that there was a bug in their code, which I believe should at least lead to softening the claims about group disentanglement. Accordingly, please consider revising the paper and re-submitting to other venues."
    ],
    [
        "Summary:  Authors propose a new NAS benchmark based on surrogate models prediction.  This surrogate model can predict all architectures in DARTS search space, which is about 10^18 possible architectures.   Strength:  - The authors have made several significant improvements over the past submission. - The paper is well-written.  - A much larger search space is covered in the search space compared with previous work. - All codes are open-sourced, which demonstrated the good reproducibility of this work.  Weakness:   - From a novelty perspective, it is not clear how this work differs from existing benchmarks, e.g. NAS-Bench-2, since all surrogate networks are based on the same search space. - Similar work has been done on surrogate networks for neural architecture search, so its contribution is incremental. - It is unclear how much novelty is provided in terms of new benchmarks, given that most of the work is very similar to existing benchmarks.",
        "This paper proposes a methodology to create cheap NAS surrogate benchmarks for arbitrary search spaces. Certainly, the work is interesting and useful, with comprehensive studies to validate such approach. It should be credited as belonging to the first efforts of introducing and comprehensively studying the concept of surrogate NAS benchmarks. In AC's opinion, it is a solid paper that will (or has already) inspire many follow up works. The paper is well written.   This paper received highly mixed ratings. Although the authors might not see, all reviewers actually participated in the private discussions. Reviewer 1eb8 indicated hesitation in her/his support. Reviewer yTPb stated that if not considering the arXiv complicacy, she/he \"would certainly raise score by one level\".  AC also reached out to Reviewer yTPb about her/his mentioned possibility of updating scores, and got confirmed that her/his original opinions wasn't changing after rebuttals. Besides, AC agrees the arXiv/NeurIPS complicacy shouldn't brought into the current discussion, and ignored that factor during decision making.   The main sticking (and considered-as-valid) critique is on the relatively outdated and incomplete selection of baselines. As a benchmark paper, it should capture and diversify the recent methods. For example, the authors might consider adding: https://botorch.org/docs/papers (latest methods in Bayesian Optimization) https://github.com/facebookresearch/LaMCTS (latest methods in Monte Carlo Tree Search) https://facebookresearch.github.io/nevergrad/ (latest methods in Evolutionary algorithms)  Given the above concerns, AC considers this paper to sit on the borderline, and perhaps with pros outweighing the cons. Hence, a weak accept decision is recommended at this moment."
    ],
    [
        "The authors propose a very simple method to improve the consistency between clean models and backdoored models after fine-tuning a clean model on a poisoned dataset with backdoor samples. They provide a theoretical analysis and show that the consistency of the backdoor model is global and instance-wise, and propose an anchoring loss to anchor or freeze the model behaviors on the clean data, with theoretical guarantees.   The method is extremely simple, and the theory is a bit extraneous. Nonetheless, the experiments do a good job of showing that their method accomplishes their goal. The presentation of the supplementary material could be improved, but overall the reviewers like the ideas in this paper.",
        "This paper proposes measures of consistency between back-doored and clean models, proposes regularization using those consistency measures, and showcases that such trained models indeed exhibit better consistency. Also, it is demonstrated that the fine-tuned model does not deviate too far from the original clean model. The reviewers' comments are all well addressed. Some concerns related to the notion of consistency and how it relates to the detection of backdoors are still left open, but the reviewers seem to be satisfied with the answers. Given the overwhelmingly positive reviews, I propose accept."
    ],
    [
        "This paper introduces a variant/generalization of the multi-set multi cover problem, where the aim is to maximize the weight of the elements covered at least n times by up to k overlays with potentially k different cover types. The objective function is not submodular, hence does not admit a classical greedy approach, but an approximate approach using mixed integer linear programming is proposed and shown to work reasonably well. There is a connection to the COVID vaccine design pipeline. The stronger contribution in my view is the observation that the problem can be helpful in the design of new vaccines.   The reviewers and AC note the following potential weaknesses: (1) limited technical novelty as an expert could likely (easily) translate the problem formulation into code. (2) unclear motivation as to why the online approach is better than the face-to-face approach. (3) marginally greedy algorithm using beam search and an ILP (Linear Inference Processes) are proposed",
        "The paper introduces the maximum n-times coverage, a new NP-hard (and non-submodular) optimization problem. It is shown that the problem can naturally arise in ML-based vaccine design, and two heuristics are given to solve the problem. The results are used to produce a pan-strain COVID vaccine.   The reviewers and I think that this is an interesting paper with a compelling application. There were some concerns about theoretical novelty and biological accuracy but these were addressed during the author response period. Given this, I am delighted to recommend acceptance. Please incorporate the feedback in the reviews in the final version of the paper."
    ],
    [
        "This paper proposed a variant of data augmentation for training with large batches that involves including in the batch M data augmentations of the training samples, which in turn increases the batch size by M Independent samples from each minibatch. The idea is interesting and simple, and of interest to the community. However, there are two main concerns raised by the reviewers. First, the claim of improved generalization performance is not sufficiently supported by the empirical study. Second, the improvement on test errors does not look significant. I agree with the reviewers that it is not sufficient to demonstrate that by introducing batch augmentation that one gains significant performance improvement on standard benchmarks.",
        "The authors propose to use large batch training of neural networks, where each batch contains multiple augmentations of each sample. The experiments demonstrate that this leads to better performance compared to training with small batches. However, as noted by Reviewers 2 and 3, the experiments do not convincingly show where the improvement comes from. Considering that the described technique is very simplistic, having an extensive ablation study and comparison to the strong baselines is essential. The rebuttal didn’t address the reviewers' concerns, and they argue for rejection."
    ],
    [
        "This paper presents a latency-aware dynamic inference method. The proposed method is novel and well-motivated. Experiments are performed on image classification and demonstrate latency reduction of 23 to 45% depending on the hardware superiority. All the reviewers agree that the paper is well-written and the method is technically sound. The concerns from the reviewers are well-addressed in the rebuttal. After checking all the reviews and rebuttal, the meta-reviewer recommends acceptance of the paper.",
        "The paper proposes latency-aware spatial-wise dynamic neural networks under the guidance of a latency prediction mode. reviewers arrived at a consensus to accept the paper."
    ],
    [
        "The paper addresses the problem of segmentation of multiple class images from partially labeled datasets. As pointed out by the reviewers, the technical novelty of the paper is limited since it is a combination of existing approaches. The authors also fail to address the multi-organ segmentation problem. The datasets are partially labeled, which is a limitation of the approach. The paper may be of interest to the medical imaging community but only if the authors can address the following issues: (a)data release; (b)performance improvement is marginal compared to multi U-Net; (c) justification of using only partially labeled data.",
        "While two our of three reviewers pointed out that the method is very similar to a previously published approach, DODNet,  these reviewers still see value in the extensive evaluation presented in this paper, and both suggested weak accept. The first reviewer also increased the score to borderline after the rebuttal owing to additional experiments for evaluation. I also agree with the reviewers that this paper addresses an important problem in the field, i.e.  partially labelled data, and presents extensive evaluation and benchmarking against important baseline approaches, and therefore suggest acceptance of this paper."
    ],
    [
        "The authors introduce LEAF, a learnable audio frontend, and evaluate it on several tasks including event classification, speaker identification, keyword spotting, language identification, music classification etc.   Overall, the reviewers appreciate the insights provided by the authors in analyzing the relationships between handcrafted audio front-ends and their learnable counterparts, and the empirical evaluation. However, there are several major concerns about the paper: 1) the novelty of the contribution is limited, i.e., LEAF is a generalization of a mel filterbank, which has been studied in the context of machine audition. 2) the authors analyze the performance of competing frontends but do not provide comparison with the state-of-the-art audio frontends for the tasks evaluated in the paper. 3) the presentation of the paper can be improved by including more insights from the experiments and story telling (e.g., how do the authors interpret the results, how much of an improvement is due",
        "All Reviewers agree that the paper has a clear and solid contribution. Furthermore, all of them highlight that the paper has improved significantly after revision. Hence, my recommendation is to ACCEPT the paper. As a brief summary, I highlight below some pros and cons that arose during the review and meta-review processes.  Pros: - Comparison across network architectures. - Comparison across a broad range of different data sets. - Compactness of the representation (few parameters to learn). - Authors will share code.  Cons: - Role of L2 normalization could be further discussed."
    ],
    [
        "This paper proposes tests of equality and contrasts based on martingales for Bernoulli and Poisson processes. The reviewers agree that the tests are solid and novel, and the authors have improved the paper during the rebuttal period in a way that makes the paper easier to follow. Please try to address the reviewers' comments for the final version of the paper, especially those concerning the clarity of the Poisson process results and the parameters for the alternative (please check the references and update the manuscript accordingly).",
        "While there is no unanimity, the majority is positive and sees the potential value of the approach for machine learning. It is good to mention that the authors did a good job in replying to comments and criticisms, which has clarified a few misunderstandings. Personally I would recommend the authors not to use the confusing terminology between Bayesian and frequentist approaches that are employed in the paper, because it has generated more harm than benefit (at least among those in the discussion here). The theoretical results seem sound and useful and the contribution is good (even if the targeted problem might be seen as too specific by some)."
    ],
    [
        "The paper provides a new uncoupling no-regret learning dynamic provably converging to the extensive-form correlated equilibrium in general-sum n-player extensive- form games. Moreover, it does so by combining analysis techniques that have shown such accelerated convergence in other settings with the framework used to achieve the result in this paper.  The reviewers agreed that this is a good and important theoretical contribution to the existing literature.   The main concern raised by the reviewers was regarding the practical significance of the result given that the number of hyper-parameters needed to tune the algorithm is exponential. However, during the rebuttal phase the authors addressed this concern and all the reviewers increased their scores. Thus, I think that the paper is clearly above the bar for acceptance.",
        "This paper builds upon existing works to prove that learning (correlated) equilibrium can be fast, i.e., faster than \\sqrt{n} even in extensive form games.  Three reviewers are rather lukewarm, and one reviewer is more positive (but seems less confident in his score). The two major criticisms is that this paper is very difficult to read and that the results might seem rather incremental with respect to the literature.  I tend to agree with both points but the paper still as merits: the reason is that extensive form games are intrinsically way harder than normal form games and they more or less all have a burden of notations. We agreed  that the authors actually did some efforts to make it fit within the page limit. but another a conference or a journal would have been better suited than ICLR.  Our final conclusion is that the result is interesting yet maybe not breathtaking for the ICLR community; we are fairly certain that another venue for this paper will be more appropriate and that it will be accepted in the near future (I can only suggest journals based on the large amount of content and notations, such as OR, MOR, or GEB - yet, conferences such as EC should be more scoped too) . It does not, unfortunately, reach the ICLR bar."
    ],
    [
        "The paper implements the ideas in \"Transformer interpretability beyond attention visualization” by Chefer et al (2021), and integrates the resulting relevance scores into the pixel affinity propagation framework of Ahn and Kwak 2018.  Although the experiments do not surpass the state-of-the-art, this experiment shows promising preliminary results. There are concerns that the reproducibility is not thorough enough, and a more detailed discussion on how to combine the approaches in practical applications is needed.  We encourage the authors to incorporate the feedback and suggestions from the reviewers in future iterations of their work.",
        "An interesting contribution with relevant results. Some more exploration of hyper-parameter tuning could be a good contribution, and a rephrasing of certain ways of describing results (see reviewer 9G6p's comments)."
    ],
    [
        "The paper is well-written and presents an effective approach to learning to translate instructions to grounded robot plans. In the experiment, the proposed approach outperforms a neural baseline, and moreover, it shows strong generalization results. While the reviewers agree on the high quality of the paper, they have different opinions on the significance of the results. Generalization results for grounded robots is very important, and this paper provides just that. However, the reviewers have concerns on the details of the technical approach, which makes the technical contribution a bit incremental, and on the experimental results, which are not state-of-the-art. Overall, the paper is still a good contribution to the workshop, and should be accepted. We would like to encourage the authors to address these comments in the final version.",
        "As both reviewers stated, this paper is a good fit for the workshop, with several positives.  I am not repeating all of them here, since I agree with the reviewers' assessment comments. From the a given a natural language instruction and an input and an output scene, the paper investigates how to  train a neuro-symbolic model which  manipulates a program that can be executed by a robot on the input scenes and generates a goal state. The authors carry out experiments to demonstrate how the neuro-symbolic model is end-to-end and show generalization to novel scenes and instructions.  I recommend acceptance of this paper, as it can lead to relevant directions in neuro-symbolic robotics."
    ],
    [
        "This paper proposes two new optimization algorithms for training deep networks with unitary weight matrices that can accelerate training of unitsary neural networks. The main idea is to approximate the gradient using a low rank approximation and then use Riemannian gradient descent, which leads to a small additional penalty on the rank of the function. The proposed methods are simple, yet effective, and the theoretical results are strong. The authors are encouraged to compare their methods with the state-of-the-art by including the additional experiments conducted during the rebuttal phase.",
        "This paper provides two routines to replace gradient updates with low-rank unitary updates, and provides extensive technical discussion and experiments.  Reviewers are uniformly positive, and I also voice similar praises, e.g., I too appreciate the extensive discussion in appendices A and B, and the detailed experiments in the later appendices.  As such, it is easy to recommend acceptance, and I will push for this to receive at least a spotlight.  Even so, I urge the authors to make careful revisions for remaining issues raised by the reviewers, and to perform a full pass of their own."
    ],
    [
        "The paper considers the problem of fair rent division, where n agents are matched and assigned a room, and then evaluated their valuation for the room. The problem is envy-free if and only if there is no uncertainty in the valuations reported by the agents. The paper introduces what they call the lexi-slack solution which remains envy free with as large a radius as possible from the agent valuation reports.  The major contribution of the paper is a formulation and analysis that provides new algorithmic and complexity results with respect to the traditional LeSack problem, bringing it closer to practical solutions.   The reviewers had some concerns about the suitability of the problem for the ICLR audience. However, since this is a practical paper focussing on the understudied problem, I believe it is worth accepting. Please incorporate the reviewers' feedback in the final version.",
        "Reviewers are all positive and excited about the paper: interesting and natural model, novel and robust mechanism with theoretical guarantees, nice sample complexity analysis, experiments on real-world data."
    ],
    [
        "This paper presents a method for learning compositional goal representations in goal-conditioned reinforcement learning, which consists in discretizing the goals using Vector Quantization and using a codebook of L discrete codes to encode each of G chunks of a state/goal representation vector.  The reviewers agree that the paper is well written, the idea is novel, the evaluations are thorough, and the results are strong.   The authors were able to address most of the reviewers' concerns during the discussion period, and R1 raised their score. R2 and R3 also participated in the discussion, where they agreed that the authors answered most of their concerns. I also read the paper and agree with their assessment, and I think the authors did a good job addressing the questions and concerns raised by the reviewers. Therefore, I recommend this paper for acceptance.",
        "This paper proposes a discrete and compositional representation of goal states for goal-conditioned RL. The idea is to learn a goal representation via self-supervised learning and discretize the learned representation via VQ-VAE, and finally use the learned goal representation for goal-conditioned RL. The proposed method improves performance on several goal-conditioned RL benchmarks.  All of the reviewers found the idea simple and reasonable, and the results on a variety of benchmarks are quite comprehensive and strong. Although there were concerns around why the proposed discretized representation forms a semantically meaningful latent space and where the improvement comes from, the authors addressed them during the rebuttal period with updated results. All of the reviewers became in favor of the paper as a result. Thus, I recommend accepting this paper."
    ],
    [
        "This paper proposes a batch normalization approach to RNNs which allows binary and ternary quantization. The approach is applied to a variety of tasks including sequence modelling, question answering, ASR, sequence classification, and sequence MNIST. The method is shown to be effective in terms of memory requirements for the tasks considered.  Reviewers generally agreed that the novelty of the approach was limited in the light of earlier approaches (Full-Precision RNN, RS-Binary RNN) which also have access to batch data. The main contribution of this paper is to combine these two techniques in a single approach.  The reviewers also raised a number of issues regarding the experimental section. For example, reviewers wanted to see more baselines (e.g. full-precision baselines) as well as more ablations. Authors added a few experiments requested by reviewers, but reviewers generally felt the baselines were not strong enough. Authors are encouraged to add these",
        "This work proposes a simple but useful way to train RNN with binary / ternary weights for improving memory and power efficiency. The paper presented a sequence of experiments on various benchmarks and demonstrated significant improvement on memory size  with only minor decrease of accuracy. Authors' rebuttal addressed the reviewers' concern nicely."
    ],
    [
        "This paper proposes a single training cycle method to train sparse networks via soft thresholding, progressive sparsification, and increasing the pruning ratio linearly while training. The reviewers have a consensus on rejection due to lack of novelty, marginal improvements over existing methods, and unconvincing experiments. The authors did not provide a rebuttal. iReporter agrees with the reviewers' assessment and would like to avoid publishing this work in the hope that it can be improved in future.",
        "This submission proposes a method for learning sparse DNNs which consists of three components: First, a \"dense\" network is maintained and updated in each backwards pass, but the forward pass is done via a sparsified version of the network; sparsification is done via \"soft\" thresholding; and the sparsity ratio is increased over the course of training. Reviewers noted that each of these components had been previously proposed, and that the state-of-the-art baselines are not actually state-of-the-art anymore. They also noted that the paper read more like a draft and needs substantial improvement. The consensus was therefore to reject."
    ],
    [
        "The paper proposes a framework for training generative models to model constraints on the output of unlabeled outputs. The output constraints are modeled as constraints on what is considered a valid python program that has to be correctly interpreted. The denoiser is then used to estimate these constraints from the output. The paper demonstrates the performance of this model on two tasks - font image generation and pseudocode-to-code translation. For the SPoC task they show an improvement of 3-5% over a simple transformer baseline.  The reviewers generally agree that this is an interesting idea, and practically useful in the cases where data is sparse. However, they also point out a few weaknesses: (1) the experiments are conducted on small-scale tasks, (2) the technical novelty is somewhat limited, (3) there are some clarity issues in the presentation.  I invite the authors to take into account the reviewers' comments to improve the paper and resubmit to",
        "This work is well written and easy to follow and proposes a novel framework to utilize unlabeled output data. The authors have also given a detailed proof that the denoiser reduces the required complexity of the predictor. However, ultimately the experimental results are somewhat weak and leave doubts as to how effective the approach is. More convincing experimental results such as significant improvements on a well understood task and acknowledging that the approach is mostly useful when combined with pre-training and back translation would improve the work.  Pros - Well written. - Technically novel approach to the problem of utilizing unlabeled output data. - Interesting proof on the reduced complexity requirement for the predictor.  Cons: - Experimental results are not convincing. Showing significant improvements on a well understood task would be more convincing. - The approach is only really useful when combined with pre-training or back-translation."
    ],
    [
        "The reviewers all liked the paper. The authors' response clarified most points raised by the reviewers. In view of that, the authors are strongly invited to take the feedback on board for the final version. The main ethical issue raised by reviewers is the risk of erasure and invisibility of linguistic variability in Chinese language training data. Data cards need to be added to the final paper.   The authors release TGEA 2.0, the largest dataset for diagnosing typed errors made by pretrained language models. A lot of Chinese language models in Chinese can benefit from training on this dataset to mitigating erroneous sentences. Many of the reviewers' concerns were addressed by the authors during the rebuttal. The final version needs to be carefully checked for language appropriateness and diversity. Some concerns are about the size and quality of the dataset. But the authors have addressed those concerns with the data collection and annotation process.",
        "The reviewers all liked the paper. The authors' response clarified most points raised by the reviewers. In view of that, the authors are strongly invited to take the feedback on board for the final version. The main ethical issue raised by reviewers is the risk of erasure and invisibility of linguistic variability in Chinese language training data. Data cards need to be added to the final version."
    ],
    [
        "The paper presents an approach for distributed Byzantine learning in the presence of Byzantine workers. The idea is to have the workers compute gradients on multiple buffers and send them to the server in an asynchronous fashion. When all of the buffers are updated, the server performs an update of the model. The theoretical analysis includes Assumption 1 and Assumption 2, which shows that the algorithm does not converge to a stationary point even with iid data and fully synchronicity. Experimental results on small-scale tasks are provided.  The reviewers and AC note the following potential weaknesses: (1) the motivation for avoiding storing instances on the master node needs to be better fleshed out; (2) theoretical results are incremental with respect to prior work; (3) experimental results are not convincing.   The revision submitted by the authors addresses some of the concerns in the initial reviews, but did not convince the reviewers enough to increase their scores. Hence, a reject is recommended.",
        "The authors present BASGD and asynchronous version of SGD that attempts to be robust against byzantine failures/attacks.  The papers is overall well written and clearly presents the results. Some novelty is present as there have been limited work in asynchronous algorithms for byzantine ML.   However, there have been several concerns raised by the reviewers, on which I agree, and they have not been fully addressed: 1) the tradeoff between asynchrony and robustness, as BASGD cannot handle the case of a buffer being straggler, which limits some of the novelty in this work 2) issues with the definition of privacy leakage has not been fully addressed 3) some reviewers mentioned the theoretical results being of limited importance, but arguably this is true for other related work in this area. Perhaps a general criticism is valid as to what is the operational value of the proposed guarantees. That is convergence does not exclude a model that has undesirable properties, eg has bad prediction accuracy for a small subset of tasks. 4) Finally, the motivation of the system model of the paper ( eg storing gradients as opposed to instances) paper is of unclear practical relevance, as was raised by multiple reviewers.   Overall the consensus was that the paper does have merits, however, some of the most major concerns were not properly addressed. This paper can potentially be improved for a future venue."
    ],
    [
        "This paper proposes a Network-Wise Quantization (NWQ) approach, which post-training quantizes the weights of trained models without fine-tuning them during training. The authors observe that the existing methods suffer from two main weaknesses: (1) NWQ approach may introduce overfitting and discrete optimization problems, and (2) it is not always possible to fine-tune the weights after the first training round. To solve the former problem, the authors propose to use ASoftmax and mixup with improved initialization to avoid the overfitting issue. They conduct thorough ablation studies and experiments on several mainstream networks to fully verify the superiority of the proposed methods. However, the proposed method seems to contain too many hyper-parameters, and the reviewers also found the experimental section to be lacking in novelty and details.",
        "This paper studies post-training quantization by proposing Network-Wise Quantization (NWQ) an end-to-end quantization approach that takes into account relationships between layers rather than treating layers independently. Using this approach, the paper demonstrates compelling empirical gains across a number of architectures and compression factors. Reviewers recognized the practical success of the approach as demonstrated by these empirical results and praised the clarity of the manuscript. However, there were concerns regarding the novelty of the approach and whether the proposed method is simply a composition of previous methods. While I understand these concerns, I think there is a significant delta between this work and previous approaches, especially when taking into account the markedly improved performance and the challenges of determining how to apply these lines of thinking to end-to-end training. The authors also expanded their discussion of these works in their updated manuscript, clarifying the differences. There were also concerns regarding the hyperparameter tuning, but the authors clarified in their response that the large majority of experiments used a constant set of hyperparameters, suggesting that these results are not simply the effect of tuning. Altogether, I think this paper makes an impactful contribution and will be a valuable addition to the conference."
    ],
    [
        "This paper provides a method to perform explicit IB functional estimation for deep neural networks using weight decay, and thus validates the IB theory of deep nets using the recent mutual information estimation method (MINE). It also provides a layer-wise explicit IBfunctional training for DNN which is shown to have good prediction accuracy.  While the writing quality of the paper is high, the paper itself is a rejection. The main issue is that the experiments are insufficient, and there is insufficient comparison to recent relevant work.  I encourage the authors to improve the paper by addressing the issues raised by the reviewers in the next version.",
        "This paper does two things. First, it proposes an approach to estimating the mutual information between the input, X, or target label, Y, and an internal representation in a deep neural network, L, using MINE (for I(Y;L)) or a variation on MINE (for I(X;L)) and noise regularization (estimating I(X;L+ε), where ε is isotropic Gaussian white noise) to avoid the problem that I(X;L) is infinite for deterministic networks and continuous X. Second, it attempts to validate the information bottleneck theory of deep learning (Tishby and Zaslavsky, 2015) by exploring an approach to training DNNs that optimizes the information bottleneck Lagrangian, I(Y;L) − βI(X;L+ε), layerwise instead of using cross-entropy and backpropagation. Experiments on MNIST and CIFAR-10 show improvements for the layerwise training over cross-entropy training. The penalty on I(X;L+ε) is described as being analogous to weight decay. The reviewers raised a number of concerns about the paper, the most serious of which is that the claim that the layerwise training results validate the information bottleneck theory of deep learning is too strong. In the AC's opinion, R1's critique that \"[i]f the true mutual information is infinite and the noise regularized estimator is only meant for comparative purposes, why then are the results of the training trajectories interpreted so literally as estimates of the true mutual information?\" is critical, and the authors' reply that \"this quantity is in fact a more appropriate measure for “compactness” or “complexity” than the mutual information itself\" undermines their claim that they are validating the information bottleneck theory of deep nets because the information bottleneck theory claims to be using mutual information. The AC also suggests that if the authors wish to continue this work and submit it to another venue, they (1) discuss the fact that MINE estimates only a lower bound that may be quite loose in practice and (2) say in their experimental section whether or not the variance of the regularizing noise was tuned as a hyperparameter, and if so, how results varied with different amounts of noise. Finally, the AC regrets that only one reviewer participated in the discussion (in a very minimal way), despite the reviewers' receiving several reminders that the discussion is a defining feature of the ICLR review process."
    ],
    [
        "In this paper, the authors show that in the active learning setting, label-comparison-based queries can improve the sample complexity.  The reviewers found the problem studied to be interesting, and the proposed approach to be technically sound.  However, the paper could be motivated better and the use cases need to be outlined better. Figures are not necessarily close to their description.  Also, the theoretical results are incremental over previous works.  We encourage the authors to revise the paper accordingly and resubmit in future venues.",
        "Meta Review: Generally, the idea of querying the label comparisons to is an interesting and natural choice to enable active learning in real-world tasks. Both theoretical analyses and empirical studies have been reported in this paper. The whole paper is well organized and easy to follow.  The expeirmental studies performed in this paper can be improved, such as considering performance comparison in passive learning, the inclusion of more SOTA baselines, etc."
    ],
    [
        "This paper proposes a counterfactual generative model that generates images from 3 separate aspects of the data, i.e., masks, forground texture, and background. Different modules of the causal data generating process are independent of each other and once the decomposition of a training image is obtained, any component can be swapped. By doing so, they can vary each aspect individually without changing other aspects, enabling the model to generate counterfunctions images.  While the reviewers have shown some positive reception to the paper, they pointed out the similarities of this work with another paper by Kocaoglu et al. (which is accepted at ICLR'18) and the authors should definitely cite this work. Also, one reviewer pointed out that the causal structure that is used in the generation of data is not different than a conditional GAN. Therefore, it would be beneficial for the authors to clearly distinguish their work from this previous work.",
        "The paper presents a \"conceptual  advance connecting causality, disentangled representation learning, invariant representations and robust classification\". Authors propose to decompose the image generation process to independent mechanism that can be composed (foreground masks (shapes), forground texture, and backgrounds), allowing for a specific image to generate counterfactuals , by changing some variations factors, while keeping other fixed. One can use interventional data to augment classifiers, this can lead in certain cases to improvement in accuracy and in other in improving the robustness.   There was concerns about the clarity of the paper regarding the structured causal model considered and its applicability beyond image generation, experimental protocol for choosing hyperparameters (loss scaling and ratios of real data and interventional samples ) and some missing references. The rebuttal of the authors and their updated paper reflected comprehensively all those concerns and addressed them, highlighting limitations of the method and adding more examples of its failures.   I liked the ideas and concepts in  this paper , and it will be exciting to generalize such generative approach to other domains, this  work is a first step. I think it will be good addition to ICLR program"
    ],
    [
        "This paper investigates how well data augmentation can help improve the performance of contemporary deep learning models for Knowledge Tracing. Three different augmentation methods are proposed, along with different types of regularization losses. Experiments are conducted on ASSIST2015, ASSISTChall, STATICS2011 and EdNet-KT1 to demonstrate the effectiveness of the proposed methods. The major concerns lie in the novelty of the paper, as most of the reviewers are not familiar with the relevant academic field. However, the thoroughness of the experiments might compensate for the lack of novelty (e.g., many of the improvements demonstrated in the paper are achieved by standard training procedures).",
        "The paper proposes new techniques for improving the generalization ability of deep learning models for Knowledge Tracing (KT). Instead of designing more sophisticated models, the paper investigates simple data augmentation techniques that can be applied to train existing models. In particular, three different augmentation strategies are proposed based on replacement, insertion, and deletion in the training data. These strategies are then applied with appropriate regularization loss ensuring consistency and monotonicity in the training process. Extensive experiments are performed using three popular neural models for KT and four publicly available datasets. Overall, the paper studies an interesting problem in an important application domain of online education. The results are promising and open up several exciting follow-up research directions to explore more complex data augmentation techniques for KT.  I want to thank the authors for actively engaging with the reviewers during the discussion phase and sharing their concerns about the quality of the reviews.  The reviewers generally appreciated the paper's ideas; however, there was quite a bit of spread in the reviewers' assessment of the paper (scores: 4, 5, 6, 7). In summary, this is a borderline paper, and unfortunately, the final decision is a rejection. The reviewers have provided detailed and constructive feedback for improving the paper. In particular, the authors should incorporate the reviewers' feedback to better position the work w.r.t. the existing literature on data augmentation and state of the art results, better motivate the data augmentation strategies in the context of educational applications possibly through additional data analysis, and add more ablation studies w.r.t. the hyperparameters associated with data augmentation. This is exciting and potentially impactful work, and we encourage the authors to incorporate the reviewers' feedback when preparing future revisions of the paper."
    ],
    [
        "This paper proposes a novel initialization method, GradCosine, based on the cosine similarity of sample-wise local optima. They theoretically proved that their proposed quantity is the upper bound of both the training and generalization error under certain assumptions. An empirical analysis is provided that shows the promising performance of the proposed method.  Most of the reviewers agree that the strength of the paper outweighs the weaknesses. There are several suggestions that the authors are strongly encouraged to incorporate in the revision, including:  1) Adding discussion and comparison with closely related methods such as Kaiming’s method in [52], etc.  2) Adding the time complexity analysis that the reviewer suggested in the revised version.",
        "The paper introduces a new procedure to initialize the optimisation in training process of DNN models, including the recent ViT architecture. All the reviewers recommend acceptance and appreciate the promising empirical results backed by the strong theoretical foundations. AC recommends acceptance as well."
    ],
    [
        "The paper presents GONs, an approach to generative model with an implicit encoder. The main idea is based on the argument that existing generative models with an encoder are “redundant” in that the decoder itself has to compute the gradient. They propose a new inference method of inference in which the encoder is augmented with a variational autoencoder. Experimental results on MNIST, CIFAR-10, and CelebA show very good results for the proposed method. The paper is well written and the idea is interesting. However, the reviewers point out that the paper seems to have been rushed. The results are only on small scale and toyish datasets, and there are very few baselines. Therefore, it is hard to draw a strong conclusion.",
        "This paper presents a new inference mechanism for latent variable models, by taking the derivative of log-likelihood with respect to a zero-valued vector. Initially, the reviewers raised concerns mostly regarding the limited experimentation and missing baselines. However, in the revised version, the authors addressed most of these concerns.   Given that most reviewers are positive after the revision and since the proposed method is simple and interesting, I recommend accepting this paper."
    ],
    [
        "The consensus among the reviewers was that this work covers an important topic and a broad number of tasks. There were concerns about the documentation, reproducibility, and accessibility of the dataset. But the authors have done a good job in addressing most of these concerns with documentation, an API, and example notebooks. I expect this kind of work to be useful not only for representation learning but also for transfer learning to other medical applications, and I think this work can aid in that.",
        "The consensus among the reviewers was that this work covers an important topic and a broad number of tasks. There were concerns about the documentation, reproducibility, and accessibility of the dataset. But the authors have done a good job in addressing most of these concerns with documentation, an API, and example notebooks."
    ],
    [
        "In this work, the utilize a graph based approach to create the largest Twitter bot detection dataset, with over 100K bot users identified. The dataset is of great use for the social media mining community in many different aspects. The work was greatly improved after a very interactive and fruitful discussion period, making the contribution a lot more refined and useful.  Pros: - Largest dataset available. - Thorough evaluation - Addition of most reviewer's suggestions have strengthen the details in the paper  Cons: - Minor statistical rigor elements are missing, but not completely necessary.",
        "In this work, the utilize a graph based approach to create the largest Twitter bot detection dataset, with over 100K bot users identified. The dataset is of great use for the social media mining community in many different aspects. The work was greatly improved after a very interactive and fruitful discussion period, making the contribution a lot more refined and useful.  Pros: - Largest dataset available. - Thorough evaluation - Addition of most reviewer's suggestions have strengthen the details in the paper  Cons: - Minor statistical rigor elements are missing, but not completely necessary."
    ],
    [
        "The AC has taken into account all strengths and weaknesses mentioned by reviewers in making a recommendation for this paper. Here is the summary of what was considered in carefully considering a final decision:  * Reviewers agree that the presented resource, the Dollar Street dataset, addresses a need for models that can be held more accountable in terms of geographic diversity and demographic diversity.  * There is generally no issues with the technical soundness of the proposed resource. * Unfortunately, experiments on demonstrating the usefulness of this resource are limited, and largely replicate what was already found in Devries et al. 2019, a workshop paper at CVPR from three years ago which also used the same source of data -- and at the same scale. The analysis in this previous paper in some way go further by matching image categories using human evaluators individually for each image -- as pointed out by reviewer dcyB. * The dataset was downloaded from a third party's website and as such the authors had no control",
        "The AC has taken into account all strengths and weaknesses mentioned by reviewers in making a recommendation for this paper. Here is the summary of what was considered in carefully considering a final decision:  * Reviewers agree that the presented resource, the Dollar Street dataset, addresses a need for models that can be held more accountable in terms of geographic diversity and demographic diversity.  * There is generally no issues in terms of methodology or soundness of the proposed resource. * Unfortunately, experiments on demonstrating the usefulness of this resource are limited, and largely replicate what was already found in Devries et al. 2019, a workshop paper at CVPR from three years ago which also used the same source of data -- and at the same scale. The analysis in this previous paper in some way go further by matching image categories using human evaluators individually for each image -- as pointed out by reviewer dcyB. * The dataset was downloaded from a third party's website and as such the authors had no control in how the images were collected, nor there was any effort to enhance this resource in terms of annotations, diversity or size. * The dataset size is 38k images which is a rather small dataset for training or enhancing a model, and its use would be limited mostly as a benchmark dataset. As a benchmark however experiments seem limited as pointed by reviewer eAoC. An experiment on training on this dataset and evaluating on this dataset is performed only with a Resnet network, however it is hard to assess what is the significance of this experiment.   There are various suggestions made by reviewers below that would enhance the quality of this paper. Despite shortcomings, reviewers are still enthusiastic to see this dataset in an easy to use format as a benchmark. I also strongly suggest the authors to revise their section on licensing where it says \"Training machine learning models on public domain work is widely accepted legally.\" as it does not seem appropriate for this paper to be making determinations or recommendations as to what is considered legal or not."
    ],
    [
        "This paper studies the problem of dynamic regression in the linear algebra setting where one of the factor matrices temporally changes.  The paper proposes to use a tree-based data structure to maintain the sketch of the data, and presents algorithms with much faster runtimes than naive algorithms. All reviewers agree that the paper makes a solid contribution to the area, and is well-written. Therefore, I recommend acceptance. I encourage the authors to take into account the reviewer comments to improve the presentation in the final version.",
        "My main concern, that was addressed by the reviewers and was not answered by the authors, is that the improvement is q times faster algorithm for an algorithm that takes time exponential in q. In addition, the missing experimental results makes this a very theoretical paper.  Still, I recommend to accept the paper due to the significance of the problem, and conditioned on the promise of the authors to update the requested changes in the final verison."
    ],
    [
        "The paper presents a new way of leveraging contrastive learning to learn goal-conditioned policies in reinforcement learning by utilizing the inner product of learnt representations as a Q-value function, which is then used to improve a policy in the policy gradient step via optimization. The method is simple, novel, and effective. The authors well motivate their approach, compare it extensively with related work, and do a good job in presenting the limitations of the approaches.  The reviewers and AC note the following potential weaknesses: (1) limited technical novelty since this is not a theoretical contribution, but rather a combination of existing techniques, (2) lack of comparison with some prior works that use additional representation learning, (3) some missing baselines, and (4) a lack of clarity in writing.  After the rebuttal and discussion, the reviewers and the AC feel that the concerns have been mostly addressed, and the paper has improved.   The paper makes a good contribution to the",
        "How to design RL algorithms that directly acquire good representations? This paper gives an answer that contrastive representation learning can be cast as a goal-conditioned RL using the inner product of learned representations. The technical novelty of this paper is sound, with the thorough theoretic motivation of the proposed method and solid experiments. The presentation of this paper is also satisfactory. All the reviewers provided positive feedback on this paper. I also enjoy reading this paper."
    ],
    [
        "This paper is proposed to address the Open World Semi-Supervised Learning (OOD) setting, where a classifier needs to identify novel classes that are not present in the labeled dataset. The authors propose a self-supervised pretraining method, followed by a fine-tuning step to fine-tune the classifier. The proposed method is end-to-end method, and achieves significant improvement on ImageNet dataset compared to baseline methods.  While the reviewers think that the setting considered in this paper is interesting and novel, there are several concerns. First, the model is trained assuming that there are only two data points with the same label space for both labeled and unlabeled data. This assumption might not hold in practice, where there may be many open problems with diverse class spaces. The supervised loss proposed by the authors partly addresses this issue by mitigating the imbalance problem caused by BCE, and the authors also validate this loss with empirical results.  Second, the",
        "This work addresses a novel and important real-world setting for semi-supervised learning – the open-world problem where unlabeled data may contain novel classes that are not seen in labeled data.  The paper provides an approach by combining three loss functions: a supervised cross-entropy loss, a pairwise cross-entropy loss with adaptive uncertainty margin, and a regularization towards uniform distribution.    The authors were responsive to reviewers’ comments and have respectively improved their paper by adding experiments, including an ablation study of each component of the objective function, study of the effect regularization on unbalanced class distributions, reporting accuracy on pseudo-labels.  While two reviewers have slightly increased their scores, some concerns still remain.  This is a borderline paper, and after some discussion and calibration, we decided that the work in its current form does not quite meet the bar for acceptance."
    ],
    [
        "**Summary**: This paper proposes a methodology for approximating offline algorithms in online settings by learning the structures of the offline algorithms themselves. The online algorithms are trained using an offline time-series dataset via a multi-task learning approach where they are given an online dataset and an online \"algorithm\" (TL) that outputs windows corresponding to an offline algorithm. The windows are mapped to class labels using a hand-crafted mapping specific to the domain. The proposed method is evaluated on synthetic and real time stock market data.  **Strengths**: Reviewers found the motivation of bridging the gap between offline algorithms and their online counterparts extremely interesting and potentially very useful, and the experimental results convincing.   **Weaknesses**: The main weaknesses pointed out by reviewers were the (1) lack of clarity in the presentation, (2) the lack of motivation for some of the choices (e.g. the choice of datasets) and (3) the limited",
        "## A Brief Summary This paper uses offline algorithms that can see the entire time-series to approximate the online algorithms that can only view the past time-series. The way this is done is basically, the offline algorithm is used to provide discrete class targets to train the online algorithm. The paper presents results on synthetic and historical stock market data.  ## Reviewer s1H9 **Strengths:** - Practical problem. - Novel approach. - Clear presentation. **Weaknesses:** - No other baselines. - No theoretical guarantees behind the approach. - Writing could be improved.  ## Reviewer EgW9 **Strengths:** - Clear writing. - Interesting research direction. **Weaknesses:** - The primary claim seems incorrect and unclear.  - Due to the unclarity about the primary claim of this paper, it is difficult to evaluate the paper.  - Lack of baselines. - The lack of discussions of the related works.  ## Reviewer gii5 **Strengths:** - Interesting and novel approach. **Weaknesses:** - Difficult to evaluate, with no empirical baselines or theoretical evidence. - The datasets used in the paper are not used in the literature before. Authors should provide experimental results on datasets from the literature as well. - The paper needs to compare against the other baselines discussed in the related works. - More ablations and analysis on the proposed algorithm is required. - Unsubstantiated claims regarding being SOTA on the task, since the paper doesn't compare against any other baselines on these datasets. - The paper can be restructured to improve the flow and clarity.  ## Reviewer zoKR **Strengths:** - Novel and interesting research topic. - Bridging classical algorithms and ML. - Clearly written.   **Weaknesses:** - Lack of motivation for the problem. - The approach only works with offline algorithms that work on time-segmented data.  ## Reviewer aaFn **Strengths:** - Novel algorithm.  **Weaknesses:** - Potentially overfitting to the offline data. - Data hungry approach. - Confusion related to the occurrence moments of predicted future actions. - Section 2 is difficult to understand.  ## Key Takeaways and Thoughts Overall, I think the problem setup is very interesting. However, as pointed out by reviewers gii5 and EgW5, due to the lack of baselines, it is tough to compare the proposed algorithm against other approaches, and this paper's evaluation is challenging. I would recommend the authors include more ablations in the future version of the paper and baselines and address the other issues pointed out above by the reviewers."
    ],
    [
        "This paper presents an approach to decide when to ask for help to improve the task performance of embodied agents. The ask4help policy first measures the agent's uncertainty at finishing the task based on its internal belief state using a pretrained Success Prediction Model (SPM), then, the ask4Help policy decides if it should ask for the expert's help (i.e., the next action to do in the environment) or use the pretrained embodied agent's predicted action.   The experiments on RoboTHOR demonstrate that the proposed method can achieve higher success rates using fewer expert queries and asks for help when the agent is not able to complete the task. All the reviewers agreed that the paper is well written, the idea is novel and the experiments are convincing. There were some concerns on the heuristics used for comparison, e.g. model confusion, expanding the action space of the embodied agent, but these concerns were addressed during the rebuttal and discussion period.",
        "I thank the authors for their submission and active participation in the discussions. This paper introduces a method for learning a policy that can ask an expert for help, i.e., to obtain the expert action. On the positive side, reviewers found the method to be general [uya8], original and significant [gw2r], intruiging in terms of being able to reuse an existing policy [HGan], and tackling an important problem [rsmr,bRWC], and the paper to be clear [uya8,gw2r,rsmr,bRWC]. In terms of negative points, reviewers were concerned about the novelty [bRWC], unimpressive qualitative results despite strong quantitative results [bRWC], and issues with the range of baselines [bRWC,rsmr] and ablations considered [uya8]. Overall, the paper is borderline. However, bRWC indicated they would raise their score but I don't see this being reflected. Furthermore, in my view reviewer rsmr's concerns regarding baselines and ablations has been addressed by the author rebuttal. Thus, I am siding with reviewers gw2r and HGan, and recommend acceptance. However, I very strongly encourage the authors to further improve their paper based on the reviewer feedback, in particular the points raised by reviewer bRWC regarding the importance of the Success Prediction component of the method."
    ],
    [
        "The paper studies the possibility and impossibility of learning from poisoned data in the presence of adversarial perturbations. In particular, the authors provide a matching upper and lower bound, up to a multiplicative constant, for deterministic learners, under an agnostic setting.  The reviewers found the paper well-written, but there were many typos which made the reading challenging at times. Overall, the paper has interesting ideas and we encourage the authors to revise the paper according to the reviewers’ suggestions and resubmit it to a future venue.",
        "All reviewers agree that this paper comprehensively studies a fundamental question of PAC learning under instance-targeted poisoning, including the study of realizable, agnostic, deterministic learning settings; overall this paper makes a nice contribution to the field of robust machine learning.   The authors are strongly encouraged to incorporate the comments by the reviewers, including revising on motivating examples, terminologies, etc."
    ],
    [
        "Ricci-GCN is a poisoning defense for graph neural networks that samples new graphs each round and reweights them according to the Ricci flow distance between nodes so as to be more robust to structural perturbation and to improve the robustness of the network against adversarial attacks. The main contribution is that each new layer gets a new graph, however, the motivation behind it is not clear (why not train all layers of GNN on different graphs instead?) and has problems. The paper also lacks clarity at some points and has inconsistencies in notation.  As suggested by the reviewers, the paper is not suitable for publication at this time.",
        "The paper proposes a new defense against adversarial attacks on graphs using a reweighting scheme based on Ricci-flow. Reviewers highlighted that the paper introduces interesting ideas and that the use of Ricci-curvature/flow is a novel and promising contribution. Reviewers also recognized that the paper has significantly improved after rebuttal and clarified some aspects of their initial reviews.  However, there exist still concerns around the current version of the manuscript. In particular, important aspects of the method and algorithm, as well as some design choices are currently unclear. This includes evaluating and discussing robustness, training method, and practicality/improvements in real-world scenarios. I agree with the majority of the reviewers that the current version requires an additional revision to iron out the aforementioned issues. However, I also agree with the reviewers that the overall idea is promising and I'd encourage the authors to revise and resubmit their work with considering the feedback from this round of reviews."
    ],
    [
        "The paper received mostly negative reviews, with one borderline reject and two borderline accepts. The raised issues include technical novelty, insufficient experiments, presentation clarity, writing and technical soundness, missing baselines and more. The rebuttal addresses some of the raised issues but not fully. The AC agrees with the reviewers that the paper is not ready for publication in its current form and encourages the authors to take the reviews into consideration for further revisions and strengthen their work.",
        "This paper proposes a learning-based method for shape registration that conditions on regions of the shape rather than learning from the entire point cloud in one shot.  The reviewers point out several questions about the method, thanks to expository issues as well as missing comparisons/ablation studies.  As the authors have chosen not to submit a rebuttal, I will refer them to the original reviews for details here for additional points of improvement."
    ],
    [
        "The paper presents a critical analysis of several reward function evaluation methods, showing that they often fail to give a good sense of their quality and whether a policy is reward-learned well. The authors also provide empirical evidence in several domains to support their points. While both are valuable, some reviewers still find the theoretical contributions to be somewhat incremental compared to prior work. This is partially due to the paper's focus on the evaluation of reward learning methods, rather than on robotics applications. Still, the analysis as a whole is valuable, and the authors are encouraged to incorporate the reviewers' feedback to improve the paper.",
        "Post discussion update ------------------------  The authors completed a rebuttal that addressed all of the reviewers' critiques, and also uploaded a revised and improved manuscript. The most significant improvement seems to be the addition of a small related work section in the introduction and a limitation plus future work section at the end of the paper. However, since the final paper has an 8 page limit, the current 9-page manuscript will need to be shortened.   The clarifications seemed to sway two of the reviewers toward increasing their ratings. Generally, it's clear that although this is a non-standard paper, it raises interesting and potentially provocative points that would be great for the CORL community to discuss. Therefore, I am recommending acceptance.    Original review ----------------   This paper addresses the HRI challenge of measuring how well a robot has learned a user's reward function. It describes two main types of measures---parameter-based and reward-based---and provides both theoretical and empirical examples of the shortcomings of each.    Strengths * This seems like the type of paper that would be useful to assign in an HRI course or give to a new grad student, because it clearly explains the different measures and provides a comparison of them.  * Reviewers noted that the issues brought up by this paper are important and very relevant to current approaches. The paper is timely.  * Reviewers agreed that paper balances well between theory and empirical examples.   * The paper was well written and easy to understand.   Weaknesses  * The main critique is that reviewers feel that the paper doesn't go deeply enough into the discussion of what to do with these findings. How should robotics researchers use this information to design better measures? In what cases are these measures likely to fail, or to be accurate? Section 6 poses such questions, but it would add substantially to the novelty of the paper if there was some suggestion of where to go from here.    * Although the paper bills itself as a survey, reviewers noted that it doesn't provide much of a discussion of related work. Reviewers also provided additional citations that address some of the issues brought up regarding current measures of performance.   * A couple of reviewers questioned the connection to robot learning in particular.  * There is no limitations statement, which is a required component."
    ],
    [
        "The paper was reviewed by four experts in the field. Based on the reviewers' feedback, the decision is to recommend the paper for acceptance to NeurIPS 2022.  The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes and include the missing references. We congratulate the authors on the acceptance of their paper!  Thank you,  Roberto Palmieri, SAC",
        "Authors present a method for single object tracking (SOT) that is entirely comprised of transformers. The architecture is simple:   1) Swin is used to generate embeddings for both template and search region 2) Embeddings are concatenated 3) An encoder transformer performs MHSA of the embeddings. 4) A decoder performs cross-attention from search tokens to template tokens and a special \"motion token\" which is constructed from a linear operation over the prior motion trajectory relative to the frame.  5) Output token is fed to final layers that perform IoU aware classification and bounding box regression.  Evaluations are performed on 5 SOT datasets, achieving SOTA on all of them.   Pros: - [AC/R] Important problem, technically sound, and new SOTA on this task. - [AC/R] New motion token approach is novel and provides significant improvement. - [AC/R] Simple and elegant architecture - [AC/R] Insightful discussions - [AC/R] Clearly written and easy to follow - [AC/R] Interesting ablations - [AC/R] High frame rate  Cons: - [R] Low novelty of transformer approach, but this is negated by the novelty of the motion token. - [R] Details regarding pretraining are missing. Authors provide in response. - [R] Motivation of motion token design is not clear. Authors provided further ablations of different implementations of the motion token, showing the current form performs best. - [R] Provide additional details regarding where and how SwinTrack outperforms other approaches on the benchmarks. Authors provided additional granularity of performance stratifications within the LaSOT benchmark. - [R] Add more recent high performing trackers. Authors added several methods published in 2022. - [R] Some additional questions about various details were posed by reviewers, which will all answered by the authors.   The single reviewer with reject recommendation changed to accept in their comments after the discussion period but did not update their score. Given unanimous agreement on accept, AC recommendation is accept.   AC Rating: Strong Accept"
    ],
    [
        "This paper compared clean (non-robust) vs. robust representations of neural networks based on the perspective of representation similarity. The authors use an existing method for comparisons of intermediate neural network activations called CKA to conduct the analysis. They find the following results: Robust representations are less specialized and distant layers are more similar in robust networks compared to clean representations, early layers overfit faster and later layers fit to local minima, and try to deduce insights in adversarial training on representation.  According to the observations, the author introduces several ways to design and train better robust networks. However, the reviewers think it is not clear whether the findings in this paper generalize to different types of networks. More experiments and analysis are needed to make the arguments convincing.   The paper received 5 reviews with ratings: 4,5,6,7,7. The main concerns of the negative reviewers are: 1) The paper introduces a lot of defence mechanisms (main",
        "The authors study representations obtained from image classifiers and contrast the classic training with adversarial training, so-called non-robust and robust networks, respectively. The authors primarily use the CKA metric on CIFAR10 and subsets of ImageNet2012 provide several novel insights on \"salient pitfalls\" in robust networks which suggest that robust representations are less specialized with a weaker block structure, early layers in robust networks are largely unaffected by adversarial examples as the representations seem similar for benign vs. perturbed inputs, deeper layers overfit during robust learning, and that models trained to be robust to different threat models have similar representations.  The reviewers agreed that these contributions are interesting to the larger community and that the presentation of the results is clear and straightforward. The main issues raised by the reviewers were carefully addressed in the rebuttal. Please update the manuscript as discussed."
    ],
    [
        "The paper addresses the problem of boosting the state-action value function approximation in a curriculum learning setting by learning the sum of residuals from a model trained on each task. Reviewers agree that the proposed boosted curriculum learning method is novel and has interesting ideas. However, it is not always clear how the approximation error bound of the action-value function is derived, and how it is related to the difficulty levels of the tasks. The authors are encouraged to add a discussion on this point in the final version.   The paper received 4 reviews with mixed initial ratings: 4,5,6,7,7. The main concerns of R1, R2 and R4, who gave unfavorable scores, included limited novelty of the proposal and lack of enough experiments. In the rebuttal, the authors provided more experiments with more baselines (NAO and boosted CRL), more ablations, and provided clarifications to the issues raised by R2/R4. However",
        "The paper proposes a novel curriculum learning method for RL based on the concept of boosting. The proposed method builds on the curriculum value-based RL framework and uses boosting to reuse action-values from previous tasks when solving the current task. The method is analyzed theoretically in terms of approximation accuracy and convergence. Moreover, extensive experiments demonstrate the effectiveness of the method. The reviewers acknowledged the importance of the studied problem setting and generally appreciated the results. I want to thank the authors for their detailed responses that helped in answering some of the reviewers' questions and increased their overall assessment of the paper. At the end of the discussion phase, there was a clear consensus that the paper should be accepted. The reviewers have provided detailed feedback in their reviews, and we strongly encourage the authors to incorporate this feedback when preparing a revised version of the paper."
    ],
    [
        "The paper proposes an interesting approach bridging the gap between VAE and GANs. While the results in the paper are certainly interesting and novel, the reviewers and AC note the following potential weaknesses: (1) the assumption that the generative model is injective is problematic, as it is well known that GAN suffers from mode collapsing problem, (2) GAN can be significantly outperformed by VAE without regularization, (3) the paper uses AIS to estimate the likelihood, yet the experimental results are not very convincing, (4) it is not clear what the take-away for the observed data distribution is from the model, and (5) the authors made some doubtful statements, such as the following:  AC thinks that this paper needs a major revision before publication, and recommends rejection.",
        "The paper's strength is in that it shows the log likelihood objective is lower bounded by a GAN objective plus an entropy term. The theory is novel (but it seems to relate closely to the work https://arxiv.org/abs/1711.02771.) The main drawback the reviewer raised includes a) it's not clear how tight the lower bound is; b) the theory only applies to a particular subcase of GANs --- it seems that the only reasonable instance that allows efficient generator is the case where Y = G(x)+\\xi where \\xi is Gaussian noise. The authors addressed the issue a) with some new experiments with linear generators and quadratic loss, but it lacks experiments with deep models which seems to be necessary since this is a critical issue. Based on this, the AC decided to recommend reject and would encourage the authors to add more experiments on the tightness of the lower bound with bigger models and submit to other top venues."
    ],
    [
        "This paper proposes a graph-based approach to commonsense knowledge graph inference, building on previous work (e.g., [1]) that uses message-passing graph neural networks. The proposed approach learns nodes in a layer-wise fashion from an incomplete KG, and then sparsifies the graph by learning edge weights via a two-step message passing process. The approach is evaluated on CommonsenseQA, OpenbookQA and CODAH, where it achieves positive results.   All reviewers agree that the paper makes a reasonable contribution, is well-written, intuitively motivated, and that the proposed method is relatively simple. After reading the authors' responses, the reviewers were satisfied that the concerns raised in the initial reviews were adequately addressed. In particular, the authors ran additional experiments to compare to additional baselines.  [1] https://arxiv.org/abs/1808.07898 Currently, this paper remains on the",
        "The paper proposes an interesting step in the direction of neuro-symbolic reasoning. While there is no consensus among reviewers about the key novelty of the method, all acknowledge the interest of the direction. All of them also recognize that the submission improved greatly during the discussion phase: clarification of motivations, of experimental settings and results, of discussion with previous work.  However, despite those improvements, the submission is not yet ready for publication at ICLR. We encourage the authors to use the very detailed reviews and comments to improve the work. In particular, we encourage them to pay attention at three aspects:  1/ Comparison with large language models: the discussion wrt T5 is important. A key motivation for the proposed model is that it is bringing information and elements for QA (or other reasoning tasks) that purely scaling up language models can not bring. Or maybe they can bring the same kind of improvement but at a much lower computational cost. In any case, this is a very important point to justify the interest of such approach, and neuro-symbolic reasoning overall, empirically.  2/ Using GPT2 (or equivalent): the discussion on using GPT-2 for generating new facts is key too. It is essential to bring this description from appendix to the core of the paper. But more discussion are expected.  For instance, what if GPT-2 generates facts that are false and lead to answering and justifying a wrong answer? In other words, how does it impact the integrity of the contextualized KG? This is an essential point that needs to be worked on more thoroughly.   3/ Overall there have been a lot of discussion to improve the motivations and the contributions. But they are not reflected in the paper necessarily. Following R2, we encourage the authors to \"refocus the existing version (e.g., from vague discussion about neural-symbolic models towards establishing solid comparison to the most related previous work in various sections of the submission)\""
    ],
    [
        "The authors propose a framework for distributed multi-agent reinforcement learning. The paper addresses three challenges in MARL: 1) Demanding data transfer 2) Inter-process communication 3) Effective Exploration. Using a container that collects environment experiences from parallel actors into buffers and learns local policies, CMARL demonstrates notable performance improvements with respect to time.  The reviewers found the paper to be well-written and easy to follow. The empirical results are promising and the ablation studies further justify the effectiveness of the proposed method. The authors are encouraged to include the additional experiments and discussions provided in the rebuttal in the final version of the paper.",
        "This paper proposes a distributed containerized multi-agent reinforcement learning(CMARL) framework that addresses three challenges in MARL: 1) Demanding data transfer. 2) Inter-process communication. 3) Effective Exploration. Using a container that collects environment experiences from parallel actors into buffers and learns local policies, CMARL demonstrates notable performance improvements with respect to time as compared to state-of-the-art benchmarks.  Although the reviewers acknowledge that the paper addresses a relevant topic, proposes an effective method, and is well written, after reading the authors' feedback and discussing their concerns, the reviewers reached a consensus about rejecting this paper in its current form. They feel that the contribution is too incremental and that the experimental comparisons are somehow unfair.  I suggest the authors take into consideration the reviewers' suggestions while preparing an updated version of their paper for one of the forthcoming machine learning conferences."
    ],
    [
        "The authors propose a hypothesis testing procedure for change detection on sequential non-iid / non-Gaussian data.  The Uniform Degradation Test (UDT) and Partial Degrades Test (PDT) are proposed to detect the mean shift of the sequential data pre-change.  They are applied to the problem of reinforcement learning and shown to (slightly) outperform baselines.  However, the paper is not self-contained and it is hard to understand how the proposed method can be used to solve an non-stationary RL problem. Also, the provided theoretical grounds looks as non-enough for publication @ ICLR.  I encourage the authors to significantly revise the paper based on the reviewers' feedback.",
        "The paper's initial evaluation was below par, but the author feedback helped clarify several crucial points after which two of the reviewers increased their scores by a point, bringing the current evaluation to borderline.   The paper addresses a relevant and challenging problem in the RL domain. However, in my opinion, from the reviewers' and authors' remarks and from my own reading of the paper, there are concerns that need to be addressed before the paper can be publication worthy. Primary among these is the quantum of novelty -- as many reviews point out, the key idea of viewing an episodic trajectory as a multivariate (vector) sample for running hypothesis tests is not novel in itself, as is the claim that new tests have been devised. Another crucial issue is the (parametric) assumption of normality for the episodic reward sequence which is not adequately justified in the paper -- even a two time-step trajectory with normal rewards per state transition can exhibit a mixture-of-Gaussians type reward distribution for the second state, breaking the assumption. As it transpired from the reviews of Reviewer4, reducing environment shift/degradation to just a mean change problem, without even considering a change in the variances (2nd order statistics), seems to be too stylized to be effective. There are other, nonparametric approaches in statistics based on testing for changes in the distribution function (kernel density estimation approaches, for instance), which could perhaps be applied without normality assumptions and yield favourable results. The experimental results for detection delay often show significant overlaps of the delay distributions for different procedures (e.g., Hotelling vs. Mean vs. UDT etc.), which does not indicate an advantage of the proposed method.   I would urge the author(s) to assimilate the feedback and delve deeper as to why and how parametric procedures based on normality assumptions may or may not succeed, so as to significantly strengthen the theoretical and practical message of this work."
    ],
    [
        "The paper is addressing the problem of efficient communication in the edge-based collaborative learning. The proposed hierarchical compression algorithm for feature data called “Stripe-wise Group Quantization” (SGQ) hierarchically encodes the features in channel and spatial level, and performs the classification and clustering in the hierarchical fashion. Theoretical analysis is provided to calibrate gradients of both features and CAG blocks in the backward process, and extensive experiments are conducted to demonstrate the effectiveness of SGQ in the scenario where only a small number of clusters is available.  After the rebuttal, all the reviewers are positive about the paper. AC agrees with the reviewers’ consensus and recommends to accept the paper as a poster.  Please incorporate the feedback from the reviewers in the final version. AC strongly recommend to include the experimental results and the discussion with reviewers, to improve the quality of the final paper.",
        "This paper proposes a novel communication-efficient learning method that significantly reduces feature size and communication traffic. The rebuttal solved the reviewers concerns about the dataset size and accuracy / latency trade off."
    ],
    [
        "Reviewers are in a consensus and recommended to accept after engaging with the authors. Please take reviewers' comments into consideration to improve your submission for the camera-ready.  Also please see \"What Matters in this Paper and Why I'm Rejecting It\", R2's post-rebuttal comment.   Congratulations!   I'm pleased to inform you that your paper has been accepted to ICLR 2021. The authors will be discussing their acceptance at the workshop.",
        "This paper presents \"Automunge\" a python library for pre-processing tabular data.  The authors develop a useful library that can be used by practicioners for data engineering in NNs applications.  The reviewers raised a common concern regarding the lack of focus on the actual usefulness of the librabry in improving the  performance of the models that is applied on. A common concern was the lack of performance plots compared to other alternatives.  In the response the authors have done a rather thorough job of addressing the reviewers comments and adding material in the supplementary. However, given the current presentation, the manuscript needs a considerable amount of  rewriting to incorporate the suggested changes into the main paper. As it is, I don't think ICLR is the right venue for the manuscript.  It might reach its audience better in venues like SysMl or PyCon also suggested by a reviewer."
    ],
    [
        "This paper proposes an interpretable RL agent architecture that uses attention masks to produce visual explanations of the action selected by the policy and output of the value function. The identified attention regions are intuitive and action-conditional whereas the goal on the inverting gaze area are less clear. The authors demonstrate their method on 3 Atari games and use A3C as the training algorithm. The presented experiments are convincing, however, the description of the method, in terms of terminology, experimental setup and results, is lacking. Therefore, it is difficult to judge the contribution of this paper. We hope the authors will take the reviews into consideration when revising their paper for submission elsewhere.",
        "The paper proposes a method to generate attention masks to interpret the performance of RL agents. Results are presented on a few ATARI games. Reviewers unanimously vote for rejecting the papers. R1, R3 give a score of 5, whereas R4, R5 give a score of 4. Their concerns are best explained in their own words:   R1 says, \"The use of attention maps to analyze and explain deep neural networks is not new in itself, and learning attention maps to improve vision tasks is not new either.\"  R3 says, \"the analysis of the learned attention masks seems selective. Some automatic metrics or systematic studies of different game categories (shooting, maze-like, and ball-and-paddle) may shed light on the learned attention's general property.\"  R5 says, \"I am still not convinced by the quality of the provided visual explanations nor am I convinced that the attention is well correlated with the current frame (the additional experiments provided do help somewhat in this regard, but are not extensive and reasonably inconclusive\"  In their rebuttal, to address R1's concern authors suggested that the use of attention on both value and policy networks is novel. This is not sufficient, because it does not show why such attention maps are more useful than ones proposed by prior work. As suggested by reviewers, a systematic study or a human study clearly showing that the proposed method adds more interpretability is critical. However, this is missing.  In response to R3, the authors provided experiments on more games. But this is not the point -- because it's not about the number of environments in which experiments are provided, but rather the nature of the analysis that is performed. Finally, R5 comments that it's unclear whether attention actually provided interpretability or not.   Due to the lack of convincing analysis that demonstrates the utility of the proposed method in advancing the understanding of decisions made by RL agents, I recommend that the paper be rejected."
    ],
    [
        "This paper presents a method for learning with noisy labels by converting the noisy labels to similarity labels that are more robust to noise. The method is theoretically justified and the empirical performance of the proposed method is consistent across different noise ratios.   Overall, the idea of dealing with label noise by transforming noisy class labels into noisy similarity labels is interesting. However, there are several concerns raised by the reviewers. First, the baselines in the experiments seem weak compared with the state-of-the-art methods. Second, the improvement of the method over the baseline methods is marginal. Third, the writing of the paper needs to be improved to be more accessible to the general ML community.  I suggest the authors to address these concerns and resubmit the paper to another venue.",
        "The paper's stated contributions are:  (1) a new perspective on learning with label noise, which reduces the problem to a similarity learning (Ie, pairwise classification) task  (2) a technique leveraging the above to learn from noisy similarity labels, and a theoretical analysis of the same  (3) empirical demonstration that the proposed technique surpasses baselines on real-world benchmarks  Reviewers agreed that (1) is an interesting new perspective that is worthy of study. In the initial set of reviews, there were concerns about (2) and (3); for example, there were questions on whether the theoretical analysis studies the \"right\" quantity (pointwise vs pairwise loss), and a number of questions on the experimental setup and results (Eg, the computational complexity of the technique). Following a lengthy discussion, the authors clarified some of these points, and updated the paper accordingly.  At the conclusion of the discussion, three reviewers continued to express concerns on the following points:  - *Theoretical justification*. Following Theorem 3, the authors assert that their results \"theoretically justifies why the proposed method works well\". The analysis indeed provides some interesting properties of the reduction, such as the fact that it preserves learnability (Appendix F), and that the \"total noise\" is reduced (Theorem 2). However, a complete theoretical justification would involve guaranteeing that the quantity of interest (Ie, the clean pointwise classification risk) is guaranteed to be small under the proposed technique. Such a guarantee is lacking.    - This is not to suggest that such a guarantee is easy -- as the authors note, this might involve a bound that relates pointwise and pairwise classification in multi-class settings, and such bounds have only recently been shown for binary problems -- or necessary for their method being practical useful (per discussion following Theorem 3). Nonetheless, without such a bound, there are limits to what the current theory justifies about the technique's performance in terms of the final metric of interest.  - *Comparison to SOTA*. Reviewers noted that the gains of the proposed technique are often modest, with the exception of CIFAR-100 with high noise. Further, the best performing results are significantly worse than those reported in two recent works, namely, Iterative-CV and DivideMix. The authors responded to the former in the discussion, and suggested that they might be able to combine results with the latter. While plausible, given that the latter sees significant gains (Eg, >40% on CIFAR-100), concrete demonstration of this point is advisable: it is not immediately apparent to what extent the gains of the proposed technique seen on \"simple\" methods (Eg, Forward) would translate more \"complex\" ones (Eg, DivideMix).   - In the response, the authors also mentioned that (at least the initial batch of) the experiments are intended to be a proof-of-concept. This would be perfectly acceptable for a work with a strong theoretical justification. However, per above, this point is not definitive.  - *Creation of Clothing1M*. The authors construct a variant of Clothing1M which merges the classes 3 and 5. Given that prior work compares methods on the original data, and that this potentially reflects noise one may encounter in some settings, it is advisable to at least report results on the original, unmodified version.  - *Issues with clarity*. There are some grammatical issues (Eg, \"is exact the\"), typos (Eg, \"over 3 trails\"), notational inconsistencies (Eg, use of C for # of classes in Sec 2, but then c in Sec 3.1), and imprecision in explanation (Eg, Sec 3.2 could be clearer what precise relationships are used from [Hsu et al. 2019]).   - These are minor but ought to be fixed with a careful proof-read.  Cumulatively, these points suggest that the work would be served by further revision and review. The authors are encouraged to incorporate the reviewers' detailed comments."
    ],
    [
        "The paper establishes the first rate of convergence for SGD in the Neural Tangent Kernel Regime  This is a theory paper that considers the learning of a two layer neural network under the NTK regime.  Theoretical results are presented that show that target functions are learned at a faster rate under this regime and also establish new rates for learning smooth target functions.  Convergence rate analysis is a fundamental problem in machine learning and understanding neural tangent kernels is an important area of machine learning. The reviewers are in agreement that the paper fills a gap in the literature and fills the gap between optimality and applicability of NTK theory. The paper is technically sound and the proof techniques are different from existing literatures.   Some reviewers have pointed out that the experiments are a plus, so the authors are requested to add some experiments to the final version.",
        "The paper presents some exciting results on the convergence of averaged SGD for overparameterized two-layer neural networks. The AC and reviewers all agree that the contributions are significant and well presented, and appreciate the author feedback to the reviews. The corresponding revisions on assumptions and references, and the added simplified proposition in the introduction have nicely improved the manuscript."
    ],
    [
        "The paper proposes a deep learning architecture for predicting mutual contacts between proteins and a method for contact prediction for PPI. The strengths of this work stem from the architecture used, consisting of attention mechanisms and invariant representations with respect to symmetric and non-symmetric projections of 3D conformations of proteins. They use a k-local nearest neighbor representation for each protein and compute geometric-based attention scores to convolute the messages over this graph. They validate this approach on the task of protein interface contact prediction, and the DIPS-plus dataset, achieving state-of-the-art performance.  The reviewers have serious concerns regarding the experiments, writing and clarity. The method is validated on two benchmarking datasets, but not others. The performance metrics and benchmarks are lacking. The authors did not respond to the reviewers' comments. The paper is not ready for publication in its current form.",
        "This paper presents a novel neural network architecture to predict interacting residues among two interacting proteins, and evaluates its performance on benchmarks. While the reviews were initially mixed, there has been a productive discussion and significant improvements in the paper during the discussion, including in particular much needed clarifications about the proposed methods, and more experimental results with an ablation study to better assess the benefits of various design choices. While no reviewer is willing to champion this paper as a \"strong accept\", due to the relatively modest novelty compared to existing methods, there is a consensus towards \"weak accept\" given the final quality of the work presented and potential usefulness of the method for the problem tackled."
    ],
    [
        "This paper proposes an approach for self-supervised learning that balances the need for exploration and efficient representation learning, while learning a good trade-off between exploration and representation learning. Specifically, the proposed two components: contrastive representation learning and particle based entropy maximization. The resulting APT pretraining method alternates between minimizing a contrastive loss and maximizing an intrinsic reward, and shows improved performance and data efficiency.  Strengths: - The paper is well written and easy to follow - Technically sound - Strong results on Mujoco and Atari environments  Weaknesses: - Novelty of the proposed method might not be entirely clear - Analysis of the results would benefit from more detailed analysis - Some of the claims made in the paper are not supported by strong evidence, e.g., it would be helpful to understand where the reported gains come from.  The reviewers reached a consensus that the paper should be accepted, and I agree.",
        "The authors propose a particle-based entropy estimate for intrinsic motivation for pre-training an RL agent to then perform in an environment with rewards. As the reviewers discussed, and also mentioned in their reviews, this paper bears stark similarity to work of 5 months ago, presented at the ICML 2020 Lifelong ML workshop, namely, \"A Policy Gradient Method for Task-Agnostic Exploration\", Mutti et al, 2020--MEPOL. What is novel here is the adaptation of this entropy estimate to form an intrinsic reward via a contrastive representation and the subsequent demonstration on standardized RL environments.  The authors have added a comparison to MEPOL, and in these experiments, APT outperforms this method, sometimes by some margin. Unfortunately this work does not meet the bar for acceptance relative to other submissions."
    ],
    [
        "The paper presents an efficient message passing technique for truncated Gaussian kernel CRF, accelerating training of the truncated CRF with mean field inference. The main contribution is the use of a convolutional layer over the CRF parameters to perform the message passing. This technique allows for a significant reduction in the computational cost of the original CRF method while achieving improved performance. The paper is well written and easy to follow. The reviewers raised a number of questions and concerns that were addressed by the authors satisfactorily. Hence, I recommend acceptance.",
        "The authors replace the large filtering step in the permutohedral lattice with a spatially varying convolutional kernel. They show that inference is more efficient and training is easier.  In practice, the synthetic experiments seem to show a greater improvement than appears in real data.  There are concerns about the clarity, lack of theoretical proofs, and at times overstated claims that do not have sufficient support.  The ratings before the rebuttal and discussion were 7-4-6.  After, R1 adjusted their score from 6 to 4.  R2 initially gave a 7 but later said \"I think the authors missed an opportunity here. I rated it as an accept, because I saw what it could have been after a good revision. The core idea is good, but fully agree with R1 and R3 that the paper needs work (which the authors were not willing to do). I checked the latest revision (as of Monday morning). None of R3's writing/claims issues are fixed, neither were my additional experimental requests, not even R1's typos.\" There is therefore a consensus among reviewers for reject."
    ],
    [
        "The paper provides theoretical analysis for two kinds of straight-through estimation (STE) for activation bianrized neural networks. One main point of concern raised by the reviewers was the lack of clear demonstration of the universality of the results. However, the authors addressed it well in their rebuttal by pointing out that Steerability properties of identity STE are different from those of Steer and ReLU STE and that using identity STE is equivalent to using Steer without gradient descent. The reviewers did not change their ratings but did agree that the paper contains interesting results worth sharing with the community.",
        "The paper contributes to the understanding of straight-through estimation for single hidden layer neural networks, revealing advantages for ReLU and clipped ReLU over identity activations.  A thorough and convincing theoretical analysis is provided to support these findings.  After resolving various issues during the response period, the reviewers concluded with a unanimous recommendation of acceptance.  Valid criticisms of the presentation quality were raised during the review and response period, and the authors would be well served by continuing to improve the paper's clarity."
    ],
    [
        "This paper proposes the use of the role diversity in multi-agent RL to measure the performance and error of different agents in a task. The paper shows that the error bound in MARL can be decomposed into three parts that have a strong relation to each other.   The reviewers found this paper interesting from a research perspective, but were concerned by the lack of clear motivation on why we should care about analyzing MARL from the perspective of roles. Also, they found the experiments unconvincing as there is a lack of sufficient theoretical justification for the findings in the paper. The authors did not respond to the reviews.",
        "This paper proposes a Role Diversity metric, meant to quantify how different roles are in a multi-agent RL setting. There's actually three versions of this metric, or three aspects (the distinction is not entirely clear to this area chair).  The reviewers are generally not very enthusiastic about the paper, with scores hovering at or just below the acceptance threshold. There has been extensive discussion between reviewers and authors, but there a sense that there is confusion about the exact purpose and contribution of the paper. This is reinforced by the authors' \"letter to area chair\", which outlines several ways the reviewers have not gotten the message. Reading the paper, it appears to me that the root cause is that the authors are indeed not communicating clearly what the paper contributes and why. It is, after all, the authors' responsibility that the reviewers understand the work. My own impression is that the text is dense and not particularly easy to get through. Perhaps the authors are simply trying to cram too many contributions into a single conference paper? This is a classic error which leads to hard-to-read papers. In addition to this, there is a lingering concern about the generalizability of the proposed methods.  I think the authors need to work more on their presentation, and perhaps reconsider which parts to include in their paper and exactly which measure they want to send, before they submit to another venue."
    ],
    [
        "This paper presents a new approach to synthesizing polyphonic music (by reusing recurrent networks) with a recurrent factorization of the score function, following the Fong and Wasserstein score.  The approach is evaluated on a few simple datasets and in a small scale qualitative experiment. The reviewers agree that the paper has a refreshing honesty in its critical evaluation of the results, highlighting fundamental problems in this field and offering solutions to overcome them. The paper is well written and easy to follow, with a good mix of recent and older literature, and is suitable for publication at MIDL.  However, the reviewers also point out several issues that need to be addressed before the work is ready for publication: 1) Clarity can be improved in the description of the method, 2) The cross entropy definition is missing important details, 3) The experimental results and results can be enriched by including more details on the participants and the task, 4) Details on the generated music and",
        "This paper proposes novel recurrent models for polyphonic music composition and demonstrates the approach with qualitative and quantitative evaluations as well as samples. The technical parts in the original write-up were not very clear, as noted by multiple reviewers. During the review period, the presentation was improved. Unfortunately the reviewer scores are mixed, and are on the lower side, mainly because of the lack of clarity and quality of the results."
    ],
    [
        "The paper proposes a model for end-to-end pretraining that supports both image-language and video-language pretraining in a unified framework.  The vision-language portion of the paper is motivated well, and the paper shows convincing experimental results on a variety of open-ended and close-ended tasks.  Reviewer concerns are mainly about the clarity of the technical presentation, which the authors have tried to fix during the rebuttal phase.  Overall, all reviewers are positive about the paper and I recommend accepting the paper.",
        "After the authors’ rebuttal and long discussion between reviewers and authors, the paper unanimously receives positive rates thanks to reasonable proposed ideas and thorough experiment evaluation. The camera-ready version may need to be updated to fully reflect reviewers’ comments and authors’ answers to them."
    ],
    [
        "This paper proposes a deep-learning framework to model shape deformations. The motivation is that prominent methods like ARAP are restrictive in their results. The authors demonstrate their method on the DeformingThing4D-Animals dataset.  Overall, the quality is high. The paper is well-written and clear. The ideas are well-motivated and they adopt a canonical model or space as used in human modeling and design a backward and forward deformation network.  It is a pity that the authors did not use the rebuttal period to revise the paper, however, I trust the authors will do so in the next version.   The experiments are adequate. The dataset is a good contribution to the community. It contains a large-scale dataset of deformations of volumetric and static objects. This enables the community to see how this method works and can inspire further research in this direction.",
        "While some of the scores on this paper are mixed, even the negative reviews highlight the quality and interest of the work and have specific (and somewhat debatable) technical concerns.  Overall, the AE recommends accept, especially in light of the detailed and thoughtful responses during the rebuttal phase.  In the camera ready, the authors are encouraged to see if they can squeeze some of the new results (e.g., transfer learning attempt in Figure 6 and comparisons to Shapeflow) in the main body of the paper, where they're more likely to be noticed."
    ],
    [
        "The authors propose to use data compression to reduce the memory space needed for continual learning, and to then replay the reconstructed data points using the compressed data. The authors achieve SOTA classification and object detection performance using this approach. Reviewers agree that the paper is well written, the data compression technique is simple and effective, and the experiments are comprehensive, showing real-world benefits of the proposed method. However, reviewers also raised several concerns: Reviewer 1 would like to see more theoretical analysis on the compressibility results, Reviewer 2 is concerned about lack of theoretical guarantees on the number of epochs, and Reviewers 3 and 5 are concerned about the lack of more realistic datasets and baselines against which the method could be applied. Overall, all reviewers agree that this is a well-executed paper on an important topic, but the novelty and significance of the work is limited, and therefore the paper does not meet the bar for publication at ICLR.",
        "This works considers limitations of rehearsal-based methods in the context of continual learning (classification and object detection). Rehearsal-based methods provide a strong baseline, but a loss in predictive performance arises when the memory is limited in size. The authors propose to leverage compression (JPEG) to increase the number of data (images) stored in the memory. The approach is evaluated in the context of an autonomous driving application.  The additional experiments conducted by the authors were highly appreciated and helped clarify open questions (e.g., class-incremental learning set-up, DPP objective to determine size of the memory, quantity vs quality of compressed data, etc.). The authors addressed the issues raised by three out of four reviewers, who did not have further comments. The remaining reviewer found that the methodological contributions of this paper, namely of using compression in the context of CL, was pretty straightforward. However, the authors addressed the concerns raised by the reviewer regarding the selection of the compression quality q as far as I am concerned and conducted additional experiments to further demonstrate the usefulness of the approach. I would encourage the authors to include this discussion in the final version of the paper. I would also encourage them to include the additional experiments they conducted with fixed memory size and amount of memory that can be saved."
    ],
    [
        "This paper introduces a self-supervised approach for surround-view depth estimation, and project features of different views into a volumetric feature spaces.  The reviewers agree that the paper is well-motivated and novel, and the problem setting may be useful for autonomous driving.   The paper has technical soundness and clarity, and all reviewers rate the paper on the accept side after the rebuttal.  Last but not least, the authors are encouraged to incorporate the suggestions from the reviewers in the final version.",
        "Initially, the paper had mixed reviews (455).  The major concerns from the reviews were:  1. missing refs about unprojection. (K314) 2. quality advantage is not convincing, slightly better than FSM, while qualitative results show not obvious improvements. (K314) 3. visualize the depth maps as point clouds (K314) 4. what is the trade-off between resolution/memory, computation, and depth estimation? (K314, ZBww) 5. insufficient experiments (9Ef1) 6. comparison with monocular methods (9Ef1) 7. cubic vs spherical space? (9Ef1) 8. can it be trained on real data w/o GT supervision? (9Ef1) 9. how to handle collision of multiple pixel rays? (ZBww) 10. why use different MLPs to fuse \"overlap\" and \"non-overlap\" features? No ablation study on this. (ZBww)  The authors wrote a response to address these concerns, providing more qualitative results and ablation studies, as well as further explanations.  The reviewers were satisfied with the response, and K314 upgraded their rating to 6, while other reviewers maintained 5s. The reviewers appreciated the novel problem and the solution that can produce more consistent depth maps across views, and also synthesize depth maps in novel views. After reading the paper, the AC agrees with the reviewers, noting that the paper  addresses the limitations of the problem setup of previous work [13], thus developing a new line of research.  Thus, the AC recommends accept. The authors should prepare a revised version of the paper according to the reviews, rebuttal, and discussion."
    ],
    [
        "This paper was reviewed by six experts and received all positive scores. AC feels this work is interesting and deserves to be published on NeurIPS 2022 dataset track. The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes and include the missing references.  The reviewers also acknowledged the contribution of continuous sampling, real-time capabilities, and end-to-end continuous simulation compared to prior work. Overall this work can be valuable for the research community in audio simulation.",
        "This paper was reviewed by six experts and received all positive scores. AC feels this work is interesting and deserves to be published on NeurIPS 2022 dataset track. The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes in the final version."
    ],
    [
        "This paper proposes a variable selection method based on normalizing flows to select features in a controlled fashion, so that the false discovery rate (FDR) is limited. The approach is evaluated both on synthetic and as-synthetic data. Asymptotically, the proposed method performs better than several competing knockoff methods. The paper is well-written and the asymptotic analysis shows that the method converges almost surely to the true p-values. The authors have addressed the concerns raised by the reviewers during the rebuttal. I recommend acceptance.",
        "This paper describes how to use normalizing flows for selecting features in a way that controls the type-1 error by using a normalizing flow along with MCMC to sample from the null distribution. The majority of the reviewers were positive, however the most confident reviewer was negative. From taking a look at that reviewers concerns, I tend to agree with most of them.  The paper is titled knockoff-free, which means in the context of this paper that both 1) 1-bit p-values are not used and 2) The full knockoff property is not required, only sampling from complete conditionals are required. Most of the experiments compare knockoff methods to the proposed approach, so it's not clear if 1) 1-bit p-values are not great or 2) the model-X process/complete conditional sampling process is better with normalizing flows. The former point is known and the latter point on the best way to sample from the complete conditionals is really the value.   If we take the paper as,   1) complete conditionals are 1-D 2) MCMC can be used to sample from a 1-D unnormalized density 3) Simple MCMC won't be bad because the problem is 1-D  -> Any likelihood based deep generative model can be used to sample complete conditionals  then it's a solid paper.  On the other hand, the belief that flows are the correct choice versus other likelihood-based deep generative models is harder to take as there's only a comparison with a mixture density network used in the original HRT paper. Also from other uses of these models, different models are better in different situations. I'd suggest a heavy discussion in the paper on this point at the minimum. Maybe even a reframing of the paper is needed.  Finally, for the test statistic, the HRT may not be the best choice for work like this paper that studies the problems with estimating X-distribution. The  paper \"CONTRA: Contrarian statistics for controlled variable selection\" at AISTATS 2021 shows that the HRT test statistic is more sensitive to model-X estimation errors than a simple mixture statistic that doesn't give up much power. The choice of test statistic also merits some discussion in step 3."
    ],
    [
        "Spectrum Random Masking (SRM) is a data augmentation method by random masking in the frequency domain. It improves performance of several algorithms in image-based RL across a wide range of settings. The idea is novel and the paper is well written. Experiments are sufficient to demonstrate the effectiveness of the proposed method. AC agrees with the reviewers that this is a good paper for NeurIPS and recommends acceptance. However, the authors are strongly encouraged to include more discussion on the limitations pointed out by reviewers in the final version.",
        "The authors have introduced a method of data augmentation for image-based reinforcement learning that performs masking in the frequency domain, combined with techniques for stabilizing Q-learning, to achieve improved performance on a number of DMControl Generalization Benchmark tasks.  There was agreement among the reviewers that this work is novel and technically sound, and their concerns were mainly related to the breadth of tasks explored in the initial submission. During the review process the authors have gone to considerable effort to introduce new tasks (e.g. DrawerWorld, Robosuite and CARLA) and the improved performance of their method appears to generalize well. I believe that this work will be of broad interest to the RL community and recommend it for acceptance."
    ],
    [
        "This paper presents a new topic model based on adversarial training inspired by InfoGAN. The topic model consists of two main steps: first to generate bag-of-words for topics and then to use a sequence decoder on the back-propagated from the bag of words to decode the sequence text. The paper is clearly written and the method is novel. Also, the experimental results are promising. However, as pointed out by the reviewers, it would be better to include more ablation studies to analyze the effect of the additional parameters, such as the reconstruction loss, on the performance of the model on other tasks.",
        "This paper proposes TopicGAN, a generative adversarial approach to topic modeling and text generation. TopicGAN operates in two steps: it first generates latent topics and produces bag-of-words corresponding to those latent topics. In the second step, the model generates text conditioning on those topic words.  Pros:  It combines the strength of topic models (interpretable topics that are learned unsupervised) with GAN for text generation.  Cons:  There are three major concerns raised by reviewers: (1) clarity, (2) relatively thin experimental results, and (3) novelty. Of these, the first two were the main concerns. In particular, R1 and R2 raised concerns about insufficient component-wise evaluation (e.g., text classification from topic models) and insufficient GAN-based baselines. Also, the topic model part of TopicGAN seems somewhat underdeveloped in that the model assumes a single topic per document, which is a relatively strong simplifying assumption compared to most other topic models (R1, R3). The technical novelty is not extremely strong in that the proposed model combines existing components together. But this alone would have not been a deal breaker if the empirical results were rigorous and strong.  Verdict: Reject. Many technical details require clarification and experiments lack sufficient comparisons against prior art."
    ],
    [
        "This paper studies connections between statistics and perception: perceptual distances, prior, image quality, and perceptual sensitivity. They show that human perception is strongly correlated with perceptual similarity, and statistical distances are correlated with perception. They empirically show that perceptual distances can be useful for statistical learning, but not always for optimal performance. They also provide some empirical evidence to demonstrate that statistical learning with perceptual distances does not always lead to noticeable gains in performance over Euclidean distance.  The paper is well-written and the connections between perception and statistics are interesting. The main concern of the reviewers is that the paper does not discuss the connections with statistical learning explicitly, but the authors have done a good job throughout the discussion period in making this explicit. The reviewers also had concerns about the significance of the experimental results, which have been largely addressed during the discussion.",
        "All reviewers suggest acceptance of this paper, which reports the relationship between perceptual distances, data distributions, and contemporary unsupervised machine learning methods.  I believe this paper will be of broad interest to different communities at ICLR."
    ],
    [
        "This paper studies the problem of constructing prediction intervals for regression on cross-section time series data with temporal quantile adjustments (TQA) . The authors provide error bounds for coverage and also support their claim empirically. The reviewers agree that the problem is important, the approach is novel, and the paper is well-written.   Main concerns of the reviewers have been addressed during the rebuttal period. Following the recommendation from the AC, the authors are encouraged to revise the paper accordingly.",
        "In this paper, the authors propose the temporal quantile adjustments (TQA) that can improve longitudinal coverage and preserve cross-sectional coverage for the prediction interval built for regression on cross-sectional time series data. While previous works focus on either of the coverage guarantees, a major contribution of this paper is to achieve both. The research questions addressed in this paper are of critical importance for practitioners in relevant areas. The paper is well written. The presented approach has solid empirical support and decent theoretical guarantees. Including a simulation study to demonstrate the validity of the proposed approach under specific (and controlled) setup will further improve the paper."
    ],
    [
        "The paper proposes a novel method that learns a hash function for count-based exploration, and uses it to control the exploration of states that are known to be useless for maximizing the extrinsic reward. The reviewers agree that the paper is well written, the idea is novel and interesting, and the experimental results are convincing. There were some concerns about missing comparisons to baselines or some of the clarity of the presentation, which were addressed during the rebuttal period.",
        "Reviews were mixed here and all quite borderline. There are legitimate points raised for why this is being consistently given borderline ratings, with two in particular resonating with my own reading (novelty and comparisons with other methods). However, despite these issues the paper itself is a solid contribution, and I think could easily lead to others building on the core ideas and approach. The paper has also improved notably during revisions and at present does not have any fundamental flaws that should preclude publication. Therefore, I recommend acceptance."
    ],
    [
        "1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.   - The problem addressed in this paper is interesting and relevant to the ICLR community. - The proposed method Matrix Data Deep Decoder yields very good results for geometric matrix completion on non-Euclidean domains.  2. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it’s a good idea to acknowledge this and note whether it influenced the final decision or not.  Three. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.  The reviewers reached a consensus that the paper should be rejected based on the lack of convergence of the proposed method to the",
        "The focus of this paper is to analyze an end to end network to reconstruct matrices originating from non-Euclidean data which are corrupted. The authors present an untrained network for this task. In the review period the reviewers raised a variety of concerns including concerns about novelty of the paper with respect to existing work, technical depth and clarity. The authors did not respond to these concerns. Therefore, I recommend rejection."
    ],
    [
        "The paper presents a new dataset and benchmark for the task of tracking any point in a video. The proposed dataset is called TAP-Vid and it has a mixture of real and synthetic data. For real data, human manually annotates the ground truth for several 2D salient points, and for synthetic data, perfect ground truth labels are provided.  The paper received 5 reviews form 5 reviewers and all are positive about the paper. The reviewers find that the paper is well written and clear, the benchmark is well designed and the experimental results are reproducible. Moreover, the authors propose a new algorithm for the dataset's collection and testing which is interesting.  Therefore, I recommend accepting this paper to the NeurIPS 2022 Datasets and Benchmarks program.",
        "TAP-Vid presents a benchmark that will be highly useful for tracking research for tracking arbitrary physical points on surfaces over long video clips. The reviews are all positive, with one reviewer raising ethical aspects in preparing the benchmark.  I find the rebuttal sufficient and adequate and hence recommend acceptance of the paper."
    ],
    [
        "This paper proposes Non-stationary Transformers as a generic framework to tackle over-stationarization problem.  The motivation is clear and the writing is easy to follow. The proposed procedure is quite simple to implement and integrate with different transformer backbone. Empirical results show consistent improvement. On the other hand, some reviewers think the theoretical part is not very rigorous. Reviewer 1 pointed out that the proposed approach share lots of similarity with section 3.3 of [1]. Reviewer 3 also raised some concerns about the experimental evaluation.  Overall, the paper is proposed to be a good contribution to ICLR. The authors are suggested to address the comments from the reviewers in their final version.",
        "The paper introduces a transformer-based method for non-stationary time series forecasting.  This research addresses a clear need, as acknowledged by the reviewers. Also, most reviewers found the method clearly described and the experiments compelling, demonstrating an improvement of the state of the art.  The reviewers asked questions about the baselines, evaluation methods and ablation studies. They also made requests related to clarifying the wording and some of the theory. The authors put in significant effort in addressing the comments, offering detailed responses to every reviewer. Only one of the reviewers responded during the discussion period, and the response came very late in the discussion period. However, I read the authors' response and concluded that they adequately addressed most issues raised by the reviewers.  As the model is in the Transformer space, and transformers have previously been shown to be state of the art on a number of tasks, I do not find it necessary to compare against other 'families' of methods. So I will consider that issue addressed as well."
    ],
    [
        "This paper studies the problem of learning the optimal threshold policy for MDPs. The key insight is to exploit the monotonicity property of threshold policies, which suggests that the optimal policy is a threshold policy. This attribute is used to develop a new off-policy actor-critic algorithm based on threshold policies. The paper received a mixed evaluation from reviewers, ranging from accept (7) to reject (3), and the general feeling was that the paper lacked novelty. Several reviewers also raised concerns about the validity of assumption and the simplification of policy gradient. The rebuttal submitted by the authors addressed some of these concerns, but not fully (especially regarding the novelty and significance). The general feeling by reviewers was that this is an interesting contribution but perhaps not yet mature enough for ICLR. I encourage the authors to revise and resubmit their paper taking into account the reviewers' comments.",
        "The paper considers a subset of dynamic problems, in which the optimal policy is a threshold-policy. The authors use this attribute to formulate tailored off-policy actor-critic algorithms, for both MDPs and RMABs which are gradient-based, so can utilize neural networks. They empirically compare their method to SOTA methods in three MDP domains and three RMAB parameterizations, the results show that their method, DeepTOP, performs better than the compared methods in all the experiments.  The paper is well written and the claims are correct.  The performance of DeepTOP compared to the other methods is impressive.  All four reviewers were on the positive side for acceptance."
    ],
    [
        "This paper demonstrates that transformers can learn to predict linear functions of interest, given a few input/output examples. The reviewers found this study interesting and insightful, with a comprehensive set of experiments. The rebuttal clarified the reviewers' questions, and all reviewers recommended acceptance after the discussion period.   I encourage the authors to extend the study to cover more complex function classes, and tone down the claim that this is the first study solely focusing on linear functions. After all, this is a toy example paper, and it would be nice to include experiments on other function classes as well.",
        "This paper demonstrates compellingly that transformers are able to in-context learn simple function classes (e.g., linear functions), to the extend that they can recover solutions from algorithms like LASSO. The experiments are well designed and executed, which lead to surprising and intriguing results. While the paper does not provide any explanation for why transformers exhibit such capabilities, it will spur both empirical and theoretical work studying how transformers learn algorithms from in-context examples. Congratulations on a nice work!"
    ],
    [
        "This paper studies ways of subsampling tall-and-dense p-norm regression involving structured Vandermonde matrices. It shows that in this setting with additional structure, sampling by Lewis weights produces poly(p) * d row sized samples for all values of p. The theoretical results in the paper are solid and the result for $p=\\infty$ is new.  While the reviewers acknowledge that the paper has some merits (well-written, solid theoretical results, a coreset), they have some concerns towards the presentation of the paper. In particular, the motivation towards this technique is not well presented. Therefore, we encourage the authors to revise the paper according to the suggestions by the reviewers and resubmit it to a future venue.",
        "Dear Authors,  The paper was received nicely and discussed during the rebuttal period. There is consensus among the reviewers that the paper should be accepted:  - The new result about query complexity of regression problem that the authors have added. Along with the result on   for (noisy) Vandemonde matrix, these make the paper lie above the accept bar. - The authors have providing satisfying clarifications during the rebuttal that convinced reviewers to increase further their scores.  The current consensus is that the paper deserves publication.  Best AC"
    ],
    [
        "Meta Review: This paper proposes a novel active learning (AL) framework with theoretical guarantees including asymptotically unbiasedness, hyper-parameter-tuning, and importance weighting. The paper is well written and the theoretical advantages of the proposed framework such as asympototic unbiasedness seem interesting. The method proposed is based on the importance of reweighting and the assumptions about the instrumental distribution are reasonable. Empirical results on MNIST and CIFAR10 are presented to show the proposed AL framework converges to a stationary point as the number of training iterations approaches infinity. There is a lot hyperparamters or customiazations possiblei in the framework. The authors have addressed most of the concerns raised by the reviewers. I recommend acceptance of this paper.",
        "Meta Review: I find this paper to present an interesting perspective, analyzing the sampling bias in active learning and correcting for it.  There was some debate with Review YKx9 about the assumptions and rigor of the theory, but I found the author responses adequate.  I recommend acceptance.  The authors should take care to improve the readability of Figure 1."
    ],
    [
        "The paper extends the Bregman Lagrangian framework of Wibisono et al. 2016 to the infinite-dimensional setting and derives accelerated gradient flow formula in the space of probability measures. All the reviewers and AC agree that the major limitation of the paper is the lack of theoretical and empirical comparison with existing methods. The experiments are a proof-of-concept on simple illustrative toy examples and no comparison with other existing method is provided. Please add comparison with SGHMC and other algorithms proposed by the reviewers in the final version.",
        "This paper developed an accelerated gradient flow in the space of probability measures. Unfortunately, the reviewers think the practical usefulness of the proposed approach is not sufficiently supported by realistic experiments, and the clarity of the paper need to be significantly improved. The authors' rebuttal resolved some of the confusion the reviewers had, but we believe further substantial improvement will make this work a much stronger contribution."
    ],
    [
        "This paper considers the problem of generalizing to unseen dynamics for model-based RL. Previous methods learn to predict a vector $Z$ that characterizes a particular environment dynamics from past transitions. However, as the environment id or label is not available, this vector inevitably contains redundant information that might hurt the generalization of the model. The paper therefore proposes an interventional approach to estimate the probability that two vectors belong to the same environment. They introduce a set of auxiliary losses based on relational intervention and causal reasoning to encourage the inferred context to be the same. The method shows improved prediction error and test reward on a range of continuous control tasks.  Strengths:  - The problem of unsupervised dynamics generalization is of practical relevance. - The motivation and design of the approach are clearly explained.  Weaknesses: - There is a lack of results on domains with much more complex dynamics than the pictured environments. - More in-depth analysis is required to understand the effectiveness",
        "Description of paper content:  The authors propose a dynamics model that can generalize to novel environments. The train and test MDPs have the same state and action spaces but different dynamics. Environment specific inference is achieved by estimating latent vectors Z that describe the non-stationary or variable part of the dynamics. These Z-s are inferred from trajectory segments in unlabeled environments. The Z-s are learned contrastively: Z-s from the same trajectory are pulled together, and Z-s from separate trajectories are pushed apart. However, to mitigate the error of distancing Z-s from different trajectories but the same environment, Z-s on trajectories with similar transitions are also pushed together using a soft clustering penalty. These losses are justified based on ideas from Pearl’s causal inference.  Summary of paper discussion:  The reviewers concluded that the contributions are conceptually interesting and “somewhat” novel. The reviewers felt that the empirical performance gains of the method over baselines were demonstrated but not extremely impressive."
    ],
    [
        "The paper attempts to shed some light on why neural networks generalize despite optimizing to zero training error, over-parameterization, etc.  The paper analyses how the representations of neural networks evolve during training, in particular which ReLU nodes are activated. The authors attempt to show how this leads to a diverse set of functions being learnt. This is an entirely empirical work. As agreed by the reviewers, it is not insightful. Furthermore, the paper makes claims that are heuristic and not justified. The paper is poorly written, poorly structured, and it is extremely difficult to parse. Therefore, I cannot support the publication of the paper in its current form.",
        "In an attempt to understand generalization, this paper aims at understanding the dynamics of functions presented by the network for different images in the training set. Authors look at activation patterns (whether a ReLU activation is on or off) as a way of characterizing the active paths in the network and approximating the function presented by the network for each image. Authors study different related statics (eg. correlation) and how they evolve during training including.  Pros:  - Understanding the dynamics of training, how diversity is encouraged by the training procedure and its relationship to generalization is an important problem. - This paper takes an empirical approach and tries to make interesting empirical observations about the dynamics of the training.  Cons: - The paper is poorly written in terms of structure, making clear arguments with enough evidence, notation, etc. - Some empirical trends are shown but their connections to the main claim of the paper about generalization is very weak. The main attempt to connect the observations to generalization is Fig. 7 which shows model accuracy correlated with the ratio of early to mid overlap. This is problematic both because it only has 6 data points and also because a simple correlation analysis is not enough to establish this claim which is more about the cause of generalization.  Reviewers have pointed to various concerns including but not limited to clarity of the paper, lack of rigorous arguments, not providing enough evidence for the arguments, etc. Unfortunately, authors did not participate in the discussion period.  Given the above concerns, I recommend rejecting the paper."
    ],
    [
        "The paper presents a new characterization of generalization error bound for general deep neural networks. Based on the analysis of depth and width of the network, as well as the spectral norm of weight matrices, it provides a generalization bound in terms of the Rademacher complexity of the empirical loss of the multi-layered network.  Reviewers pointed out several concerns, including the vacuousness of the bound discussed in Arora et al. and the RHS of the equation which misses terms related with B_{d,2}. In response, the authors have nicely addressed all the reviewers' comments and provided an improved version of their work. All the reviewers agree to vote for acceptance.",
        "I'm quite concerned by the conversation with Anonymous, entitled \"Why is the dependence...\". My issues concern the empirical Rademacher complexity (ERC) and in particular the choice of the loss class for which the ERC is being computed. This  class is obviously data dependent, but the Reviewers concerns centers on the nature of its data dependence. It is not valid to define the classes by the Jacobian's norm on the input data, as this _structure_ over the space of classes is data dependent, which is not kosher. The reviewer was gently pushing the authors towards a very strong assumption... i'm guessing that the jacobian norm over all data sets was bounded by a particular constant. This seems like a whopping assumption. The fact that I can so easily read this concern off of the reviewer's comments and the authors seem to not be able to understand what the reviewer is getting at, concerns me.  Besides this concern, it seems that this paper has undergone a rather significant revision. I'm not convinced the new version has been properly reviewed. For a theory paper, I'm concerned about letting work through that's not properly vetted, and I'm really not certain this has been. I suggest the authors consider sending it to COLT."
    ],
    [
        "The paper introduces a normalization method for image classification with pixel-wise tensor normalization which improves both accuracy and robustness of the model. The results shows somewhat improvement, but not significant.   As agreed by all the reviewers, the paper still needs further polishment and is not ready for publication at the moment. We encourage the authors to improve the paper based on the reviewer's comments and resubmit it to a future venue.",
        "Reviewer KVLA raises some concerns on the completeness of this paper, suggesting that this paper needs further improvements for publication. Based on the comments of both reviewers, this paper is accepted as a long paper. Please address the reviewers' comments in the final version."
    ],
    [
        "This paper introduces a new reinforcement learning algorithm that uses the Laplacian to facilitate learning state representations that can be used for reshaping states during goal-driven exploration.  All of the reviewers agree that the paper addresses an important problem, is technically sound and novel, and presents convincing experimental results. The authors have also addressed the reviewers' concerns during the discussion phase, e.g. with respect to baselines, datasets, and experiments.  I recommend acceptance.",
        "This paper provides a novel and non-trivial method for approximating the eigenvectors of the Laplacian, in large or continuous state environments. Eigenvectors of the Laplacian have been used for proto-value functions and eigenoptions, but it has remained an open problem to extend their use to the non-tabular case. This paper makes an important advance towards this goal, and will be of interest to many that would like to learn state representations based on the geometric information given by the Laplacian.   The paper could be made stronger by including a short discussion on why the limitations of this approach. Its an important new direction, but there must still be open questions (e.g., issues with the approach used to approximate the orthogonality constraint). It will be beneficial to readers to understand these issues."
    ],
    [
        "This paper studies the problem of end-to-end semantic parsing for multi-task AV requests from a virtual assistant, using cross-domain schemas (CDS). The main idea behind the work is to encode the request utterances into an intermediate representation language that then serves as the decoder for semantic parsing. The proposed approach is evaluated on the Snips (Goo et al., 2018) and Wikitext-2Seq datasets.   The reviewers agree that the paper is well-written and the idea of using cross domain schemas for this task is interesting and novel. However, all the reviewers had major concerns about the current draft. In particular, the paper totally disregard the recent massive literature on semantic parsing, including all the recent work on Semantic Role Labelling and on languages for expressing the general meaning of language. Although the authors updated the draft to address some of the reviewers' comments, in the end only one reviewer was in favor of acceptance",
        "Interesting approach aiming to leverage cross domain schemas and generic semantic parsing (based on meaning representation language, MRL) for language understanding. Experiments have been performed on the recently released SNIPS corpus and comparisons have been made with multiple recent multi-task learning approaches. Unfortunately, the proposed approach falls short in comparison to the slot gated attention work by Goo et al.  The motivation and description of the cross domain schemas can be improved in the paper, and for replication of experiments it would be useful to include how the annotations are extended for this purpose.  Experimental results could be extended to the other available corpora mentioned in the paper (ATIS and GEO)."
    ],
    [
        "The authors propose a new fully single loop stochastic algorithm for bilevel optimization problems where the inner problem is strongly convex and the outer objective is smooth. They give theoretical convergence guarantees for both SGD version and variance reduction version for the proposed algorithm.   The reviewers found the paper to be well written and easy to follow. The theoretical results for variance reduction do not justify the need for using it in the given framework as it is not directly compatible with the convergence results for SGD or SAGA. However, the empirical results are encouraging and can lead to further research in this direction.",
        "The main topic of this work is stochastic bilevel optimization. It provides an efficient algorithm for this task, and provides theoretical results in this setting.    The reviewers are unanimous that this is well-presented work of high quality and should be accepted, and so do I."
    ],
    [
        "The paper proposes a new Bayesian neural network learning paradigm that operates in functional space, i.e. rather than in weight space, and thus learns distribution in the functional space instead of in log-like space. The approach is motivated by extending the idea of Riemannian Langevin dynamics to functional spaces, with a corresponding functional sampling algorithm. The paper is very poorly written, and it is hard to understand the details of the algorithm and how the proposed method differs from existing MCMC methods. There are also inconsistencies in the notations, and missing experiments, that make the paper hard to follow.",
        "This paper addresses a promising and challenging idea in Bayesian deep learning, namely thinking about distributions over functions rather than distributions over parameters.  This is formulated by doing MCMC in a functional space rather than directly in the parameter space.  The reviewers were unfortunately not convinced by the approach citing a variety of technical flaws, a lack of clarity of exposition and critical experiments.  In general, it seems that the motivation of the paper is compelling and the idea promising, but perhaps the paper was hastily written before the ideas were fully developed and comprehensive experiments could be run.  Hopefully the reviewer feedback will be helpful to further develop the work and lead to a future submission.  Note: Unfortunately one review was too short to be informative.  However, fortunately the other two reviews were sufficiently thorough to provide enough signal."
    ],
    [
        "The paper introduces a method for safety-aware RL, which aims to reduce the side effects of the actions of a reward-maximizing reinforcement-learning agent. Basically, the proposed solution trains an agent who focuses on the total reward and another agent who minimizes the total side effects. The authors then empirically investigate the effectiveness of combining the two agents, and demonstrate that their side-effect minimization performance can match some baselines on the multi-task SafeLife suite.  The reviewers agree that the paper is well-motivated and timely, and that there are interesting side-effects of the proposed approach. However, there was a consensus that the experiments need more work. In particular, the reviewers would like to see more comparisons with baselines that consider non-trivial side effects (e.g., those based on safety measures), and/or experiments that consider more complex environments.   I encourage the authors to incorporate the reviewers' feedback and resub",
        "Based on the paper, reviewers' comments and discussions, and the responses, the meta-reviewer would like to suggest the authors to improve the paper and resubmit."
    ],
    [
        "This paper introduces a method for unsupervised scene decomposition that infers object shapes, appearances and 3D poses without any supervision. The reviewers agree that this is an important problem that is relevant to the robotics community. This paper also shows that the inferred object representations can be used in a visual reasoning task.  Strengths: - The proposed method is general in that it can work with multiple object NeRF functions - The performance is competitive on CLEVR6.  Weaknesses: - Comparison to slot-attention-based methods is limited in the experiments. - It is not clear how the inferred 3D object representations are useful for 3D manipulation. - Some of the downstream tasks in CLEVR3D are unclear.  Post-rebuttal: The authors have addressed most of the concerns raised by the reviewers. In addition, the authors have shown that the 2D to 3D segmentation is still possible with their method. The paper is clearly written and the",
        "The paper proposes an approach for learning a decomposition of a scene into 3D objects using single images without pose annotations as training data. The model is based on Slot Attention and NeRF. Results are demonstrated on CLEVR and its variants.   The reviewers point out that the method is reasonable and the paper is quite good, but even after considering the authors' feedback agree that the paper is not ready for acceptance. In particular, the key concern is around experimental evaluation - that it is performed on one dataset (and variants thereof) and that the evaluation of the 3D properties of the model is not sufficiently convincing: it does not outperform 2D object learning methods on segmentation and is not compared to those on \"snitch localization\".  Overall, this is a reasonable paper, and the results are promising but somewhat inconclusive, so I recommend rejection at this point, but encourage the authors to improve the paper and resubmit to a different venue.  (One remark. The paper makes a point of not using any annotation. It is technically true, but in practice on CLEVR unsupervised segmentation works so well that it's basically as if segmentation masks were provided. If the authors could demonstrate that their method - possibly with provided coarse segmentation masks - works on more complex datasets, it would be a nice additional experiment)"
    ],
    [
        "This paper presents AdaRL, a transfer learning approach for improving domain adaptation in reinforcement learning. The core idea is to learn a latent representation with \"domain specific\" and \"domain shared\" components, and the transfer is done by collecting some data in target domain and estimating \" domain specific\" variable of the target domain. The proposed method is evaluated on variations of a cartpole and a pong domain and evaluated against a set of recent, competitive baselines.  The paper is a good paper but could benefit from some clearer writing and more extensive experiments. Reviewers had several concerns about the writing and the clarity of the paper. The authors have improved the writing significantly, for instance, they have gone through the appendix and removed unnecessary text. Similarly empirical evaluations have also been improved.  After the rebuttal, all reviewers are in favor of accepting the paper and the discussion period with the authors was constructive. Therefore, I recommend acceptance.",
        "The authors present a method called \"AdaRL\" that learns a structured latent representation that characterizes relationships between different variables in an RL system. The method is evaluated on modified Pong and Cart-Pole domains and it is shown to outperform other transfer learning baselines. The reviewers agree that the method makes sense and addresses an important problem of transfer in RL. The authors did a good job in the rebuttal to empirically validate their claims and provided extra experiments. The reviewers also point out that the evaluated domains are rather simple and the paper would benefit from evaluations in a more complex environment as well as better writing. Please focus on improving these aspects in the final version of the paper."
    ],
    [
        "The paper studies the degradation in performance of deep learning models under both adversarial as well as natural perturbations or contamination. The main driving question of this paper seems to be whether naturalperturbations hurt generalization as much as adversarial examples. To this end, the authors propose a technique to “standardize” the robustification process across different perturbation.  The reviewers and AC note the following potential weaknesses: (1) It is unclear exactly what contributions this paper is making. The experiments are often not consistent across tasks, it is not always clear if the reported results are over training or testing samples, and the observations are not always supported by experiments on other datasets as well. (2) The notation throughout the paper is at times confusing. (3) The authors have improved the notation in their rebuttal, however, the overall quality of the paper seems not to be at the standards expected by ICLR papers.  Overall, the paper",
        "The reviewers indicated a number of concerns (which I agree with) which have not been addressed by the authors as they have not provided any response.  Indeed, the paper would be significantly improved once these issues are addressed."
    ],
    [
        "This paper denoises existing semi-supervised learning methods via a novel objective function. The proposed objective is shown to have less variance in some cases, and is now consistent when $n->\\infty$. The author also presented theoretical results on statistical learning results for the proposed methods.   The main concerns from the reviewers are: 1) Presentation: the presentation is very poor and very hard to follow. 2) Generalization error bounds: they are based on the missing completely at random (MCAR) assumption, whereas in practice, many methods use a Gaussian process (or pseudo-Gaussian) assumption to reduce the sample complexity.  The authors addressed part of these concerns in their response and promised to include further experiments in their revision. The paper is thus recommended to be accepted. The reviewers have provided detailed and constructive feedback to the authors. The authors are encouraged to incorporate this feedback when preparing the final version of the paper.",
        "This paper provides an interesting generalized perspective on SSL techniques and proposes a debiasing technique that can be viewed as decreasing the variance of the risk estimate. The authors argue that this leads to estimators that are better than the purely supervised estimator under a rather weak assumption called MCAR - which assumes that the probability of a missing label is independent of covariate and label.   Although the exposition and perspective are interesting, this paper is borderline for the following two main reasons:  1. A few reviewers were not convinced of the theoretical result that is supposed to show that unlabeled data strictly helps - indeed, whereas usual variance reduction techniques (e.g for optimization schemes such as SGD etc.) lead to a strict gain in terms of convergence rate, there is no clear asymptotic/high probability statement that indicates statistical gain of the corresponding estimator (which is what we really care about - not the risk estimate). The dependence of lambda_opt on theta (which changes every iteration) does not help in providing such a statement. Since this is the primary contribution of the paper, I would suggest the authors follow through with the analysis to show a gain for the actual estimator compared to the \"complete case\" (only using supervised data).   On that note, the authors claimed in their rebuttal that they have added an asymptotic variance analysis in Appendix I, which indeed would have made a very valuable point - however, I could only find a copy-pasted version of Theorem 3.1. in Appendix I? Similarly, Appendix F does not seem to include the comparison between debasing using labeled and unlabeled data but instead contains the proof of Theorem 3.2. Perhaps the wrong revision was uploaded, but unfortunately, given the current version, this point is not adequately addressed.  2. If the experimental results were more extensive and conclusive, then the current theorem could have perhaps been alright as a mainly methodological contribution. However, as the authors note, extensive experiments require a lot of compute power - however, given the lack of the ultimate theorem, the methodology becomes the primary contribution and would thus require more experimental evidence as the reviewers asked for.    Addressing one of the above points would push the paper above the acceptance threshold which we hope the authors can pursue in their next submission."
    ],
    [
        "Meta Review: The paper is clearly written, the idea is interesting, and fits the theme of UAI well. All reviewers agree that the paper would lead to interesting discussions during the conference.   The approach is original, and the evaluation and experiments are necessary. Although the first half of the paper is generally clear, the reviewers feel the second half could be significantly improved, in clarity, in explaining the complicated ideas, and in experimental content.  We encourage the authors to take the reviews into account when preparing the camera-ready version.",
        "Meta Review: The paper presents a new means to learn sparse Choquet integral, using for instance classical L_1 penalization techniques. This research participates to a long trend of research aiming at learning preference functions in various settings (here, having only limited preferential information).   All reviewers agree that the paper is well-written and the contribution nicely presented. Two main critics were done by the reviewers:  * The first is the potential significance of the research, i.e., that it addresses an actual real-world problem. After discussion and rebuttals, this critic appears to be of less importance  * The second (with which I would concur) is that the experimental part is limited in different ways. The main critics regarding those are as follows: 1. The authors only use synthetic data that mostly comply with their assumptions, thereby confirming that their approach is valid. THey do not really challenge it. 2. There is no realistic data sets used (which is very difficult to obtain in incremental preference learning, but less in passive preference learning). 3. There is also no real comparisons with other methods intending to learn value functions from observed preferences. Given the large literature on preference learning and the fact that most learning papers require the comparisons with other baselines when possible, one could have hoped to have such comparisons.   Depsite that, the paper appears to be well-made with a relevant algorithmic contribution."
    ],
    [
        "This paper presents a weakly supervised contrastive learning approach for the classification of whole-slide images (WSI). The proposed method consists of two main steps: a domain-specific self-supervised feature extractor and task-specific feature aggregation modules. The main contribution of the paper is the novel framework for SCL-WC which is evaluated on the whole slide image classification task. The experimental results show the effectiveness of the proposed method on multiple datasets. The paper received mixed reviews with two weak accepts and two borderline rejects. After reading the paper, reviews, rebuttals, and discussions between reviewers and authors, the area chair agrees with the reviewers that there are several weak points to this paper (i.e., limited novelty, limited ablation studies, lack of discussion on the importance of each component proposed in the method). Overall, this paper can not be recommended for acceptance given its current form.",
        "This work presents a method to obtain slide level representations in computational pathology. The specific contributions of this work are a positive-negative-aware module (PNM) and a weakly-supervised cross-slide contrastive learning (WSCL) module and a loss to encourage intra-WSI local patch separation and inter-WSI global feature contrast. The idea is to use the attention weights in a MIL framework as patch level pseudo labels. These are used to compute \"weights\" for positive and negative patches (the latter of which is assumed to be significantly larger in number for a given WSI). By using these weights in a contrastive manner to push the representations from positive patches away from those of negative patches, the model learns more effectively since it is less susceptible to the noise from the negative patches.  The reviewers found these contributions novel. During the review, the largest source of concern was along the choices made during the empirical evaluation. Specifically, the manuscript in its current form lacked empirical backing for several of the choices made regarding the neural architecture, the algorithm for self-supervised learning etc. In response to this the authors conducted several different kinds of ablation studies (which were incorporated into the supplement) during the rebuttal process, which other reviewers found convincing as a potential explanation of the outcomes.  Overall, I found the main contributions of this work (leveraging patch level attention weights as psuedo labels) to be an interesting use case for computational pathology to better focus the learning signal on positive patches. My additional comment is that I think the additional ablation experiments (and references) are an important part of the contributions of this work and should be incorporated into the main paper rather than in the appendix (several equations can be compressed to make space in the manuscript in addition to the additional page)."
    ],
    [
        "The submission presents a numerical analysis of the training dynamics of neural networks with more than one hidden layer. It builds upon the work of Luo et al. 2021. Different layers of the three-layer architecture exhibit changes to their parameters under different initialization scaling schemes. The paper shows that different layers can be simultaneously in the linear, critical or condensed regime.  Reviewers agree that this work is well presented and easy to read. It presents a detailed numerical study of gradient flow of feedforward neural networks. The most important part of the paper, where the parameters gamma2 and gamma3 are derived, is rushed. It needs to be re-written so that it makes more sense. The reviewers also think that the condensed regime is a bit trivial and the linear regime is not explained well.",
        "This work studies the effect of initialization scaling on the gradient flow training dynamics of three layer (two hidden layer) MLPs. . Extending Luo et al. 2021's analysis, the authors identify \"linear\", \"critical\" and \"condensed\" regime depending on initialization scaling parameters  Strength pointed out by the authors include, \"new insight into training dynamics of MLPS with more than one hidden layer\", \"elegant and insightful analysis\" for a \"dauntingly difficult problem\" and that \"phase diagram is neat and valuable contribution\"  Reviewer `PDY9` saw major weakness as treating the second layer as linear regime only, which makes the analysis similar to previous work (Luo et al., 2021). In general, the reviewer believes that the full comprehensive analysis on different phases for each layer is lacking. Although the reviewer did not respond to the AC, this issue has been addressed by author response. Also please do follow the recommendation of the reviewers in terms of improving writing (better description of gamma_2, gamma_3 for example), improving related works, as well as making figures more legible.   Overall, while the paper is somewhat borderline, there are interesting insights and analysis as the reviewers pointed out without critical issues. I recommend accepting this work at NeurIPS 2022."
    ],
    [
        "This paper proposes an extension of the VAE framework with a prior encoder network to construct an implicit prior, which is more flexible and learns an unconstrained prior that can model more complex correlations in the latent space. The method is evaluated on three datasets and shows promising results. The paper is well-written and the algorithm is novel and interesting. The reviewers and AC note the following potential weaknesses: (1) limited novelty in light of prior work that uses a similar architecture, (2) lack of experiments on more complex datasets, and (3) the algorithm should be evaluated on a wide range of tasks beyond the MNIST and CELEB a datasets.  The authors addressed most of the concerns in the rebuttal and added experiments on additional datasets and clarifications to the algorithm, and reviewers agreed that the paper should be accepted.",
        "All three referees have provided detailed comments, both before and after the author response period. While the authors have carefully revised the paper and provided detailed responses, leading to clearly improved clarity and quality, there remain clear concerns on novelty (at least not sufficiently supported with ablation study) and experiments (neither strong enough nor sufficient to support the main hypotheses). The authors are encouraged to further improve their paper for a future submission."
    ],
    [
        "This paper proposes a genetic algorithm for constrained molecular optimization. The reviewers and AC note the critical limitation of novelty of the contribution, which is the use of a novel two-stage procedure, and unconvincing experimental evaluation. There is consensus among the reviewers that this work is not suitable for publication at ICLR in its current form, and the authors did not provide a rebuttal to address reviewers' concerns. AC decided to reject the paper.",
        "The paper describes a genetic algorithm for molecular optimization under constraints. The aim is to generate molecules with better properties while close to an initial lead molecule. The proposed approach is a two-stage one. The first stage aims to satisfy constraints and searches for feasible molecules that are similar to the lead. The second stage optimizes the molecular property. The method is evaluated on logP optimization task, with minor improvement over previous work.  The reviewers point out the following strengths and weaknesses:  Strengths:  - Molecular optimization under structural constraints is an important research direction. - Comprehensive related work section.  Weaknesses:  - Lack of novelty because it is a standard application of genetic algorithm. - The results show that the proposed method did not outperform existing baselines. - The main claim of the paper (benefit of two-stage procedure) is not supported by ablation study. - The authors only conduct experiments on improving LogP, which is a benchmark that is too easy and not challenging. - The objective function and cross-over operation are the same or very similar to previous work. - The experimental evaluation is limited, and the overall setting is not very relevant to real-world tasks.  Overall, all reviewers vote for rejection. It is clear that the paper needs more work before it can be published."
    ],
    [
        "This paper proposes a new method (C-MinHash) to approximate the Jaccard similarity in massive binary data by generating K independent random permutations of the binary string instead of one or two as in MinHash. The theoretical results show that the proposed method has a better approximation error than MinHash and is unbiased. Experiment results also show it outperforms MinHash in some cases. Reviewers generally agree that this is a solid contribution and the paper is well-written. I suggest acceptance.",
        "This was a somewhat unusual submission in that the authors tried to motivate their paper by pointing to a separate anonymous manuscript.  However, the authors didn't seem to want to confirm they would merge the manuscripts when asked about this. It was thought that in fairness the submitted manuscript should be judged on its own. After discussion, it was agreed that the submitted paper on its own, did not generate enough enthusiasm to merit acceptance."
    ],
    [
        "The paper is clearly written although it contains several typos, and the proposed task of cross-modal inference is an interesting task. However, the reviewers seem to hardly find the significance of the proposed method and the haptic space defined in the paper is not clearly defined. Concepts have to be clearly defined prior to their use. Also, the paper was not proof-read, and contains sentences that are not written clearly.  Overall, this paper needs a significant improvement in writing and organization before it can be accepted.",
        "The paper describes the use of tactile sensors for exploration.  An important topic which has been addressed in various previous publications, but is unsolved to date.  The research and the paper are unfortunately in a raw state.  Rejected unanimously by the reviewers, without rebuttal chances used by the authors."
    ],
    [
        "This paper has three main contributions: 1) It provides a theoretical justification for normalization in model training on how it affects model performance and training time in zero-shot learning (ZSL) 2) It proposes a class normalization trick to alleviate the variance inflation/diminish in ZSL from the perspective of data variances. 3) Experiments on continual learning demonstrate the strong accuracy and training speed of the proposed approach in standard generalized ZSL.  However, there are three major concerns raised by the reviewers. 1) Theoretical justification is based on a simplified model. It is not clear how the two normalization tricks are enough to achieve variance control in a deep architecture. 2) The experiments shows these tricks are not enough w.r.t. normalizing the variance in a non-linear model for continuous zero shot learning (CZSL). 3) Empirical results are not very encouraging for CZSL. The datasets used in the paper",
        "This paper got mixed reviews. One for reject and three for acceptance. The reviewers and authors have extensive discussion. Authors also provided additional experiments for further clarifying some questions from the reviewers. The paper has some clarify issue in the theoretical justification part as pointed out by AR1. Authors should extensively improve this part or revise the statement. However, the method proposed in this paper is simple and the results are indeed good. This paper is valuable and should be shared within the community to advance research on ZSL. Therefore, AC recommends acceptance."
    ],
    [
        "After reading the reviews and the rebuttal, I lean towards acceptance for this paper. I agree with the reviewers that the method is simple and effective, and the writing is clear and easy to follow. The only real limitation I see is that there might be some overclaiming here, and some overstatements in the empirical results. Nevertheless, I think this is a solid contribution to the nearest neighbor search area, which is very important for many applications.",
        "The paper provide a good and exciting improvement over LSH based widely used Falcon Library. All the reviewers found the contribution worthy of publication."
    ],
    [
        "This paper develops new algorithms and theoretical results for reinforcement learning in stochastic Markov games, which are extensions of Markov decision processes from the single-agent setup to the multi-agent one. The reviewers agree that the paper is well-written and the results are novel. The main contribution is a model-based algorithm called Nash-VI, based on successive episods of planning and counting, which involves solving a matrix game at each iteration, looking for a notion of equilibria that is computable in polynomial time. While there were some concerns about the novelty of the work in the initial round of reviews, the authors did a good job at addressing them during the rebuttal and convinced all the reviewers to vote to accept the paper. Therefore, I recommend acceptance.",
        "The reviewers, AC, and PCs participated in a very thorough discussion. AC ultimately felt that the work was unfinished, and in particular that details in the proofs still needed work before publication."
    ],
    [
        "This paper analyzes the loss minimisation approaches for epistemic uncertainty quantification using second-order neural networks and empirically demonstrates that they fail to incentivise the network to represent the uncertainty in a faithful way. While the reviewers had some concerns regarding the technical novelty of the analysis and its relevance to current work, the authors did a particularly good job in their rebuttal. After the discussion phase, all reviewers unanimously agreed that this paper should be accepted. Please incorporate the reviewers' suggestions in the final version.",
        "This meta review is based on the reviews, the authors rebuttal and the discussion with the reviewers, and ultimately my own judgement on the paper. There was a consensus that the paper contributes interesting insights on uncertainty quantification, and most reviewers praised several aspects of the submission. I feel this work deserves to be featured at NeurIPS and will attract interest from the community. I would like to personally invite the authors to carefully revise their manuscript to take into account the remarks and suggestions made by reviewers. Congratulations!"
    ],
    [
        "This paper studies the regret distribution of the policies obtained by common bandits in the large T regime (where the arms are connected) and the heavy-tailed/light-tailed distinction between the two modes of regret. The main result of the paper is that any consistent policy must suffer a heavy tailed regret distribution, i.e., have a logarithmic regret while being light-tailed. The authors also show that it is possible to have an optimal regret that is lighttailed and have worst-case optimal regret at the same time - they show the trade-off between these two targets in Theorem 1, and analyze the performances of the new SE and UCB algorithms theoretically and numerically.   The reviewers found the problem of characterizing the tail behavior of the random regret for algorithms that are designed to solve the multi-armed bandit problem to be novel and interesting. Reviewers also found the paper to be well-written and easy to follow. Overall, this",
        "The reviewers came to consensus that this paper makes a good contribution to the study on the tail behavior of the regret of bandit problems. I agree with these opinions and please polish the paper so that the minor concerns raised by the reviewers become clear in the final version."
    ],
    [
        "Overall, this paper provides a great starting point for future benchmarking experiments. The reviewers engaged in a lively discussion with the authors and provided valuable suggestions for future improvements, which the authors have integrated in their submission. I would recommend acceptance of this paper and congratulate them on a strong submission! When revising your paper for publication in the future, please take into account the reviewers' comments and please also update the paper with the clarifications provided in your rebuttal.",
        "Overall, this paper provides a great starting point for future benchmarking experiments. The reviewers engaged in a lively discussion with the authors and provided valuable suggestions for future improvements, which the authors have integrated in their submission."
    ],
    [
        "The paper proposes a framework for characterizing harmful text generated from LLMs. This is a timely and extremely important topic, and the paper engages with the complex socio-technical questions around it. The reviewers are split in their opinions (three in favor of acceptance; three opposed). The key argument raised against the paper is that it does not introduce a new benchmark or dataset, and does not make falsifiable claims. The meta-reviewers consider the paper to be well in-scope for the track: despite lacking empirical results, it provides a \"framework for responsible dataset development\" and clearly identifies \"significant problems with existing datasets.\"  The authors successfully address the other concerns. The paper makes an important contribution to the community and deserves to be accepted.",
        "The paper proposes a framework for characterizing harmful text generated from LLMs. This is a timely and extremely important topic, and the paper engages with the complex socio-technical questions around it. The reviewers are split in their opinions (three in favor of acceptance; three opposed). The key argument raised against the paper is that it does not introduce a new benchmark or dataset, and does not make falsifiable claims. The meta-reviewers consider the paper to be well in-scope for the track: despite lacking empirical results, it provides a \"framework for responsible dataset development\" and clearly identifies \"significant problems with existing datasets.\"  The authors successfully address the other concerns. The paper makes an important contribution to the community and deserves to be accepted."
    ],
    [
        "This paper proposed a training-free NAS method which estimates an architecture’s performance from two perspectives: (1) trainability, and (2) expressivity. The authors proposed to rank architectures by analyzing the two indicators. The metrics for trainability and expressivity seem to be the direct application of deep learning theories. The proposed method can search within 30 minutes (on CIFAR-10) and 4 hours (on ImageNet) on the DARTS search spaces, according to the experiments.  All the reviewers agree that the results are extremely promising. The paper is well-written and easy to follow, and the idea of using TE-NAS to estimate architecture expressivity and trainability is novel.  During the rebuttal, the authors answered most of the questions raised by the reviewers. After the discussion, all the reviewers agreed that the authors could improve the paper by adding more experimental results and moving some of the clarifying discussions from the supplementary material into the main",
        "The authors propose training-free neural architecture search using two theoretically inspired heuristics: the condition number of the Neural Tangent Kernel (to measure \"trainability\" of the architecture), and the number of linear regions in the input space (to measure \"expressivity\"). These two heuristics are negatively and positively correlated with test accuracy, respectively, allowing for fast, training-free Neural Architecture Search. It is certainly not the first training-free NAS proposal, but achieves competitive results with much more expensive NAS methods.  A few reviewers mentioned limited novelty of the method, a claim with which I agree. The contribution of the paper, however, is something different than how it was presented. The core message seems to be that the two proposed heuristics can greatly speed up NAS, and should be a baseline method against which more expensive methods should test.  I feel like this is a borderline paper, but may be of interest to researchers in the field."
    ],
    [
        "This paper suggests improving mutual informaton based feature selection methods with an extra term (i.e., the unique relevance (UR)). The work is well-written and methods are not novel. There is a technical flaw in the analysis. The results indicate that the method improves the baseline. But there doesn't seem to be much evidence that the methods are better than prior ones. The experiments are not very informative. And there isn't much comparison with prior work.",
        "During the discussion among reviewers, we have shared the concern that this work has a significant overlap with [Liu et al. 2018] and [Liu & Motani 2020]. Although the authors tried to address this concern by the author response, I also think that the difference is not enough. In particular, the reviewers pointed out that Figure 1, Table 1, and Figure 3 are exactly the same with those in [Liu, 2020], and Proposition 2 in [Liu & Motani 2020] is Proposition 1 in this paper. Since these overlaps are not acceptable, I will reject the paper."
    ],
    [
        "This paper studies the memorization and forgetting dynamics of large language models during training. The reviewers agreed that the paper measures memorization as the proportion of correctly predicted labels (which corresponds to predicting the correct next/masked token) and forgetting as the decline in memorization. Under the new definition, larger models memorize faster and remember less, and they seem to memorize unique parts of speech tokens like nouns and numbers.  There were some concerns about the size of the vocabulary sets used in the experiments and hyperparameter tuning. The authors added more large vocabulary sets experiment results to the paper to show the effect of size. I think the paper is borderline and needs another round of reviews before acceptance.",
        "This paper studies the underlying training and memorization dynamics of very large language models. The main take aways are that larger-sized language models memorize training data faster, and that this memorization happens before the overfitting of language modeling. Tokens with certain part-of-speech tags (nouns, numerals) seem to be memorized faster during training.   Overall, most reviewers feel positively about this paper, agreeing that it tackles an important problem and that it provides a solid contribution. The experimental results are detailed and use reasonable metrics for data memorization, including the forgetting identifier experiments. Some of the weaknesses that have been pointed out (e.g. regarding the significance of the part-of-speech tags experiment, clarifying the criteria for memorization, etc.) seem to have been well addressed during the author response. Therefore, I recommend acceptance."
    ],
    [
        "This paper proposes a novel method, IterefineE, for cleaning up noise in KGs. It combines the advantages of using ontological information and inferences rules and KG embeddings with iterative co-training, and shows its effectiveness on multiple datasets.  The reviewers agree that the combination of two significantly different types of reasoning is a promising direction to explore for KG cleaning, and the paper is well-written and easy to follow. However, there are concerns about the significance and novelty of the proposed approach, as well as the experimental evaluation. While the rebuttal addressed some of these concerns, not all the reviewers were convinced by the end of the discussion period. In particular, two reviewers argue that the comparison with existing work is not fair, and one reviewer points out that the results of one single run is not sufficient to conclude that the method is effective, while one reviewer argues that multiple runs is sufficient for validating the proposed method. While I agree that",
        "This paper proposes a novel method, IterefineE, for cleaning up noise in KGs. This method combines the advantages of using ontological information and inferences rules and KG embeddings with iterative co-training. IterefineE improves the task of denoising KGs on multiple datasets. While the importance of multiple iterations is mixed, reviewers agree that the combination of two significantly different types of reasoning is a promising direction."
    ],
    [
        "This paper presents a novel adversarial novel idea that allows an attacker to fool exact verifiers by creating neural networks that, due to floating-point error, lead to wrong robustness certifications on most input images. The authors demonstrate that it is possible to create adversarial networks that produce imprecise results in floating point arithmetics. They also demonstrate how to insert a backdoor to the network such that the backdoor is missed by the verifier while it triggers some behavior desired by the attacker.  While the idea is novel and interesting, the presentation of the method and the empirical evaluation are somewhat weak. Also, there are some concerns about the general motivation and applicability of the paper. In particular, it is not clear how this idea can be applied to more sophisticated verifiers (e.g., CIFAR 100) and how it can be used in combination with other techniques like batch normalization.  Therefore, I think the paper is not quite ready for publication",
        "The authors demonstrate that complete neural network verification methods that use limited precision arithmetic can fail to detect the possibility of attacks that exploit numerical roundoff errors. They develop techniques to insert a backdoor into networks enabling such exploitation, that remains undetected by neural network verifiers and a simple defence against this particular backdoor insertion.   The paper demonstrates an important and often ignored shortcoming of neural network verification methods, getting around which remains a significant challenge. Particularly in adversarial situations, this is a significant risk and needs to be studied carefully in further work.  All reviewers were in agreement on acceptance and concerns raised were adequately addressed in the rebuttal phase, hence I recommend acceptance. However, a few clarifications raised by the official reviewers and public comments should be addressed in the final revision: 1) Acknowledging that incomplete verification methods that rely on sound overapproximation do not suffer from this shortcoming. 2) Concerns around reproducibility of MIPVerify related experiments brought up in public comments."
    ],
    [
        "The paper proposes Halo, a novel type of variational autoencoder with structured latent space. It decomposes the latent space into a content space to explain the generated images and a motion space to learn motion dynamics. The dynamics are defined by linear Hamiltonian Dynamics, where a latent variable z is introduced for explaining content and kept fixed for all frames. A global content vector that summarizes the image sequence and a discrete motion space are optimized for motion. The method is demonstrated on Sprites and MUG to demonstrate the efficacy.  Reviewers agree that the method is interesting and sound, the experiments are thorough, and the ablation studies are sufficient to verify the claims. The main concern is on the lack of novelty on top of the previously proposed PVAE (PVAE-Halo).   Overall, this is a good paper and can be accepted.",
        "This paper proposes a novel type of variational auto encoder, referred to as HELO. The latent space is decomposed into a content space and a motion space, and the main contribution is the proposal to model the motion space using Hamiltonian dynamics. All reviewers agree that the idea of using Hamiltonian dynamics is interesting and novel. One main critique, that the authors agreed on, was that the operator does not contain any stochasticity and that this might be a limitation when applying the idea to model more complex data. Another remark was that the experiments are limited and experiments on less constraint data are missing. A quick look at the baseline methods revealed that they also use the same kind of data sets to evaluate their methods, so this latter concern might be of minor importance.  All in all, the potential positive outcomes of this paper outweight its current limitations, so we recommend acceptance at this point, while urging authors to address the remaining concerns in the final version."
    ],
    [
        "The paper combines the idea of masking and unrolling autoencoders for discrete sequence modelling with autoregressive generative models, and shows promising results on several domains including music, music, and word-level language modelling. The reviewers agree that the paper has some interesting aspects, such as the ability to model discrete sequences \"in the loop\", and the fact that the model can take control at inference time. However, the reviewers also point out several major concerns with the current manuscript:  1. Clarity: The paper needs significant improvements in writing. The organization is very loose, making it very confusing for the readers.  2. Experiments: The current experiments do not compare the proposed method with other state-of-the-art methods for the different tasks. This makes the results hard to judge the merit of the proposed model.  3. The related work is not adequately discussed: In relation to the previous work SUNDAE, the paper does not",
        "This paper introduces SUNMASK for modeling discrete sequences. It builds upon previous works such as SUNDAE, Coconet and order-agnostic NADE, but uses a masking scheme that enables fine-grained or human-in-the-loop control during the generation. The qualitative experiments about musical inpainting and masking terms in language modeling do support this motivation to some extent. However, the reviewers are mainly concerned with both the algorithmic novelty and experiments of the paper.   Regarding the algorithmic novelty, some reviewers are concerned that the method is a straightforward combination of SUNMASK and Coconet. I tend to agree with this. Also the reviewers are concerned that the paper could have done a better job in the introduction and background section by putting the method in a better context and better describing related methods such as SUNDAE. This could help highlight the novelty of the paper.   Regarding the experiments, some reviewers are concerned about language modeling (Fig. 2) experiments, and that they do not show much improvement over SUNDAE. I tend to agree, and this is also shown in the results of Table 3 where it is clear that the quality of the language model is not on a par with the recent developments.   Also some of the motivations of the paper, especially the arguments about \"high trust / low trust\" interpretation of the mask, was unclear to me.   In short, I believe the paper should be clarified and improved by addressing the above concerns."
    ],
    [
        "The paper addresses the problem of entity-monitoring for domain generalization. According to the problem formulation, it is very related to the object re-identification and instance retrieval problem. The paper proposes a novel end-to-end system for the data association and filtering (DAF) problem. All experiments are performed with synthetic dataset. This does not expose much real-world challenges, so it is hard to judge the performance of the proposed system. The overall problem formulation is interesting, but the solution seems to be well-known and well-engineered, and the experimental comparison is not strong.",
        "This paper proposed a long-term object-based memory system for robots.  The proposed method builds on existing ideas of data association filters and neural-net attention mechanisms to learn transition and observation models of objects from labelled trajectories.  The proposed method was compared with baseline algorithms in a set of experiments.  The initial reviews raised multiple concerns about the paper. Reviewers nrGQ and  V7qP commented on the conceptual gap between the problem proposed in the introduction and the extent of the experiments. Reviewer qPet understood the paper to be a form of object re-identification and was concerned about the limited comparisons with related work.  The author response clarified their goal of estimating the states of the objects in the world, which they state is different from the goals of long-term tracking and object reidentification mentioned by the reviewers.  The authors also clarified the relationship to other work in slot-attention and data association filters.    The ensuing discussion among the reviewers indicated that the paper's contribution remained unclear even after the author response. Two reviewers noted the paper did not clearly communicate the problem being solved (all reviewers had a different view of the problem in the paper).  These reviewers wanted a better motivation for the problem being addressed in this paper.  The third reviewer remained unconvinced that the problem in the paper was different from long-term object tracking.  Three knowledgeable reviewers indicate reject as the contributions of the paper were unclear to all of them. The paper is therefore rejected."
    ],
    [
        "Meta Review: The paper proposes an improvement method for weak supervision techniques via combination of a foundation model embedding space with self-supervised learning. The major concern of the proposed method is the label model. The authors modeling the P(y,\\lambda|x) as a probabilistic graphical model. It is suggested that the authors should provide the graphs. The paper is somewhat presented in atelegraphic style. There are inconsistent ideas and motivation in the paper, e.g. the title “shores up the foundations”. The meta reviewer agrees with the reviewers' concerns and does not recommend acceptance.",
        "Meta Review: This paper proposes LIGER to better use the foundation model in a weakly-supervised setting. LIEGER has two key components: 1) a finer estimator of weak source quality by dividing the embedding space and learning the source accuracy for each part, 2) source voting expansion  in the embedding space.  The reviewers agree that the proposed work is innovative and makes a significant technical contribution in using pretrained models under weak supervision. There were some concerns raised by reviewers, but most of them have been well addressed by the authors.  I recommend acceptance of this paper given its novelty and significant technical contribution."
    ],
    [
        "This work studies how to improve contrastive learning by mining hard negative samples in the range [w_l, w_u] of the center and right side of the images, and how to do this effectively for multiple contrastive algorithms, including InfoNCE, CMC, MoCO, and more.   This work is well-motivated, and all reviewers agree that the contribution is valuable. During the rebuttal period, the authors have addressed most of the reviewers' concerns, and several reviewers increased their scores. Overall, there is consensus among the reviewers that this work is a valuable contribution to ICLR. Therefore, I recommend acceptance.",
        "This paper addresses the problem of how best to sample hard negatives during contrastive learning, a topic of importance for the recently resurgent field of metric learning / contrastive loss-based unsupervised representation learning. Backed by theoretical results for a new low-variance version of the NCE, the paper proposes an easy-to-implement \"Ring\" method for selecting negatives that are at just the right level of difficulty, neither too hard nor too easy.  Happily, this is a paper that has improved significantly through the interactive peer review of a dedicated set of reviewers combined with prompt responses from the authors. Perhaps the result that tipped this paper over the line in my assessment: the new experimental results now show significant gains from applying the \"Ring\" approach for hard negative sampling to near-state-of-the-art implementations of the MoCo-v2 approach, which is among the leading unsupervised visual feature learning approaches."
    ],
    [
        "ODConv is a convolutional network that combines previous ideas, i.e., filter recalibration in SENet and additive kernels in CondConv/DyConv. It has good performance on public datasets, such as ImageNet and MS-COCO. The key to the proposed method is efficiency, due to separate attention weights for different dimensions. The paper is well written and the experimental results are convincing. The proposed method can be plugged into most existing CNN architectures and the performance is appealing.  The reviewers and AC note the following potential weaknesses: (1) the paper is more experimental-oriented without thorough analysis on the results, (2) the contribution is incremental. The experimental part of the paper has been improved based on reviewers' suggestions, but there are still some major issues preventing it from getting accepted.   The authors did not provide a rebuttal to address the concerns. Given the above concerns, the recommendation is a reject.",
        "This paper presents ODConv, a convolution pattern which uses attention in the convolutions across all dimensions of the weight tensor. The paper is well motivated and well explained, easy to follow. This work is built on top of previous work, but reviewers all agree that the contributions of this paper are significant. The experimental section is comprehensive, with several benchmarks, and show clear improvements. The reviewers suggested a few additional remarks, and discussions to add to the paper, which the authors have addressed in the rebuttal. Reviewers seem in general happy with the authors answers to their concerns. This seems like a sound and meaningful paper. I am fully in favour of acceptance, and I recommend this paper to be presented as a spotlight."
    ],
    [
        "This paper proposes an evolutionary ensemble method for decoding neural signals.  The reviewers and AC note the following potential weaknesses: (1) limited novelty, (2) poor clarity, and (3) empirical evidence of improvement over baselines.  AC thinks that the paper needs a major revision before publication, and encourages the authors to take the reviewers' comments into consideration to improve the manuscript   The authors are encouraged to make the necessary changes to the best of their ability. The paper is not ready for publication in its current form.",
        "The review ratings/confidences were 5/2, 6/2, 4/4, and 5/2. Although the average rating of 5 was just above the acceptance threshold, I think that it should somehow be discounted by the lower confidence levels. Although I myself does not have expertise in the field of BCI, as for the reviewers' evaluation, I think that they basically agreed on the following points: - The problem is well motivated. - The proposed method was built on DyEnsemble with some empirically-motivated extensions to have decoder models dynamically evolving. One could then argue that the proposal is not groundbreaking but somehow incremental. - The authors showed experimentally that the proposed method works well compared with a number of other existing methods.  I also noticed that the authors made revision (adding a paragraph at the end of Section 2: It can be observed in the August 10 revision), which would have improved readability of this paper. I would thus recommend acceptance of this paper, provided that there is room for it."
    ],
    [
        "The main contribution of the paper is to reformulate the training of neural networks as a non-linear control problem and propose a Lyapunov-based loss. The authors show that the proposed loss function can achieve a faster convergence in finite time than the existing ones. Furthermore, they provide upper bounds in terms of the learning rate which are tighter than existing bounds.   The reviewers appreciated the novelty of the idea. However, there were also concerns regarding the applicability of the setup in practice, which limited the significance of the theoretical contribution. In particular, the setup is very similar to the backpropagation algorithm and the upper bounds cannot be applied to multi-layer networks as the layers are stacked. The paper would be significantly strengthened if the authors could also provide some analysis for the setting where multiple layers are applied (e.g. multi-class classification).",
        "This paper aims to study the convergence of deep neural networks training via a control theoretic analysis. This is a very interesting approach to establish theoretical understanding of deep learning. However, there are several concerns raised by the reviewers:  1. The contribution of this paper is limited. The results simply follow from standard optimal control. It is not clear what new insight the paper provides. 2. There are already quite a few works on control theoretic analysis of deep learning. This paper did not do a good job on presenting its novelty and difference with existing works. 3. The experimental part is weak. It only involves small data set and very simple networks.  Based on these, I am not able to recommend acceptance for the current manuscript. But the authors are encouraged to continue this research."
    ],
    [
        "This paper studies the problem of multi-cloud configuration. The key idea is to find the best cloud provider for multi cloud compute selection (time, cost) to avoid vendor lock-in. This is achieved using a best-arm identification algorithm where each arm runs an BBO on each provider and eventually chooses the best arm. They test this approach on 60 different configuration across 3 providers using a proposed dataset. The results show the proposed method can find best cloud providers with best instances more cheaper or faster, compared to BBOs.  Overall, the paper is well-written and technically sound. The problem studied in this paper is interesting. However, several aspects of the problem were ignored. Reviewers raised concerns that: 1) The problem formulation is from a different domain than the one studied in the paper; 2) The proposed dataset is not well-motivated and experimental results are inconclusive; 3) There are many moving parts but the paper has not been updated to address",
        "This paper studies the problem of choosing the best cloud provider for a task. The problem is formulated as a bandit and solved using algorithm CloudBandit. The algorithm is compared to several baselines, such as SMAC, and performs well. The evaluation is done on 60 different multi-cloud configuration tasks across 3 public cloud providers, which the authors want to share with the public.  This paper has four borderline reject reviews. All reviewers agree that it studies an important problem and that the promised multi-cloud optimization dataset could spark more research in the area of cloud optimization. The weaknesses of the paper are that it is not technically strong and that the quality of the new dataset is not clear from its description. At the end, the scores of this paper are not good enough for acceptance. Therefore, it is rejected."
    ],
    [
        "This paper proposes a new dataset for learning disentangled representation that has 1M higher-resolution simulated images along with 1K annotated real-world images of the trifinger robot.  The authors also present a new neural architecture to scale disentanglement on more complex datasets.Dataset contains dependencies in FoV, not artificially induced but present due to the attempt at realism in the simulation.  Reviewers generally agree that the methods proposed in the paper are novel and well justified, and the dataset is important to the community.  However, there are concerns about the weakly supervisedness of the construction of the dataset, the justification of the method proposed, and scalability of the proposed method.  Most of these concerns have been addressed during the rebuttal and discussion period, and reviewers have increased their scores.",
        "This paper introduces a new dataset for evaluating disentanglement and its impact on out of distribution generalization based on the trifinger robotics platform. Using this dataset, the authors rigorously investigate the performance of beta-VAEs in this setting under a number of conditions, finding that weak supervision is necessary to induce disentangled representations, and that, perhaps surprisingly, disentanglement does not help for sim2real settings despite the similarity between the simulator and the real data. Reviewers were divided on the work, but had a number of concerns related to the claims of novel architecture, comparisons to baselines, and issues with the clarity of the paper, some of which were addressed in the authors' response. I agree with some of these concerns, particularly with respect to the claims of novel architectures since the modifications could simply be viewed as tweaking hyperparameters and are not rigorously compared to baselines. However, I think the novelty of the dataset and the rigorous evaluation of OOD generalization settings is likely to be valuable enough to the community to merit acceptance. I'd encourage the authors, however, to tone down some of the claims regarding the architecture (or provide sufficient baseline comparisons), and instead focus on the dataset and the OOD results. I recommend acceptance."
    ],
    [
        "The paper presents a new dataset, Touch and Go, which contains both visual and tactile data from human operators. The reviewers are positive about the importance of the problem and the dataset. They appreciate that the dataset is more diverse than prior efforts in both visual-tactile and multimodal domains. The authors also demonstrate the value of the dataset for multiple applications, including a new tactile-driven image stylization task.  The paper is well written and guides the reader well.  Some minor concerns were raised by the reviewers, and the authors have addressed them in their response. Please address these concerns in the final version.",
        "Overall, all reviewers see the novelty in the dataset that provides an original new set of tactile data, accounting for a wide range of objects and scene, collected in the wild. The paper is overall well written, clear and easy to follow, and provides a good demonstration of the importance and usefulness of the dataset, going beyond datasets collected by robots in the context of material properties. It also includes initial steps towards benchmarking, although it is not the core contribution of the paper, which lies in the creation of the dataset itself.   Two reviewers recommend acceptance, two stand marginally below acceptance, and one does recommend rejection. The authors have provided detailed responses to all reviewers’ comments and concerns and updated their manuscript. The main concerns of those reviewers sitting on the fence seem to be answered and limitations acknowledged however the element of bias in the data collection was still considered as a possible concern. Based on my reading and accounting for the authors changes, there approach itself is novel and original and hence provides already a relevant contribution to NeuroIPS; while the authors acknowledge limitations and future work avenues. The one reviewer recommending rejection didn’t engage in the discussion but from my reading of both the paper, the comments, and the authors responses, I believe the main points were addressed by the authors and misunderstandings clarified. Overall, I believe the papers offers a novel, non-existing dataset that can inspire interesting future works; all the dataset is shared and presented clearly for others to use."
    ],
    [
        "This paper proposes a method to perform comparisons between two kernels using optimal transport. The idea is interesting and novel. The reviews are overall positive. Please try to address the reviewers' comments for the camera-ready version, especially the ones from Reviewer 3, in the final version.   ### Minor Comments I'd like to point out:  1. The expression \"semantic transport\" is from optimal transport theory, but the use of the term \"symbolic transport\" does not make sense in this context. Note that optimal transport has also been used for other kernel comparisons, e.g. distance-based comparisons. The authors should state the relation of the proposed method to other methods in the literature. 2. It is not clear how comparing two kernels is equivalent. Is it equivalent to comparing two trees? I.e., if the kernel is tree-based, then the similarity between kernels is based on their grammar, not on distance. But if the authors",
        "This is a strong submission that benefitted greatly from productive and clarifying discussion between the authors and reviewers, after which the reviewers reached a unanimous stance in favor of acceptance. I recommend the authors to revise the manuscript accordingly in light of these discussions."
    ],
    [
        "The paper proposes a diffusion model for discrete states based on a continuous time variant of the diffusion model. The key idea is to sample from the diffusion via tau-leaping over discrete states. The authors derive the criterion for tau jumping from existing continuous time diffusion models.  Reviewers generally agree that the paper is well written and the proposed idea is natural and interesting. The main concerns were around novelty (e.g. the replacement of the forward process with a discrete-state CTMC) and clarifications on the experimental setup (addressed during rebuttal). Overall, all reviewers were in favor of acceptance and so I recommend acceptance as well.",
        "The work proposes a continuous-time generalization of diffusion models on a discrete space. The description uses continuous-time Markov chain (CTMC), in parallel to the existing stochastic differential equation description for continuous space. Reverse CTMC and modeling and ELBO objective are described. Some practical considerations and inspirations are also discussed, including avoiding exponentially large model in high dimensions, efficient reverse (generation) process simulation, and a corrector technique that further exploit the model to improve simulation (generation) quality. An error bound on the learned data distribution is also presented that shows a mild dependency on data dimensionality.  All the reviewers agree that this work presents the very right way to describe the continuous-time version of diffusion model on discrete space, and thereafter inspired techniques make a desired contribution to the community. Some concerns are raised, including still inferior performance than the continuous counterpart, and on the independence among dimensions. The authors provide reasonable remarks on them. Hence, I recommend accept to this paper.  One minor point: In Sec. 4.2, it would be clearer if the independence is specified both among the random variables $x^{1:D}$ in “output” and between each $x^d$ in “output” and $x^{1:D\\backslash d}$ in “input”. Conventionally independence refers to the former, in which case the size is only reduced to $S^D \\times D S^2$."
    ],
    [
        "This paper proposes a bit flip attack on deep learning models, where the parameters of a quantized model are bit-flipped so that a misclassified example is also misclassified, while other examples are correctly classed. The reviewers agree that the method is interesting, and the paper is well-written and sound. However, the success rate and benign accuracy results are not very significant compared to previous attacks. The method requires many more bits to flip a single example, and thus does not work for many other settings.",
        "The major concerns about this paper are that (1) There are too many hyper-parameters, such as those needed for ADMM. I'd point out that there are adaptive variants of ADMM and heuristics methods for choosing optimization hyper-parameters, although it would be nice if the authors addressed these issues in the paper.  (2) Some reviewers are concerned that, compared to other related attacks, it’s unclear why flipping fewer bits is an important objective - an attacker might only care about poisoning performance and clean data performance.  The authors respond that flipping fewer bits makes the attack more effective when bits are manipulated by a physical method such as manipulating memory.  Despite these criticisms, reviewers agree that the paper is a well thought-out approach that improves the state of the art by some metrics."
    ],
    [
        "The paper provides an empirical evaluation of various OoD methods.  The paper is about a comparison of methods for out of distribution detection on image classification.   The reviewers motivate the paper by the necessity of having better evaluation to be reflective of real world scenarios.  Fine-tuning/pre-training gives a strong performance boost for OoD detection. The results show that cosine similarity consistently outperforms other methods across all sub-tasks. There is no real discussion or insights into why certain methods work in some scenarios and not others.  It is concluded that more experiments are needed to allow a better understanding of the different methods and why they work for different OOD detection tasks.  There are many recent and relevant papers that are not cited or compared against in the paper.  We encourage the authors to update the paper accordingly.",
        "This paper proposes an OOD evaluation framework under three categories: irrelevant input detection, novel class detection, and domain shift detection. As with several reviewers, the AC recognizes the importance and effort to distinguish between different cases of OOD detection, as well as the amount of experimental comparison across several prominent methods in literature (MSP, MC-dropout, cosine similarity, ODIN, Mahalanobis).    Despite being well-motivated, three knowledgeable reviewers find the paper not ready yet for publication at ICLR. The AC recommends a rejection, given the standing major concerns from the reviewers. The AC is hopeful that the paper can be significantly improved by   - sufficiently discussing and highlighting the novel insights of the results.  - a more rigorous definition of  \"novel\" vs. \"irrelevant\" inputs. There seem to be overlapping definitions between what Hsu et al. considered vs. this paper. In particular,  Hsu et al distinguish i) samples of a novel class but in a known domain, called semantic shift (S), and ii) samples of known class in a novel domain, called non-semantic shift (NS), both of which are reconsidered in this paper. Therefore, the novelty of this submission is more precisely to distinguish within the category of semantic shift. The AC agrees that this might deem some more rigorous measurement and definition of \"semantic closeness\".  - The AC also finds the evaluation of domain shift in Section 3.3.2 may be potentially misleading the community, as it falls out of the standard OOD scope. The notion of common corruption is closer to the robustness problem (which is how ML model predictions changes w.r.t some delta changes in the input space). The changes may not be substantial enough to be \"out-of-distribution\"."
    ],
    [
        "This paper characterizes the bias of adversarial training toward specific minimum-norm solutions or KKT points of a particular optimization problem. Their results generalizes the work of Li et al 2020 by proving the directional alignment with the adversarial max-margin solution for deep linear models.  The reviewers, on the other hand, found the results, to be largely unsurprising, given previous works on standard training, but I believe the rigorous justification presented in the paper is of importance. I recommend acceptance.",
        "The paper is a nice addition to the developing theory of implicit bias in neural training. While the results are somewhat expected, the technical aspects are fairly involved due to the adversarial component."
    ],
    [
        "This paper analyzes composite neural network performance from function composition perspective. In particular, it considers the problem of building a composite network from several pre-trained networks and whether it is possible to ensure that the final output has better accuracy than any of its components. The analysis done in the paper is a simple linear mixture of the outputs produced by each component. As the number of components increases, there are more vectors/objects that can be represented, which may not be all that bad according to some interpretations of the results. However, the reviewers do not seem to think that the contribution of this paper is significant enough as it currently stands.",
        "Dear authors,  All reviewers pointed out the fact that your result is about the expressivity of the big network rather than its accuracy, a result which is already known for the literature.  I encourage you to carefully read all reviews should you wish to resubmit this work to a future conference."
    ],
    [
        "The authors propose a model for low-dimensional feature representation learning for better interpretability. They start with a feature selection prior to the last linear layer of a neural network, and build from there.  The approach is evaluated on image classification tasks as well as human interpretability study.   The reviewers found the paper well-written and the interpretability claims well-motivated. The results are strong, the discovered features are interesting, and the qualitative examples are sensible.  I agree with the reviewers that this paper is a good fit for the workshop. I recommend acceptance.",
        "This paper proposed an interesting method to induce a low-dimensional feature space for interpretable image classification. The proposed method is supported by comprehensive and strong experimental evaluations. Please consider the reviewers' comments in the final version. One common concern is it is unclear if the paper has novel technical innovation compared to the prior works."
    ],
    [
        "This paper presents a modification of predictive coding (PC) as an alternative to backpropagation for deep neural network training that allows working with arbitrary distributions and is more scalable than the traditional PC framework which assumes Gaussian activations. This generalization of PC leads to surprisingly strong empirical results, particularly in terms of training extremely complex neural architectures such as transformer networks. The reviewers unanimously agree that this is an important contribution and a worthy paper for NeurIPS.",
        "Motivated by advancing the applicability of backpropagation alternatives, the paper extends predictive coding to non-Gaussian distributions, so it can be used to train effectively complex architectures such as transformers.  The reviews are divided: three reviews give a score of 7 (accept) whereas one review gives a score of 4 (borderline reject). The positive reviews cite the following strengths: clearly stated motivation, technical soundness, potential for impact and convincing experiments. The negative review cites lack of clarity as the main weakness (something also mentioned in one of the positive reviews), while the reviewer is not convinced about the originality of the method given similar advances in variational inference and generative modelling.  On balance, given the potential of impact in the field of predictive coding and the technical soundness, I'm happy to recommend acceptance, even though clarity is somewhat lacking.  Some reviewers requested more details on computational complexity, memory consumption and scalability. I encourage the authors to use the extra content page in the camera-ready version to discuss these aspects further."
    ],
    [
        "The paper proposes to enhance the GAN-based image restoration with another task-specific branch for further improvement. The reviewers and AC note the critical limitation of novelty and appealing results. In addition, it is not clear how much data was used to train the super-resolution model and how it compares to the state-of-the-art. AC decided that the paper can benefit from another round of revision to strengthen the contribution and therefore recommend rejection.",
        "This work presents a reconstruction GAN with an additional classification task in the objective loss function. Evaluations are carried out on medical and non-medical datasets.   Reviewers raise multiple concerns around the following:  - Novelty (all reviewers) - Inadequate comparison baselines (all reviewers) - Inadequate citations. (R2 & R3)  Authors have not offered a rebuttal. Recommendation is reject. Work may be more suitable as an application paper for a medical conference or journal."
    ],
    [
        "This paper improves the Nondeterministic Stack RNN by using unnormalized positive weights instead of probabilities for stack actions and allowing the model to directly observe the state instead of relying on probabilistic predictions. The paper also uses the new NS-RNN for a language modelling task on the Penn Treebank by introducing a memory-limiting technique to reduce the memory usage. While the reviewers agree that the changes are simple and appear to improve the model on some synthetic tasks, they find that the gains are not large and meaningful improvements are seen in the synthetic data set. This paper continues a recent line of work on stack-augmented RNNs and the reviewers find the paper interesting and well-written. The ideas are technically sound and empirically proved. However, the paper has two main weaknesses: (1) It is not space and memory efficient since the stack is unbound, and thus, consumes large memory. (2) The experiments do not demonstrate significant",
        "This paper advances the long running thread of sequence modelling research focussed on differentiable instantiations of stack based models. In particular it builds upon recent work on the Nondeterministic Stack RNN (NS-RNN) by introducing three extensions. The first is to relax the need for a normalised distribution over the state and action distribution and allow unnormalised weights, this mostly serves to facilitate gradient flow and thus easier training. The second extension allows the RNN to condition on the top stack state as well as the symbol, improving expressiveness. The third improvement introduces a method for limiting the memory required to run the proposed model on long sequences, thus allowing its application to practical language modelling tasks. Each of these requires substantial algorithmic innovations.  The reviewers all agree that this is a strong paper worthy of publication. The paper includes a useful review of previous differentiable stack models which nicely sets up the rest of the paper where the contributions are well motivated and clearly presented. The reviewers had a number of clarification questions, partly due to the author's use of overly concise citations for key algorithms rather than inline descriptions. This situation has been improved by updates made to the paper. The evaluation includes a series of synthetic experiments which are clear and provide a good elucidation of the various stack models properties. The practical evaluation on language modelling is more limited and serves mostly to demonstrate that the nondeterministic model can be scaled to a basic language modelling task.  Overall this is a strong paper with a well motivated and clear hypothesis. It provides a substantial extension to the prior work on nondeterministic stack models and progresses this line of research toward practical applications."
    ],
    [
        "Reviewers are in a consensus and recommended to accept after engaging with the authors. Please take reviewers' comments into consideration to improve your submission for the camera ready.  Also, please take time to consider the comments about the limitations of your work and how you could improve them - see the comments of reviewer 3 regarding examples and related work, and the suggestions of reviewer 2 regarding making your work more accessible (e.g., motivating the use of RNNs more clearly).",
        "The overall view of the reviewers is that the paper is not quite good enough as it stands. The reviewers also appreciates the contributions so taking the comments into account and resubmit elsewhere is encouraged."
    ],
    [
        "This paper proposes to solve high-dimensional nonlinear parabolic partial differential equations by using an Actor-Critic neural network architecture with a particular focus on reducing the number of parameters, hyperparameters, and convergence rate. While the general approach seems promising, the paper does not seem to articulate the research gap. Furthermore, the authors have not provided an accurate definition of the abbreviations D(BSDE) and D(DE) since September. The introduction has no reference to previous work, and the first time any relevant previous work is referenced is on page 3.  The potential for the proposed idea is difficult to realize because the paper lacks essential details. Therefore, the discussion of the method itself could be made clearer. The authors have improved the writing of the paper during the rebuttal, which is appreciated. However, the task of solving the equations with the proposed method still seems to be an open problem. The solution could be better explained.",
        "Reviewers were mixed about this paper. The stand-out concern is clearly the fact that this paper does very little to set itself in context. I would echo these concerns, and this is clearly the single greatest weakness of the paper. For example I would highlight lines 54--62, in which the proposed technique is compared only against some nebulously-defined \"other\".  Despite these concerns, I am inclined to agree with reviewer QEo4 that the paper is acceptable for a workshop, and would strongly encourage the authors to address the concerns raised by reviewers.  In addition to the review comments, a few comments of my own:  - Equation (2) assumes that the SDE is solved via the Euler--Maruyama method. Whilst analytically convenient, I believe it is more elegant to treat the general case for as long as possible (without reducing to just the EM method at this early stage). If the noise has particular structure then it may become desirable to solve the SDE via some more efficient numerical method, e.g. Milstein if using commutative noise or Heun if using additive noise (Heun converges to the Stratonovich solution, but for additive noise then Itô and Stratonovich are identical). - I think equation (2) may be missing a $t_{n+1}-t_n$ coefficient for the $f$ term. - The \"not too far\" of line 67 is usually referred to as a \"trust region\"."
    ],
    [
        "The paper proposes a natural interpolation method in the latent space of a deep generative model based on the Cauchy distribution of the latent variables and shows its advantages in terms of interpolation quality and robustness to heavy tails. Reviewers agree that the interpolation analysis is interesting, and the experimental evidence is extensive and convincing. At the same time, there are some concerns raised about the soundness of the proposed interpolation methodology, which could be improved in a number of aspects: (1) the linear interpolation rules should be different for different latents, it is not clear how to select suitable latents depending on the latent space dimension, (2) the assumption of a uniform prior is quite strong, and may not always hold in practice, (3) discussion of the Latent Manifold Entropy Theorem and its application in general in high-dimensional latent spaces is missing, and (4) empirical evidence is lacking for some of the experiments presented",
        "All the reviewers and AC agrees that the main strength of the paper that it studies a rather important question of the validity of using linear interpolation in evaluating GANs. The paper gives concrete examples and theoretical and empirical analysis that shows linear interpolation is not a great idea. The potential weakness is that the paper doesn't provide a very convincing new evaluation to replace the linear interpolation. However, given that it's largely unclear what are the right evaluations for GANs, the AC thinks the \"negative result\" about linear interpolation already deserves an ICLR paper."
    ],
    [
        "The paper proposes a new masking strategy for unsupervised vision transformer training. The main idea is to mask intra- and inter-part images in a way that maximizes the semantic information contained in the images. An iBOT-pretrained ViT is used to extract the features, and then a StyleGAN-based decoder is trained to learn semantic parts. The semantic parts of objects are the visual analogue of words, so according to the authors, masking semantic parts from intra-part patterns to inter-Part would help the vision transformer learn better representations.  The paper is well-written and easy to follow. The intuition behind the method is clear. The experiment results are convincing. The authors and reviewers had nice discussions about the limitations of the method and the possible directions to improve the method.",
        "Authors present a method attempting to perform Masked Auto-Encoding (MAE) using semantic knowledge, to try to better approximate the semantic MAE seen in language domain. To do this, they leverage an iBOT framework and add some embeddings of the class token to create \"part tokens\", which are then compared to patch tokens from iBOT to produce attention maps. The objective for this process is a StyleGAN-based image reconstruction.  Once the part attention maps training is done, the network is then used to guide semantic based part masking based on the generated attention maps, for semantic MAE.    SemMAE pretrained networks are then compared against other forms of SSL pretraining on ImageNet 1k, iNa, CUB, Cars, and ADE-20K, demonstrating improvements in all domains.  Pros: - [R] Idea is interesting / novel - [R] Well written - [AC/R] Results improve over baselines     Cons: - [AC/R] Pipeline is complicated. - [R] What about starting from random MAE and then adapting based on parts knowledge? Authors respond that this is future work. - [AC/R] Not convinced parts are visual analog of words. Authors provide benchmark improvements in performance, and qualitative visualization of the parts. However, there is no quantitative assessment of the parts and whether they have true semantic meaning. - [AC/R] Some improvements are marginal. Authors respond that although marginal in some cases, they are consistent.  - [R] Paper does not discuss more how to deal with background. Authors respond that this is future work.  Overall, all reviewers have changed their assessments to accept, including the one reject reviewer. AC recommends accept, though would be preferable if quantitative assessment of the quality of the semantic parts (for example, by segmentation masks) could be provided.  AC Rating: Accept"
    ],
    [
        "This is a well-written paper that proposes a new framework to investigate if two causal effects of different stimuli share a common stimulus. While the question has some \"causal flavour\", most of the reviewers feel that the proposed method is rather irrelevant to causality, and hence a more empirical approach is needed. All reviewers agree that the problem considered is interesting and important, and the proposed metrics are intuitively reasonable. However, given the potential overlap of this conference with the causality literature, it is uncertain whether this paper is a good fit for the conference.",
        "The authors develop two metrics for evaluating how different brain zones may be affected by the same stimuli. The framework created shows promising results when applied to actual and simulated data. This is a well-written paper with a particular application in mind. It designs a framework for discussing causal effects for applications in neuroscience. This paper's developed metrics and framework are potentially impactful and present a promising start for future research in this direction. The reviewers and I found the author's replies and rebuttal especially helpful in reaching our decision, so I hope some of these comments and arguments are included in the final version of the paper.  Minor comment: In addition to the comments made by the reviewers below, I would encourage the authors to make the references more consistent. At the moment some authors' first names are included and others are not."
    ],
    [
        "The paper considers natural gradient methods for generative adversarial networks.  Pros: Paper addresses an important problem, and the proposed approach is simple and easy-to-implement.  Cons: - Lack of theoretical justification - Use of explicit Wasserstein distance is not well justified  All reviewers agree that the paper is not suitable for publication at ICLR in its current form, but I encourage the authors to address the points raised by the reviewers to improve the paper for future submission.",
        "Both R3 and R1 argue for rejection, while R2 argues for a weak accept. Given that we have to reject borderline paper, the AC concludes with \"revise and resubmit\"."
    ],
    [
        "The paper aims to create unlearnable examples so as to protect data privacy during adversarial training. The key idea is to perturb the data so that standard error-minimizing noise perturbations do not learn a good model from the perturbed dataset. The proposed algorithm, called REM, has been validated under different settings, including poisoning and standard error minimization on real-world datasets.   The paper is well-written and the experiments are extensive. However, the proposed algorithm has the following issues: Unrealistic assumptions. The paper only considers simulated datasets. In real world, what if catastrophic events happen to the real data? This issue is not discussed properly in the paper. The claim that catastrophic events can be prevented in this setting is not well-supported. More discussions and experiments are required to support this claim.  The presentation of the paper has lot of room for improvement. The font sizes are too small to read and the figures are not very informative.",
        "To address the problem of unauthorized use of data, methods are proposed to make data unlearnable for deep learning models by adding a type of error-minimizing noise. Based on th fact that the conferred unlearnability is found fragile to adversarial training, the authors design new methods to generate robust unlearnable examples that are protected from adversarial training. In addition, considering the vulnerability of error-minimizing noise in adversarial training, robust error-minimizing noise is then introduced to reduce the adversarial training loss. The authors have tried to respond to reviewers' comments along with adding more experiments. Overall, this manuscript finally gets three positive reviews and one negative review, where the possible vulnerability or robustness of error-minimizing noise against (simple) image processing operations was not verified. In comparison with other manuscripts I'm handling that got consistent positive comments, this manuscript is still recommended to be accepted (poster) with a further study of robustness under simple image transformations in the final version."
    ],
    [
        "The reviewers agree that the paper has good motivation and is well written, with clear and solid motivation. The method uses a randomized scheme for extracting patches, self-enforcing and spatial ensembling to extract the patches. The authors also did a good job in the rebuttal to address the questions and concerns raised by the reviewers, and the additional experiments and clarifications in the revised version are convincing and will be a good addition to the program.",
        "The paper presents a novel idea of a 2.5D segmentation approach considering the characteristics of medical imaging data. The practical importance and novelty of the proposed approach are well received by all the reviewers. Clear description and illustration are included appropriately in the paper. Some experimental details-related questions were raised by the reviewers, and they were well addressed in the rebuttal."
    ],
    [
        "This paper analyzes reward shaping in reinforcement learning, providing a theoretical analysis of its effect on the sample complexity. The authors show that, contrary to what was assumed in the literature, this analysis does not lead to regret-maximizing strategies for RL. Instead, it indicates that such strategies only improve sample complexity slightly.  The reviewers were unanimous in their vote to accept. They praised the soundness of the theoretical analysis, the clarity of the writing, and the strength of the experiments.",
        "The reviewers carefully analyzed this work and agreed that the topics investigated in this paper are important and relevant to the field. Overall, the reviewers had a generally positive impression of this paper. One reviewer argued that this paper addresses a relevant and valuable question and makes an important step towards a better understanding of regret when reward shaping is used. Even though this paper makes assumptions that were of some concern to other reviewers, this reviewer argued that the paper is nonetheless an important milestone for the community. Another reviewer acknowledged that this paper conducted a formal theoretical investigation of the impact of reward shaping methods on the sample complexity of RL algorithms and argued that all proofs seem to be sound. This reviewer had a few technical questions, which were all addressed by the authors. Post-rebuttal, the reviewer encouraged the authors to incorporate the corresponding details (such as those discussed in the rebuttal) in the updated version of their draft. A third reviewer emphasized that this paper shed light on reward shaping from a theoretical perspective. They argued that the quality and scientific soundness of the paper are objectively excellent, that the paper is original, and that it deserves merit. The reviewer pointed out one main weakness, however, regarding the assumption of the type of the shaped reward function. They wondered whether this assumption could limit the impact and applicability of the paper's results. After reading the authors' thorough rebuttal, however, the reviewer stated that they were satisfied with all responses and updated their score accordingly. Finally, a fourth reviewer also had an overall positive view of this work but pointed out, as a weakness, the seemingly strong assumption that the shaping signal is an approximation of the optimal value function. After reading the authors' response, however, the reviewer stated that the assumptions made in this paper were not as restrictive as they initially thought, and updated their score. Overall, thus, it seems like most reviewers were positively impressed with the quality of this work. They look forward to an updated paper version addressing the suggestions mentioned in their reviews and during the discussion phase."
    ],
    [
        "In this paper, the authors give a new algorithm for testing the closeness of distributions that has a sample complexity $\\tilde{O}(\\sqrt{n} \\log n), which avoids the exponential scaling that one would get from traditional closeness testers. The algorithm leverages several oracles called COND, PCOND, and DUAL to derive its complexity. The empirical results show the implementation's number of samples for a wide array of problems, and the new approach works significantly better than existing ones.  All reviewers, including myself, find this paper well-written and the contributions are clear. They give an algorithm with query complexity scaling up to polylog factors, which is significantly improved over previous approaches. There are some concerns raised by one reviewer that this approach may not be applicable to high-dimensional data, but I don't see any potential negative societal impact from this work. In addition, I think the authors have adequately addressed the concerns.  I recommend acceptance.",
        "This submission studies (a somewhat non-standard version of) tolerant closeness testing of distributions over the n-dimensional hypercube. Instead of only iid samples, it is assumed that the tester is able to efficiently evaluate the probability mass at any point in the domain and to sample from the distribution conditioned on any subset of size two of the domain. The main result is an algorithm with query complexity scaling near-linearly in the dimension. Using only iid samples, one would need exponential dependence on dimension. The algorithm is evaluated on synthetic and real-world datasets. It is experimentally shown that their algorithm outperforms a previous baseline, which in the worst case has complexity scaling exponentially in the dimension. Overall, this is an interesting work that appears to meet the bar for acceptance."
    ],
    [
        "This paper presents a method for performing various signal processing operations directly on implicit neural representations (INRs) of discrete lattices. The authors provide a way of expressing operators on top of the neural field as functions of the first and higher-order derivatives of theMLP, and provide sufficient guarantees for their method to work well for a number of common INR tasks such as denoising, deblurring, inpainting, and classifying images.   The reviewers found this to be an interesting and important paper that provides a practical and elegant way of performing various operations on discrete neural lattices without decoding them. Given the potential significance of the proposed method, the authors were very responsive during the rebuttal period and were able to address most of the reviewers' concerns. I would like to thank the authors for engaging with the reviewers and providing an updated version of the paper that addresses many points raised by them.",
        "The paper proposes a framework to perform signal processing tasks on a signal represented with an implicit neural representation directly in the representation space, without the need to instantiate the signal.   After the rebuttal period, all reviewers recommend acceptance.   In particular reviewer 1Yx6, an expert on the topic, finds the idea original, and the quality and clarity of the paper to be high. The reviewer finds that while for now the significance is limited (since working as proposed in the representation space is computationally prophibitavely expensive), this is not a major issue, since the the paper is likely to inspire work that will push the idea further.  Reviesers edqT and qGk1 also liked the general idea of the paper and find the proposed method to directly perform operations on the representation space of implicit neural representations to be novel and interesting  Reviewer Uh51 initially identified a few issues regarding experimental design, the validation, and on the included literature. The main concern regarding the experimental design of the reviewer was that the paper focuses on images (and not signal processing tasks more broadly), which I don't consider a shortcoming, due to the importance of image processing tasks. The concerns on the validation issues have been addressed as well, and the reviewer raised their score.   I recommend acceptance of the paper."
    ],
    [
        "This paper proposes a novel VIO method which estimates 5 DoF poes (with the elevation fixed) from monocular camera and IMU. The proposed method adopt Unscented Kalman Filter (UKF) for state estimation and learns the filtering parameters by making the filter differentiable. The approach is evaluated against a set of baselines on the KITTI dataset. Experimental results on two domains demonstrate that the proposed approach is effective and competitive against recent deep learning-based architectures.  It is not clear in what ways the proposed model is exactly interpretable. The differentiable training of the UKF makes it possible to apply the method to existing VIO methods without training the entire filter. However, the merit of this paper is not established well by the existing literature. The comparison with respect to the literature is insufficient in its current state.  The paper is recommended for rejection.",
        "The paper proposes a differentiable approach for monocular VIO estimation based on BEV, without relying on deep neural networks. The reviewers find the paper well written and the idea of using BEV to be interesting. This paper received highly mixed reviews. The major concerns raised by the reviewers include empirical evaluations of the model interpretability, justification for relying on algorithmic priors than parameters, results on more challenging datasets, positioning this work with respect to existing work on deep state estimators, and clarifications regarding the claims made, among others. Most of the concerns raised by the reviewers have been thoroughly addressed in the rebuttal. I thank the authors for the engaging discussions during the rebuttal. Some minor concerns still exist. Nevertheless, I agree with the reviewers that the paper is an interesting contribution."
    ],
    [
        "This paper studies an important question of generalization in learning graph embeddings and presents a novel result that the dimensionality of the problem is not necessary for this problem as long as the norm of the embedding vectors is considered. All of the reviewers agree that the theoretical results presented in this paper are significant both in that it gives a new perspective on the problem as well as it provides an important insight both from a theoretical and empirical perspective. Therefore, I recommend acceptance.",
        "This paper provides a generalization analysis for graph embedding methods concluding with the observation that the norm of the embedding vectors provides an effective regularization, more so than dimensionality alone. The main theoretical result is backed up by several experiments.  While the result appears to be correct, norm control, dimensionality reduction and early stopping during optimization are all very well studied in machine learning as effective regularizers, either operating alone or in conjunction. The regularization parameters, iteration count, embedding dimensionality is typically tuned for an application. The AC agrees with Reviewer 2 that the paper does not provide sufficiently interesting insights beyond this observation and is unlikely to influence practical applications of these methods.   Both reviewer 2 and 3 have also raised points on the need for stronger empirical analysis."
    ],
    [
        "This paper proposes a new method for regularized inverse RL. Reviewers generally agree that the mathematical foundation is rigorous and the experimental results are promising. However, there are also concerns about the clarity of the paper. The paper is a bit notation heavy and that makes it hard to follow.  The paper builds upon work by Geist et al. who studied regularized MDPs with convex policy regularizers. The Shannon entropy is a special case of such a policy regularizer. Some reviewers are also concerned that the experiments are conducted under different settings, but some cons are needed to revise. Overall, this paper is proposed to be borderline lean accept.",
        "This paper studies inverse reinforcement learning through the prism of regularized Markov decision processes, by generalizing MaxEntIRL from the negative entropy to any strongly convex regularizer (as a side note, strict convexity might be enough for many results). The reviewers appreciated the clarity, the mathematical rigor and the empirical evaluation of this paper. They asked some questions and raised some concerns, that were mostly addressed in the rebuttal and the revision provided by the authors. This is a strong paper, for which the AC recommends acceptance."
    ],
    [
        "The paper studies the convergence of the stochastic proximal point algorithm (SPPA) for convex, finite-sum functions and uses the result to argue for its use in the training of neural networks. Reviewers agree that the paper is well-written and provides a clean analysis. However, there are some concerns about the novelty and significance of the results as well as the conditioning on the number of future iterates, which goes against usual convergence results, and the analysis is not interpretable.   I encourage the authors to revise the paper accordingly and resubmit it to a future venue.",
        "The paper considers the stochastic proximal point algorithm, the main contribution is a convergence proof (in addition to arguing that it is a practical algorithm for ERM problems).  However, reviewer EvJ6 and xJB8 pointed out a fatal flaw in Lemma 1 that affects all the downstream results, and the other two reviewers and myself agree that this invalidates the core results. Reviewer EvJ6 gives extensive examples of how the lemma cannot be simply fixed. So while this is an interesting stochastic extension of the famous deterministic method and may warrant further study, this paper doesn't yet provide a rigorous convergence proof."
    ],
    [
        "The reviewers agree that the paper presents an interesting approach to encoding ordinal relationships between classes, which is an important problem that is relevant to the medical imaging community. However, the authors should address the feedback from the reviewers in their revision, which includes, but is not limited to, improving the clarity of the data presentation and strengthening the evaluation of the method, as outlined in the reviews. The methodological contribution is also limited, as the problem being solved does not seem to be particularly common or clinically relevant, and the validation is a bit weak.",
        "This is a borderline paper -- while the underlying idea is good and relevcant, the authors don't do a very good job of selling it; their experiments are performed on a very specific task with limited clinical relevance. The reviewers had a number of questions regarding experimental setup, which were largely answered in the rebuttal."
    ],
    [
        "The paper reviews a number of recent works on spectral clustering for node classification in graph-based data. The idea is interesting, and the paper is clearly written and easy to follow. However, as the reviewers pointed out, the paper does not offer significant methodological novelty, it does not propose any new methods, insights, or conclusions. It would have been better to focus the paper on one or two of the methods mentioned by the reviewers and empirically justify the importance of those methods, and then position the paper relative to other works on the topic. I encourage the authors to incorporate the reviewers' comments and make a stronger submission in the future.",
        "There was some discussion on this paper, both with the authors and between reviewers. On the one hand, there is a general agreement that the empirical results suggesting that spectral clustering-based method can be competitive with SOTA methods on node classification benchmark is an interesting result. One the other hand, reviewers did not find a significantly novel contribution in the methodology proposed, and found that the empirical evaluation lacks depth and details to be really informative (eg, to understand why some methods work or not on some benchmarks). There is therefore a consensus that the paper is not ready for ICLR in its current form, but we hope that the reviews and discussion will help the authors prepare a revised version in the future."
    ],
    [
        "The paper proposes to learn self-exciting processes with a non-stationary kernel in the presence of noise, and uses stochastic gradient descent to optimize the likelihood. Reviewers agree that the paper has interesting ideas and could be a good one with more complete work. However, authors missed an important influential paper by Feng Chen and Peter Hall 2013, which suggests they need to compare their work with Chen/Hall more thoroughly in order to make a case for their work, which was missed by the authors. The reviewers also think the the theoretical results appears to have very few links with empirical results.",
        "This paper proposes a self-exciting temporal point process model with a non-stationary triggering kernel to model complex dependencies in temporal and spatio-temporal event data. The kernel is represented by its finite rank decomposition and a set of neural basis functions (feature functions). The proposed model has superior performance in comparison to other state-of-the-arts methods. All the reviewers recognized that the model is interesting and advances the state of the art in a meaningful way. While they were some concerns regarding the experimental evaluation, particularly in terms of real data, and the presentation, the rebuttal/revision by the authors cleared up these concerns."
    ],
    [
        "The paper considers the problem of learning with noisy labels and exploiting the small loss criterion. The authors build on the idea of small loss criteria, which favors learning on certain samples in the beginning of the learning process, and proposes a novel type of distributional normalization based on Wasserstein distance. This is done with a particle based stochastic dynamics, where the Wasserstsein ball centered on the measure of certain samples is used as the surrogate objective. An SDE grad flow is then proposed for solving the normalization. A series of experiments show that the new methodology proposed in the paper leads to state-of-art results.  Strengths:  1 - Empirical results on CIFAR-10/100 and Clothing1M suggest that the propose algorithm outperforms other SOTA approaches.  2 - The paper is well-written and easy to follow.  Weaknesses:  3 - The technical novelty of the paper is limited, as it",
        "This paper proposes a potentially very interesting and original approach to handle label noise.  The numerical experiments suggest that the method works very well. But the paper  itself has been deemed very hard and demanding to read and understand for a general machine learning crowd and even by experts in the fields of optimal transport and  Markov theory.   Note that due to the low confidence in several review an additional emergency review by an expert was asked and it confirmed the global opinion from  other reviewers that the paper is interesting but needs a major rewriting before acceptance in a ML conference. The AC strongly suggest that the authors work on a more pedagogical introduction and explanation of the method before resubmitting."
    ],
    [
        "This paper proposes a method for causal influence maximization in MARL, through the use of an intrinsic reward based on maximizing mutual information between agents via counterfactual actions. The idea is interesting and novel, and the authors have done a good job in the rebuttal period in addressing reviewers' concerns. There is general agreement that this is a good paper and that it deserves to be published. However, all reviewers have concerns regarding the significance and clarity of the current version of the paper. While I agree with some of these concerns, I believe that there are interesting ideas in this paper and I encourage the authors to revise and resubmit.",
        "The reviewers raised a number of concerns including the appropriateness of the chosen application and the terms in which social dilemmas have been discussed, the lack of explanations and discussions, missing references, and the extent of the evaluation studies. The authors’ rebuttal addressed some of the reviewers’ concerns but not fully. Overall, I believe that the work is interesting and may be useful to the community (though to a small extent., in my opinion). However, the paper would benefit from additional explanations, experiments and discussions pointed in quite some detail by the reviewers. AS is, the paper is below the acceptance threshold for presentation at ICLR."
    ],
    [
        "This paper introduces a curriculum generation approach based on hindsight experience Replay. The approach is evaluated on multi-goal RL tasks.  The reviewers and AC note the following potential weaknesses: (1) the paper can be further improved in terms of writing, (2) the proposed method relies on assumptions that might not hold true for many goal-conditioned environments, (3) the baselines used are weak, and (4) there is a lack of comparison with prior works.   The authors were able to address some of the concerns in their rebuttal, and there was a consensus among the reviewers that the paper should be accepted after the rebuttal. However, the reviewers agree that there are still concerns regarding the paper, and we encourage the authors to take these comments into account when preparing the final version of the paper.",
        "This paper extends the idea of hindsight experience replay (HER) to learn Q functions with relative goals by constructing a distribution over relative goals sampled from a replay buffer using a clustering algorithm. This approach is evaluated on three multi-goal RL environments and is shown to learn faster than baselines.  ${\\bf Pros}$: 1. Faster convergence as compared to baselines 2. Interesting use of clustering in the context of HER but this choice is made without strong justifications or formal arguments  ${\\bf Cons}$: 1. Some of the key choices made in this paper are not justified or explained property, e.g. - the goal sampling strategy, choices made in the clustering algorithm and associated heuristics, implicit assumptions (e.g. R1 raised the question of using L2 distance in measuring metrics between two states)  2. There are several choices made without sufficient formal arguments, verification or guarantees.   The paper studies an interesting problem but could be made stronger by incorporating feedback received during the discussion period."
    ],
    [
        "This paper present a biologically plausible approach to equilibrium propagation for energy-based models with holomorphic activation functions.   Strengths:  + This work shows that equilibrium propagation can be used as a method of learning local learning rules for credit assignment problems, which can lead to important applications in neuroscience.  + The paper is well-written.  Weaknesses:  - This work does not provide any pointers as to how this may be implemented in biology except mentioning that there may be connections to theta neurons. - The model is sensitive to noise, which makes it hard to scale to large machine learning tasks.  This work could be improved with experiments on more complex models.  The reviewers agreed that this work presents a very novel idea.  It greatly increases the power of a local learning rule using the elegance of complex analysis.  Holomorphic versions of EP are shown to be able to learn from the data with a significantly higher degree of freedom compared to original EP.",
        "Equilibrium propagation is a biologically plausible form of backpropagation based learning where the true gradient of an energy based model is computed for infinitesimal perturbations. In this innovative work, authors extend EP using complex analysis that links contour integrals for finite perturbations with the oscillatory dynamics in time. This not only allows better gradient estimates, but also applications to related theories of learning in neuroscience as well as neuromorphic engineering. It represents a significant advance that opens new doors."
    ],
    [
        "The paper studies a repeated online allocation of a single type of good to agents who have the same but unknown valuation distribution for the good. The planners does not know the realized valuation at each period. This work is thus the first to propose an approximate BIC policy, with sublinear regret, when neither of these conditions hold.  The problem is well-motivated and the solution is both new and technically sound. The paper is also well-written and was appreciated by all reviewers.",
        "Executive summary:  The authors study the repeated allocation of an identical good over T rounds to n strategic buyers in a \"no monetary transfers\" setting. The buyers have i.i.d. valuations drawn from an unknown distribution, and the algorithm must work with reported valuations. The goal is to maximize social welfare (= sum of valuations) under the constraint that each buyer receives a pre-specified fraction of the total number of goods.   The main result is an algorithm for this problem that ensures two things:   (a) approximate Bayesian incentive compatibility (approx-BIC) (Definition 2 and Theorem 1) and   (b) low individual regret (Definition 3 and Theorem 2).   The key idea of the algorithm (is to exploit the iid-ness of the problem) and detect misreports from the underlying CDF using Dvoretzky-Kiefer-Wolfowitz type bounds.  Discussion and recommendation:  After some initial set back on the problem motivation, the reviewers bought into the motivation for studying this online allocation problem \"without monetary transfers\" (adding examples such as the foodbank example might be good).    There was some discussion around \"assuming iid valuations\" limiting the generality of the result, but there is in fact a history of papers that studies learning with strategic agents under this assumption (eg Kanoria and Nazerzadeh 2021).  The main difference of the current work is that it's working in a setting without money.  The idea behind the algorithm is maybe \"the obvious think to do\" - but of course it still requires some work to formally prove that it actually works.   I think one thing that could strengthen the paper would be to add some discussion around the tightness/non-tightness of the approximate BIC and individual regret bounds.  Weak accept."
    ],
    [
        "This paper presents a new Knowledge distillation (KD) method for face recognition, where the student model learns to use the teacher's classifier as the student’s classifier in the optimisation of the student loss, with concatenation of features from both the teacher and student models and then conducting dimension reduction to obtain the ensemble. The experiments show that the proposed KD method can improve the performance of student models in the task of face recognition.   The paper received two positive reviews and one borderline negative review. The reviewers appreciated  the simplicity of the idea and the good results, as well as the ablation studies on the different components of the proposed method. The rebuttal also addressed some of the reviewers' questions. However, there are still some concerns on the novelty and significance of the work as pointed out by the reviewers (e.g.,   whether the performance improvement is coming from the extension of the distillation method or from the teacher model itself",
        "This paper presents a knowledge distillation method for face recognition, by inheriting the teacher’s classifier as the student’s classifier and optimizing the student model with advanced loss functions. It received comments from three reviewers: 1 rated “Ok but not good enough - rejection”, 1 rated “Marginally below” and 1 rated “Marginally above”. The reviewers appreciate the simple yet clear methodology illustration and the well written paper. However, a number of major concerns are raised by the reviewers, including limited novelty, lack of comparison with more advanced knowledge distillation methods and their special case in face recognition. During the rebuttal, the authors made efforts to response to all reviewers’ comments. However, the rating were not changed. The ACs concur these major concerns and more comprehensive comparisons with the state of the art KD methods are necessary to better illustrate the contribution of this work. Therefore, this paper can not be accepted at its current state."
    ],
    [
        "The paper receives unanimously positive reviews from four knowledgeable experts. They all agree that the proposed approach, NormGrad, addresses a relevant problem for medical applications of deep learning, which is quite unique in my opinion. They also praise the writing, technical soundness and extensive experimental evaluation. The authors' rebuttal addresses the main concerns of the reviewers, including the lack of sufficient clarity in the description and the discussion of the method. In my opinion, the authors have addressed most of the concerns raised by the reviewers. I recommend the acceptance of the paper.",
        "The paper receives unanimously positive reviews from four knowledgeable experts. They all agree that, though the saliency detection method NormGrad is not invented by the authors, its use in the context of medical image analysis shows promising results, which is clearly demonstrated by the authors. They also express some concerns, which are largely addressed by the authors in the discussions. I, therefore, recommend the acceptance of this paper."
    ],
    [
        "This paper seeks to understand theoretically the bottleneck of few-shot learning. It shows that classification error is mainly caused by classifier discrepancy, and proposes a new loss based on reducing it.   Reviewers were mixed on this paper. Reviewers agreed that it is an important problem and found the theoretical analysis and proposals for solving it interesting. However, they also raised concerns about poor writing quality, insufficient experiments, and some of the claims being too strong. Overall, the paper was judged to be below the acceptance threshold by the reviewers. I encourage the authors to improve the paper, taking into account the detailed reviewer comments.",
        "This paper proposes a contribution aiming at understanding the cause of errors in few-shot learning. The motivation is interesting but the reviewers pointed out many aspects that require more precisions and polishing in addition to the fact that the upper bound provided it rather loose. The rebuttal provided addresses some concerns, but there are still some remarks that require some clarifications en work. Hence, I propose rejection."
    ],
    [
        "This paper proposes a new method to reverse-engineer trojan triggers in the feature space. The main insight is that trojan features will form a hyperplane in the high dimensional space of a neural network. The method effectively defends both input-space and feature-space Trojans. The experiments show that the proposed method achieves better trojan detection performance than prior works and can also be used to mitigate trojan attacks. The paper is well-written and the experiments are comprehensive. During the discussion period, the authors properly addressed most of the reviewers' concerns.",
        "This paper proposes a new reverse-engineering method for trojan attack detection. The idea is to focus on feature representation space so that the detection is more robust to dynamic / input-dependent attacks and other feature-based attacks. The reviewers consider the idea generally novel and effective, and the experiments thorough. Some reviewers hope to see more visual analysis that can provide better insights into the effectiveness of the method."
    ],
    [
        "This paper presents a reinforcement learning approach to option learning based on the options framework. The key idea is to learn a parameterized joint distribution over options and actions, and uses a soft-continuation based approach to interrupt or \"switch\" between options before option termination. The method is novel and shows empirical improvements over existing methods in simulation and on 3D virtual environments.  However, there are several concerns raised by the reviewers. The main one is the clarity of the paper. All reviewers struggle to follow the paper and its notation. As a result, it is hard to understand what the authors propose and what the results mean. The reviewers also think that there is a lack of theoretical analysis.  For these reasons, the paper can not be accepted in its current form. I recommend the authors to take the reviewers' comments into consideration to improve and resubmit to a future venue.",
        "There was a fair amount of discussion about the paper.  Several reviewers felt that the paper would have been stronger if it tried to do less but better.  The reviews describe in detail what the reviewers would have found compelling, but the key suggestion is to remove the complexity that is not essential for the approach to provide consistent improvements.  Doing this requires a better understanding of the algorithm's behavior and a valid ablation study, a new concern raised during the discussion with the authors.   The reviewers felt that the proposed approach is potentially interesting and would like to see this paper done well."
    ],
    [
        "This paper proposes a differentiable multi-layer fern-based architecture for tabular data which is a generalization of the NODE architecture. The reviewers find that this approach is computationally efficient on CPUs and can learn sparse representation which is better suited for low-end devices. The performance is on-par with state-of-the-art methods, and the ablation study shows that it is possible to get decent accuracy with this approach.   However, there are concerns on the sparseness of the sparse representation and its ability to scale to higher-dimensional datasets. One reviewer also finds that the paper lacks a comparison to other methods like CatBoost, TabNet and NODE.  Overall, the paper is a good contribution, but it is not ready for publication at ICLR.",
        "The submission introduces the sparse hierarchical table ensemble (S-HTE), based on oblivious decision trees for tabular data. The reviewers acknowledged the clarity of the presentation and the importance of the computational complexity analysis. However, they also raised concerns regarding the novelty of the proposed method and the significance of the results compared to competing methods (e.g., CatBoost). Given the consensus that the submission is not ready for publication at ICLR, I recommend rejection at this point."
    ],
    [
        "This paper explores the effect of task diversity in the training phase of meta-learning. The authors consider a multi-task setting in an episodic setting and compare their performances against a standard uniform sampling. They evaluate the performance on four few-shot image classification datasets.  The findings indicate that increasing task diversity during the meta-training process does not boost performance in this setting and that the benefits of diversity in early training are lost as the tasks become more similar.  All of the reviewers agree that this is a well-written paper and the empirical investigation is comprehensive. Although there are some concerns about the lack of surprising findings, the paper fills a gap in the existing literature and provides valuable insights for future research in this direction.",
        "This paper set out to show that increasing task diversity during meta-training process does not boost performance. The reviewers mostly  agreed (only reviewer wVFn dissented) that the empirical set up of the paper was convincing, but they also felt it over-emphasized empirics over a deeper understanding of the phenomena observed. In turn, this resulted in discussions around how the experiments and the explanations didn't fully prove that increasing task diversity does not help. Overall, the discussion and the additional analysis tools provided by the authors (such as the diversity metric) will greatly improve the paper."
    ],
    [
        "This paper proposes to model outliers using a conditional VAE structure to generate pseudo OOD samples by providing some synthetic conditional information. They show that their approach outperforms other SOTA methods in the task of out-of-distribution detection.  The paper is well-written, covers the related works, and is well motivated. In the majority of setups, CGA shows competitive performance against the conventional OOD detection methods.  However, there are some concerns about the limited novelty of the proposed approach. Moreover, there is a lack of ablation studies and detailed analysis to show the generality of the approach.  Therefore, the current version of the paper is not suitable for publication at ICLR.",
        "The paper adopts CVAE to generate OOD samples for training an outliner detector. It consists of two phases that train an OOD detector by leveraging the generated OOD data and shows it outperform other methods. According to reviewers’ discussion, there is a concern from the discussion: why CVAE works but other variants or cGAN doesn’t. The paper needs more motivation or evidence or ablations to support the generality of the work."
    ],
    [
        "The authors propose a new framework, Bayes Augmented with memory (BAM), that allows an agent to adaptively decide which past observations to remember and which to forget. The paper aims to solve the downside of the posterior shrinkage of Bayesian online learning when applied in a non-stationary environment.  The reviewers found the paper to be well written and easy to follow. The method is novel and does not rely on parametric assumptions, and the experiments provide a variety of experiments demonstrating its effectiveness.  On the other hand, the method still falls short on several fronts, e.g., a more immediate improvement would be to use a fixed memory, a more realistic environment, more diverse experiments (e.g. in pixel-based world), or to provide parametric baselines.  After reading the authors' responses, the reviewers decided to maintain their original scores. The authors are encouraged to take into consideration the suggestions provided by the reviewers to improve the paper",
        "The article introduces a Bayesian approach for online learning in non-stationary environments. The approach, which bears similarities with weighted likelihood estimation methods, associate a binary weight to each past observation, indicating if this observation should be including or not to compute the posterior. The weights are estimated via maximum a posteriori.   The paper is well written, the approach is novel and its usefulness demonstrated on a number of different experiments. The original submission missed some relevant references that have been added in the revision. The approach has some limitations, highlighted by the reviewers: * it requires to solve a binary optimisation problem whose complexity scales exponentially with the size of the dataset; although the greedy procedure proposed by the authors seems to work fine on the examples shown, the approach may not be applicable to larger datasets * it requires to store all the data * it requires the traceability of the marginal likelihood  Despite these limitations, there was a general agreement that this paper offers a novel and useful contribution, and I recommend acceptance.   As noted by reviewer o4TK, I also think that the title is not very accurate. Bayesian methods naturally allow recursive updates of one's beliefs, and therefore have \"memory\". Maybe change the title for \"Bayes with augmented selective/adaptive memory\"?"
    ],
    [
        "This paper proposes a CNN-based attention prediction approach for improving Transformer models for improving performance in a task-independent way. However there are many unclear expressions and claims in the paper, and some ablations are missing which might be critical to better understand the module. The experiments on GLUE are also weak and could be a result of variance over the existing BERT model.   The paper is not ready for publication at this time. We hope the authors find the reviews helpful.",
        "Multiple reviewers point out the interesting improvement to mix attention maps at different layers via convolution based prediction modules. This module is sufficient to show improvements only on encoder side while comparing to concurrent work Synthesizer. However, the novelty of the work is limited as compared to other papers and the results though improved did not convince the reviewers fully to gain a strong accept."
    ],
    [
        "Pros:  RML Mapper for Excel spreadsheets is a relevant and important topic for the workshop. The paper is well written and provides some useful insights.  Cons:  The presentation could be improved. It was hard to understand whether this was a system demo, a research paper, or just an RML translator with some additional modules.  It would also be helpful if the authors described the differences between RMLMapper and the proposed spreadsheets in some detail.  Verdict:  Potential weak accept. usefulness is clearly demonstrated, and the provided code is well documented.",
        "The paper presents an extension of the RMLMapper tool to cover Excel features. The three reviewers agreed that the contribution is relevant to the workshop and presents a solid work. Please take into account the comments provided to include them in the camera-ready paper, try to be clear if the work presents a demo or a short research paper.  The recommendation is to accept."
    ],
    [
        "The paper introduces a new family of Boltzmann machines where the underlying potentials are parameterized such that they obey a monotonicity constraint. This ensures that the inference problem has a single global optimum, which can be found using some generalized variant of parallel mean field.  To turn inference into learning, the model is treated as a supervised learning model and given learning rates and a loss function. Simulation and small-scale experiments are done as proof of concept.   The paper is well-motivated and well-written. The contribution is original and significant. The experiments are convincing. The rebuttal has addressed the concerns raised by the reviewers. Please add the clarifications to the final version.",
        "This is an interesting contribution to the Boltzmann machine (BM) literature that makes a nice connection to DEQ models. On a positive note, reviewers found that it was well-written, clear, and interesting. Unfortunately, there were significant concerns with the manuscript that were not fully addressed in the revision: inappropriate or incomplete baselines, insufficient credit given to previous works, and the fact that this model is limited as compared to its BM relatives.  I would recommend that the authors take into account the reviewers' feedback in a revision of the work."
    ],
    [
        "This paper proposes a new method for generating discrete data by using a first hitting time as the stopping time for diffusion models, which can be adapted to arbitrary domains. Diffusion models based on infinite time have been proposed in the past, but this work takes a more principled approach. Learning and inference is performed by approximating the drift term in the diffusion process with a neural network, and then using the estimated diffusion loss to train the model. The authors also propose a fast sampling algorithm for the rotational symmetric domain and show experimental results in time complexity and sample quality on MNIST and CIFAR-10.  Pros: - All reviewers agree that this is a novel and interesting data generation method. - The idea of using hitting times to model diffusion has been previously proposed in physics (e.g. first hitting laws, which are based on physics simulations) - The paper is well-written and easy to follow  Cons: - The assumption of a fixed stopping time does",
        "The paper introduces a new approach for generative modeling: a diffusion process is run until it first hits a target set, and then outputs the first point that is hit.   Three reviewers generally praised the originality, technical quality, and empirical results of the paper. They found the idea very interesting and novel, and technically sound. The numerical results were judged to be compelling and fair. One concern was clarity of exposition. There seemed to be two issues: (1) there were more typos and rough edges than expected, (2) more significantly, there was some difficulty in following all details of the main method given the notational complexity and significant amount of mathematical background on diffusion processes. Reviewer FUwB gave a number of concrete suggestions for improvement.  Reviewer wpmu had a negative overall opinion and critiqued the originality, quality, and clarity. On these issues: (1) the quality concern was based on a misunderstanding that was later resolved, (2) the originality concern does not seem justified to the meta-reviewer (it is based on a shared technical tool with a not-yet-published paper), and (3) the clarity concern is similar to those raised by other reviewers (especially FUwB). Overall, the meta-reviewer does not feel that the low score (3 = “reject”) was fully justified.   In summary, overall reviewers found the paper sound and novel, with the main area for improvement being clarity of exposition about diffusion processes; one reviewer considered originality a weakness, but the meta-reviewer did not find this position well justified."
    ],
    [
        "The paper presents a novel approach to contact slip avoidance in robotic manipulation of objects using both tactile sensor data and future planned actions as input. The approach proposes two methods, one purely reactive (i.e. it uses an LSTM to detect and predict slip events triggering the controller to slow it's velocity) and the second one that uses a combination of past and future tactile data as input to predict slip.  The paper received mixed reviews from four expert reviewers. The reviewers appreciated the novel formulation and two reviewers found the problem of contact slip to be important and interesting.  However, concerns were raised about the experimental evaluation, in particular the comparison with the PSC method. The authors provided a strong rebuttal that addressed many of the reviewers' concerns, including more experiments on real-world manipulation tasks.  Overall, the paper presents an interesting contribution to the CoRL community and I recommend acceptance.",
        "This paper presents a method for preventing slips in point-to-point motions while grasping an object using LSTM-based models for detecting and predicting slips. This approach is effective when contact force cannot be increased. Reactive and proactive controllers are presented, and the latter demonstrated better performance.   The paper proposes an interesting approach to slip prevention especially useful for handling delicate objects. The authors successfully addressed most of the concerns raised by the reviewers, while expanding the dataset and examples will be addressed in a future journal paper. Nevertheless, the paper will make a valuable contribution to the conference."
    ],
    [
        "The three tasks of entity alignment (EA), relation alignment (RA), and knowledge graph completion (KGC) are jointly tackled in this paper. The paper shows that the three tasks can benefit each other and jointly optimize the loss function. AlignKGC trains a model to jointly complete multiple monolingual KGs, and aligning their entities and relations. The experiments on DBP5L show significant improvements over the baselines.  The reviewers and AC note the following potential weaknesses: (1) it is not clear whether the proposed KG completion task can also be applied to EA andRA tasks, since the tasks are not identical in each language; (2) the contributions and significance of the work are not significant, given the existing literature; (3) there are many clarifications in the paper, but they are hard to follow in places.   The authors provided strong rebuttals to the reviewers' comments. After reading the rebuttals, updating the reviews, and",
        "This paper introduces AlignKGC, a neural model that performs entity alignment (EA), relation alignment (RA), and knowledge graph completion (KGC) on multilingual knowledge graphs. The model jointly optimizes for the linear combination of losses for all 3 tasks. The authors present a convincing set of experiments to show that each of these tasks helps the other two. The paper is well written and demonstrates strong empirical results on DBLP5L containing 5 languages on all 3 tasks. Results are reproducible as both the code and data are made public. No major concerns after the author's response."
    ],
    [
        "This paper studies the expressive power of message passing graph neural networks (MPNNs) with random node initialization. The main Theoretical result of the paper is that k-GCN (or k-IGN) for any k graphs is not expressive for those with k non-uniform subgraphs. The paper then constructs two new datasets wich require 2-WL distinguishing power (which is higher than the ones MPNNs have) for these datasets. The theoretical result in this paper is supported by some numerical experiments.  This paper received a mixed evaluation from the reviewers, ranging from accept (7) to reject (3). The main concerns of the negative reviewers are that the theoretical result is somewhat expected and not very novel. On the other hand, the positive reviewers found the experiments interesting and the paper well-written. Therefore, I recommend acceptance. However, I strongly suggest to the authors to improve the presentation of the theoretical results in the final version.",
        "In this paper, the authors show the effect of RNI on the expressive power of GNN for the first time, where the RNI was initially proposed in Sato et al. 2020. Overall, I like the idea of random node initialization because it is simple, effective, and theoretically well-founded. The key concern was that the novelty over the Sato's paper and the reviewers were still not convinced by the response. Therefore, the paper is still below the acceptance threshold.  I strongly encourage authors to revise the paper based on the reviewer's comments and resubmit it to a future venue."
    ],
    [
        "This paper examines the effect of individual neuron class selectivity. The authors introduce a regularization term to the loss that controls the amount of selectivity in the units of the network. They find that the selectivity of the units in standard networks can be reduced while maintaining classified performance. They observe that discouraging selectivity can have a small benefit, and generally doesn’t harm performance even at very high values. Conversely, encouraging selectivity dramatically decreases performance in many cases, and in some cases mildly improves performance.  The paper is well-written and the experiments are carefully conducted. The reviewers and I find the contributions of this paper significant for publication at NeurIPS2022. I strongly encourage the authors to take all the comments into account when preparing the final version.",
        "This paper has received three positive reviews. In general, the reviewers have commented on the importance of the question related to how much selectivity is needed from units of a neural network for good classification -- from both the neuroscience and ML perspectives. The reviewers also commented on the thoroughness of the experiments and the general readability of the paper. This paper should be accepted if possible."
    ],
    [
        "The authors propose an automatic batching strategy that work for dynamic computation graphs. The speedup is measured in terms of CPU/GPU time and is statistically significant.  The reviewers had some concerns about the novelty of the approach which was addressed during the discussion phase. However, the authors are expected to release code to reproduce their experiments on a public dataset so the community can benefit from these results. Therefore, I recommend to reject the paper in its current form.",
        "This paper describes a new batching strategy for more efficient training of deep neural nets. The idea stems from the observation that some operations can only be batched more efficiently in the backward, suggesting that batching should be different between forward and backward. The results show that the proposed method improves upon existing batch strategies across three tasks. The reviewers find the work novel, but note that it does not properly address the trade-offs made by the technique - such as memory consumption. They also argue that the writing should be improved before acceptance at ICLR."
    ],
    [
        "This paper proposes a new few-shot learning method that takes into account the semantic relatedness of the ground truth labels. The method (TASNet) is built over Protonet (Snell et al.) method and learns separately from visual and semantic features. Experimental results are provided on four benchmark datasets that demonstrate that the proposed approach outperforms existing approaches.  In general, the reviewers find the paper to be poorly written. The explanation of the proposed method is unnecessarily redundant. The experiment results are unconvincing. The effect of using a pre-trained feature extractor is unclear. It is also unclear whether the advantage of proposed method over existing methods is significant.  The authors did not respond to the reviewers' comments.",
        "This paper proposes a few-shot learning method that learns task-adaptive semantic features that can incorporate for both of the support and query sets. Two approaches for modality combination are developed. The additional experiments in the author response addressed some concerns of the reviewers. However, the technical novelty of the proposed method is high enough since the proposed method uses existing techniques."
    ],
    [
        "This paper presents a multi-task paradigm for transfer learning via cross-domain mixup. The strategy is simple to implement but effective. It finds a one-to-one mapping from source dataset classes to the target dataset classes, and applies mixup between the samples from the samples of the source and target classes to improve the transfer performance. The paper is well-written and easy to follow. The reviewers liked the simplicity of the method. However, the reviewers expressed concerns about limited novelty, insufficient experiments, and lack of convincing experiments. The author(s) tried to address some of the concerns but failed to convince the reviewers about the others.",
        "All reviewers recommend rejection due to limited novelty and insufficient experimental analysis. The author’s response has addressed several other questions raised by the reviewers, but it was not sufficient to eliminate the main concerns about novelty (as the method is a combination of existing techniques) and missing comparisons to justify the effectiveness of the proposed approach."
    ],
    [
        "In this paper, the authors propose an adversarial attack strategy for graph neural networks based on influence maximization in a black-box setting where the attacker has limited access to the model and is restricted to perturbations of the node attributes. The main contribution is that the authors draw a connection between the restricted attack problem and the influence maximisation problem. The paper is well-written and generally easy to follow. However, some major concerns remain after the discussion among the reviewers. In particular, under some Assumption 1, the attack is assumed to be evasion-based and the model is in a tabular state, which makes the problem of restricted attack very simple. Although the reviewers acknowledge the novelty of this connection, some of them think this assumption is too strong and hard to verify. For example, under Assumption 2, the problem is not restricted to node attribute perturbation but to node features (which is a much more realistic setting). The authors are encouraged to discuss",
        "This paper relates the problem of influence maximization and adversarial attacks on GCNs.  The paper, and its formulation and assumptions stirred up quite a discussion among the reviewers and the authors. I do appreciate the thorough rebuttal that the authors provided, and the reviewers did take it into account (and revised their scores).  However, all in all, I am afraid that there are just a few too many concerns with this paper.  If the authors take the reviews to heart, they should be able to improve the manuscript and submit a stronger and improved version to the next conference."
    ],
    [
        "This paper proposes a new method for partially observable cooperative multi-agent reinforcement learning that uses information from counterfactual predictions of optimal joint action selection to encourage agents to communicate. The paper identifies the limitations of existing methods QMIX and WQMIX in partially observable settings and proposes a method that explicitly encourages agents to take messages into account while training. The experimental results show improvements over the baseline method.   The reviewers agree that the paper proposes an interesting and novel idea, and the experimental results support the claims. The weaknesses pointed out by the reviewers have been successfully addressed during the rebuttal. Therefore, the meta-reviewer recommends acceptance.",
        "After reading the reviews and feedbacks, I lean towards acceptance. A majority of reviewers gave a positive score after the rebuttal period and some concern were answered in the authors response. Specifically authors have shown that the recent baselines they use outperform other baselines and therefore those do not need to be added in the paper, they have also clarified some proofs and some notations. Overall, the reviewers found the method presented interesting, the paper well written and appreciated the comparison to other methods of the literature. Finally, experiments shows interesting results on large scale domains which is a sign that the proposed method could scale up."
    ],
    [
        "This paper studies the bottleneck in feature learning for long-tailed classification. Contrary to common belief, the authors find that the bottleneck is in data representation rather than the classifier itself, and that it is the representation that is the bottleneck. They further show that data augmentation can help relieve the issues in long-tail feature space and confirm that intra-class compactness and inter-class separation can improve performance. Extensive experiments are performed to support their claims. Reviewers have a consensus on rejection due to limited novelty and contributions.",
        "This paper investigates the role of representation learning when the distribution over the feature space has a long tail. The main motivation is to determine how much of the overall learning, in this case, is bottlenecked specifically by representation learning. The main findings are that vanilla learning gives brittle long-tailed representations, harming overall performance. The paper suggests a form of data augmentation to remedy this. Reviewers acknowledge that this investigation is worthwhile. However, many concerns were raised as to whether experiments support the drawn conclusions. A more principled approach to the data augmentation methodology is also needed. The authors address some of these, providing further experiments, but these were not enough to sway reviewers. Since results are fundamentally empirical in nature, this shortcoming indicates that the paper is not ready to share with the community just yet. Stronger experiments with clearer evidence are needed to fully support the thesis of the work."
    ],
    [
        "The paper studies the condensation of weights of neural networks during the initial training stage. It showed theoretically and empirically that the maximal number of condensed orientations is twice the multiplicity of the activation function. This condensation restricts the capacity of NNs at the beginning, working as an implicit regularization. Both theoretical and empirical results are provided.  The paper is well-written and the claims are supported both by theory and experiments. It would be good to improve the discussion of prior work on this topic in the revised version. There were a few typos and unclear sentences in the current form.",
        "*Summary:* Study isolated orientations of weights for networks with small initialization depending on multiplicity of activation functions.   *Strengths:*  - Interesting analysis of properties in early stages depending on activations.   *Weaknesses:*  - Reviewers found the settings limited.  - Reviewers found experiments limited.    *Discussion:*  In response to ejGJ authors reiterate scope of covered cases and submit to consideration that their experiments should be adequate for basic research. Reviewer acknowledges the response, but maintains their assessment (limited scope of theory, limited experiments). KucV found the experimental part limited in scope, the settings unclear (notion of early stage, compatibility with theory), and review of previous works lacking. KucV’s sincerely acknowledged authors for their efforts to address their comments and improving the manuscript, and raised their score, but maintained the experimental analysis is not fully convincing and unclear, and the comparison with prior work insufficient. zuZq also expressed concerns with the experiments and the notions and settings under consideration. They also raised questions about the comparison with standard initialization. Authors made efforts to address zuZq concerns. zuZq acknowledged this but maintained initial position that the article is just marginally above threshold. jDJ5 found the paper well written and the conclusion insightful. However, also raised concerns about the experiments the settings under consideration. Authors made efforts to address jDJ5’s concerns, who appreciated this but was not convinced to raise their score.   *Conclusion:*   Two reviewers consider this article marginally above and two more marginally below the acceptance threshold. I find the article draws an interesting connection pertaining an interesting topic. However, the reviews and discussion conclude that the article lacks in several regards that in my view still could and should be improved. Therefore I am recommending reject at this time. I encourage the authors to revise and resubmit."
    ],
    [
        "This paper proposes a pretraining approach for vision transformers using self-distillation based method DINO with mask image modeling. The paper is well written, the method is simple and gives better performance than DINO. Nevertheless, the comparison between the different approaches does not seem to be complete enough. One of the questions raised by the reviewers about the experiments has been answered by the authors in the rebuttal, however the reviewers did not change their evaluation. The performance of iBOT in comparison to the other pretrained VTA methods is still not great.",
        "The paper is interesting, and its focus is timely and important, given the continuing rapid rise of transformers (and their dependence of tokenization of images). All three reviewers recommend acceptance, to varying degree. The paper will be a valuable contribution to the program at ICLR."
    ],
    [
        "This paper shows that it is O(n polylog) times faster to recover private images from the InstaHideHide dataset than previous challenges, but the running time is exponential in the number of private images, which makes the result less practical for the average user. The reviewers consider the problem interesting and appreciate the improvements to the sample complexity of the challenge, but find that the paper is still below the acceptance threshold in terms of technical clarity. I suggest improving the following aspects of the paper for the final version:  - Theorem 1: While the bound in (O(n^2) is not practical for recovering private images given the dimensionality of the dataset, it is still a practical bound that makes the theoretical results obtainable.  - Section 3.2: It is shown that one can recover all private images using near-linear size samples from the distribution of the private images. However, the value for the general readers are limited, therefore I suggest for weak",
        "All reviewers agree that this is a reasonable contribution but that it is also extremely limited in scope. The authors suggest in one of their response that their technique could apply to \"any data mixing method with “batched k-sum” structure\". Such a larger level of generality might make the paper more interesting, but at the moment it is an extremely niche result."
    ],
    [
        "The authors extend the Lyapunov chaos analyses of learning to more general bimatrix-like general mixed-sum and mixed-concordant games, and derive two new tools: matrix domination and a linear program.  The reviews are generally positive. The reviewers identify the following strengths of the paper: - The paper is well-written and clear and the claims are supported by mathematical rigor - The authors have addressed most of the questions raised by the reviewers - The analysis provides tools for better understanding the underlying dynamics of learning in general sum games  The reviewers also identified several weaknesses, including - The main contribution of this work seems to be extending the results of Cheung and Piliouras to other games, but the paper's organization and presentation of the key results are not very clear from the main text. - Theoretical results are presented in a somewhat preliminary and not rigorous way. - Empirical analysis of the empirical results is limited.",
        "This paper looks at chaos in learning in games, extending a line of work in two players zero-sum games (that I found quite restrictive in the past). It somehow reduces the class of more general games to zero-sum and cooperative games (this decomposition is already known) so that the techniques can be transposed here.  The paper is interesting, yet sometimes difficult to follow, and I am not certain that it gives many new insights.   Nonetheless, we believe its quality justify acceptance."
    ],
    [
        "This paper proposes a method called MemUP to help recurrent neural networks learn long-term dependencies better. Specifically, it uses a memory model to predict future outcomes with high uncertainty, so that by skipping all states with lower uncertainty, the training process takes less computational cost in backpropagation. It also keeps useful past states for future use, so it saves both computation and memory.  While the basic idea is clear, the paper could have make a better job exploring the MemUP idea further. All the reviewers agreed that the paper needs more work in terms of experimental design, baselines, ablation study, etc. To improve the paper, we suggest the authors to:  - Do experiments on more complex tasks with longer task-dependencies (e.g., in supervised learning) - Study the effect of different components of MemUP on different tasks and dataset(s).  Also, as suggested by Reviewer 1, it would be great if the authors could add some",
        "The reviewers found the ideas presented in the paper interesting -- the use of mutual information to train memory for a model, and the clear presentation. Some questions were raised about demonstrating on a more elaborate set up such as NLP tasks -- the main experiments aside from the toy experiments of copy, etc algorithmic tasks, seem to be on RL experiments, but the method has been advertised more broadly in the motivation. Another reviewer raised the question of the complexity of training multiple networks. Nevertheless, the reviewers found the paper interesting enough to recommend a weak accept and I support that recommendation.  From a reviewers lens, I was a little surprised that the paper made no mention of prior works on maximizing mutual information between features of neural networks to improve results. As an example, see the following paper [1] that uses a mutual information regularizer between states at different steps of a recurrent neural networks. There is also a rich literature of doing so for convolutional neural networks. It would have made sense to compare how the idea in the paper performed in comparison to these methods (and in a sense the ablation study which looked at randomly choosing time steps, k, (regardless of the uncertainty estimator) is an experiment in this direction). I understand that part of the paper deals with the choice of time points to increase mutual information between, and so its probably more efficient than the other alternatives, but a comparison (or discussion in related works) would have made the paper stronger.  [1] Better Long-Range DependencyBy Bootstrapping A Mutual Information Regularizer. https://arxiv.org/pdf/1905.11978v1.pdf"
    ],
    [
        "The paper presents a new dataset, Touch and Go, which contains both visual and tactile data from human operators. The reviewers are positive about the importance of the problem and the dataset. They appreciate that the dataset is more diverse than prior efforts in both visual-tactile and multimodal domains. The authors also demonstrate the value of the dataset for multiple applications, including a new tactile-driven image stylization task.  The paper is well written and guides the reader well.  Some minor concerns were raised by the reviewers, and the authors have addressed them in their response. Please address these concerns in the final version.",
        "Overall, all reviewers see the novelty in the dataset that provides an original new set of tactile data, accounting for a wide range of objects and scene, collected in the wild. The paper is overall well written, clear and easy to follow, and provides a good demonstration of the importance and usefulness of the dataset, going beyond datasets collected by robots in the context of material properties. It also includes initial steps towards benchmarking, although it is not the core contribution of the paper, which lies in the creation of the dataset itself.   Two reviewers recommend acceptance, two stand marginally below acceptance, and one does recommend rejection. The authors have provided detailed responses to all reviewers’ comments and concerns and updated their manuscript. The main concerns of those reviewers sitting on the fence seem to be answered and limitations acknowledged however the element of bias in the data collection was still considered as a possible concern. Based on my reading and accounting for the authors changes, there approach itself is novel and original and hence provides already a relevant contribution to NeuroIPS; while the authors acknowledge limitations and future work avenues. The one reviewer recommending rejection didn’t engage in the discussion but from my reading of both the paper, the comments, and the authors responses, I believe the main points were addressed by the authors and misunderstandings clarified. Overall, I believe the papers offers a novel, non-existing dataset that can inspire interesting future works; all the dataset is shared and presented clearly for others to use."
    ],
    [
        "This paper presents a method to combine VAEs and ProbLog for conditional image generation. The idea is to include a symbolic component (z_sym) in the latent representation and make use of the Probabilistic logic program. The method is tested on two image generation tasks and is shown to have better generalization than VAE.  Strengths:  1 - The integration of VAE with ProbLog is a novel direction. 2 - Good generalization results are shown. 3 - The paper is well written and easy to follow.  Weaknesses:  - The experiments are limited and the proposed method should have been better motivated. - The connection between z_sym and the ProbLog program needs to be better explained.  Overall, the reviewers agree that the paper is not ready for publication yet. I encourage the authors to take the review feedback into account and improve the paper for the next submission.",
        "The paper proposes to include a component enforcing logical constraints on top of a variational autoencoder (VAE). The resulting method, VAEL. does so by leveraging ProbLog in addition to a neural encoder and decoder. VAEL is employed for simple generative tasks with constraints over the outputs, such as conditional image generation with MNIST and small Mario levels.  The reviewers have appreciated the direction where VAEL is heading and the importance of integrating constraints in deep generative models. Some concerns are still open. Specifically, the motivation behind some architectural choices (and the specific choice of VAEs as deep generative models) and the small-scale nature of the experiments. The complexity and scaling campabilities of performing symbolic reasoning with ProbLog are not discussed in depth."
    ],
    [
        "This paper proposes a recommender transformer with a pathway attention mechanism to capture different types of user pathways and predict user action sequences with high accuracy. The whole paper is well written and easy to follow. The idea of using pathway in recommendation algorithms is not new, but the use of it in this context is novel. The proposed method is compared with several state-of-the-art methods, and the performance is good. The reviewers raised some concerns, such as the method not being compared with SOTA methods and the simplicity of some of the comparisons, which were addressed by the authors in the rebuttal. Overall, the paper receives positive reviews and is recommended to be accepted.",
        "This paper presents Recommender Transformer (RETR) with a pathway attention mechanism that can dynamically zeroing-out the interactions (e.g., the trivial/noisy ones) in transformer-based sequential recommender systems. Extensive experimental results demonstrate the effectiveness of the proposed architecture.   Overall this paper received mixed reviews with borderline scores. The reviewers raised concerns around baselines and evaluations, some of which the authors promptly addressed in the revision during the rebuttal period. I also read the paper in details myself. I do agree with some of the concerns from the reviewers but I don't think a method needs to beat every other published papers to be published (and I think the current baselines are more than thorough enough). My biggest complaint about the paper is around the writing, specifically, how the proposed idea is presented.   This paper tries to tackle an important question, which is that in sequential recommendation, not every interactions are useful in helping predict future interaction. The self-attention mechanism in transformer kind of addresses this problem but in a more \"softer\" fashion with attention weights. This paper presents a simple yet effective method to introduce a pathway mechanism that adaptively zeroing-out some of the interactions via a binary pathway router. In order to train such a model end-to-end, Gumbel-softmax sampling is utilized.  The most important part of the contribution to me is that this is an improvement to the transformer architecture, as opposed to a new model which is what this paper's writing suggests -- the proposed approach is effectively model-agonistic and doesn't marry to a particular loss function or finer-grained architectural choices (number of layers, etc.). Currently there are many baselines in the paper, but each made some different model/architecture choices, which could contribute to the difference in performance (or not, but we wouldn't know). An ideal evaluation should have been to take all the transformer-based baselines that are currently in the paper, add this pathway mechanism without changing anything else, and show that the results improved over the transformer architecture. In this way, we know the improvements are exactly coming from introducing the pathway. The authors might argue some of the current results are already supporting this argument, but my point is to emphasize this point very explicitly rather than leaving it for the readers to infer.   From what I read in this paper, I truly believe this pathway idea has its potential. Therefore, I would especially want the authors to further refine the presentation to better convey the idea, which in turn will hopefully increase the impact of this paper once it is eventually published.   Some minor comments: * The way the paper is currently written seems to suggest there are only three types of pathways and the network is capable of capturing all of them. I am personally not a big of fan of over-interpreting what a neural net is trying to do. Therefore, I wouldn't overly focus on the characterization of different pathways and only show the qualitative examples at the end as a high-level demonstration. * In Eq 2 \"softmax\" should really be \"sigmoid\" if a 0-1 prediction is made there. Then the following line \"logit\" is probably not the right word here.  * The qualitative examples at the end (figure 3) can be more carefully examined/labeled. For example, the current categorization is quite ambiguous -- \"Indie\" refers to the type of developers while \"JPG\" refers to the genre of the game, they are certainly not mutually exclusive."
    ],
    [
        "This paper proposes a novel continual learning approach based on recursive gradient optimization. The idea is to find the gradient that causes the least interference with the previous task the most. This is done by multiplying the gradient direction by multiplying it with a projection matrix. The authors introduce a Feature Encoding Layer to encode the feature representations and add the Hessian for each task. The proposed method is empirically shown to improve task performance on a number of benchmarks.  The reviewers agree that the paper is well-written and the idea is novel and interesting for the continual learning setting. The experiments seem comprehensive in range (many benchmarks, many architectures, many tasks). Theoretical analysis is also sufficient.  During the discussion, the authors also successfully addressed some of the questions and concerns raised by the reviewers (e.g., ablation studies and sensitivity analysis w.r.t. to hyperparameter choices).   One of the main remaining concerns is the computational scalability of the method",
        "This paper proposes an innovative method for continual learning that modifies the direction of gradients on a new task to minimise forgetting on previous tasks without data replay. The method is mathematically rigorous with a strong theoretical analysis and excellent empirical results across multiple continual learning benchmarks. It is a clear accept. There was good discussion between the reviewers and authors that addressed a number of minor issues, including clarifying that the method has the same computational complexity as backpropagation. The authors are encouraged to make sure that these points are addressed in the final version of the paper."
    ],
    [
        "The paper studies the important problem of out-of-distribution generalization for node-level prediction and presents a new perspective that formulates the OOD problem as invariant risk minimization under different environments. The proposed approach, \"Explore-to-Extrapolate Risk Minimization (EERM)\", that adopts K context generators solve the problems in a smart way and according to the invariance theory. The experiments show promising results on multiple datasets. The paper is well-written and the theory seems to be solid. Reviewers' raised concerns and questions are properly addressed by the author's response. After the discussion phase, all the reviewers and AC recommend acceptance.",
        "The reviewers have improved their scores after the rebuttal, and I agree that the work has value. It proposes a model-driven data augmentation approach to environment-invariant graph representation. Just like most data augmentation works in graph representation learning, the approach relies on graph proposal generator. The work has an implicit mechanism hidden in the graph generator (the authors' reply to a reviewer that \"we target the extrapolation via a new invariant learning approach that is agnostic to specific GNN models\" is a misunderstanding of why & how these types of methods work). The submission could significantly improve the introduction by properly describing the work w.r.t. other OOD efforts in graph representation learning. While the tasks of different works may be different (e.g., graph classification vs node classification), it is important to emphasize what each different approach brings to the table (rather than just state that the tasks are different). I hope the authors take this opportunity to improve the introduction. This work is more similar to the former OOD graph representation works than IRM & REX, since (without modeling assumptions) both IRM and REX require the support of the environments in test to be a subset of the ones in training. The present work does not need this support assumption since it uses an implicit mechanism in the graph generator.  The toy example in Section 3.1 is informative, thank you. The theory looks solid and easy to understand. The technical novelty is limited, since once the input graph has been decomposed into a set of ego-graphs the definitions, formulations, and theory are all straightforward adaptations from the respective versions for IID data.   Minor: - In Assumption 2, m() should be defined inside the assumption."
    ],
    [
        "This paper proposes to improve the way in which information from a Translation Memory (TM) in Neural Machine Translation (NMT) can be retrieved from the target language. The proposed method consists of two parts: a universal memory encoder and a TM guided decoder. The model and the experiments are generally well-motivated and well-described. The results also show improvements over a reasonable but not SOTA baseline for the English-French task.  However, there is a consensus among the reviewers that more work is needed to make the work convincing: (1) the novelty part of this work is the new retrieval way, which is not quite clear and convincing to reviewers; (2) more languages pairs should be verified and more experiments beyond English to French.  We hope the authors will consider re-submitting the work after addressing these two points.",
        "This paper presents a way to use a translation memory (TM) to improve neural machine translation.  Basically the proposed model uses a n-gram retrieve matching sentence （or pieces） and takes advantage of the useful parts using gated attention and copying mechanism.  Although the idea of leveraging TM in the context of NMT is not new,  this work seems to be a fair contribution. My major concerns are the following 1. The retrieval part  is not clearly presented, raising questions about  complexities and the noise brought by the common words. The authors should give a better exposition on the ranking mechanism.  2. The experiments are not convincing enough since the proposed model is not compared to the SOTA and the competitive models described in the prior work.  In conclusion I would suggest to reject this paper."
    ],
    [
        "The paper considers the problem of using proper scoring functions for survival analysis, in addition to maximum likelihood. All reviewers agree that the paper is well written and the approach is sensible. However, all reviewers believe that the novelty of the approach (scores other than maximum likelihood) is limited, and that the experimental results are not strong enough to justify acceptance of the paper.   I would encourage the authors to improve their paper by taking into account the constructive feedback provided by the reviewers. In particular, I would like to see the authors try to move the manuscript towards the focus that it deserves to be, by including stronger baselines, and more experimental results that clearly show the benefits of the proposed approach.",
        "All reviewers agree to reject. While there were many positive points to this work, reviewers believed that it was not yet ready for acceptance."
    ],
    [
        "Overall, the paper is capturing a really timely and increasingly important topic. Although the authors mention that they want to make their dataset particularly useful for academics/future research, I believe, that the topic is of great interest for companies, making the raised ethical considerations even more important. A critical reflection upon possibly ‘unintended uses’ can’t be emphasised enough, as well as possible biases in the data. However, I appreciated that the authors have done a fantastic job in their response and strengthening their article. Moreover, all reviewers recognise the utility and relevance of the proposed dataset and the authors did provide satisfactory responses to all raised concerns/comments. I believe this paper will stimulate some interesting and hopefully critical reflections on how to use/or not use the dataset and future improvements to overcome dataset biases.",
        "Overall, the paper is capturing a really timely and increasingly important topic. Although the authors mention that they want to make their dataset particularly useful for academics/future research, I believe, that the topic is of great interest for companies, making the raised ethical considerations even more important. A critical reflection upon possibly ‘unintended uses’ can’t be emphasised enough, as well as possible biases in the data. However, I appreciated that the authors have done a fantastic job in their response and strengthening their article. Moreover, all reviewers recognise the utility and relevance of the proposed dataset and the authors did provide satisfactory responses to all raised concerns/comments. I believe this paper will stimulate some interesting and hopefully critical reflections on how to use/or not use the dataset and future improvements to overcome dataset biases."
    ],
    [
        "The paper considers the problem of estimating the intensity of a multi-dimensional Poisson process. Inspired by the generalized additive model, the authors propose a certain non-parametric form for the log-likelihood along with a lower-dimensional projection for the intensity. The approach is novel, and the experimental results are strong.  The reviewers and AC note the following potential weaknesses: (1) the paper is not clearly written, (2) the synthetic data is not representative of the real data (New York taxis), (3) it is not clear how the approach can be extended to other high dimensional Poisson processes, (4) the assumption of the intensity form is motivated by the Kolmogorov-Arnold theorem, yet no formal guarantees of convergence are given for the proposed method.   The authors provided a rebuttal and a revision to address some of the above concerns. After the revision, the reviewers and the AC decided to keep their original scores. However",
        "The paper proposes a novel approach for estimating the high-dimensional intensity function of a Poisson process. The proposed approach builds on generalized additive models, using lower-dimensional projections.   The reviewers noted that, although the paper is well written, the position of this paper compared to earlier related work is unclear, and the empirical evaluation of the method should be strenghtened. The authors clarified some points in their response, but the paper would still require some more modifications to be ready for publication. I therefore recommend this paper to be rejected."
    ],
    [
        "The authors propose an improved deep-learning-based representation learning method for clustering-friendly clustering. The integration of a softmax-formulated orthogonal constraint is able to provide more stable latent feature representation. Instance discrimination loss and feature decorrelation loss are combined to optimize the network for instance discrimination and to stabilize the latent representation. The paper is well written and the experimental results are good. The reviewers were impressed by the far above state-of-the-art values of evaluation metric metric. The authors used datasets that are somewhat larger than often used in the literature, which allowed for better analysis of the method. The inclusion of the study of the temperature parameter also helped clarify a few questions I had when reading the paper.",
        "This paper received mostly positive reviews. The reviewers praised the strong performance when compared with previous work. Also, the evaluation clearly shows the benefit of the proposed contributions in terms of performance. Most concerns raised by reviewers were properly addressed in the rebuttal.  Lack of comparison to several previous works has been noted in a comment, but the authors clarified this concern, stating that the current work is a “large deviation from prior works”. The authors promised to include the missing references into the comparison.  Given the reviews, comments, and author's answers, I suggest acceptance."
    ],
    [
        "This paper proposes a new back-door attack method using warping based triggers, which distorts the global structure of the image ( input) making the attack undetectable/unnoticeable by humans. To bypass backdoor detectors, the authors also propose a “noise” mode of training poisoned classifiers with noise to fool detector models. The paper is well-written and easy to follow. The authors have addressed the reviewers’ comments and revised the manuscript accordingly. Backdoor attacks are an important topic of interest and this paper provides a new interesting contribution to the community.",
        "The paper presents a new method for generation of backdoor attacks against deep networks. The new method uses global warping instead of noise patches which makes the attack much more stealthy than previous approaches. The attack effectiveness is demonstrated on 3 benchmark datasets. A small user study is carried out to demonstrate that the attack is stealthier than conventional backdoor attacks.   The new attack is a novel and original contribution which is likely to advance the understanding of backdoor attacks. There were some issues with respect to clarity in the original manuscript but the authors adequately addressed the critical remarks raised by the reviewers."
    ],
    [
        "The paper studies the cascading bandits problem, where an agent chooses a list of items, each of which corresponds to a Bernoulli random variable. The goal is to minimize the total regret. The reviewers agreed that the problem is well-motivated, the paper is clear and well-written, and that the results are interesting. However, the reviewers also pointed out a few weaknesses: (1) The assumption that the variables in the lists are independent Bernoullis is quite limiting in practice, especially when the number of items is large, and (2) The variance-aware estimator for estimating the bandits rate is not very useful, as it will be unable to estimate the variance of the actual bandits. The authors agreed to take these comments into account in the revised version of the paper.",
        "All the reviewers were generally happy with this paper. There were some comments about a better experimental section and maybe a better discussion of results and extensions (e.g. gap-dependent bounds, what happens in the K->L regime), but everyone felt that the manuscript as written was solid enough to merit acceptance. I encourage the authors to incorporate the discussions on these points in the final manuscript."
    ],
    [
        "This paper proposed a unified sequence interface (Pix2seq+) for computer vision tasks. The keypoint tokenization is not clear to me. Some concerns about novelty and contributions are raised. In addition training(pretraining) setup is slightly confusing. However, the proposed method achieves state-of-the-art performance on 4 benchmarks. In my opinion, results are promising. This paper could initiate a new research line unifying different computer visuom tasks.",
        "Four reviewers provided reviews for this submission. Several reviewers felt that the idea to unify core vision tasks into a sequential output format is interesting and an entirely new approach and can have a large impact on how we train vision models in the future. There were a few concerns discussed between reviewers and authors. One concern was the comparison to past works that pre-trained on ImageNet vs the proposed model that was pre-trained on Objects365. The second concern was differentiating this work with Pix2Seq. In my opinion, the authors were able to answer both questions well. Overall, given the positive reviews, novelty of the work, potential to cause a significant shift in the approach of future modeling and discussion, I recommend acceptance."
    ],
    [
        "The paper presents a modification of a convolutional layer that they claim forces their model to be more robust to texture attacks. However, all reviewers and AC note the critical limitation of this paper.   The paper proposes a mechanism that randomly produces a subset of neurons on the convolution layer and biases the network's focus away from texture and towards shape features. The technique is simple and effective, however, no theoretical support is provided for the claims. In addition, AC also agrees with the reviewers that the paper is not well-written.",
        "The paper presents a method to make CNN focus more on structure rather than texture by constraining a random set of neurons per feature map to have constant activation.  The paper has limited novelty and unclear analysis of the experimental results, for instance plots of accuracy vs strength of adversarial perturbation should be produced. Tables are not readable and results tend to be cluttered and confusing.  Some comparisons seem to be cherry picked as pointed out by some reviewers. Although the approach seems to be well received by the reviewers they all shared similar concerns about having a stronger motivation and better validation of the approach (that is not amount of comparisons but the right comparisons that would clear doubts and make the work directly comparable to others). I strongly encourage the authors to perform a deeper analysis and to clearly work on hypothesis and validation of their work. In my opinion, although the reviewers think different, the experiments are not sufficient to validate the strong claim of the paper."
    ],
    [
        "This paper proposes to combine Normalizing Flows with Generative Diffusion Models, where the target data is first non-linearly transformed via the flow and then the distribution over latent embeddings is modeled with a diffusion model. Since the flow is invertible and defined by a deterministic function, it is possible to formally relate the combined flow and diffusion process to a non-linear diffusion directly in data space. Empirically, such nonlinearity results in a tighter variational gap compared to the linear diffusion and other baselines, a claim which is supported both theoretically and empirically.  The paper is set up in the emerging toping of generative diffusion models. The paper comes with a strong theoretical flavour and the proposed approach is well grounded. However, all these remarkable developments come with an unacceptably low quality of english usage. While the paper is clearly written and easy to understand, little is understood about the connection between the proposed method and previous work.",
        "This paper presents a simple approach called PDM for composing non-linear and complex normalizing flows with score-based generative models. Since score-based models can be considered as a special form of continuous-time normalizing flows, PDM corresponds to a composition of different classes of normalizing flows.   Pros:  * Combining generic normalizing flows with score-based models is an interesting direction as they have different characteristics and can be complementary to each other. * Using Ito's lemma to show that the model learns a non-linear SDE in data space is valuable.  * The authors show that the variational gap can be reduced using normalizing flows.  Cons:  * The proposed method does not exhibit a clear advantage compared to the diffusion baseline without the normalizing flow component. On the CIFAR10 dataset, the best NLL and FID results are obtained by the diffusion baseline.  * Theorem 2 makes a very unrealistic assumption that a flow network is flexible enough to transform $p_r$ to any arbitrary distribution. If this holds, we wouldn't need the score-based generation model anymore. We could simply train the normalizing flow to map the input data distribution to a Normal distribution.  * This submission chooses to discuss differences with the recent LSGM framework. However, in doing so, several inaccurate claims are made. The lack of inference data diffusion in LSGM is mentioned as one of its drawbacks. However, it is not clear what is the value of having such a mechanism and what implications it may have on the expressivity of the model. Note that mapping from data space to latent space in VAEs can be considered as a stochastic inversion rather than an exact inversion. Ito's lemma does not require invertibility and it can be easily applied to the forward and generative diffusion in LSGM. The authors argue that applying it to the forward diffusion in LSGM will result in $\\hat{p_{r}}\\ne p_{r}$. But, $\\hat{p_{r}}$ would be only considered for visualization of the forward diffusion and it is not used for training or any other purposes. LSGM, the proposed PDM, and score-based models are all trained with a reweighting of ELBO (see [here](https://arxiv.org/abs/2106.02808)). It is not clear if the drawback mentioned above has an impact on the training or expressivity of the model.  * The presentation in the paper requires improvement. The motivation on why invertibility plays a key role is not clear beyond generating the visualization in Figure 2.   In summary, the paper proposes an interesting idea and explores directions very relevant to the current focus in generative learning. However, given the concerns above, we don't believe that the paper in its current form is ready for presentation at ICLR."
    ],
    [
        "This paper presents a method for algorithmically constructing Gaussian Processes based on Ordinary Differential Equations, where the objective strictly follows a given ordinary differential equation. The Smith normal form restricts the class of problems that can be tackled to linear, homogenous, ordinary differential equations with constant coefficient. The resulting LODE-GPs are compared to classic GPs in three experiments, showing better performance.  After the discussion phase, there was a consensus among the reviewers that this is a technically solid paper and the idea is interesting to the NeurIPS community. It has the potential to open up various avenues of research and therefore I recommend acceptance. However, the authors are highly encouraged to take into account the comments from the reviewers in preparing the final version of their paper. In particular, the revised version should include the additional experiments included in the discussion.",
        "The reviewers found this paper novel, significant for the community, and well written. All four reviewers recommended accepting the paper. I also appreciated the numerous illustrative examples in the paper. You addressed many of the remaining questions/concerns in your rebuttal and in the author-reviewer discussion. Please, go through the reviews once more for the camera-ready and take these into account."
    ],
    [
        "This paper introduces asynchronous variants of Red by Denoising (RED) and Asynchronous Red (RED-BY-Denoising) algorithms, which are effective in improving the speedup of RED by denoising while taking advantage of multicore resources. The reviewers appreciated the idea, but they were not convinced by the experiments. The experiments compare against other methods and do not show a significant speedup. Also some of the theoretical results are hard to interpret because they require strong assumptions to be met, such as Assumption 4 on the convergence of the Red algorithm.",
        "The reviewers agree that this paper overcomes a number of difficult algorithmic and technical challenges in parallelizing the RED method for image reconstruction."
    ],
    [
        "The paper aims to address the heavy performance drop that takes place in the large-batch training regime for object detection and segmentation. To this end, the authors propose AGVM - an optimizer-agnostic technique that can work with a very large batch size. While i have many low-level concerns about the paper positioning and quality, I am strongly in favor of paper acceptance. The paper is well-written, the proposed method is simple to implement, and the theoretical analysis is interesting. Experiment results on different kinds of dense prediction tasks like object detection, instance segmentation, panoptic segmentation validate the effectiveness of the approach.",
        "The authors describe a new method of large-batch optimisation for dense prediction computer vision tasks. The reviewers appreciate the simplicity of the method, convincing experiments and the potential practical importance. AC recommends acceptance."
    ],
    [
        "This paper investigated three types of emphasis effects in information visualisation: varying colour, size, and blur/focus. The authors found that blur was the most effective strategy to improve prominence in the visualizations.  Strengths: - The paper is well written and easy to follow. - The authors conducted a large-scale study and gain a lot of understanding from the results.  - The choice of visualizations in study 2 was based on their resemblance of scatterplots so the authors tackled the difficult issue of distance in the users' reaction metrics to the different effects and magnitudes.  Weaknesses: - Some of the findings are expected and not very surprising to the reader, e.g. the authors claim to have clarified how visualizations were chosen. They use 16 visualizations... Which ones??? I'd like to know exactly which forms were used. - More analysis is needed on the participants' reaction to the choices of the blur, size and shape. -",
        "The reviewers found that the article tackles of problem of relevance in formation visualisation, and that the studies bring relevant insights to the community. They nonetheless highlight of number of problems remaining in the article that should be addressed before being published.  1. Clarify the presentation of the study conditions (all reviewers). 2. Better integrate of the literature in relation to the problem tackled in the article, both in the related work section (R1) *and* in the discussion (R2). 3. Clarify the visualizations used in study 2 (all reviewers). 4. Expand on the limitations of the experiments and their analysis (R2) 5. Reflect and contextualise of the results may apply in the wild (R3)"
    ],
    [
        "The paper presents a new video text VQA dataset, along a new baseline. The reviewers’s key concerns are around the size and difficulty of the dataset; the authors successfully address those during the discussion and revision period. The dataset is likely to be of interest to the community and was non-trivial to construct. We congratulate the authors on the successful submission and look forward to seeing it at the conference.  Update: The authors are encouraged to take the reviewer comments into account when preparing the camera-ready version.",
        "The paper presents a new video text VQA dataset, along a new baseline. The reviewers’s key concerns are around the size and difficulty of the dataset; the authors successfully address those during the discussion and revision period. The dataset is likely to be of interest to the community and was non-trivial to construct."
    ],
    [
        "This paper studies an interesting problem of 'language drift' in multi-agent communication - namely, when two pretrained natural language agents are jointly optimized to communicate and solve some external non-linguistic objective, their internal communication often diverges to a code-like, unnatural communication system. This paper solves this \"language drift\" problem by requiring that the messages between agents be usable as inputs to an image caption retrieval system.  The paper is well-written, the experiments are thorough, and the results are encouraging. However, reviewers remain concerned that the experimental results are unfortunately much weaker than I would have hoped for. In particular, the datasets used are relatively simple and the improvements are marginal. We encourage the authors to update the paper based on the reviewer's comments and resubmit to a different venue.",
        "This paper proposes a method to resolve \"language drift,\" where a pre-trained X->language model trained in an X->language->Y pipeline drifts away from being natural language. In particular, it proposes to add an auxiliary training objective that performs grounding with multimodal input to fix this problem. Results are good on a task where translation is done between two languages.  The main concern that was raised with this paper by most of the reviewers is the validity of the proposed task itself. Even after extensive discussion with the authors, it is not clear that there is a very convincing scenario where we both have a pre-trained X->language, care about the intermediate results, and have some sort of grounded input to fix this drift. While I do understand the MT task is supposed to be a testbed for the true objective, it feel it is necessary to additionally have one convincing use case where this is a real problem and not just the artificially contrived. This use case could either be of practical use (e.g. potentially useful in an application), or of interest from the point of view of cognitive plausibility (e.g. similar to how children actually learn, and inspired by cognitive science literature).  A concern that offshoots from this is that because the underlying idea is compelling (some sort of grounding to inform language learning), a paper at a high-profile conference such as ICLR may help re-popularize this line of research, which has been a niche for a while. Normally I would say this is definitely a good thing; I think considering grounding in language learning is definitely an important research direction, and have been a fan of this line of work since reading Roy's seminal work on it from 15 years ago. However, if the task used in this paper, which is of questionable value and reality, becomes the benchmark for this line of work I think this might lead other follow-up work in the wrong direction.  I feel that this is a critical issue, and the paper will be much stronger after a more realistic task setting is added.  Thus, I am not recommending acceptance at this time, but would definitely like the authors to think hard and carefully about a good and realistic benchmark for the task, and follow up with a revised version of the paper in the future."
    ],
    [
        "This paper presents a novel weakly supervised semantic segmentation for both 2D-3D images and 3D point clouds. After the author response and discussion, all reviewers are positive about this work. The reviewers believe that the paper is well-written, novel, and well-motivated. The proposed method is effective and improves existing methods by a large margin. The experiments are comprehensive and demonstrate the effectiveness of the proposed method. The AC agrees with the reviewers.",
        "The paper proposes two constraints, transferring the knowledge from 2D domain to 3D domain and vice versa, to do weakly supervised semantic segmentation in 2D and 3D.  During inference the model doesn't require paired data.  The paper is clearly written, and explains how the 3D geometrical information complements the redundant dense 2D information.  The reviewers mention limited experiments.  However, the ablations are thorough, and show significant improvement over SotA performance.    The authors addressed the reviewers' comments during the rebuttal.  The reviewers agree that the benefits of the proposal outweigh its flaws.  I recommend the paper for publication."
    ],
    [
        "This paper proposes a method to prune deep neural networks. The aim is to reduce the computational cost and inference time while maximally maintaining the classification performance. The key challenge is to find a good objective that can be efficiently calculated to make the approach scalable to various modern convolutional networks. In particular, SOSP-I employs Hessian approximation while SOSP -H employs exact Hessian. The authors further show that the method can also be used to find and remove architectural bottlenecks, which further improves the performance of the pruned networks.  Overall, this paper has its merits. The proposed methods are designed to capture the correlations among all structures and layers, which is important for efficient pruning. The method of this paper is novel and technically sound. The numerical experiments show the effectiveness of the proposed methods in terms of accuracy and efficiency, and the ablation studies are comprehensive and convincing.",
        "Four reviewers have evaluated this submission with one score 6 and three scores 8. Overall, reviewers like the work and note that *a rigorous and principled approach is taken by this work*. AC agrees and advocates an accept."
    ],
    [
        "I actually enjoyed reading the paper myself and agree with the authors that the clinical challenge is important, the paper presentation is solid, and the contribution is solid and significant. The use of a multi-centre data set is another strength, aside from the contribution of the follow-up lesion prediction following up on the initial scan is interesting. Some of the questions by the reviewers could be addressed better, e.g. with a discussion of the limitations of the approach, but I think that the authors have addressed most of them to their satisfaction.",
        "While the reviewers raised some concerns about the experimental results, I agree with the overall sentiment that this paper proposes a promising temporal convolutional network for segmentation in 4D CTP data. The authors may want to consider updating the title of the paper as the \"outcome prediction\" term seems to be a source of common confusion."
    ],
    [
        "The paper investigates boosting in RL, i.e., how to convert weak learners into effective policies. The main idea is to use a variant of the Frank-Wolfe method to overcome the non-convexity of the value function and obtain an independent sample complexity independent of the number of states. This is an interesting idea and well-motivated. However, the paper has several weaknesses as pointed out by the reviewers: 1) the paper is hard to follow and its writing needs to be significantly improved; 2) the theoretical results are not very surprising and their main properties are not well explained; 3) the empirical results are very weak; 4) the technique is very similar to another recent work and the experimental results are inconclusive.  The authors did not respond to the reviewers' comments. Given the above, we do not think this paper is ready for publication at ICLR.",
        "The paper proposes a boosting algorithm for RL based on online boosting. The main advantage of the result is that the sample complexity does not explicitly depend on number of states. Post rebuttal, some of the reviewers have changed their opinion on the paper. However, overall the reviewers still seem to be on the fence about this paper. Seems like the paper combines the techniques from Hazan Singh’21 along with a frank-wolfe algorithm to deal with non-convex sets but the reviewers seem to view this as not as significant a new contribution.   I see the paper as being interesting but do agree with some of the comments of the reviewers and am leaning to a reject."
    ],
    [
        "The authors propose a method for efficiently automatically generating pool of sparse risk scores. They evaluate both the speed and accuracy of their approach on multiple benchmark datasets.  The reviewers found the paper to be solid and efficient, and the methodology to be a practical one. The main concern was the novelty of the work, which was found to be incremental. The paper's main contribution seems to be the use of beam search (a well-known method for sparse scoring) to automatically generate scores. The reviewers liked the simplicity and effectiveness of the approach, but were concerned about the lack of significant empirical improvements in terms of accuracy or speed. The experiments were added during the rebuttal period, but the reviewers did not find the results compelling enough to change their opinions.",
        "Thank you for submitting your paper to NeurIPS! This paper makes a valuable contribution to the scoring model literature, providing a fast and scalable algorithm to derive sparse risk scores. The reviewers uniformly appreciated the methodological approach (integrating beam search with logistic regression, diverse feature selection, and star search for choosing integer coefficients), and noted that the stand-alone Python implementation is also advantageous over competitors that rely on mathematical programming solvers. I am pleased to recommend acceptance of this practically relevant work."
    ],
    [
        "all reviewers agree that the weaknesses of this work outweigh the few positive aspects and thus the paper does not meet the bar for publication. No rebuttal or revision was provided by the authors. The authors are encouraged to take into serious consideration all the comments by the reviewers to improve their work for a future submission and resubmit to one of the MIDL's upcoming MIDL tracks.  PS: The segmentation of white matter in the brain is an important problem that receives quite a bit of attention from the medical community and deserves more attention than the one it receives in this paper which seems to ignore it.",
        "all reviewers agree that the weaknesses of this work outweigh the few positive aspects and thus the paper cannot accepted in the current form. No rebuttal or revision was provided."
    ],
    [
        "This paper develops a semantic type detection model DCoM, which takes column values as text in addition to auxiliary features extracted by Sherlock. The reviewers and AC note the critical limitation of novelty of this paper to solve a very natural problem. Existing methods adopt regular expressions or dictionary-lookup or feature engineering. To solve this problem, this paper adopts deep neural networks to process raw text tokens directly. It adopts novel architectures and differentiates itself from existing methods with novel architectures. The experimental results on the VizNet corpus show thatDCoM models with DistilBERT/ELECTRA outperforms Sherlock and other non-Deep Learning models.  Authors have successfully addressed some of the reviewers' concerns during the rebuttal. However, AC decided that the authors need more works to publish in ICLR.",
        "The paper studies semantic type detection.  The problem is of practical significance to  i  tabular data.  However, in its current form, there are concerns about  the scope of novelty and technical significance."
    ],
    [
        "The paper looks at leveraging successor features to actor-critic approaches for solving simple continuous control tasks. All reviewers found the topic interesting and timely, and while there were some concerns regarding clarity of the initial submission, the authors did a very good job at improving the draft during the rebuttal phase. The reviewers all agree that the paper should be accepted. Hence I recommend acceptance. I encourage the authors to take all the reviewer comments into account when preparing the final version of the paper.",
        "The paper presents an actor critic type of method consisting of two types of features -- dynamics and tasks, in the multi-task continuous control setting. While the topic of the research is interesting and relevant to ICLR, the reviewers have concerns with the novelty and technical significance of the work. Specifically, the proposed method is very similar to several other works leading to an incremental novelty. In addition, the method is evaluated only on simple environments. The concerns remain after the discussion period.   In the next version of the manuscript, the authors are encouraged to pursue more difficult settings and modify the method to work on those problems. That would make the paper stronger, and lead to a more novel method evaluated on harder problems."
    ],
    [
        "The paper provides a new analysis of the convergence of the proximal-GDA algorithm in the strongly concave regime when applied to non-convex strongly-concave functions. The main result is that the GDA method admits a Lyapunov function that monotonically decreases on every iteration. The reviewers agree that the analysis is novel and gives a new perspective on understanding the convergence behavior of GDA under the KL geometry. Some of the main weaknesses of the paper, however, are in the following two areas: (1) the analysis requires strong assumptions that are quite restrictive, and (2) the paper mostly shows results that are already known in the stochastic case. Nevertheless, I think providing a better theoretical understanding of the phenomenon is of interest to the non-machine learning community, and I recommend acceptance.",
        "The paper studies nonconvex-strongly concave min-max optimization using  proximal gradient descent-ascent (GDA), assuming Kurdyka-Łojasiewicz (KŁ) condition holds. The main contribution is a novel Lyapunov function, which leads to a clean analysis. The main downsides of the paper as discussed by the reviewers are the lack of experiments and somewhat stringent assumptions needed in the analysis. Nevertheless, the paper was overall viewed favorably by the reviewers, who considered it a worthwhile contribution to the area min-max optimization."
    ],
    [
        "This paper proposes a new approach to using ground depth as a depth cue for monocular 3D object detection. The ground depth is estimated by camera pose and vanishing point, and the ground depth information is further integrated with image features via an attention layer to form a ground depth map. The paper received a mixed evaluation from reviewers, ranging from borderline reject to strong accept. After author response and reviewer discussion, the reviewers did not come to a full agreement, with two reviewers leaning towards reject and two leaning towards accept.   The AC carefully read the reviews, responses, and discussions. The AC appreciates the authors' efforts to respond to the reviewers' comments and questions during the rebuttal period. After reading the reviews and the responses, the AC feels the authors did a reasonable job in responding to reviewers' concerns, and overall the AC's assessment is that the contributions of the paper are solid enough to merit the acceptance of this paper.  In the final version, the authors",
        "The paper received positive leaning reviews (2x borderline accept, 1x weak accept, 1x accept). The meta-reviewer agrees with the reviewers' assessment of the paper."
    ],
    [
        "This paper addresses the task of unsupervised knowledge base construction. The reviewers like that the authors present a novel and clever approach, and are happy with the thorough experiments. However, they also point out that the approach could be motivated better, and that it makes many assumptions that are not explained properly.  We recommend acceptance, but nudge the authors to consider the reviewers' comments and suggestions to improve the paper for the next iteration.",
        "This paper addresses the task of unsupervised knowledge base construction. The reviewers like that the authors present a novel unsupervised approach, and are happy with the thorough experiments. However, they also point out that the approach could be motivated better, and that it makes many assumptions that are not explained properly.  We recommend acceptance but nudge the authors to consider the reviewer suggestions."
    ],
    [
        "This paper proposed an extension of area attention, which is a very interesting and important extension of the current attention models, to allow for the consideration of the combination of adjacent words. The paper reported some interesting results on BLEU and perplexity tasks. However, some important concerns were raised by the reviewers, such as the lack of clear motivation and justification on why the proposed method is expected to work better than past extensions of attention, lack of clarity on the motivation, and lack of strong baselines and ablations. The authors did not provide a rebuttal. Hence, I cannot suggest this paper for presentation at ICLR.",
        "although the idea is a straightforward extension of the usual (flat) attention mechanism (which is positive), it does show some improvement in a series of experiments done in this submission. the reviewers however found the experimental results to be rather weak and believe that there may be other problems in which the proposed attention mechanism could be better utilized, despite the authors' effort at improving the result further during the rebuttal period. this may be due to a less-than-desirable form the initial submission was in, and when the new version with perhaps a new set of more convincing experiments is reviewed elsewhere, it may be received with a more positive attitude from the reviewers."
    ],
    [
        "This paper tests various pretraining objectives (language modeling, machine translation, skip-thought, and autoencoding) on two syntactic tasks: POS tagging and CCG tagging. It finds that language modeling outperforms the other Pretraining objectives; additionally, randomly-initializing an encoder achieves decent performance when given a large amount of labeled data.  The results are sensible but confirm what we already strongly suspected, which is that language models are very effective on POS tagging tasks (POS, CCG). The authors propose a new task for CCG which is likely to prompt more research in this direction.  All reviewers vote for accepting the paper, so I will follow their recommendation.",
        "Strengths:    -- Solid experiments  -- The paper is well written  Weaknesses:  -- The findings are not entirely novel and not so surprising, previous papers (e.g., Brevlins et al (ACL 2018)) have already  suggested that LM objectives are preferable and also using LM objective for pretraining is already the  standard practice (see details in R1 and R3).   There is a consensus between the two reviewers who provided detailed comments and engaged in discussion with the authors."
    ],
    [
        "The paper studies local asymptotic stability of min-max equilibrium, i.e. the stable points of gradient descent ascent with different step-sizes.  The authors' main result is that for any fixed point for the GDA dynamics, that point is stable for GDA with a large enough timescale separation if and only if it is a local Stackelberg equilibrium.   The reviewers' initial concerns were addressed satisfactorily by the authors during the rebuttal period. Thus, I recommend acceptance.",
        "This paper treats the problem of running gradient descent-ascent (GDA) in min-max games with a different step-size for the two players. Earlier work by Jin et al. has shown that, when the ratio of the step-sizes is large enough, the stable fixed points of GDA coincide with the game's strict local min-max equilibria. The main contribution of this paper is an explicit characterization of a threshold value $\\tau^*$ of this ratio as the maximum eigenvalue of a specific matrix that involves the second derivatives of the game's min-max objective at each (strict local) equilibrium.  This paper generated a fairly intense discussion, and the reviewers showed extraordinary diligence in assessing the authors' work. Specifically, the reviewers raised a fair number of concerns concerning the initial write-up of the paper, but these concerns were mostly addressed by the authors in their revision and replies. As a result, all reviewers are now in favor of acceptance.  After my own reading of both versions of the paper and the corresponding discussion, I concur with the reviewers' view and I am recommending acceptance subject to the following revisions for the final version of the paper: 1. Follow the explicit recommendations of AnonReviewer3 regarding the numerical simulations (or, failing that, remove them altogether). [The authors' phrase that \"The theory we provide also does not strictly apply to using RMSprop\" does not suffice in this regard] 2. Avoid vague statements like $\\tau \\to \\infty$ in the introduction regarding the work of Jin et al. and state precisely their contributions in this context. In the current version of the paper, a version of this is done in page 4, but the introduction is painting a different picture, so this discussion should be transferred there. 3. A persisting concern is that the authors' characterization of $\\tau^*$ cannot inform a practical choice of step-size scaling (because the value of $\\tau^*$ derived by the authors depends on quantities that cannot be known to the optimizer). Neither the reviewers nor myself were particularly convinced by the authors' reply on this point. However, this can also be seen as an \"equilibrium refinement\" result, i.e., for a given value of $\\tau$ only certain equilibria can be stable. I believe this can be of interest to the community, even though the authors' characterization cannot directly inform the choice of $\\gamma_1$ and $\\gamma_2$ (or their ratio).  Modulo the above remarks (which the authors should incorporate in their paper), I am recommending acceptance."
    ],
    [
        "This paper presents a new framework to describe and understand the dynamics of RNNs inspired by quantum physics. The authors also propose a novel RNN architecture derived by the analysis. Although this is mainly a theory paper, it would have a lot more strength if the authors provide some experiments to demonstrate the strength of the proposed architecture.   Overall, the meta-reviewer feels the paper is not ready for publication at ICLR. The major concerns are: 1) Since the framework is theoretically derived, it requires more than just a detailed theoretical analysis. Ideally, some experiments would be provided to demonstrate its usefulness. 2) Given that this is primarily a theoretical paper, some empirical results would be necessary to support the claims. 3) Since this paper is mostly on the theory side, some more experiments on real-world tasks would also be necessary.  The authors did not respond to any of these concerns. In its current state, the paper does not meet the bar for publication",
        "although the way in which the authors characterize existing rnn variants and how they derive a new type of rnn are interesting, the submission lacks justification (either empirical or theoretical) that supports whether and how the proposed rnn's behave in a \"learning\" setting different from the existing rnn variants."
    ],
    [
        "Primary strengths of the paper are 1) the hierarchical formulation of optimal transport as a distance between two distributions of histopathology slides, 2) extensive experimental validation on a variety of applications including transfer learning in rare cancer datasets, and 3) well written and easy to follow manuscript. The primary weaknesses are 2) lack of novelty in the theoretical analysis, and lack of convincing transfer learning experiments. Overall the paper can be accepted to MIDL based on the strengths above.",
        "All reviewers agree that the paper has value and proposed a fairly novel idea. This method is solely applied to digital pathology images and deserves future work, but it is interesting for the MIDL community."
    ],
    [
        "This paper provides a uniform generalization bound for over-parametrized neural networks when the size of the network goes to infinity. It is already known that training the network via gradient descent type algorithms is equivalent to learning via the Neural Tangent Kernel (NTK)  and the Matern kernels. In this work, the authors provide a more generalized equivalence of the NTK and NNGP kernels of MLPs and theMatern kernels for activation functions of form $max(0,x)^s$. They show that for a fixed x, $| f_{ntk}(x) | < Poly(n, log(1/\\delta)$ with probability greater than $1- \\delta^2$ for all x, the generalization error is uniform under this setting.   The main contribution of this paper is that it provides a tighter characterization of the eigenvalue decay of the neural tangent kernels associated with fully",
        "The paper provides a uniform generalization bound for overparameterized neural networks using the notion of maximal information gain. The analysis relies on the eigendecay of the eigenvalues of the NTK, which has recently been the object of a lot of work in the literature, including the work of Bietti and Bach (the proof actually uses one of their key lemma).  The paper originally received a set of reviews with a large disagreement between the reviewers (including two reviewers with a negative opinion and three reviewers being more positive). After the discussion period, two reviewers kept a very negative opinion, while other reviewers slightly lowered their score. Some of the problems raised by the reviewers include the restrictions imposed on the data, a missing proof (which was eventually added by the authors), the discussion of prior work being inadequate (including for instance the differences with more classical generalization bounds), and the novelty of the analysis.  Overall, the paper clearly has some merits but some of the concerns above are too important at this stage to accept the paper. I recommend the authors address the concerns mentioned in the reviews before re-submission."
    ],
    [
        "This paper proposed a model compress method for binary networks based on the Strong Lottery Ticket Hypothesis, and extended previous work on binary networks. The proposed method consists of three main parts: a) adaptively pruning different network layers; b) an effective binary initialization scheme; c) adding the last layer batch normalization layer. The experimental results demonstrated the effectiveness of the proposed method in terms of accuracy and robustness on several datasets, including CIFAR-10 and CIFar-100.  The reviewers generally agree that the paper is well-written and easy to follow. The paper has a strong contribution to the area of binary network compression, and will be a good addition to the conference program.  However, there are several concerns raised by the reviewers: 1) There is no ablation study on the impact of the added hyperparameters, 2) Experiments are only performed on small datasets, 3) The novelty and significance of the work is limited",
        "The reviewers agree the paper studies an interesting problem on training robust binary neural networks and the paper does a good job in evaluating the proposed approach on multiple datasets and compares well with baselines. However the paper also has some drawbacks such as the proposed method has limited novelty and is a combination of existing techniques, missing comparisons to standard training based approaches, evaluations limited to ResNets.  Overall the paper is on borderline. I suggest acceptance and encourage the authors to include all the changes that came up during discussion in the final version and discuss the limitations."
    ],
    [
        "This paper proposes an information-theoretic method to reduce task-irrelevant information in the feature vectors in the pre-trained representation for low-resource tasks. The idea is inspired by the idea of information bottleneck. Although it's a relatively incremental idea, the paper shows state-of-the-art results compared to other recent regularization methods, and the novelty partly stems from applying the DVIB to a new specific setting. The authors have addressed the reviewers' concerns through the discussion phase.",
        "The paper shows the success of a relatively simple idea -- fine tune a pretrained BERT Model using Variational Information Bottleneck method of Alemi to improve transfer learning in low resource scenarios.  I agree with the reviewers that novelty is low -- one would like to use any applicable method for controlling overfitting when doing transfer learning, and of the suite of good candidates, VIB is an obvious one -- but at the same time, I'm moved by the results because of: the improvements and the success on a wide range of tasks and the surprising success of VIB over other alternatives like dropout etc, and hence I'm breaking the tie in the reviews by supporting acceptance.  Its a nice trick that the community could use, if the results of the paper are an indication of its potential."
    ],
    [
        "The paper studies the problem of inferring a reward function from demonstrations from people or animals that have unknown biases, which can be used to model intrinsic rewards. Boltzmann rationalism is a generic model of bias that covers many animal and human behaviors and has been used to modeling a wide range of potential biases. The approach in the paper applies this model to the reward estimation problem in RL.   The paper addresses an important problem and makes non-trivial advances over the state of the art. The reviewers have pointed out several points for improvement and the authors have agreed to make changes to address them. I think the paper is above the bar for acceptance and encourage the authors to make the changes suggested by the reviewers.",
        "The authors study an inverse reinforcement learning problem where the goal is to infer an underlying reward function from demonstration with bias.  To achieve this, the authors learn the planners and the reward functions from demonstrations. As this is in general impossible, the authors consider two special cases in which either the reward function is observed on a subset of tasks or in which the observations are assumed to be close to optimal. They propose algorithms for both cases and evaluate these in basic experiments. The problem considered is important and challenging. One issue is that in order to make progress the authors need to make strong and restrictive assumptions (e.g., assumption 3, the well-suited inductive bias). It is not clear if the assumptions made are reasonable. Experimentally, it would be important to see how results change if the model for the planner changes and to evaluate what the inferred biases would be. Overall, there is consensus among the reviewers that the paper is interesting but not ready for publication."
    ],
    [
        "Four out of five reviewers recommend acceptance of the paper with a score of 7. These reviewers praise the quality and importance of the dataset. Moreover, all reviewers acknowledge the quality of the writing.  The authors have constructively engaged into the discussion with the reviewers, and have put a lot of effort into drastically improving their submission based on all reviewers' comments. The weaknesses raised by the reviewers have been successfully addressed.  In particular, the reviewer (dm8f) who gave a rating of 4 raised the following concerns:  1. There exist other time series anomaly detection datasets. 2. More anomaly detection methods should be considered in the experiments.  3. The finetune mode and distillation mode are not detailed, their pseudocodes should be provided.  I believe that the authors have sufficiently addressed these concerns.  Overall, the proposed dataset and benchmark will be valuable to the community. It has the potential to be a benchmark for future anomaly detection benchmarks. Based on the",
        "Four out of five reviewers recommend acceptance of the paper with a score of 7. These reviewers praise the quality and importance of the dataset. Moreover, all reviewers acknowledge the quality of the writing.  The authors have constructively engaged into the discussion with the reviewers, and have put a lot of effort into drastically improving their submission based on all reviewers' comments. The weaknesses raised by the reviewers have been successfully addressed.  In particular, the reviewer (dm8f) who gave a score of 4 raised the following concerns:  1. There exist other time series anomaly detection datasets. 2. More anomaly detection methods should be considered in the experiments.  3. The finetune mode and distillation mode are not detailed, their pseudocodes should be provided.  The authors have addressed these concerns as follows:  1. In their answer, the authors went through an extensive list of existing benchmarks and justified why they are not appropriate to solve their focused problem, and how their dataset differ from those. The main added value of the proposed dataset is its timespan and the fact that its occurring distribution shifts are natural (as opposed to synthesized). 2. The authors have expanded their experiments with more anomaly detection models. The new results corroborate the previous conclusions. 3. The authors have added the pseudocode algorithm in Appendix and have added code to replicate their experiments in the git repository.  I believe that the authors have sufficiently addressed the reviewer's concerns (and more).  For these reasons, I recommend acceptance of the paper."
    ],
    [
        "The paper attempts to learn domain-invariant representations for both clean and adversarial data in order to improve model robustness and clean accuracy. The main idea to solve this problem is to treat the problem as a domain adaptation problem by considering the data shift between adversarial and clean distributions. To achieve domain invariance, the authors propose a domain classifier that discriminates against adversarial examples and their corresponding feature representation and a neural network to generate domain invariant and robust feature representation.  The proposed method, DIAL, shows promising empirical results on two datasets (synthetic and natural images). The paper is well-written and easy to follow. The authors did a good job in the rebuttal. During the discussion phase, most concerns from the reviewers were well addressed. The additional results and clarifications from the authors convinced the reviewers. The final scores are 6,8,6,8. Thus, the paper is recommended for acceptance.",
        "The paper describes an adversarial training approach that, in addition to the commonly used robustness loss, requires the network to extract similar representation distributions for clean and attacked data. The proposed method is inspired by domain adaptation approaches that require a model to extract domain invariant/agnostic features from two domains. Although the experimental results are solid and technically sound, the novelty of the methodology is not enough, as the domain classifier and the gradient reversal layer are the same with those methods in domain adaptation such as \"unsupervised domain adaptation by backpropagation\". On the other hand, more recent SOTA methods are missing and only smaller scale datasets are used for evaluation. During the discussions, the major concerns from three reviewers are novelty.   I totally agree that the simplicity of the method should be a virtue. However, the idea of domain-invariant representation learning is already established well, and its application to adversarial training is quite intuitive to the community. Also, the similar methodology already exists in domain adaptation. According to the top-tier conference culture in the ML community, what most valuable is the novelty and insight, not the performance. In the end, I think that this paper may not be ready for publication at ICLR, but the next version must be a strong paper."
    ],
    [
        "WPipe is a technique that improves model parallelism for training large DNN models. The key idea is to sub-divide the model into two groups, update one group at a time, and update the other group at the end of the parallelism pipeline. This removes the need for resnet and avoids storing and updating resets. The experimental results show that WPipe can achieve higher throughputs and reduce memory footprint with similar final model accuracy while reducing the memory cost. PipeDream-2BW can be easily parallelized and optimized in the same amount of time using the same GPU and CPU hardware, while the overhead of WPipe is significantly reduced.  Pros: - The paper tackles an important problem of how to fit rapidly growing model sizes into slower growing device memory. - The experimental gains are significant.  Cons: - Improvement over PipeDream is marginal. Related to that, PipeDream 2BW has a number of hyperparameters that are optimized and optimized using the",
        "The paper proposes a new pipeline-parallel training method called WPipe. WPipe works (on a very high level) by replacing the two-buffer structure of PipeDream-2BW with a two-partition-group structure, allowing resources to be shared in a similar way to PipeDream-2BW but with less memory use and less delays in weight update propagation across stages. The 1.4x speedup it achieves over PipeDream-2BW is impressive.  In discussion, the reviewers agreed that the problem WPipe tries to tackle is important and that the approach is novel and interesting. But there was significant disagreement among the reviewers as to score. A reviewer expressed concern about the work being incremental and difficult to follow. And while these were valid concerns, and the authors should take note of them when revising their paper, I do not think they should present a bar to publication, both based on my own read of the work and also in light of the fact that other reviewers with higher confidence scores did not find novelty to be a disqualifying concern. As a result, I plan to follow the majority reviewer opinion and recommend acceptance here."
    ],
    [
        "This work addresses the need for better evaluation methods for medical deep learning models and proposes a multi-pronged approach to evaluate the robustness of healthcare ML models. It is well-motivated and addresses a unique and important challenge in ML for health. All reviewers have given positive feedback. The authors have answered major concerns raised by the reviewers and we are glad to see them update their final scores in the discussion phase. They have agreed to take care to correct any remaining errors in the final version.",
        "The paper introduces model-agnostic ways of quantifying predictive uncertainty and latent space differences in the situation when the distribution of data encountered during deployment differs from what the system was trained on and there is no access to the data itself. The model is evaluated on large scale EEG data.  The paper solves an important problem, in particular to the field of healthcare which has previously seen instances of models underperforming significantly at the time of deployment. As mentioned by the reviewers, this direction has not been sufficiently explored, so there is novelty in the problem itself, as well as in the solution. The experiments on EEG data were seen as convincing by the reviewers, though some questions were raised about the scope of the paper.  Overall, there is considerable merit in the work and recommend acceptance of this paper. In the camera ready, the authors should make sure not to overstate the applicability of their method. While this work could, in theory, be applied (or adapted) to other data, the merits of it outside of models trained on EEG data have not been demonstrated and should therefore not be stated as a given.  Reviewers x119 and PL6S have not engaged in the discussion although the authors responded to the issues they raised, which I kept in mind when issuing my recommendation."
    ],
    [
        "The paper studies Byzantine-robust distributed learning in the setting where worker nodes have heterogeneous (non-iid) data. It presents a bucketing scheme to reduce the heterogeneity of the data in order to increase the robustness of the federated learning in this setting. The paper presents both theoretical results and empirical results on a real-world dataset.   The paper is well-motivated, clearly written, and contains solid contributions. However, there are some concerns from the reviewers. The theoretical results are incremental, and the empirical results are in line with prior work. Also, the related work is not adequately discussed. In addition, some of the claims are too strong, and should be better moderated.  We encourage the authors to take into account the reviewers' comments to improve the paper and resubmit to another venue.",
        "This manuscript proposes and analyses a bucketing method for Byzantine-robustness in non-iid federated learning. The manuscript shows how existing Byzantine-robust methods suffer vulnerabilities when the devices are non-iid, and describe a simple coordinated attack that defeats many existing defenses. In response, the primary algorithmic contribution is a bucketing approach that aggregates subgroups of devices before robust aggregation. This approach is also easily composed with existing Byzantine-robust methods. The manuscript includes an analysis of the performance of the proposed approach, including an information-theoretic lower bound for certain settings.  During the review, the main concerns are related to the clarity of the technical contributions, and unclear technical statements. The authors respond to these concerns and have satisfied the reviewers. After discussion, reviewers are generally strongly positive about the strength of the manuscript contributions. The authors are reminded to make the final changes agreed in the public discussion e.g., discussion of the reduction to SGD when  $\\delta=0$"
    ],
    [
        "This paper provides an empirical investigation on the behavior of multi-headed attention in vision transformers. The paper interprets deep models as a series of independent blocks, and then proposes a new architecture, in which the last conversation block is replaced with multi-head self-attention. A series of empirical observations are made. Some main observation are that the poor performance of ViT in the small data regime is not due to overfitting but to issues induced into the optimization procedure.  The paper also presents a hybrid CNN-ViT architecture that combines some of the benefits of ViTs with advantages of CNNs. A new architecture -- AlterNet, with CNN block and MSA block -- is shown to outperform pure CNNs in both large and small data regimes.  Based on the observations a new model is proposed that combines convolution and MSAs. This paper provides a new perspective on the relationship between transformers and CNNs and makes some interesting observations. However, the current",
        "The paper presents an empirical analysis of Vision Transformers - and in particular multi-headed self-attention - and ConvNets, with a focus on optimization-related properties (loss landscape, Hessian eigenvalues). The paper shows that both classes of models have their strengths and weaknesses and proposes a hybrid model that takes the best of both worlds and demonstrates good empirical performance.  Reviewers are mostly very positive about the paper. Main pro is that analysis is important and this paper does a thorough job at it and draws some useful insights. There are several smaller issues with the presentation and the details of the content, but the authors did a good job addressing these in their responses.  Overall, it's a good paper on an important topic and I recommend acceptance."
    ],
    [
        "This paper introduces a new model-based policy optimization algorithm that explicitly tries to estimate the Jacobians of the underlying dynamics. It combines a standard value-gradient based method and a new sample-based method based on DDPPs. The experimental results in Figure 1 show the sample efficiency and show an improvement over the relevant baselines, using 5 trials. The paper also includes theoretical analysis.  The reviewers and AC note the following potential weaknesses: (1) the novelty of the approach is limited, (2) the core change proposed by the method does not provide very large improvements over baselines and (3) the baseline results without the gradient loss are better than the MAAC baseline.  During the rebuttal, the authors addressed some of the concerns, but not to the degree that reviewers think it passes the bar of ICLR. We encourage the authors to further improve the paper based on the reviewer feedback and resubmit to another venue.",
        "The paper considers model-based RL, and focuses on approaches that benefit from the differentiability of the model in order to compute the policy gradient. It theoretically shows that the error in the gradient of the model w.r.t. its input appears in an upper bound of the error in the policy gradient computing using the learned model. Motivated by this, it suggests a MBRL approach that learns two models, one of them minimizes the next-state prediction error (as commonly done) and the other minimizes a combination of prediction error and the gradient error.  The paper empirically studies the method through extensive experiments.  Reviewers are generally positive about this work. They believe that the paper is insightful and the method is original. At first, there were some important concerns raised by the reviewers, but the authors revised their paper in the discussion period, and it appears that the reviewers are all satisfied now. I also read the paper during the rebuttal phase, and I should say that I have some concerns myself, especially on the theory part of the paper. Given that the authors did not have an opportunity to answer my questions, I do not put much weight on my concerns (and I believe most of them can be addressed with some clarifications). Considering the positive response of reviewers and promising results, I am going to recommend **acceptance** of this paper.  I strongly encourage the authors to consider the comments by reviewers, as well as the following ones, in the revision of their paper.   **Comments**  1) The true dynamics $f$ is defined as a stochastic one, i.e., $s_{t+1} = f(s_t, a_t, \\epsilon_t)$ (just before Eq. 1), and similarly for the learned model. Here $\\epsilon_t$ is the noise causing the stochasticity of the model. But later, when the errors on the model and its gradient are introduced (i.e., $\\epsilon_f$ and $\\epsilon_f^g$), the role of stochasticity becomes unclear. For example, we have $\\|| \\tilde{f}(s,a) - f(s,a) \\||  \\leq \\epsilon_f$.  What happened to the noise term?  The same is true for Eq. (5). The next-state s' (either according to the true dynamics or the learned model) is random. In that case, it is not obvious how to interpret Eq. (5). Is it the error of the expected gradient of the next state? Or is it something else?  In case the dynamics is assumed to be deterministic, this should be clarified early in the paper.  2) The upper bound in Theorem 1 might be vacuous if the Lipschitz constant $L_f$ of the model is larger than 1. To see this, consider Lemma 1. The constant $C_0$ is $\\min [D/\\epsilon_f, (1-L_f^{t+1})/(1 - L_f)]$. If $L_f$ is larger than 1, for large enough t, the term $(1-L_f^{t+1})/(1 - L_f)$ blows up and $C_0$ becomes $D/\\epsilon_f$. Therefore, the upper bound of Lemma 1 becomes $D$. Here $D$ is the diameter of the state space, which is assumed to be bounded.  This carries to in the next lemmas. In Lemma 4, $C_5$ would be of the same order as $C_0$ (multiplied by an extra $L_1 L_f / (1 - \\gamma) )$, so the upper bound of this lemma becomes proportional to D too.  The $C_0$'s appearance continues in the proof of Theorem 1, in which $C_8$ is proportional to $C_0$ and $C_5$. So, $C_8$ is also become proportional to $D/\\epsilon_f$. When we have $C_8 \\epsilon_f$ in Eq. (34), we get a constant term $D$. A similar dependence appears in the proof of Theorem 2, where B_3 is proportional to $C_8 \\epsilon_f$, which can be as large as $D$. And in Eq. (47), we have $B_3^2$. So the upper bound in Eq. (47), which seems to the be upper bound of Theorem 2, is proportional to $D^2$. This means that if $L_f$ is larger than one, the upper bound does not go to zero, no matter how small the model error $\\epsilon_f$ is (unless it is actually zero). This makes the bound meaningless.  This might be unavoidable. I am not sure about it at the moment. But it definitely requires a discussion.  3) Assumption 2 has a term in the form of $E[\\frac{s_{t_2}}{ s_{t_1}} ]$ (I have simplified the form). The states $s_{t_2}$ and $s_{t_1}$ are vectors in general. How is the division defined here?  4) Please improve the clarify of the proofs. For example, in Lemma 2 it seems that a negative sign is missing in Eq. (49). Also how do we get Eq. (50) and Eq. (52)? (I couldn't easily verify them).  5) I believe the \"periodicity property\" used in Assumption 1 should be \"ergodicity property\".  6) The paper still has a lot of typos, e.g., \"To optimize the objective, One can ...\" (P3), \"argument data\" (instead of augmented) (p4), \"Superpose\" (p5), \"funcrion\" (p6)."
    ],
    [
        "Both reviewers give strong support for the paper and recommend acceptance. The authors commit themselves to open-source the dataset and codes for reproducibility which is a great strength of the paper. The dataset includes instance-based annotations which would be valuable for the community. Please consider adding these annotations to the paper (or include code in the open-sourced repo) for maximum impact.  Minor comments: - A typo in the abstract (section 3.2) mentioned by Reviewer 1: \"Alicia Mendler, Ankur P. Parikh, Dipanjan Das, Prasad Tadepallia, and Tom Kwiatkowski gave an open source code for attribute attribute annotations (https://arxiv.org/abs/2102.13132). This is part of an ongoing effort to develop open source tools for attribute annotations.\" Please add it to the camera ready version. - It would be great if the authors could add citation to the Jonas",
        "The reviewer praises the creation of this potentially very valuable dataset and while there are some shortcomings in the presented benchmark/baseline results, I believe these will be quickly addressed by the community if the data becomes more widely used. MIDL aims to give some space for the presentation of open source data and I therefore also recommend acceptance."
    ],
    [
        "The reviewers are in agreement that the paper should be rejected. Furthermore, the authors have declined to rebut the arguments of the reviewers. As such, I agree with the suggested rejection. However, I would like to encourage the authors to take into account the reviewers' comments and submit a revised version of the paper to a future conference. There are several opportunities for improvements/clarifications, including but not limited to: improving the quality of exposition; providing more details about the evaluation; improving the clarity of the text; taking into consideration the different comments by the reviewers when preparing the final version of their paper.",
        "The reviewers are in agreement that the paper should be rejected. Furthermore, the authors have declined to rebut the arguments of the reviewers. As such, I agree with the suggested rejection."
    ],
    [
        "This paper studies the effect of distribution shift and no single data point on the robustness of image-text models trained under Contrastive Language-Image Pre-Training (CLIP). Reviewers agree that the paper studies an interesting and important question, but also point for deeper investigation into the causes of the observed differences in robustness between different data points. The authors' rebuttal has addressed some of reviewers' concerns, but not to the degree that reviewers think it passes the bar of ICLR.",
        "This paper studies the effect of pre-training data on the robustness of pre-trained vision-language models such as CLIP. Both empirical and theoretical results are provided to show that simple scaling may not always improving robustness. This is a timely results that shed light on how to perform better pre-training to improve robustness to distribution shifts. All reviewers agree that the work is technically solid and the contribution is significant."
    ],
    [
        "The paper presented a very interesting idea of applying exponential smoothing to ERM which is a modification of empirical risk minimization (ERM) paradigm to obtain more robust or fairer results, using a tilted objective. The basic idea is interesting and novel, and all reviewers agree that it is well presented and justified theoretically and empirically. However, some major concerns remain after the discussion among the reviewers. In particular, technical novelty of the proposed method is limited, and it heavily relies on the key hyper-parameter t in the TERM loss, whereas other works have shown that it can be tunable independently. The applicability of the method is not clear, and there is a lack of theoretical analysis on how the method works experimentally, although it is supported theoretically.",
        "Dear Authors,  Thank you very much for your detailed feedback to the initial reviews and also for further answering additional questions raised by a reviewer. Your effort has been certainly contributed to clarifying some of the concerns raised by the reviewers and improving their understanding of this paper.  Overall, all the reviewers found a merit in this paper and thus I suggest its acceptance. However, as Reviewer #2 suggested, investigating the convergence in the stochastic case is very important. More discussion on this would be a valuable addition to the paper, which the authors can incorporate in the final version."
    ],
    [
        "This paper studies the multi-fidelity version of the best-arm-identification problem. The reviewers have agreed that the paper is well written and covers the prior work well, and that it is technically sound. The authors tackle establishing the best arm in a multi-arm bandit problem with varying levels of fidelity. They present and analyse a new algorithm, IISE, that theoretically outperforms basic bandit algorithms that do no exploit the multi fidelity structure of the problem. To this end, the authors also propose a new performance measure called cost complexity. Then, they give a lower bound for the cost complexity of this problem, which is upper-bounded by the IISE and is better than the regular cost bound for regularBAI.  There is a disagreement among the reviewers on whether this is a paper for NeurIPS. On the one hand, all reviewers agree that the problem is well-motivated and the paper well-written, and on the other hand",
        "This paper considers the multi-fidelity variant of the best-arm identification problem. I recommend its acceptance and I strongly encourage the authors to take the several fantastic points raised by the reviewers while crafting their next draft. For instance, please include a discussion about (and clarification of) Assumption 1 that reflects the discussion with the reviewers."
    ],
    [
        "The paper proposes a method for zero-shot learning for attributes. The proposed method decomposes the attributes into basic attributes, and then recombines these basic attributes into new ones, which can be used to solve Zero-Shot Classification (ZSC) problems. The experimental results show that the proposed method outperforms state-of-the-art methods on the CUB dataset.   All the reviewers agree that the paper is well-motivated and the idea of decomposing and recombining basic attributes to solve attribute learning is interesting. However, there are concerns on the experimental section. For example, more ablation studies and real-world applications are needed to convince the readers of the value of the decomposing-and-resembling method. The paper currently lacks enough experiments to support the claim.",
        "This paper has proposed a method named zero-shot learning for attributes to deal with a research problem about novel attribute classification and attribute labeling. The reviewers have many questions in the intial round. After the rebuttal, the authours clarify most unclear points, and some reviewers raise the score. In general, all the reviewers agree with the acceptance of this paper."
    ],
    [
        "This paper proposes a new method for training seq2seq models that does not require any MLE pre-training and can directly optimize from the sampling. The authors conduct a number of experiments and show that this scheme allows them to attain state-of-the-art performance on end-to-end speech recognition (STN) datasets and the reported results are a significant improvement over the sota  performance. All the reviewers consider this paper is well-written and the method is interesting. The method addresses concerns about exposure bias and about the typical MLE objective being different from the final evaluation metric for many tasks. This paper would be a great addition to the program of ICLR 2021. Authors, please address the issues raised by the reviewers in the final version.",
        "This paper proposes an algorithm for training sequence-to-sequence models from scratch to optimize edit distance. The algorithm, called optimal completion distillation (OCD), avoids the exposure bias problem inherent in maximum likelihood estimation training, is efficient and easily implemented, and does not have any tunable hyperparameters. Experiments on Librispeech and Wall Street Journal show that OCD improves test performance over both maximum likelihood and scheduled sampling, yielding state-of-the-art results. The primary concerns expressed by the reviewers pertained to the relationship of OCD to methods such as SEARN, DAgger, AggreVaTe, LOLS, and several other papers. The revision addresses the problem with a substantially larger number of references and discussion relating OCD to the previous work. Some issues of clarity were also well addressed by the revision."
    ],
    [
        "this paper is for the expert audience mostly and is difficult to grasp for people without deep learning for speech enhancement background.  authors work on this problem based on three novel techniques:  a) a complex U-net,  b) a new complex mask representation, and  c) an objective function motivated by SDR.  Some human listening tests using MOS or preference score are conducted.  experimental results show the proposed method has superior performance over the baselines.   The paper is well written. The proposed method is reasonable, and authors have added some human evaluation results. However, still this paper is a little bit too specific to the speech enhancement applications. It would have been nice to see also some simple baselines adapted for this purpose.",
        "The authors propose an algorithm for enhancing noisy speech by also accounting for the phase information. This is done by adapting UNets to handle features defined in the complex space, and by adapting the loss function to improve an appropriate evaluation metric.  Strengths - Modifies existing techniques well to better suit the domain for which the algorithm is being proposed. Modifications like extending UNet to complex Unet to deal with phase, redefining the mask and loss are all interesting improvements. - Extensive results and analysis.  Weaknesses - The work is centered around speech enhancement, and hence has limited focus.   Even though the paper is limited to speech enhancement, the reviewers agreed that the contributions made by the paper are significant and can help improve related applications like ASR. The paper is well written with interesting results and analysis. Therefore, it is recommended that the paper be accepted."
    ],
    [
        "This paper presents an approach for improving an existing machine learning architecture, the retriever-reader architecture, for open-domain QA, by iteratively retrieving passages with user-interaction, and tuning it with reinforcement learning. The approach is evaluated on a QA dataset against several strong baselines. The reviewers agree that the paper is well-written and the paper has interesting ideas. However, there are concerns about how much novel technical novelty there is in the paper compared to prior work (e.g., retrieval-based approach for open domain QA + multi-step reasoning approach for retrieval) as pointed out by R1, R2, and R4. The author response was not sufficient to address these concerns. Given these concerns, we encourage the authors to revise the paper and submit it to a future venue.",
        "pros: - novel idea for multi-step QA which rewrites the query in embedding space - good comparison with related work - reasonable evaluation and improved results  cons:  There were concerns about missing training details, insufficient evaluation, and presentation.  These have been largely addressed in revision and I am recommending acceptance."
    ],
    [
        "This paper shows that deep convolutional networks (CNNs, without pooling) with a suitable prior over weights can be seen as shallow Gaussian processes (GPs) by extending an argument by Matthews et al. (2018a) and Lee et al (2017) to include infinitely many channels, provide a computationally tractable approach to compute the corresponding GP kernel, and achieves state-of-the-art results on the MNIST dataset.  While the reviewers acknowledge that the proposed approach is interesting, they also point out several weaknesses: (1) limited novelty (the extension is mostly heuristic and based on existing arguments), (2) the method is not scalable to large datasets (I am surprised the authors managed to run this experiment on full MNIST), (3) no theoretical analysis is done, (4) the paper lacks in terms of theorem statements.  Overall, the reviewers are not convinced by authors' response and they think this work is not",
        "This paper builds on a promising line of literature developing connections between Gaussian processes and deep neural networks.  Viewing one model under the lens of (the infinite limit of) another can lead to neat new insights and algorithms.  In this case the authors develop a connection between convolutional networks and Gaussian processes with a particular kind of kernel.  The reviews were quite mixed with one champion and two just below borderline.  The reviewers all believed the paper had contributions which would be interesting to the community (such as R1: \"the paper presents a novel efficient way to compute the convolutional kernel, which I believe has merits on its own\" and R2: \"I really like the idea of authors that kernels based on convolutional networks might be more practical compared to the ones based on fully connected networks\").  All the reviewers found the contribution of the covariance function to be novel and exciting.  Some cited weaknesses of the paper were that the authors didn't analyze the uncertainty from the model (arguably the reasoning for adopting a Bayesian treatment), novelty in appealing to the central limit theorem to arrive at the connection, and scalability of the model.  In the review process it also became apparent that there was another paper with a substantially similar contribution.  The decision for this paper was calibrated accordingly with that work.  Weighing the strengths and weaknesses of the paper and taking into account a reviewer willing to champion the work it seems there is enough novel contribution and interest in the work to justify acceptance.  The authors provided responses to the reviewer concerns including calibration plots and timing experiments in the discussion period and it would be appreciated if these can be incorporated into the camera ready version."
    ],
    [
        "The paper studies the problem of overlapped communication in distributed training and proposes a new algorithm called Distributed SGD which combines local SGD with delayed averaging steps to hide the communication overhead but workers still synchronize their forward/backward passes in each iteration. The paper is well-written and easy to understand. However, the reviewers think it is not a very novel idea and a very similar method has already been proposed very similar in [1] with very similar idea. The theoretical analysis is also very limited. Finally, experiments are not convincing enough to support the claims of the paper.",
        "This paper proposes a variant of stochastic gradient descent that parallelizes the algorithm for distributed training via delayed gradient averaging. While the algorithm (DaSGD) proposed is sensible and seems to work, it also seems to miss a lot of related work. As pointed out by one of the reviewers, the class of asynchronous decentralized methods already seem to cover the space of DaSGD, and it's not clear how DaSGD differs from the existing methods in this space. As a result of this lack of comparison to related work, the reviewers recommended that the paper not be accepted at this time, and this evaluation was not challenged by an author response. I agree with this consensus."
    ],
    [
        "This paper studies the problem of decentralized stochastic non-convex optimization and provides several novel results including rates that are significantly tighter than existing bounds. The reviewers found this to be a technically solid paper that advances the state of the art. For the final version, the authors are encouraged to incorporate the reviewers' comments to improve the presentation and clarify some of the points raised in the reviews. In particular, it would be useful to discuss how the new results might be useful for other applications (e.g., in the case of non-stationary PL).",
        "This paper presents some new results on near-optimum algorithms for distributed optimization, nearly matching lower bounds. Most of the reviewers are positive about the contributions of this work. However, one issue that came up is the assumption of bounded gradient dissimilarity, which is essentially a gap between upper and lower bounds. While I am recommending to accept this paper, I believe this gap should be more prominently discussed in the abstract and introduction."
    ],
    [
        "The paper proposes a technique for controlling the productions of a Transformer-based pretrained generator by augmenting the architecture of the pretrained model with a special \"content-conditioner\" block which is able to exploit a contextual condition. CoCon has the capacity to condition on the entire input sequences. The authors show that it can take an arbitrary phrase as the hint after generating the embedding but before generating the text. Experiments showed that the control is effective at directing the generated text.  The paper tackles the problem of controlled text generation by converting it into a conditional text generation similar to (Keskar et al.19). It proposes an architectural modification to the transformer LM used in GPT2. A CoCon layer is added as a separate transformer block in the middle allowing self-attention to be performed. This allows the model to perform conditional conditional generation while still maintaining the top-down attention of the transformer, which is important for downstream tasks such as text",
        "The paper aims at controllable generation by introducing an additional \"content-conditioner\" block in the Transformer models. The paper further provides 4 different variants of a pre-training task to train the content-conditioner model.   While the proposed approach seems an incremental contribution over CTRL and PPLM, certain reviews praised the approach being novel while keeping the architecture changes minimal. Overall, reviews indicate that the overall proposed method of fine-grained controlled generation with self-supervision is valuable, and empirical results support its effectiveness.   All reviewers initially raised concerns regarding clarity and lack of human evaluation. However, clarity issues seem to be resolved through author/reviewer discussions and the updated revision.  R3 had important concerns regarding topic and sentiment relevance evaluations.   While the reviewer remains unconvinced after discussions with authors, after carefully reading the revised paper and discussions, I feel that the authors tried to address this point fairly  through their additional experiments and also edited their contribution statement accordingly.  Overall, at least two reviewers sounded very excited about this work and other than R3's concerns, the general sentiment about this work was positive. Therefore, I recommend weak accept.    There are still some writing issues that I strongly encourage authors to carefully address in the future versions. Quoting from reviewer discussions:  > Differentiability of the adversarial loss. Authors just added one statement saying \" Through continuous approximation..\" without any more details are given, which continuous approx was used (Gumbel softmax?) and how they overcame the problem of its training instability.   > Table 6, can be misleading, authors bold the results when cocon+ is performing better than baselines (mostly in content similarity) but not the other way around topic/sentiment accuracy. The latter is arguably more important."
    ],
    [
        "This paper aims to improve continual semantic segmentation by addressing the overcompression issue in model learning. To this end, the authors introduce wider convolution for final feature extraction and apply dropout to the output of the feature encoder. The effectiveness of the proposed methods have been demonstrated on the PASCAL VOC dataset.  Overall, the paper is well-written and the proposed method is interesting. The major concern of the paper lies in the limited novelty as the novelty is achieved through \"simple tricks\". The reviewers also feel that the experiments should be improved with more analysis on different setups and data.   I recommend the acceptance of this paper.",
        "This paper deals with continual learning in semantic segmentation.  Authors introduce wider convolution at final feature extraction layer and apply dropout to limit the overcompression issue.   No reviewer was convinced by the approach and they have raised many issues, including model design choice, training protocol and missing experiments.   No rebuttal has been provided by the authors.   As it is, this submission is not ready for publication, and we encourage the authors to consider the reviewers feedbacks for future publication."
    ],
    [
        "This paper presents an interesting idea of using multi-granularity features for source code summarization with a pyramid attention mechanism for feature aggregation and distribution across different granularities. The idea is inspired by the fact that source code is written in a hierarchical way. Reviewers find the idea interesting and the paper well-written. However, there are some important concerns about it. 1) The paper does not provide limitation section nor analyze the results qualitatively. Authors are encouraged to provide more details about the results. 2) More ablation studies are needed to better understand the benefits and limitations of the proposed method. 3) Evaluation on more tasks and datasets would make the paper stronger. Overall, the paper is on the borderline.",
        "The paper presents a multi-granularity input represenaion and a pyramid attention mechanism for code summarizaiton tasks. After extensive discussion, the reviewers still cannot agree on accepting or rejecting this paper. The key discussion points and my opinion are summarized in below.    1. Performance improvement -- a few reviewers point out the performance improvement is relatively small (about 1%) compared with baseline. With the additional error bar provided by the authors, it seems to me the improvement is statistically significant. The authors also provide sufficient ablation study to justify the improvement. Although it's arguable if the proposed appracoh is substantial, the progress of AI is often driven by incremental improvement in terms of performance. Therefore, I'm less concerned by this issue.   2. Comparison only on 1 language and 2 datasets. I partially agree with the authors and reviwers Xtyo that the paper already conducted extensive experiments and the merits of the proposed approach are justified. However, I disagree with the attritue that the comparison on 1 language is sufficient given the recent progress of code summariziton. As the proposed approach is mainly justified by empirical comparison, conducting results on a limited dataset raises the concern whether the proposed approach is generalizble to other languages and datasets. It also makes future work harder to compare with this work. I especially disagree the point that some earlier papers only compared on limited datasets. These papers are published earlier than the benchmark CodeXGlue has been released. As most recent baselines are compared on CodeXGlue, there is a need to justify the missing of results on this dataset. Besides, the argument of the dataet is noisy the performance is low do not seem rigorous and reasonable to me.  3. Human evaluation. The authors provide a preliminary study of human evaluation on the generated outputs. On one hand, it shows the proposed approach indeed improve the quality of the summary, but on the other hand, the study requires more rigorous design. I would suggest including the human evaluation on the main text rather than in appendix.   4. Presentation. The paper is mostly well-written and provide nice intuition behind the propose method. However, I also agree with Q2Zz that some statements might overclaim and require justification. The later part of the paper has significant number of typos and require a careful proofread. It's pity that the authors do not take the opportunity during the rebuttal period to revise the paper.  Overall, I think the paper has sufficient merits but still have room to improve."
    ],
    [
        "The paper proposes a hypergraph-based method for action representation learning in reinforcement learning. While the reviewers agree that the representation learning for high-dimensional action spaces is an interesting direction, they find the technical contributions (particularly the use of hypergraphs to represent the decomposition of action-value functions in multidimensional action spaces) to be borderline incremental, and in addition they are unconvinced by the experimental results, which are evaluated only in a few simple grid-world environments. Therefore, the paper does not seem ready for publication at this time.",
        "After reading the reviews and rebuttal and looking over the paper, I feel that the results are indeed strong, and the paper could have an impact in terms of exploiting the relationship among action dimensions. Maybe the only detail that I would add is that going through the example given in Fig 1 completely could be useful as it might not be perfectly obvious how (e.g. considering a simple mixing function like summation) one retrieves the q values for someone not familiar with this particular topic."
    ],
    [
        "This paper explores the time-varying features of salamander retina in response to natural movies, by modifying a U-Net architecture to predict future movie frames from responses to the previous frames. While the paper is well organized and the logic flow is good, the reviewers expressed concerns about the significance of the contributions, especially the novelty and significance of some of the findings. The reviewers agreed that the paper needs a major revision to better motivate the contributions and clarify the significance.",
        "The authors analyze the latent representation of visual features from natural movies in the salamander retina using a U-net. They train an encoder to learn a compressed latent representation from a large population of salamander retinal ganglion cells responding to natural movies, while a decoder samples from this compressed latent space to generate the appropriate movie frame. They characterize its representation of “time in the natural scene” in the latent space of their model.  Overall, the reviewers expressed a lot of interest in the topic and valued the novel application to salamander retinal data. There were some questions about the significance of the finding, and through the rebuttal period, the authors provided a number of experiments to compare against other variants of their baselines (and ablations), with some reviewers increasing their scores in favor of acceptance.   At the same time, there was concern that the U-Net architecture could potentially reconstruct the movie without any retinal data. Thus, it was not entirely clear whether the model was truly leveraging the retinal data to obtain meaningful outputs. Unfortunately, this concern was not fully addressed in the revision, leaving the reviewers overall with mixed views but the majority in favor of acceptance."
    ],
    [
        "This paper proposes a model, called PoET, for single-view, multi-object 6-D pose estimation. The backbone object detector (Scaled-YOLO-v4), which produces multi-scale features and bounding boxes, is then used by an attention-decoder model to process each detected object, using an architecture based on Deformable DETR. The model then predicts rotations and translations, using geodesic loss and L2 distance, from the captured RGB images.  Reviewers generally agree that the approach is novel and achieves state-of-the-art results on the YCB-V and LM-O datasets for RGB-only methods.  However, there are concerns from multiple reviewers on why the performance of PoET is better than existing methods. The only input to the system is the RGB image, it does not use depth maps or 3D models. Reviewers also note that the dataset used for evaluation is limited and",
        "Dear Authors,  Thank you for submitting your manuscript to CoRL. I'm happy to inform you that your paper is acceptable for publication. We have completed the review of your manuscript and a summary is appended below.  The reviewers have advised accepting your manuscript as a poster after improvement of the quality of the manuscript presentation based on the comments. Please note it is crucial to incorporate all provided explanations from authors to convince the reviewers and recommended editing into the final manuscript.  Regards,"
    ],
    [
        "Meta Review: Granger causal modeling is an important topic in machine learning with many applications. The reviewers agree that the paper makes an interesting contribution to this area. The experiments are extensive and provide some insight into the hyperparameter h in the proposed model. There are some concerns regarding the lack of sufficient explanation on how the method can be applied in real-world scenarios and the limited number of experiments. In the rebuttal the authors have added more explanation on prior methods, and have shortened the experiment part.",
        "Meta Review: In this paper, the authors proposed a new method for forecasting and other prediction  analyses for multiple time series dynamic networks. All the reviewers consider that the proposed method is fundamental and useful."
    ],
    [
        "This paper considers the problem of classifying unlabeled data that lies in an uninformative subspace, under a two-part partitioning assumption: informative and unpredictable regions of the space.  The paper shows that a once-in-a-world classifier can identify these uninformed subspaces due to the structure of the feature space under which it can be segmented into informative and completely unpredictable parts, and thereby learns a classifier from the informative subspace while abstention can only select regions that are in the uninteresting part of the subspace.  Reviewers all agreed that the paper is well-written, clearly organized and easy to follow, and considers an important problem relevant to the ICLR community. The theoretical results, though highly stylized and based on a novel formulation of supervised learning with abstention, are revealing and provide a good starting point for future work.",
        "This paper studies a learning scenario in which there exist 2 classes of examples: \"predictable\" and \"noise\". Learning theory is provided for this setting and a novel algorithm is devised that identifies predictable examples and makes predictions at the same time. A more practical algorithm is devised as well. Results are supported by experiments.  Reviewers have raised a number of concerns (ranging from how realistic this settings is to missing references). Overall they found this work interesting and relevant to ML community and appreciate the effort that authors have put in in their thoughtful response. However, after a thorough deliberation conference program committee decided that the paper is not sufficiently strong in its current form to be accepted."
    ],
    [
        "The paper presents an f-divergence between two support distributions that may have different supports. The reviewers agree that the idea is interesting. However, they also point out that the paper needs a bit more work before being accepted to a top venue like ICLR.  In particular, the paper focuses too much on keeping the identity of the indiscernibles and forgets the study of other properties, including downsides, such as variance increase. The paper needs to be edited and motivated better.",
        "This manuscript proposes spread divergences as a technique for extending f-divergences to distributions with different supports. This is achieved by convolving with a noise distribution. This is an important topic worth further study in the community, particularly as it related to training generative models.  The reviewers and AC opinions were mixed, with reviewers either being unconvinced about the novelty of the proposed work, or expressing issues about the clarity of the presentation. Further improvement of the clarity, combined with additional convincing experiments would significantly strengthen this submission."
    ],
    [
        "This paper studies the task of source code summarization and proposes an approach to provide a more language-agnostic representation of the code without language specific features, by augmenting the standard seq2seq model with additional structural information from an abstract syntax tree (AST). The approach is simple, well motivated, and the experiments convincing. Code2seq and GREAT datasets are used as benchmark datasets and the results show that Code Transformer does better than these models.  Reviewers agree on the importance of the problem, the empirical results are strong, and that this work puts it in a good position relative to previous work. Reviewers also agree on several aspects of the paper that are improved after the rebuttal such as the clarity of the writing, experiments on additional datasets and analysis of the model's performance when additional positional information is added.  The main area of improvement for this paper seems to be in the experiments, where more information about the relative semantic similarity across languages and also more analysis",
        "The paper gives an extension of the transformer model that is suited to computing representations of source code. The main difference from transformers is that the model takes in a program's abstract syntax tree (AST) in addition to its sequence representation, and utilizes several pairwise distance measures between AST nodes in the self-attention operation. The model is evaluated on the task of code summarization for 5 different languages and shown to beat two state-of-the-art models. One interesting observation is that a model trained on data from all languages outperforms the monolingual version of the model.  The reviewers generally liked the paper. The technical idea is simple, but the evaluation is substantial and makes a convincing case about setting a new state of the art. The observation about multilingual models is also interesting. While there were a few concerns, many of these were addressed in the authors' responses, and the ones that remain seem minor. Given this, I am recommending acceptance as a poster. Please incorporate the reviewers' comments in the final version."
    ],
    [
        "This paper presents an empirical study of pretrained GPT-2 language model, image model, and training from scratch for offline RL. The study looks at the differences in activations, parameters, and gradients as well as the impact of the context length during final fine-tuning. The reviewers have a consensus on rejection due to limited novelty compared to prior works. Pre-trained models are already known to perform well on language tasks, and image pre-training seems like a natural next step.",
        "The paper unanimously receives positive rates thanks to strong motivations and interesting results. As the reviews show satisfaction on the authors’ feedback, the final draft needs to respect it accordingly, for example, about the limitations of this research."
    ],
    [
        "This paper uses Moreau envelope theory to obtain generalization bounds for a broad class of losses over linear predictors. Although similar results have been published in the literature, the generality of the results due to the use of Moreau envelopes make them interesting. The setting is fairly broad, as it allows for models misspecification and more general loss functions. One main issue with the paper is that some of the assumptions made are not transparent and seem to be difficult to verify. Nevertheless, the authors address this issue in their rebuttal and all the reviewers agree that this paper should be published.",
        "The manuscript proves a new (finite-sample) generalization bound for generalized linear models, using Moreau envelope theory. The paper also provides experimental validation.  While the results only hold for Gaussian data, I believe there is some interesting novel results which might inspire some future work in the learning theory community. (In comparison, several novel frameworks have been created in the past for other problems, in which the initial versions assumed Gaussianity, e.g., the work on support recovery on sparse linear regression, for instance.)  Several technical clarifications regarding the assumptions (e.g., surrogate distribution, comparison to prior results) were asked by the reviewers, which the authors thoroughly and successfully addressed during the rebuttal phase. I recommend adding this to the camera-ready version of the paper, as well as other discussions and clarifications raised by all the reviewers."
    ],
    [
        "importance sampling is used to reweight the demonstrator/novice observations according to the imitator observations at training time.  The paper addresses an important problem in imitation learning. The paper is well-written and the theory is solid. The originality is limited, but the paper presents an interesting solution to an interesting problem. Experiments on Mujoco and Atari demonstrate that the proposed method gets the best imitation learning performance.   The authors have addressed most of the concerns raised by the reviewers, and the reviewers agree that the paper should be accepted.",
        "In this paper, the authors tackle the problem of demonstrators and learners having different observation spaces, by proposing an importance-weighted learning algorithm to bring the support of the imitator state marginal closer to that of the expert demonstrator's state marginal.   All reviewers have voted to weak accept, but it would seem that this year's NeurIPS mechanism of reviewer assignment has resulted in a much higher acceptance rate than typical, with 80%+ of the AC batch having accept votes. As such, I am tasked with the tough job of rejecting some papers that reviewers were only lukewarmly excited about. It pains me to do this to a paper that reviewers have found methodologically correct. I will be recommending this paper be rejected based on calibration against other papers I'm AC'ing, mostly for the following reason:  The HOIL paper assumes a problem setting where:  1. expert observations with more privilege observations than learner:  2. access to expert observations being high cost and invasive  3. importance-weighting the data to close the support between learner and expert state distributions mitigates (1) and (2)  However, it's not demonstrated that (1) and (2) is an actual problem in practical applications. Is sensor mismatch between human and autonomous vehicles the actual problem for learning? Do self-driving cars even utilize a policy formulation explored in the HOIL paper? How big are these state / support mismatches in practice, and couldn't they be mitigated by simpler methods? This paper is the first I've heard suggested that sensor mismatch between humans and autonomous vehicle sensors is the bottleneck for performance. If we remove this motivation from the paper and only consider the importance weighting algorithm used for removing out of distribution examples, then it doesn't feel quite as novel as there are many works that propose some kind of distribution-projection step as a way to mitigate state marginal differences between teachers and learners (e.g. CQL).   In fact, the setting (1) is not only avoided, but actively exploited by some learning papers (Asymmetric Actor Critic, Guided Policy Search, and other ideas) to *boost* the sample efficiency of learning, with the idea that the asymmetry in state support allows experts to provide useful learning signal in a way that the learner cannot adversarially overfit easily.   From reviewer pD56,  ``` I didn't find the authors' response to be particularly convincing (the self-driving example doesn't seem like a good fit for what they're doing, and I think they're conflating differences in perceptual accuracy with differences in sensing hardware). ```"
    ],
    [
        "This paper proposes a novel machine learning architecture that is in the form of matrix exponential non-linearities. The idea is to use the matrix exponential as a layer in a neural network. The reviews are generally positive and find the paper is clear and easy to read. There are some concerns regarding the robustness results, but they are based on a very basic result on matrix exponentials. The authors provide a robustness result however it is not very convincing. Also, the computational cost seems high.",
        "This paper was reviewed by 4 reviewers who scored the paper below acceptance threshold even after the rebuttal. Reviewer 4 is concerned about motivation, Reviewer 2 rightly points out that there exist numerous works that use some form of spectral layers in a deep setting on challenging datasets - something lacking in this work. Reviewer 3 is concerned about limited discussion on lie groups and the overall benefit of expm(.). Reviewer 1 reverberates the same comments regarding insufficient experiments,  comparisons and limited motivation. We encourage authors to consider all pointers given by reviewers in any future re-submission."
    ],
    [
        "The paper describes a system that assists medical residents and their reviewers in keeping track of their learning progress during the training process in a medical training program.   The reviewers appreciated the extensive feedback given to the authors, which assisted in significantly improving the clarity and organization of the paper. Also, all reviewers agreed that the system is likely to be useful for others in the medical IT field.  The main areas of weakness pointed out by the reviewers were related to the limited novelty of the work, the lack of in-the-wild usage data, and the possibly limited assessment of the system. However, the authors were able to provide additional information and validated their work through additional user studies and the reviewers have all increased their scores accordingly. I believe that this work will be of interest to the audience attending the conference and I recommend acceptance.",
        "The reviewers are in agreement that this is a well-motivated paper and should be accepted. As R1 mentioned, the contribution does not lie in a novel visualization but rather in the process, insights, and patterns learned during the design and evaluation process.   The reviewers also agreed that the design implications section lacked depth. This is the one area where the paper has the biggest scope of improving. The reviewers have offered suggestions for different approaches to addressing this shortcoming.   Some other comments worth highlighting: R1 has raised some concerns regarding how the 5 questions were selection and would like added details regarding the process.  R2 would like some discussion around the prior approach or set-up that this system replaced.  R3 has provided detailed feedback on minor changes which will improve the overall readability of the paper and can be accomplished prior to the camera ready submission."
    ],
    [
        "This paper proposes a novel, probabilistic model for visual question answering with a particular focus on discrete structured latent variables. The model is compared to state-of-the-art models on the SHAPES dataset. Reviewers agree that the paper is well written and the model addresses the challenge of learning discrete latent variables in the presence of uncertainty. However, reviewers raised questions regarding the novelty of the technical contributions (variational neural module networks vs. variational autoencoders), evaluation metrics, and scalability of the model to larger datasets. In the rebuttal and discussion phases, authors were able to address most of the concerns raised, and reviewers were satisfied with authors' responses. Overall, all reviewers recommend acceptance. AC agrees with the reviewers and recommends acceptance.",
        "This paper proposes a latent variable approach to the neural module networks of Andreas et al, whereby the program determining the structure of a module network is a structured discrete latent variable. The authors explore inference mechanisms over such programs and evaluate them on SHAPES.  This paper may seem acceptable on the basis of its scores, but R1 (in particular) and R3 did a shambolic job of reviewing: their reviews are extremely short, and offer no substance to justify their scores. R2 has admirably engaged in discussion and upped their score to 6, but continue to find the paper fairly borderline, as do I. Weighing the reviews by the confidence I have in the reviewers based on their engagement, I would have to concur with R2 that this paper is very borderline. I like the core idea, but agree that the presentation of the inference techniques for V-NMN is complex and its presentation could stand to be significantly improved. I appreciate that the authors have made some updates on the basis of R2's feedback, but unfortunately due to the competitive nature of this year's ICLR and the number of acceptable paper, I cannot fully recommend acceptance at this time.  As a complete side note, it is surprising not to see the Kingma & Welling (2013) VAE paper cited here, given the topic."
    ],
    [
        "The paper presents an empirical study of binary weight networks (BWNs). They find that there exists a subnetwork that stabiles early in training and propose a novel quantization algorithm that achieves more aggressive compression than standard BWNs.  The reviewers agree empirically that weight signs are more important than weight magnitudes. The authors also exploit the latter to propose a new quantization method that increases the compression of binary networks. The experiments include numerical results for a wide range of data sets and networks. However, the reviewers agree that the empirical study is still preliminary and needs to be further improved. The idea that weights with large norms are stable and sensitive on sign changes can be utilized for improving the training of BWN's and maybe BNNs. It is also suggested to study how the effect of these findings changes with other models and architectures.",
        "## Description The paper discovers interesting phenomena in training neural networks with binary weights: - Connection between latent weight magnitude and how important its binarized version for the network performance -training dynamics, indicating that large latent weights are identified and stabilize early on - Observation that amongst learned binary kernel, several specific patterns prevail, up to the bits who's reversal has very little effect. This is so regardless of the architecture, the layer considered or the dataset.  The paper further demonstrates how these observations may be used to compress binary neural networks below 1 bit per weight.  ## Review Process and Decision The reviewers welcomed the experimental investigation of new phenomena, but commented the overall technical quality of the work as somewhat substandard. The redundancy of consecutive affine transforms is known and not connected to binary weights investigation. The investigation itself lacks a more in-depth analysis. The proposed compression results appeared not convincing to reviewers since a significant drop of accuracy occurs. The AC shares these concerns and supports rejection.  ## General Comments From my perspective, the study undertaken is methodologically „wrong“. An ad-hoc training method is investigated, which is not even clearly defined in the paper (there are many „STE“ variants) and for which it is not known what it is doing, what are the real-valued weights for and whether they are needed at all (as empirically argued by Helwegen et al. (2019)). As such, the investigation makes impression of poking a black box (the training method in this case). At the same time, there are more clear learning formulations, applicable in the setting of the paper (binary weights), in particular considering the stochastic relaxation: * Shayer et al. (2017): Learning Discrete Weights Using the Local Reparameterization Trick * Roth et al. (2019): Training Discrete-Valued Neural Networks with Sign Activations Using Weight Distributions * Peters et al. (2018): Probabilistic binary neural networks  These methods are approximate, but at least the optimization is well posed and it is known what do the real-valued weights represent (e.g. logits of binary weight probabilities). From this perspective, it can be seen that latent weights close to 0 correspond to Bernoulli weights that are almost fully random (and thus only contribute noise) and are fragile to gradient steps. Therefore the model can only perform well if it learns to be robust to their state or their state becomes more deterministic (corresponding to large latent weight). So one would actually expect to see in these models phenomena similar to the observed in the paper and not bee too much surprised or astonished by them. Furthermore, there are recent works explaining STE and its latent weights as optimizing the stochastic relaxation: * Meng et al. (2020): Training Binary Neural Networks using the Bayesian Learning Rule * Yanush et al. (2020): Reintroducing Straight-Through Estimators as Principled Methods for Stochastic Binary Networks.   The authors are encouraged to make the observed phenomena more explainable by connecting to the mentioned works.  ## Further Details  *  „We show that in the context of using batch normalization after convolutional layers, adapting scaling factors with either hand-crafted or learnable methods brings marginal or no accuracy gain to final model.“  From theoretical perspective, this is obvious and known to me. Practically, there could be in principle some difference due to the learning dynamics, and verifying that there is none is a useful but a weak contribution. The section devoted to this issue can be given in the appendix but is not justified in the main paper.  * „change of weight signs is crucial in the training of BWNs“  The sign determines the binary weights, so this is by definition.  * „ Firstly, the training of BWNs demonstrates the process of seeking primary binary sub-networks whose weight signs are determined and fixed at the early training stage, which is akin to recent findings on the lottery ticket hypothesis for efficient learning of sparse neural networks“  In the lottery ticket hypothesis paper it is shown explicitly that the identified sparse subnetwork changes during the learning the most rather than retains its initialization state or the state in the beginning of the training. It is therefore could be of a different nature."
    ],
    [
        "This paper investigates the memorization effect/behavior in adversarial training in perspective of model capacity, convergence, and generalization. They first investigate the difference of memorization behavior between two adversarial. training methods, PGD-AT and TRADES, with random labels, and discover that model capacity differs from training on true labels. They also discover that robust overfitting can occur with memorization and use temporal ensembling to mitigate it. Lastly, they propose a mitigation algorithm by a regularization term for avoiding the excessive memorization of adversarial examples and show that it works well.  The paper is generally well-written and provides new insights on the convergence properties of AT. However, the findings in the paper are disconnected and some of them lack explanations, making it hard to get a clear consensus. The reviewers have pointed out some of these issues in the discussion.   I encourage the authors to take into account the reviewers' comments to improve the paper and res",
        "This paper demonstrates that deep networks can memorize adversarial examples of training data with completely random labels, which motivates some analyses on the convergence and generalization of adversarial training (AT). The authors identify a significant drawback of memorization in AT that could result in robust overfitting and propose a new algorithm to mitigate this drawback. Experiments on benchmark datasets validate the effectiveness of the proposed algorithm. One of the reviewers is concerned about (1) the validity of stability analysis where 80% of the data labels are noisy, and the perturbation (64/255) is large, (2) the gap between theory and practice, and (3) novelty. The authors have made a great effort to address these concerns. Although there is still no consensus after the author's response, the majority of the reviewers are in strong support. I, therefore, recommend acceptance."
    ],
    [
        "The paper proposes a novel convolution operation, called FlexConv, for learning convolutional filters with kernels that are learnable in terms of their bandwidth and kernel size. The paper is well-written and the results compared with state-of-the-art baselines are convincing. The reviewers raised some issues regarding the novelty of the paper, but the rebuttal addressed most of them well. As a result, two of the reviewers raised their scores. Overall, since all the reviewers agree that the paper is a good fit for publication, I also recommend accepting the paper.",
        "This submission proposes a method for learning convolutional filters with trainable size, that builds on top of multiplicative filter networks.  Anti-aliasing is achieved by parametrization with anisotropic Gabor filters.  The reviewers were unanimous in their opinion that the paper is suitable for acceptance to ICLR.  The authors are encouraged to make use of the extensive reviewer discussion in improving the final version of the paper."
    ],
    [
        "The authors propose a method for hierarchical reinforcement learning (HRL) with a two level hierarchy, with the lower level controller controlling both the upper and lower level policies. The authors propose to simplify the training by separating the computation of the state representation into proprioceptive and task-specific parts, which leads to a reduced training cost. The reviewers raised some concerns regarding the clarity of some of the statements, as well as the experimental results, which the authors have tried to address in their rebuttal. However, the reviewers agree that the paper still needs some more work in order to clarify the main points of the paper, and they are not convinced that the current version is ready for publication. I will therefore recommend rejection, and encourage the authors to submit to a future venue.",
        "Strengths   The paper presents a method of training two-level hierarchies that is based on relatively intuitive ideas and that performs well. The challenges of hierarchical RL makes this an important problem. The benefits of periodicity and the separation of internal state from external state is a clean principle that can potentially be broadly employed.  The method does well in outperforming the alternative baselines.  Weaknesses  There is no video of the results. There is related work, i.e., [Peng et al. 2016] (rev 4) uses  a policy ensemble;  phase info is used in DeepLoco/DeepMimic; methods such as \"Virtual Windup Toys for Animation\"  exploited periodicity (25y ago);  More comparisons with prior work such as Florensa et al. would help.  The separation of internal and external state is an assumption that may not hold in many cases. The results are locomotion focussed. There are only two timescales.  Decision  The reviewers are largely in agreement to accept the paper.  There are fairly-simple-but-useful lessons to be found in the paper for those working on HRL problems, particularly those for movement and locomotion.  The AC sees the novely with respect to different pieces of related work is the weakest point of the paper.   The reviews contain good suggestions for revisions and improvements;  the latest version may take care of these (uploaded after the last reviewer comments). Overall, the paper will make a good contribution to ICLR 2019."
    ],
    [
        "This paper proposes a new method to solve combinatorial optimization problems with reinforcement learning. The key novelties and contributions are an RL-based approach to train the widely-used GCN model to generate probability heatmaps, and a meta-learning approach to finetune the solutions at inference. The proposed method is evaluated on TSP instances (size 500, 1000, and 10000) and MIS problems.  The paper is well-written and the method is theoretically well-motivated. The experiments are convincing. During the rebuttal, the authors have addressed most of the concerns raised by the reviewers. All the reviewers agree that the paper should be accepted, and so do I.",
        "This paper proposes a differentiable meta-solver applicable to large-scale combinatorial optimization. After a thorough discussion phase, all the reviewers are on the positive side of this paper. The reviewers appreciated the novelty of this paper and the importance of scaling neural combinatorial optimization for large-scale instances. Overall, I recommend acceptance for this paper.  However, the reviewers also showed concerns about the presentation of this paper. The gap between generalization and testing performance is not clearly discussed and the connection to prior works using continuous latent space should be clearly stated. Since scalability is an important issue, it would be useful to clear up time/objective comparison and unify experimental settings as suggested by Reviewer fQdp and fe3B."
    ],
    [
        "Both reviewers agree that the results presented in this paper are impressive and worthy of publication at MIDL. I recommend acceptance. As suggested by reviewer 1, it would be great if the authors could add a discussion of the limitations of the proposed approach (e.g., runtime, complexity, more parameters for the synthesized and synthesized+deformed versions of the phantoms), and how this approach compares to other approaches that generate realistic phantom-like deformation fields.",
        "The paper contains interesting ideas and fits well within MIDL's short paper scope of also providing a live discussion space for accepted journal publications. Given that unfortunately only one reviewer was available, whose weak reject is mostly based on formatting, I believe that the paper can still be accepted. However, I strongly urge the authors to reformat their paper to be consistent with the MIDL style when preparing the camera-ready version."
    ],
    [
        "This paper propose a framework to obtain the disentanglement of syntactic roles as latent variables for sentence representations, by using a attention-driven VAE to separate latent variables based on syntactic role in the latent space.  The paper is clearly written and the main idea is very exciting. Reviewers agree that it is well-motivated and the experiments are convincing. However, there are several concerns that remain unaddressed even after the rebuttal phase. First, it is still unclear why the performance of the model is directly linked to the attention mechanism. Is it due to the fact that the model makes use of attention, as opposed to more 'generic' attention-based models such as RNNs?  Second, the encoder-decoder framework seems to heavily rely on the GCN design. In particular, encoder and decoder networks are very similar.  Overall, the paper is still not ready for publication. The authors are encouraged to take",
        "This paper proposes improving human interpretability and manipulability of neural representations by obtaining syntactic roles (here, subject, object, prepositional object, and main verb) without supervision by means of them becoming linked to latent variables in a novel proposed attention-driven VAE (ADVAE) model, which provides cross attention between a language transformer and latent variables. The paper argues that syntactic roles are quite central to meaning interpretation and that the ADVAE recovers them better than LSTM or Transformer (with mean pooling) VAEs.  This is a quite interesting direction and paper. There was active discussion with the reviewers, one of whom (9pDc) moved their rating from reject to quite strong support, while the other reviewers either sat on the fence or raised from reject to borderline. Nevertheless, I overall tend to agree that the paper is still lacking in empirical support, a view clearly shared by reviewers WuPD and 7uFL. The SNLI data is very simple descriptive sentences, nearly all in the form of S V O or S V PP. Would this work on more complex data, in other languages, or with more word order variation? There isn't very much investigation, but the new results added during reviewing based on Yelp data seem to offer more concerns than confidence. These are also very short sentences but with more varied structure and some complementation. It seems like D_{dec} is now very low (much lower than for the sequence VAE), the ability to distinguish out grammatical roles seems limited to {subj} vs. {dobj, pobj} in the encoder and none at all in the decoder (Figure 6/7). And then for the examples in Appendix D, the disentanglement abilities barely seem stronger than being able to pick out subjects, though when there are sentences with subordinate clauses, it is perhaps random which subject you get. The resampled realizations in appendix H also seem to show limited disentanglement: resampling the subject usually seems to change the object as well, often markedly. No convincing downstream applications are shown. As such, while I agree that disentanglement is at the heart of representation learning, I can't get on board with reviewer 9pDc feeling that this paper now has convincing results. Reviewer 7uFL also emphasizes that there is no strong reason that the latent variables have to align with syntactic roles. In particular, the motivation in NMT whereby constituents clump and reorder together does not exist here. It may only work for the very simple and regular sentences of SNLI.  Hence, overall, I feel that this method needs more extensive validation on harder, more varied data sets before it becomes a convincing contribution, and so I propose rejecting the paper at this point in time. Nevertheless, I do think the topic is interesting and this approach has the potential to be good."
    ],
    [
        "This paper explores methods for improving the consistency of prompt-based factual probing of pre-trained language models. P-Adapters is a model that is between the embedding layer and first attention layer of LLMs. It takes LLM embeddings as input and output prompts used to query the LLM. The work evaluates the performance of the models using a pooled collection of fact-seeking prompts (e.g., LAMA, LPAQA and ParaSel) The results show that different interventions in the inputembeddings cause large differences in inter-prompt consistency. This is an important problem for consistency in training LLMs and the paper does a good job in studying it. Overall, all the reviewers are positive to accept the paper. There are some concerns on the computational cost and training time. The authors provide additional results in the rebuttal. We suggest the authors report the results in table 10 and add discussion on computational complexity.",
        "This paper introduces a prompting technique for eliciting factual knowledge from frozen pretained transformer LMs. The key idea is to modify the embeddings produced by the embedding layer before they are passed to the first attention layer and the paper investigates several different design choices. The Reviewers all agree that the paper tackles an important problem with interesting methods, that it is well written and has strong results. The main concerns, raised by Reviewer jddf, were about clarifying the connections to the robust optimization literature and evaluating on OOD relations. The former has been addressed in the revised version. While the latter point remains valid, I find that the paper in its current state has enough useful experiments and analysis to warrant publication. The authors have clarified most of the other points raised by the reviewers in their rebuttal."
    ],
    [
        "This paper investigates the behavior cloning-based strategies of offline RL algorithms, studying different variants and motivations behind them. The results indicate that more complex design choices, such as the large sequence models and value-based weighting schemes used in some prior works, are generally not necessary for achieving good performance in offline RL.  The reviewers appreciated the comprehensive experiments and analysis presented in this paper. They also expressed concerns regarding the expressivity of policy architecture, regularization, choice of conditioning variables, and the recipe to perform policy regularization offline. The paper aims to address a very important problem in RL. However, the reviewers found that many of the technical details are missing and the presentation can be further improved.  We encourage the authors to incorporate the reviewers' comments to improve the paper for its next iteration.",
        "The paper studies the behavior cloning based strategies of offline RL algorithms in different type of environments and reports that performance primarily depends on model size and regularization. The results contradict some of the earlier claims, and the authors conjecture that model size and regularization characteristics can explain past results.    During the review period, the reviewers agreed that the paper has certain merits, and on the other hand, they also raised some concerns, regarding some missing technical details, whether the empirical finding could be trusted, the generalization of the findings to more scenarios, and the comparison with some highly related papers. The authors did a good job in their rebuttal, which removed many of the above concerns (although not all) and convinced the reviewers to raise their scores. As a result, we believe it is fine to accept the paper (although somehow like a weak accept)."
    ],
    [
        "This paper proposes a new method for learning zero-sum Markov Games with kernel function approximation using value-target regression and provides regret bounds in terms of the effective dimension of the kernel. The reviewers all agree that the paper is well-written and the results are novel, interesting, and provide new insights. The authors have also addressed the concerns raised by the reviewers during the rebuttal period. Overall, it is a good paper and I recommend acceptance.",
        "This paper considers the problem of online reinforcement learning in two-player zero-sum Markov games. They consider a class of Markov games called kernel mixture Markov games, which extend the linear mixture MDP setting considered in prior work to the RKHS setting. The main result is to propose and algorithm called KernelCCE-VTR, which uses the principle of value-targeted regression to achieve regret bounds that scale with the effective dimension of the kernel. The authors also provide an improved variant of the algorithm based on Bernstein-type confidence bonuses.  The reviewers found the setting to be important and found the paper to be well-written, and agreed that the main results are technically challenging and likely to be a useful starting point for future work on learning Markov games with function approximation. The main issue raised by the reviewers is that the algorithm design and analysis appears to be based on a combination of well-known existing techniques for simpler settings---for the final revision, the paper can be strengthened by more strongly advocating for the novelty required in combining these techniques."
    ],
    [
        "The paper proposes an independent mechanism that divides hidden representations and parameters into multiple independent mechanisms, for the Transformer architecture. The authors evaluate their models on the image transformer model, speech enhancement, and NLP tasks.  The paper is well-written and the formulation is interesting.  However, reviewers raised a lot of concerns about the experimental setup, the novelty and the significance of the paper, and poor presentation. In particular, the experiments on a toy image Transformer and speech enhancement demonstrate the effectiveness of the proposed approach, however, it is not clear whether such an approach can be applied on more complex real-world applications.  We encourage the authors to address the comments raised by the reviewers to improve their paper.",
        "The reviewers agree that the idea of introducing structural biases in the attention mechanism is interesting but the results and presentation right now is not convincing. Improvements are seen on only some datasets and the comparisons are not exact. A reject."
    ],
    [
        "This paper proposes a method for generating small molecules by combining autoencoder networks with graph neural networks. The key idea is to generate a scaffold of motifs and support atom-by-atom generation by using a motif-specific initial seed along with a graph convolutional neural network encoder. The seed is generated along with the motifs, and the GCN encoder predicts the graph based on the given motifs. Experiments show that the proposed method is able to generate high quality molecules compared to some existing methods.  The reviewers agree that the paper is well written and easy to follow. The idea is novel and the experimental results are promising. However, there are some concerns about the technical novelty of the work as the main idea is not presented as a complete framework. In addition, a more thorough ablation study is needed to better understand the role of the different components of the proposed framework.",
        "Most reviewers were positive about the paper, seeing that the proposed method is practical and has convincing experimental performances. One reviewer was a bit negative and raised questions about clarity. After the authors responded, the negative reviewer didn't respond further. After reviewing all the comments, the AC feels that there is enough support from reviewers to accept this paper."
    ],
    [
        "This paper derives a novel lower bound for the GP posterior contraction rate when the true function has an additive structure and under compositional assumptions. For any GP in such a scenario, the contraction rate is worse than the minimax estimation rate of deep GP.  The paper is well-motivated, well-written and easy to follow. The work is significant enough for publication in this venue.  On the other hand, all work in this area is somewhat abstracted from practical reality. This is a purely theoretical work and there is no empirical study. Therefore, the authors have not discussed negative societal impact of their work. In the future, they should try to make their work more applicable to real-world applications.",
        "The reviewers unanimously agree that the theory here exhibiting a particular case where Gaussian process priors are inferior to deep Gaussian processes is interesting, and furthermore that the proof techniques themselves are novel. Indeed, reviewers had minimal or no substantial concerns about the paper, and most of the questions asked by reviewers txpX and sPbe read as simple follow up questions that the authors may choose to include discussion on."
    ],
    [
        "Thank you for your submission to NeurIPS.  This paper investigates a new variant of fair division -- a multi-agent allocation problem that combines MMS and EF1 fair division.  All reviewers were positive about the novelty and the quality of the paper. However, all reviewers (and I) found the motivation for this problem (and the motivating example) to be weak and/or unconvincing, and the result to be a rehashing of existing ideas. In particular, the paper does not motivate well the use of the word \"pairing\" in the problem definition, and it is unclear why this is expected. The motivating example is also rather artificial and lacks any real-world relevance. We encourage the authors to strengthen their paper by developing the problem and motivating it better.",
        "Reviewers agreed that the model is new and interesting and the theoretical results are solid. The main criticisms are about the model: some reviewers felt that it is too specific and there is not enough motivation. Some reviewers liked the technical depth while others felt that it is not enough to compensate for the lack of motivation. Overall, reviewers felt that the paper in its current form is not ready for publication at NeurIPS."
    ],
    [
        "The paper received four detailed reviews and there was a reasonable amount of interaction between authors and reviewers. After rebuttal, the reviewers were not convinced about some of the main claims in the paper (e.g., that SOTA semi-supervised learning methods neglect spatial information and that the proposed method exploits inherent knowledge on the sample distribution via clustering to improve the latent space), and also felt that the novelty of the work was not high enough. In particular, the paper seems to rely heavily on well-known techniques and the experiments do not necessarily support these claims very well.",
        "All reviewers agree that the writing is not precise. It does not help to find any novelty in the ideas, and the limited and too quickly described experiences are not convincing enough to forgive this problem. The authors chose not to oppose or comment on the detailed arguments provided by the reviewers. I agree with the reviewers in recommending the rejection of this paper."
    ],
    [
        "In this paper, the authors study the problem of data selection in the presence of bad training data by maximizing the utility function $U$ over all subsets of cardinality $k$. The authors first show that the valuation based approaches can have bad performances, and propose the DataSifter algorithm to solve the combinatorial optimization problem with a general purpose. While the reviewers think the proposed framework of DATASIFTER is interesting and novel with promising results, they also agree that the paper lacks some empirical/theoretical evidence to support its claims. In particular, empirical evidence on the effectiveness of the proposed method is lacking, which makes the paper's claims less convincing. The authors are encouraged to strengthen their paper by addressing the reviewers' comments and resubmit to another venue.",
        "The paper considers the question of identifying bad data so that models can be trained on the subset of data that is good. This question is formulated as a utility optimization problem. The paper shows that some popular heuristics are quite bad in the framework they propose. They also propose a new algorithmic framework called DataSifter. There is empirical evaluation provided for this. Questions have been raised in the reviews about the size of the models that have been used in the empirical evaluation. The authors have responded to this by suggesting the use of proxy model techniques. There are also questions about learnability of data utility for which some responses are provided in the rebuttal."
    ],
    [
        "This paper presents a new task and model for predicting the hierarchical structure of organizations / institutes. The model predicts is-ancestor relationships between the institutions by modeling the set operations between the strings. The authors develop a new dataset, automatically derived from GRID, and compare their set-based model against a few baseline approaches.   The reviewers agree that the task presented in this paper is interesting and useful. However, there are concerns on the novelty of the work as it mainly relies on the previously proposed Isomap question. Furthermore, the experimental evaluation is limited to a single dataset and comparison with a few baselines. Therefore, the paper does not meet the standard of publication at ICLR.",
        "This paper presents a new task and model for predicting the hierarchical structure of organizations / institutes. The model predicts is-ancestor relationships between the institutions by modeling the set operations between the strings. The authors develop a new dataset, automatically derived from GRID, and compare their set-based model against a few baseline approaches.   The reviewers’ comments were generally positive and praised the usefulness of the task, which makes us recommend acceptance. However, there were some concerns about the experimental setup (choice of baselines and evaluation).   We strongly recommend improving these aspects on the final version, as per the reviewers’ suggestions."
    ],
    [
        "Contextual HyperNetworks (CHN) are used to incorporate new features into existing models. They are also used to extend existing models to deal with the new features. The paper is generally well written and the approach is interesting. It is applied to a P-VAE and some empirical results are provided to demonstrate its effectiveness. There are however, some important concerns raised by the reviewers that are not well addressed by the authors' rebuttal. In particular:  1. The novelty of the method is limited. It seems that the main contribution is the idea of using CHN to an existing model and applying it to a recommender system architecture. The approach is not novel. 2. The baselines compared with MAML are weak. 3. A more detailed ablation study is required to evaluate the benefits of the proposed approach.  Overall, the paper has some interesting ideas, but the work is not ready for publication.",
        "This work presents a straightforward and easy to understand method for using hypernetworks to adapt existing models to be able to increase their output space. The method itself is also interesting and is detailed enough for reproducibility. However, the experiments and results should be improved by expanding the demonstration of CHNs beyond the narrow P-VAE application and comparing against relevant baselines in the recommendation system literature.  Pros - Clear writing. - Detailed hyperparameters to aid reproducibility. - Straightforward model.  Cons - Lack of sufficient comparison to related work, especially to existing recommendation systems that handle the cold-start issue and to Vartak, 2017. - Limited results that only demonstrate application to P-VAE meaning it's still unknown if CHNs work well with other models. The result on the synthetic dataset is also less persuasive. - Lack of sufficient ablations, i.e. training a SVM/linear regression model until convergence."
    ],
    [
        "This paper studies automatic tuning of the hyperparameters of the smoothing parameters in the Directional Gaussian Smoothing algorithm. The problem is well motivated and the paper is well written. However, as agreed by all the reviewers, the contribution of this paper is marginal compared to previous work. The default target precision is quite low (0.5% of the diameter of the space). The authors could consider instead optimizing the precision beyond this point.   Furthermore, the tuning set can potentially be very sensitive to the parameter $\\alpha$, as pointed out by some reviewers. The authors are encouraged to analyze the sensitivity of their method to this parameter.",
        "The main goal of this paper is to develop a new adaptive strategy to remove the need of hyperparameter fine tuning, which hinders the performance of DGS (Zhang et al., 2020) method. This paper applies a line-search of the step-size parameter of DGS  to reduce tuning.  A heuristic update rule of the smooth parameter in DGS (Zhang et al., 2020)) is also used.   Pros + The topic of learning hyperparameters on the fly is well-motivated and an important direction to improve many existing methods. + A wide range of tasks are considered in the experiments are interesting, with a wide range of tasks considered.    Cons - Reviewers have found the contribution to be incremental and marginal. Specifically, the reviewers have expressed concerns on the impact of the work since it verifies improvement upon DGS only. The paper could be stronger by showing evidence of improving other algorithms.  -  In the work of [Zhang et. al., 2020], there are two parameters that require careful selection - the learning rate and smoothing radius. However, the proposed approach still relies on some hyperparameters. Although the authors claim that the method is not sensitive to these hyperparameters, it could be better justified.  - The initial version lacks evaluation of the adaptive mechanism, although the authors added the comparison in the revised version.  - The paper could be further improved by comparing against other hyperparameter optimization methods.   We acknowledge the detailed response and the modifications of the manuscript. We believe the paper will make a more profound contribution and impact after addressing some of the major concerns raised by the reviewers."
    ],
    [
        "This paper proposes a new data distillation approach based on neural feature regression that is similar to a truncated backgprop through time using a pool of models. The proposed approach obtains a new state-of-the-art performance both in terms of accuracy and training efficiency while avoiding using a surrogate objective like previous works.   After rebuttal and discussion, the reviewers agree that this work makes a strong contribution to ICLR and the meta-reviewer agrees. The authors are encouraged to include the additional experiments and discussions they provided in the rebuttal to the final version.",
        "The paper proposes a new algorithm for dataset distillation, based on two key ideas:  (1) train a linear layer given the fixed feature extractor, and (2) use a diverse set of modes as feature extractors. The paper has received overwhelmingly positive reviews. Many reviewers find the algorithm effective, the paper well-written, and the results compelling. The rebuttal further addressed the concerns regarding the backbone models and missing experiments as well as provided additional clarifications. The AC agreed with the reviewers’ consensus and recommended accepting the paper."
    ],
    [
        "This paper presents an approach for graph-based logical reasoning to answer questions. Subject-predicate-object triples (subjects, predicate-object) are extracted from the text using dependency parsing and the resulting representations serve as input to the final classification layer for answer prediction. After forming a subgraph, reasoning is performed by a graph convolution module to predict the correct answer.  Strengths:  1 - The paper is well-written and easy to follow.  2 - In the experiment section, the authors show that the proposed FOCAL REASONER outperforms the previous SOTA models.  Weaknesses:  3 - Graph reasoning is evaluated only on one dataset. It would have been great to see evaluation on other datasets.  4 - Evaluation of the proposed approach on more datasets would make the paper stronger.  This paper received 4 reject recommendations. The reviewers have raised concerns that the novelty of the paper is limited since the extraction of fact tri",
        "Strengths: * Well-written paper * Strong empirical results on three benchmarks * Interesting approach of producing semantically augmented LMs using dependency parses to extract svo triples, and finding coreferences between them across multiple sentences  Weaknesses: * None of the reviewers seem particularly excited about the paper * Stronger baseline comparisons would have improved the paper * Authors re-define a lot of terminology, but the novelty of the method is more from the type of graph used to initialize their method, which seems to be a function of OpenIE triplets"
    ],
    [
        "Reviewers are in a consensus and recommended to reject after engaging with the authors. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.   Also, please take time to reflect on the feedback from the reviewers and improve your paper in the camera-ready version. This includes, but is not limited to:  - The combination of PER with DDPG not being novel enough  - Concerns about the strength of the empirical results and how they are qualitatively and quantitatively different from each other  - Careful discussion of the limitations of your approach and potential directions for improvement.  Evaluating your approach on a wider range of tasks would strengthen your evidence.",
        "The authors take two algorithmic components that were proposed in the context of discrete-action RL - priority replay and parameter noise - and evaluate them with DDPG on continuous control tasks. The different approaches are nicely summarized by the authors, however the contribution of the paper is extremely limited. There is no novelty in the proposed approaches, the empirical evaluation is inconclusive and limited, and there is no analysis or additional insights or results. The AC and the reviewers agree that this paper is not strong enough for ICLR."
    ],
    [
        "This paper proposes a new criterion for memory selection in the context of continual learning, in which we want to be able to surprise our users. The surprise is defined as the prediction that the incoming point will be in the category of those points being in a high-precision stream (i.e., with high information). The learnability of the prediction is defined by the criterion as being able to distinguish between points that are informative and those that are not informative.  Reviewers agreed that the proposed approach is interesting and relevant to the ICLR community, and that the paper is well-written and easy to follow. However, all reviewers had concerns about the experimental evaluation. Specifically, the performance of the proposed method is highly dependent on the choice of hyperparameters, such as the depth of the replay buffer. It is not clear whether the proposed criterion provides a significant improvement over previous methods. Additionally, the reviewers found the paper to be missing some related work. I encourage the authors",
        "One way of avoiding catastrophic forgetting in continual learning is through keeping a memory buffer for experience replay.  This paper addresses the problem of online selection of representative samples for populating such memory buffer for experience replay.  The paper proposes novel information-theoretic criteria that selects samples that captures surprise (samples that are most informative) and learnability (to avoid outliers).  They utilize a Bayesian formulation to quantify informativeness. They provide two algorithms: a greedy approach, and an approach that takes timing (when to) update memory into account based on reservoir sampling to mitigate possible issues with class imbalance.  Pros:  The paper is well written and organized.  It was easy to follow. The formulation is novel and technically sound. The idea of taking learnability into account is novel and interesting.  It provides a nice way of avoiding outliers and balancing surprising information. The authors presented the motivation for each part of the framework well.    Cons: To understand the contribution of each component of the formulation and competing criteria, an ablation study is needed. Reviewers had several detailed suggestions and questions, including sensitivity to hyperparameters, additional citations, additional data sets beyond MNIST and CIFAR10, etc.    In the rebuttal, the authors have addressed several of these concerns.  Please make sure to include and incorporate reviewer suggestions in the final revised version."
    ],
    [
        "This paper proposes a cycle-consistency type of image enhancement method for low-light images using GANs. The proposed approach has been compared to lot of previous work, both with and without paired data, and it has some interesting aspects such as geometric and lighting consistency together with the contextual loss. However, all the reviewers agree that the current version still has some issues that need to be addressed before it is ready for publication:  1. The lack of novelty as none of the individual contributions is individually novel in this work. Also, the proposed approach also seems to be unable to distinguish itself from the existing works on geometric consistency, lighting consistency, and contextual consistency. This makes it difficult to justify the use of these components if not having sufficient novelty on their own. 2. The experimental section needs significant improvement in order to clearly show the benefits of this work over the existing methods. More ablations and comparisons are needed to analyze the contribution of each component individually.",
        "None of the reviewers championed the paper. Many weaknesses were shared across the reviewers: none of the individual contributions is individually novel, paper is not well written and the results do not show significant improvement over the prior state of the art. No rebuttal was provided. The AC agrees with the reviewers that the paper is not ready for publication at ILCR."
    ],
    [
        "The paper presents an attention-based approach to learning a policy for solving TSP and other routing-type combinatorial optimization problems. An encoder network computes an embedding vector for each node in the input problem instance and an decoder network then uses those embeddings to output a permutation of the nodes which is used as the solution to the optimization problem. Both the encoder and decoder are trained using REINFORCE to maximize solution quality. An optimization problem is solved for each input example by finding the optimal permutation over all nodes.  The paper is clearly written and experiments are well conducted. However, the relation of the proposed approach to the Transformer architecture of Vaswani et al. 2017 is not clear. The theoretical analysis is also weak. Overall, this paper can not be accepted in its current form.",
        "The paper presents a new deep learning approach for combinatorial optimization problems based on the Transformer architecture. The paper is well written and several experiments are provided. A reviewer asked for more intuition to the proposed approach and authors have responded accordingly. Reviewers are also concerned with scalability and theoretical basis. Overall, all reviewers were positives in their scores, and I recommend accepting the paper."
    ],
    [
        "The authors propose a new method for performing counterfactual inference on time series data in healthcare, using ODEs to model interventions in continuous time. Differential equations are used for differential equations, and are augmented with additional confounding variables such as unit-wise noise and latent variables to deal with potential confounding.   Pros: - The authors propose an interesting approach for computing causal inference for time series.  Cons: - Novelty of the work is limited, e.g. it seems limited to static time series, and it's not clear how well it would scale to more recent and diverse datasets. - Experimental results are not very convincing. - Better baselines alternative methods should be compared to. - Presentation needs to be improved.",
        "There are some interesting ideas raised on continuous-time models with latent variables in machine learning. However, the reviewers argue, and I agree, that the connection to causal models as typically required in applications about the effects of interventions is not addressed with as much care as it might have been needed."
    ],
    [
        "The paper studies robustness in the data poisoning setting, where a fraction of the data may be corrupted. The paper proposes an algorithm to tackle this problem and evaluates it on a standard datasets, finding that the proposed algorithm is robust to label noise w.r.t. the perturbed data. The theoretical results make sense, but there lack detailed proofs to make this paper self-contain. In particular, the algorithmic contribution seems incremental over a concurrent work and the novelty may be overclaimed. Reviewers also raised many concerns on the experiments.",
        "The papers studies machine learning tasks in the presence of adversarially corrupt data (during training). In particular, it is assumed that the labels of a small constant fraction of the datapoints are arbitrarily corrupted.  The paper proposes a natural method to solve this problem and evaluates it on various datasets. As pointed out by the reviewers, the theoretical contributions of this paper are subsumed by a number of prior works (which were not initially cited). The experimental results of the paper are interesting. However, the method proposed  and evaluated is not particularly novel. In my opinion, the problems studied in this submission are important (in particular, the memory/space consideration in the context of robustness). However, this work still needs work and is not ready for publication."
    ],
    [
        "This paper proposes to incorporate transformer models into particle simulation, resulting in a model that is much more light-weight and computationally efficient (i.e., requiring far fewer parameters). The proposed method is evaluated in four simulated environments: FluidFall, FluidShake, BoxBath, RiceGrip.  After the author response and discussion, all reviewers favor accepting the paper, with two reviewers strongly supporting the paper (R3 and R2), and the other two reviewers slightly leaning towards acceptance (R1 and R4).  The main strengths of the paper are:  - the SiT method is able to leverage the material specific properties learned in the \"abstract tokens\" to better simulate the properties of the solid interacting with the fluid. - This is a novel application of transformers to particle simulation. - The paper is well written and easy to follow.  On the other hand, the main weaknesses are: - the experimental results do not show SiT to",
        "The submission received split reviews: two reviewers recommended weak accepts, and the other two weak rejects.  The AC went through the reviews, responses, and discussions carefully.  The AC agrees that this paper is well-written and has demonstrated the possibility of using transformers for particle-based physical simulation.  The AC also believes that the authors have addressed the concerns of reviewer dYcg, despite that the reviewer didn't engage in the discussions.  The contributions are however not most exciting, and none of the reviewers would like to champion the submission.  Further, the AC agrees with the knowledgeable and responsible reviewer ZsKn that the presentation and experiments can be better positioned to highlight the key contribution. As reviewer ZsKn has summarized, it's recommended that \"the authors took the approach of integrating the different parts of the newly proposed layer into existing architectures (possibly including non-simulation settings), and try to understand better that way how the new layer may help in a more apples-to-apples comparison.\"  The recommendation is reject, and the authors are encouraged to revise the paper for the next venue."
    ],
    [
        "The paper investigates the combination of learning representations and ensemble clustering for improving unsupervised visual embedding. The reviewers agree that the idea is interesting, but point to a number of concerns with the current manuscript. In particular, the paper focuses on a specific domain (clustering) and the empirical evaluation is not sufficient to meet the high standard of ICLR. I encourage the authors to revise the paper based on the reviewer's comments and submit it to a future venue.",
        "This paper proposes a model for learning using ensemble clustering. The reviewers found the general idea promising. However, while promising, all reviewers noted that in its curent form the paper is not fit for publication. The reviewers pointed out missing references, issues with the abstract, lack of motivation for some of the algorithmic choices, limited novelty over clarity in the description of difference w.r.t. previous work. Because of all these reasons, this paper does not meet the bar of acceptance. I recommend the authors take into account the feedback provided in the reviews and discussion and resubmit to another venue."
    ],
    [
        "This paper investigates improvements to the popular Conformer architecture for speech recognition, and introduces Squeezeformer, a novel hybrid attention-convolution architecture. The paper received three detailed reviews and a healthy interaction between authors and reviewers. The reviewers agree that the observations made in the paper are interesting and useful to the community, and that the paper is well-written and easy to follow. The open-sourced code and trained model checkpoints are also helpful resources for the community. While there were some concerns regarding comparisons to prior work (e.g. Conformer-CTC), the authors have done an excellent job in their rebuttal. They have addressed most of the open questions/concerns raised by the reviewers. Given the popularity of the model, and the contribution of the paper, I recommend acceptance.",
        "The paper conducts thorough analysis of the Conformer architecture and brings insights and techniques from other fields to simplify and improve the model structure, which is also demonstrated to show nice gains. Though as pointed by reviewers the novelty is limited, the study is very useful to the field."
    ],
    [
        "This paper gives an algorithm for perfect sampling from a discrete distribution given data in the form of pairwise comparisons. The authors use a variant of coupling from the past (CFTP) to develop their method. The sample complexity of the resulting algorithm may depend on the structure of the distribution, but it is shown that it is not necessary to know the distribution structure in order to sample from it. The paper is well-written and the results are interesting. Overall, it is a nice addition to the NeurIPS program.",
        "The authors show how to perfectly sample a discrete distribution, given sample access to the Bradley-Terry-Luce model on subsets of size 2. While the learning problem has been previously studied extensively, this work initiates the study of sampling. Technically, the authors introduce re-weighting and rejection sampling ideas that speed up coupling from the past by utilizing an approximate learning algorithm; these techniques could be useful in other applications, as the authors hint in the rebuttal.  The reviewers agreed that the paper is technically quite strong and that it's quite well written. The authors responded to all remaining questions by the reviewers, clearing the path to the paper being accepted."
    ],
    [
        "The paper shows that using an exponential moving average (EMA) over a non-moving average (MA) for GAN training leads to more well-behaved solutions than either MA (or no averaging) or none averaging (None). This finding is supported by some numerical experiments. However, the reviewers found the theoretical results to be unconvincing and thin, and the empirical support to be limited. I agree with this assessment and hence must reject.",
        "This work analyses the use of parameter averaging in GANs. It can mainly be seen as an empirical study (while also a convergence analysis of EMA for a concrete example provides some minor theoretical result) but experimental results are very convincing and could promote using parameter averaging in the GAN community. Therefore, even if the technical novelty is limited, the insights brought by the paper are intesting."
    ],
    [
        "This is a very high-quality dataset, which is especially noteworthy since legal NLP benchmarks are very difficult to build. The authors approached every aspect of the process with extreme care. It will likely have an impact on law practice and start interesting discussions about the use of ML in these settings. The paper is also very well written and enjoyable to read.  Most reviewers are heavily in favor of acceptance. Reviewer Aeqk brought up some weaknesses, but at least from the AC's perspective, these seem to be answered well by the authors.",
        "This is a very high-quality dataset, which is especially noteworthy since legal NLP benchmarks are very difficult to build. The authors approached every aspect of the process with extreme care. It will likely have an impact on law practice and start interesting discussions about the use of ML in these settings. The paper is also very well written and enjoyable to read.  Most reviewers are heavily in favor of acceptance. Reviewer Aeqk brought up some weaknesses, but at least from the AC's perspective, these seem to be answered well by the authors."
    ],
    [
        "This paper studies the effect of model overparametrization in GANs. It considers two types of training of the GAN model, one with the simultaneous gradient descent ascent and another where the discriminator is trained to optimality for every generator update. While the reviewers acknowledge that the paper has some interesting ideas, they think it is not ready for publication at ICLR. In particular, the paper does not provide any bound on the gap between training error and test error. The experimental results cannot fully validate the authors' claims.",
        "### Paper summary  This paper investigates theoretically and empirically the effect of increasing the number of parameters (\"overparameterization\") in GAN training. By analogy to what happens in supervised learning with neural networks, overparameterization does help to stabilize the training dynamics (and improve performance empirically). This paper provides an explicit threshold for the width of a 1-layer ReLU network generator so that gradient-ascent training with a linear discriminator yields a linear rate of convergence to the global saddle point (which corresponds to the empirical mean of the generator matching the mean of the data). The authors also provides a more general theorem that generalizes this result to deeper networks.  ### Evaluation The reviewers had several questions and concerns which were well addressed in the rebuttal and following discussion, in particular in terms of clarifying the meaning of \"overparameterization\". After discussing the paper, R1, R2 and R4 recommend acceptance while R3 recommends rejection. The main concern of R3 is that the GAN formulation analyzed in the paper is mainly doing moment matching between the generator  distribution (produced from a *fixed* set of latent variables z_i) and the empirical mean of the data. R3 argues that this is not sufficient to \"understanding the training of GANs\". At least two aspects are missing: how the distribution induced by the generator converges according to other notion of divergence (like KL, Wasserstein, etc.); and what about the true generator distribution (not just its empirical version from a fixed finite set of samples z_i)? While agreeing these are problematic, the other reviewers judged that the manuscript was useful first step in understanding the role of overparameterization in GANs and thus still recommend acceptance. And importantly, this paper is the first to study this question theoretically.  I also read the paper in more details. I have a feeling that some aspects of this work were already developed in the supervised learning literature; but the gradient descent-ascent dynamic aspect appears novel to me and the important question of the role of overparameterization here is both timely, novel and quite interesting. I side with R1, R2 and R4: this paper is an interesting first step, and thus I recommend acceptance. See below for additional comments to be taken in consideration for the camera ready version.  ### Some detailed comments - Beginning of section 2.3: please be clearer early on that you will keep V fixed to a random initialization rather than learning it. The fact that this is standard in some other papers is not a reason to not be clear about it. - Theorem 2.2: in the closed form of the objective when $d$ is explicitly optimized, we are back to a more standard supervised learning formulation, for example (5) could look like regression. The authors should be more clear about this, and also mention in the main text that the core technical part used to prove Theorem 2.2 is from Oymak & Soltanolkotabi 2020 (which considers supervised learning). This should also a bit more clear in the introduction -- it seems to me that the main novelty of the work is to look at the gradient-descent dynamic, which is a bit different than the supervised learning setup, even though some parts are quite related (like the full maximization with respect to $d$). - p.6 equation (8): typo -- the  $-\\mu d_t$ term is redundant and should be removed as already included from $\\nabla_d h(d,\\theta)$. - p.7 \"numerical validations\" paragraph: Please describe more clearly what is the meaning of \"final MSE\". Is this a global saddle point (and thus shows the limit of the generator to match the empirical mean), or is this coming from slowness of convergence of the method (e.g. after a fixed number of iterations, or according to some stopping criterion?). Please clarify."
    ],
    [
        "Meta Review: The paper makes a careful study of trade-off between privacy, fairness, and accuracy. The reviewers appreciate the authors' careful treatment of this topic, providing a new perspective from the viewpoint of fairness, accuracy, and privacy. Understanding such trade-offs is an important area of research, and the authors do a good job in making a case for their findings.   There are some concerns from the reviewers that are worth addressing in the final version. (1) Discussing related work on fairness with accuracy, including the differences and benefits to accuracy in some cases. (2) Addressing the concern that some notions of fairness are also being ignored in the experiments (e.g., age, and content of datasets). The authors should make an effort to include such discussions in the revision.",
        "Meta Review: The paper studies the intersection between fairness, privacy, and accuracy. Reviewers are overall positive about the novel insights that the paper provides. Minor concerns are well covered by the rebuttal."
    ],
    [
        "This paper proposes a multi-class conformal prediction set, similar to multi-label classification, but with a statistical sound way of thresholding each (class-specific) classifier.  The reviewers and AC note the following potential weaknesses: (1) the practicality of the approach is not clear (since the concrete implementation is rather straightforward and substandard for ICLR);  (2) substantial 'power' is lost as the validation set is used to compute the quantiles; (3) some technical details are missing; (4) the clarity of the writing needs to be improved.  There was a productive discussion between the authors and reviewers, and the reviewers have updated their scores in response, so there may be room for the authors to improve the paper according to the reviewers' comments and the discussion.",
        "The paper presents a conformal prediction approach to supervised classification, with the goal of reducing the overconfidence of standard soft-max learning techniques. The proposal is based on previously published methods, which are extended for use with deep learning predictors. Empirical evaluation suggests the proposal results in competitive performance. This work seems to be timely, and the topic is of interest to the community.  The reviewers and AC opinions were mixed, with reviewers either being unconvinced about the novelty of the proposed work or expressing issues about the strength of the empirical evidence supporting the claims. Additional experiments would significantly strengthen this submission."
    ],
    [
        "This paper studies offline learning in linear contextual bandits. It introduces a novel family of pessimistic learning rules that generalizes over the Bellman--consistent pessimism and lower confidence bound strategies. The statistical guarantees established here are proven to be minimax optimal, and they also give lower bounds for several classes of linear contextualBandit problems.  The paper is well-written and the main ideas are easy to follow. The theoretical results are interesting and novel. Overall, this paper is a nice contribution to the community and I recommend acceptance.  However, I do have one major concern about the current presentation. I suggest the authors to make it possible for the reviewers to easily check the paper (e.g., by providing high-level instructions) and make it accessible to a broader audience.",
        "The reviewers are in agreement that this paper provides a minimax optimal solution to the problem of offline linear contextual bandits. This new family of learning rules beat state of the art approaches and provide a unified view on existing approaches, such as Lower Confidence Bound and Bellman-Consistent Pessimism. The theoretical results are backed by reasonable numerical simulations. Accept."
    ],
    [
        "The paper proposes a new technique for denoising CT images that works in both the image and the spatial frequency domain.   The reviewers appreciated the simplicity of the method and the thoroughness of the experimental evaluation.  However, there are some concerns about the novelty of the work in comparison to other dual-domain cascades and multi-domain U-nets. The authors' rebuttal did not fully address all the reviewers' concerns. I encourage the authors to conduct a more thorough revision and resubmit to a different venue.",
        "Interesting idea, well written paper. I suggest the authors to include and compare with relevant previous work as suggested by the reviewers."
    ],
    [
        "This work develops a multi-agent virtual environment to demonstrate human-AI collaboration in household tasks. The reviewers agreed that the paper is well suited for ICLR, with a strong contribution on collaborative planning and perception. Questions were raised regarding the practicality of the proposed system and its evaluation, which the authors have addressed in a convincing rebuttal. I am confident that this work will be useful for the community and attract interest from across the field. I recommend acceptance.",
        "Summary: This paper provides an interesting and unique challenge problem on human-AI collaboration, with sample baselines. I think this is an extremely important topic and the community should embrace such challenge problems.  Discussion: Reviewers agreed this paper should be accepted, particularly after seeing that ICLR has accepted such challenge papers in the past.  Recommendation: I'd really like to see this get a spotlight as it would be great to highlight this innovative challenge to the community."
    ],
    [
        "The paper proposes using attractor networks to \"denoise\" recurrent neural networks inspired by Hopfield nets. The idea is to add an extra dimension of recurrence with every step of an RNN to create attractor dynamics around a hidden state, thus denoising the network. While the paper is clear and the main idea is rather interesting, the presented experimental validations are arguably weak, and one would really like to see more analysis, going beyond measuring entropy. It is also important to understand how this idea connects to bodies of literature (hopfield networks). Overall, the idea is novel and interesting, and the paper should be accepted.",
        "The paper is well written and develops a novel and original architecture and technique for RNNs to learn attractors for their hidden states (based on an auxiliary denoising training of an attractor network). All reviewers and AC found the idea very interesting and a promising direction of research for RNNs. However all also agreed that the experimental validation was currently too limited, in type and size of task and data, as in scope. Reviewers demand experimental comparisons with other (simpler) denoising / regularization techniques; more in depth experimental validation and analysis of the state-denoising behaviour; as well as experiments on larger datasets and more ambitious tasks."
    ],
    [
        "The paper proposes an anchor-free approach with attention mechanism for polyp detection. Using attention mechanism, the architecture removes the setting of priors, that is, anchors. The architecture bases on the body of ResNet-50 and the head of FCOS.   The major concerns from the reviewers is that the novelty is very limited and the experimental results are not convincing. In addition, there is not a clear tendency to better performance. Therefore, this paper is not recommended for acceptance at this time.",
        "The methodological contributions and technical novelties are relatively small, but the dataset is very useful. Therefore, if the authors want to claim that the dataset is a major contribution, the dataset should be publicly released; otherwise, this contribution cannot be realized."
    ],
    [
        "The paper proposes a method for introspective learning in neural networks for improving robustness and calibration under distribution shift. The basic idea is to ask the network introspective questions (e.g., why was class A selected and why was there a correct answer given class B not A?). This is done by augmenting the input features with the loss gradients of the last layer, and then asking the network to answer these questions as to the extent that the last hidden layer is computationally equivalent to the solution provided by the introspective question. The approach is simple, modular, and shown to improve upon prior work. The paper is well written, and the approach is well motivated.   The reviewers and AC note the following potential weaknesses: (1) the method is demonstrated on only one dataset (CIFAR-10 corrupted), (2) the interesing notion of “why did the correct label A choose to be selected” should be better explained,",
        "The reviewers all appreciated the novel concept behind the work. I agree with this, I think the principles behind the work are novel and interesting, and I would encourage the authors to improve the validation of this method and publish it in the future.  However, reviewers also raised a number of issues with the current paper: (1) the evaluation appears a bit preliminary, and could be improved significantly with additional datasets and more ablations/comparisons; (2) it's not clear if the improvements from the method are especially significant; (3) the writing could be improved (I do see that the authors made a significant number of changes and improved parts of the paper in response to reviewer concerns to a degree). Probably the writing issues could be fixed, but the skepticism about the experiment results seems harder to address, and while I recognize that the authors made an effort to point some existing ablations in the paper that do address parts of what the reviewers raised, I do think that in the balance the experimental results leave the validation of the work as somewhat borderline.  While less important for the decision, I found that the paper is somewhat overselling the contribution in the opening -- while the particular concept of using gradients as features in this way is interesting, similar ideas have been proposed in the past, and the paper would probably be better if it was more clearly positioned in the context of prior work rather than trying to present a new \"framework\" like this. It kind of feels like it's biting off too much in the opening, and then delivering a comparatively more modest (but novel and interesting!) technical component."
    ],
    [
        "This paper deals with offline RL (aka batch RL). It builds on \"Representation Balancing MDP\" and tries to improve the procedure of \"stationary DIstribution Correction Estimation (DICE)\".  The SDE RepB-SDE learns a robust representation for the model learning process, which regularizes the distance between the data distribution and the discount stationary distribution of the target policy in the representation space.  The paper is pretty general, and could be paired with other pessimistic model-based offline RL methods.  However, the proposed approach has limited novelty, and is a straightforward extension of RepBM.  Furthermore, the empirical results are not convincing.  No new algorithms are introduced, and the gains are small.  Overall, the paper is below the high acceptance bar of ICLR.",
        "The paper studies offline RL, which is an important topic in high risk domains. Compared with the existing works, this paper gives a tractable method to explicitly learn the model representation w.r.t the stationary distributions of two policies. This method is pretty general and could be paired with other pessimistic model-based RL methods.  The experiments are limited to simpler domains, and could be extended to include harder tasks from other continuous control domains. Some examples could be domains such as in Robosuite (http://robosuite.ai/) or Robogym (https://github.com/openai/robogym). These environments have higher dimensional systems with clearer implications of representation learning.   There are concerns on writing style and comprehension.  - The work is on the one hand very specialized, on the other hand just an incremental modification of existing methods.  - The presentation is very dense and quite hard to grasp, even with the Appendix. - The formalism, while important, can be very loose in terms of bounds. While that does open questions in RL theory, it would be useful for authors to be more candid about this fact in the paper.  I would recommend including the response to R1 in the paper.  Other relevant and concurrent papers to potentially take note of: - Fine-Tuning Offline Reinforcement Learning with Model-Based Policy Optimization (https://openreview.net/forum?id=wiSgdeJ29ee)  - Robust Offline Reinforcement Learning from Low-Quality Data (https://openreview.net/forum?id=uOjm_xqKEoX)  Given the overall positive reviews, I would recommend acceptance. However, the method would benefit from additional pass on re-writing to make the manuscript more accessible, which in turn to increase impact of this work."
    ],
    [
        "This paper studies the relationship between disentanglement and multi-task learning. The analysis goes through multiple different network architectures and tabulates different metrics, and is reasonably thorough. While the reviewers agree that the paper has some interesting findings, it is inconclusive on whether more tasks lead to better representations, which is the main claim of the paper. The authors try to address this issue in the rebuttal by adding some more experiments, but the conclusion is still inconclusive. More studies on the number of tasks and also the relevance of different tasks could help resolve this issue.",
        "This paper aims to look at the relationship between disentanglement and multi-task learning.  The authors claim to show that disentanglement emerges naturally from MTL.  The main discussion was whether the claim that disentanglement emerges naturally from MTL has been adequately demonstrated.  The main   issue is that MTL results in more extraction of information and that is hard to disentangle from the disentanglement metrics used.  Reviewers agreed the work was interesting but not as complete as would be desirable.  I also feel it is not ready for ICLR presentation, but   with further work could be a nice future contribution."
    ],
    [
        "The paper proposes to interpret image generation using the sparse coding framework and derived sparse code. The core idea is interesting and novel, and the paper includes extensive experiments. However, as pointed out by the reviewers, in practice the approach is not very practical and the promised understanding of the network internals is lacking. The paper would be significantly strengthened if the presented experiments were extended to a wider range of image synthesis tasks and the analysis of the synthesis process.",
        "This paper introduces sparse modeling-inspired regularizations to improve deep neural network-based image generators. Experimental results on both (low-resolution) image synthesis and deep image prior-based inverse problems are used to validate the proposed method. The majority of the reviewers were against the acceptance of the paper. As summarized by Reviewer tsoA: \"There are shortcomings in the overall concept as well as its evaluation. The findings suggest that this might be a promising avenue of research, but it would need to be taken further. At present, the paper boils down too much into simply adding a simple regularizer at the end and observing that it somewhat improves some metrics in a limited number of scenarios. Due to the limitations of the evaluation, it remains unclear whether the proposed improvement carries over to state of the art models and datasets. Similarly, the promised elucidation of the purpose of the feature values never really materializes.\" The AC agrees with that summarization and recommends rejection."
    ],
    [
        "The paper analyses the approximation properties of GCNNs under the context of the ridgelet theory. All the reviewers agree that the paper is interesting and sound. The main concern is whether the group convolutional neural network is a useful tool in practice. In particular, R1 and R3 suggest that the authors motivate their analysis better and emphasize their contributions more clearly. I suggest the authors to revise the paper accordingly and emphasize the focus on the universality result (i.e., proof that one hidden layer determines the effective width of the network) more strongly. This will increase the impact of the paper.   In addition to this, I would like to ask authors to clarify the relation of their work with regards to the existing universality results of Ding et al (2020) and Jin et al. (2021). The latter paper already considers the setting of a single hidden layer and shows that the two types of networks are equivalent under the assumption that groups are non-",
        "The paper studies the approximation properties of group convolutional neural networks. It establishes the “cc-universality” of group CNNs, i.e. that such networks can approximate any continuous function over any compact set, using a new constructive approach which is based on a generalization of the ridgelet transform. The proof is constructive, in the sense that approximating networks are given in closed form by discretizing the transform. This approach may have applications beyond the scope of the paper — most immediately, to identifying classes of functions for which neural network approximations are accurate in a quantitative sense; this can be tied to the decay properties of the ridgelet transform. Reviewers found the paper to be clearly written and of high technical quality, albeit somewhat mathematically dense in its presentation. Universal approximation theorems provide an important piece of theoretical background, as well as a “sanity check” for new network architectures; having a unified, constructive approach to derive them could stimulate further work."
    ],
    [
        "All four reviewers found the work to address an interesting and important problem (over-smoothing of predicted meshes) with a reasonable approach, and all four recommended the paper for acceptance post rebuttal. The AC concurs and recommends acceptance.   Please incorporate all reviewer feedback in the final version. In particular, please take care to include the additional experiments and results discussed in the rebuttal to improve the clarity of the paper.",
        "The 4 reviewers all had a consistent view of this paper:  concern that the scope of the work was overstated (paper claims, without evidence, to apply in more generality than the 1 example scenario shown); concern about the difficulty of implementing this approach (1 TSNN required for each rendered viewpoint); and lack of examples showing how the method performs under more challenging scenarios.  The AC encourages the authors to revise the work in response to the reviews.  That would involve additional experimentation and examples, and some attention to revising the manuscript.   After two of the reviewers complained of lack of clarity in the algorithm description, the authors replied, \"We explain our algorithm in the paper; the reader can refer to our code for implementation details.\"  I hope the authors can be more responsive to the readers' concerns than that in their revisions."
    ],
    [
        "There are contrasting review rating ranging from 9 to 3. The reasonable concerns about this paper not been well validated for ML community. The proposed datasets has been benchmarked with some classical and some relevant DL methods. The established benchmark motivates future work to address the domain gap on the existing pretraining data and aggregation methods to better model slide-level and patient-level prediction. I think the proposed dataset OpenSRH can be a good contribution to the medical imaging community.",
        "There are contrasting review rating ranging from 9 to 3. The reasonable concerns about this paper not been well validated for ML community. The proposed datasets has been benchmarked with some classical and some relevant DL methods. I have taken into account the expertise of reviewers and their concerns carefully. I do agree with some reviewers opinion about this dataset will be importance to medical CV community. I do agree with authors response \"The open questions for the ML community that OpenSRH may foster innovative discoveries include the following: 1) domain adaptation between SRH images and other histology images such as H&E images in the large scale TCGA project; 2) using multiple instance learning (MIL) to avoid expensive dense patch annotations; 3) different aggregation methods for patch-based training, including clustering, attention, or MIL; 4) self supervised learning and comparing different augmentation strategies for SRH images; and 5) data efficient training of ViT architectures using SRH data. \" Even though the authors have not verified these innovative applications on the openSRH dataset. I will go with acceptance opinion of few reviewers for this paper."
    ],
    [
        "The benchmark will provide hardware-aware NAS performance evaluations, consisting of inference time, power usage measurements and code for 5-6 different hardware devices on two existing NAS benchmark tasks: NASBench-201 and FBNet. While all reviewers agree that the benchmark fills a gap in the literature, and the proposed dataset is a good contribution, some concerns were raised, e.g., about the limited set of architectures and the lack of more recent models being compared. The authors have added additional details regarding the use of other network types in the revision. Overall, the proposed benchmark is a solid contribution to the NAS community, which will benefit the community in many different ways and is ready for acceptance.",
        "This paper presents a new NAS benchmarks for hardware-aware NAS. For each of the architectures in the search space of NAS-Bench-201, it measures hardware performance (energy cost and latency) for six different hardware devices. This is extremely useful for the NAS research community, since it takes very specialized hardware domain knowledge (including machine learning development frameworks, device compilation, embedded systems, and device measurements) as well as the hardware to make these hardware-aware measurements on as many as six (very different) devices.   The code has been made available to the reviewers during the author response window and has been checked by the reviewers in the meantime. All reviewers appreciated the paper and gave (clear) acceptance scores.   Before this work, it was very hard for the average NAS researcher to assess their method properly in a hardware-aware setting, and I expect this work to change this, and to open up the very important field of hardware-aware NAS to many more researchers. For this reason I recommend to accept this paper as a spotlight."
    ],
    [
        "This paper studies the convergence of gradient descent for learning one-hidden-layer neural networks with Gaussian mixtures input. The authors provide a precise theorem to guarantee convergence of this algorithm, and studies how the learning process can depend on the parameters of Gaussians. The main techniques used in this paper are novel and the analysis is insightful. However, the main concerns from the reviewers are that the relation of this paper with existing work Fu et al. 2020 and Zhong etal. 2017 is not clear, and the novelty is not high enough. I think the authors need to improve their theoretical analysis for the Gaussian mixture setting, which is well-motivated from a practical viewpoint.",
        "This paper gives a way to learn one-hidden-layer neural networks on when the input comes from Gaussian mixture model. The main algorithm uses [Janzamin et al. 2014] as an initialization and then performs gradient descent. The main contribution of this paper is 1. to give a characterization of sample complexity for estimating the moment tensors when the input distribution comes from a mixture of Gaussian; 2. to give a local convergence result when the samples come from a mixture of Gaussian. The paper claims certain behavior in the input data would make the problem harder and slow down the convergence, although the claim is based on an upperbound and would be stronger if there is some corresponding lowerbound."
    ],
    [
        "This paper proposes a new unsupervised learning framework for supervised learning with deformable state-of-the-art convolutional networks. It addresses an important open problem in supervised learning (robustness to distribution shift, as well as regularization of the network parameters) while being able to generalize to unseen states. The paper is well written, and the proposed method is validated both empirically and through ablation studies. The reviewers identify correctly weaknesses in the method, i.e. overfitting of the networks. The authors have addressed most of the clarity and style issues raised by the reviewers in their rebuttal, however, I agree with R2 that the paper can be improved in terms of language and form, e.g. no brackets around Figure references, and better linking to public datasets. I recommend the authors use the reviewers' feedback to improve the final version of the paper.",
        "The review highlights numerous problems with the current progress of the work. While MIDL encourages early submission of ongoing research as short paper, this work is not mature enough for publication. I therefore recommend rejection."
    ],
    [
        "This paper studies the problem of finding rules for a knowledge graph completion task by using linear programming. There has been a lot of recent work on finding scoring functions for KGs, much of it focused on automatically generating rules from existing knowledge graphs. This paper focuses on a much more challenging task: selecting candidate rules from an explicit set of rules which are then solved using a shortest path heuristic. The author show that their model can achieve state-of-the-art efficiency and computational complexity compared to existing scoring functions, and they provide theoretical proofs of their statistical significance.  The reviewers were all in agreement that this paper is well-written and addresses an important problem. However, they also all had concerns about the novelty of the approach, given the amount of previous work on constructing scoring functions from rules (e.g. AMIE, AnyBURL and others), and the breadth of the experimental results. The authors did address some of these concerns in the rebuttal, but",
        "The paper shows how to make use of a linear program for extracting logical rules for knowledge graph completion. Overall, the reviewers and I agree that this is an interesting and important direction for research. Moreover, the presented approach shows good performance with rather small sets of rules extracted. However, all reviewers point out that the related work is not well discussed. While the authors have improved the related work sections during the rolling discussion, overall the positioning of the new method has still to be improved, including a better empirical comparison across different datasets. Overall, we would like to encourage the authors to polish their line of research based on the feedback from the reviews."
    ],
    [
        "This paper introduces a new method for generating black-box adversarial attacks based on slowly-varying contextual bandits. The authors use Bayesian optimization framework with respect to the loss function of the target model to achieve query efficiency and success rate. The effectiveness is demonstrated on various classifiers for ImageNet and compared against several score-based adversarial Black-box attacks. All reviewers agree that the method is novel and the query efficiency is an important aspect of the proposed method. However, there are concerns on the justification of the choice of the optimal bandit for the proposed algorithm as well as the experimental evaluation. Some of the claims are also not well supported by the current experiments.   Given all the above concerns, the current version falls below the acceptance threshold of ICLR. I encourage the authors to revise and resubmit this work to a future venue.",
        "The paper presents a new Bayesian optimization method based on the Gaussian process bandits framework for black-box adversarial attacks. The method achieves good performance in the experiments, which was appreciated by all the reviewers.  At the same time, the presentation of the method is quite confusing, which currently precludes acceptance of the paper. In particular, during the discussion phase the reviewers were not able to decipher the algorithm based on the description presented in the paper. It is not clear how the problem is modeled as a bandit problem, what the loss function $\\ell$ is minimized and why minimizing it makes sense (assuming, e.g., that $\\ell$ it the hinge loss as suggested and the initial prediction is good with a large margin, that is, the loss is zero, equation 6 never changes $x_t$ when the procedure is started from $x$). This connection, since it is the fundamental contribution of the paper, should be much better explained. Once the problem is set up to estimate (maximize?) the reward, it is changed to calculating the difference in the minimization (cf. equation 11), which is again unmotivated. (Other standard aspects of the algorithm should also be explained properly, e.g., the stopping condition of Algorithm 1)  Unfortunately, the paper is written in a mathematically very imprecise manner. As an example, consider equation (6), where $B_p$ and the projection operator are not defined, and while these can be guessed, a projection of the argmin seems to be missing as well in the end (otherwise nothing guarantees that $x_T$, which is the final outcome of the algorithm, remains in the $L_p$ ball). Another example is the $Discrete\\ Approximate\\ CorrAttack_{Flip}$ paragraph which requires that every coordinate of $x$ should be changed by  $\\pm\\epsilon$. It is also not clear what \"dividing the image into several blocks\" means in Section 4.1 (e.g., are these overlapping, do they cover the whole image, etc., not to mention that previously $x$ was a general input, not necessarily an image). It is also unlikely that the stopping condition in Algorithm 1 would use the exact same $\\epsilon$ for the acquisition function as the perturbation radius for adversarial examples, etc. While some of these inaccuracies and unclear definitions are also mentioned in the reviews, unfortunately there are more in the paper.  The authors are encouraged to resubmit the paper to the next venue after significantly improving and cleaning up the presentation."
    ],
    [
        "The paper presents a GAN that generates samples that are tailored to a user preference distribution, rather than the full data distribution, for the purpose of achieving the model's generalization performance. This is an interesting and novel idea, and the authors have done a good job in justifying and explaining the method. However, the paper has a number of weaknesses that make it not ready for publication in its current form:  1) The motivation of the paper is based on a real-world dataset, but it is unclear how realistic/real-ish the method really is. In the paper, the user preference is assumed to be given per-pair, but in practice, the preferences may be expressed in terms of preferences per-1 or per-2 pairs. It would be useful to analyze the sensitivity of the method to this limitation in more depth.  2) The paper would benefit from a more thorough ablation study. For example, the authors only consider pairwise preferences,",
        "The paper presents a method to regularize the discriminator in  GAN training with a ranking loss based on the user preference for a desired set within a larger dataset. The tradeoff between GAN loss and preference loss dependence on the distance of the set to the full dataset and the authors consider two regimes : \"small and major correction\". A major correction is needed when the targeted set is very different from the whole density, authors propose in this scenario to replace samples from the data by samples from the generator. The setting in the paper is interesting and can be useful in practice.   There was a lengthy discussions between the authors and the reviewers, the discussion pinpointed issues , some of them were addressed in the rebuttal . Some issues remain unanswered regarding the clarity and some claims in the paper.  The clarity of the paper needs further improvement and  1)  clarify section 3  the setup and the background section   2)  justify claims about the method, in  the strong correction scenario  when fresh generated samples are introduced how  is this an effective procedure? (conceptually / theoretically)."
    ],
    [
        "The authors study a stochastic bandit problem when the constraint function and reward function lie in a reproducing kernel Hilbert space (RKHS) with a bounded norm. The authors show that by carefully combining Gaussian processes, UBC, and primal-dual algorithms, a non-trivial algorithm can be designed. This algorithm achieves sublinear cumulative regret with sub linear cumulative constraint violation.  The reviewers generally agree that this is a solid theoretical work on kernelized bandits. As long as the cumulative violations are small, the authors’ algorithm can obtain sublinear regret. The reviewers pointed out some technical issues that should be addressed in the final version of the paper, and the authors are encouraged to address them in their final submission.",
        "The paper provides new techniques (algorithmic as well as analytical) to solve black box optimization of smooth functions with constraints. The reviewers are largely in favor of the paper's contributions, and the author responses have helped to clarify several aspects of the presentation and connections to existing work. Therefore, I recommend that the paper be accepted."
    ],
    [
        "This paper studies the problem of learning cooperative behaviors in social dilemmas for MARL with multiple agents. It introduces a simple update to Deep RL to promote cooperation by introducing the status quo bias and putting more emphasis on the one-step reward in order to improve coordination. The paper shows that this improves coordination in both overall performance and social welfare.  Strengths: - The paper is well written and easy to follow.  - The idea of converting multi-agent sequential multi-step games into a matrix game seems novel and interesting. - The experiment results seem promising.  Weaknesses: - There are some concerns about the lack of large-scale experiments and comparisons. - There is also a lack of any theoretical guarantees or guarantees on the generalization of the approach to non-matrix games.  The paper initially received mixed ratings. The authors did a very good job in their rebuttal. They addressed most of the concerns and updated the paper to include more experiments",
        "In general there is agreement under reviewers that the ideas/method presented are somewhat interesting/promising but also that the paper lacks a lot of clarity. Reviewers agree that the paper needs more work (on the method) and more extensive experiments to be convincing, and that in its current form it is not mature enough for publication at ICLR."
    ],
    [
        "This paper proposes a differentially private and communication-efficient method to aggregate the client updates in federated learning. The method is based on a recent compression technique relative entropy coding (REC). Relative Entropy Coding (REC) targets the entropy of the loss associated with each model update of the client. The authors further modify this technique to satisfy differential privacy guarantees, and perform various experiments to back their claims. While the reviewers think the idea is interesting, the results are weak at the moment due to the weakness in the privacy-utility trade-off. In particular, the proposed method can save communication for ~(4000, 20, 800, 100) times, but at the cost of accuracy degradation.",
        "This submission describes an approach to compressing the communication in federated learning. The key idea is using a set of random samples from a prior distribution and then performing importance weighed sampling. The work performs an analysis of the privacy guarantees of this process and experimental evaluation. The main issue with this work is the authors appear to be unaware that the basic problem they pose is solved in a more comprehensive and lossless way in a recent work https://arxiv.org/abs/2102.12099 (Feldman and Talwar, ICML 2021). That work shows that any differentially private randomizer can be compressed via a simpler algorithm that performs rejection sampling using a PRG. The algorithm does not loose privacy or utility (under standard cryptographic assumptions) while guaranteeing low communication. In contrast this work loses significantly in utility and provides opaque privacy guarantees. This submission analyzes  a randomized that adds Gaussian distribution and, in particular, the compression technique in (Feldman and Talwar) applies to it. The technique proposed in this work is very similar in spirit (with prior distribution corresponding to reference distribution in the earlier work. In light of the earlier work I do not think the contributions in this submission are sufficient for publication."
    ],
    [
        "The paper addresses the problem of extracting good policies from trajectory optimizers and the imitation learning of trajectories from an expert using cross-entropy-method trajectories. The expert is modeled as a black-box planner and the policy is learned as an expert guided by DAgger like initialization. The approach is evaluated on four continuous control tasks and achieves good performance compared to baselines.   The reviewers agree that the problem addressed in the paper is interesting and important. However, they also agree that empirical evaluation is not sufficient to support the claims of the paper, highlighting missing baselines, ablation studies, and important details of the experiments. The authors did not provide a rebuttal. Hence, I recommend rejection.",
        "This paper proposes a method to solve high-dimensional, continuous robotic tasks offering a trajectory optimization and a distill policy. The paper is well-written and the work is promising. It is very relevant for the robotics and RL communities."
    ],
    [
        "This paper proposes a gradient-based method for solving offline infinite-width model-based optimization (BDI) with a finite-width DNN model. The authors claim that the backward mapping can distill more information into high-scoring designs.  Overall, the proposed algorithm is simple and effective. Experiments are comprehensive and demonstrate the effectiveness of this principle on a standard benchmarking framework, where the authors have provided detailed experimental results to support their claims.  After the rebuttal, all the reviewers are positive about this submission.  So, we recommend accepting this paper.",
        "This paper studies Offline Model-Based Optimization. This paper proposes a gradient-based method for solving Offline MBO problems using infinite-width Deep learning models. The key novelty of the paper is in proposed use of a distillation objective to constrain the optimized design-score pairs.  All three reviewers identify the novelty of the problem and the approach.  The paper also presents strong empirical evaluation on standard benchmarks.   The rebuttal discusses yielded constructive changes in the paper, and the authors are expected to account for the discussion and suggestions in the next iteration of the manuscipt.  The AC concurs with the reviews and the discussion thereafter."
    ],
    [
        "The paper considers the problem of active learning from the perspective of large-scale mixed integer programming. It proposes an active learning strategy, where every iteration chooses a core set that minimizes the Wasserstein distance between unlabeled samples from the pool. Generalized Benders Decomposition is used to solve this IP through relaxations of the weight terms. An empirical analysis is provided showing that the proposed method can outperform existing active learning methods like k-center, k-medoids, and WAAL in very small sample budget settings.  The paper considers an interesting problem and proposes an interesting methodology. However, there are shared concerns among all reviewers in the novelty and experimental analysis. The paper can be further improved by comparing with other strategies for active learning (e.g. discrete vs continuous) in the large data regime. The clarity of the paper can also be improved by discussing how the formulation of MIP is useful in practice.",
        "This is an interesting submission, which was overall well received by the reviewers. I would recommend the authors to discuss further the vast modern litterature on efficient computation of Wasserstein distances and their minimization (see, e.g. Peyré and Cuturi 2019, and references therein)"
    ],
    [
        "This paper presents an interesting approach to imitation learning that aims to learn policies that can maintain optimal state trajectories offline, as a true offline expert does. This bound is very different from the standard bound in Backbone BC, and the authors use this bound to motivate the construction of an algorithm that recursively learns policies that keep being on optimal states while improving the reward function. The proposed algorithm uses this insight to improve upon previous works, and shows very promising results on a number of challenging benchmarks.   The reviewers and AC note the following potential weaknesses: (1) the clarity of the presentation could be improved, including the positioning of the paper wrt to prior works, (2) more detailed experiments would be useful, including comparisons to more baselines, (3) the significance of the performance improvements over the baseline, and (4) the need for further ablations.  The authors provided a strong rebuttal that addressed many of the concerns raised by the reviewers.",
        "This paper focuses on the problem of performing imitation learning from trajectory-level data that includes optimal as well as suboptimal demonstrations.  The authors wish to avoid the requirement of a separate filtering process that would throw away the bad trajectories.  The authors propose a clever innovation that allows for leveraging the policy that is itself being learned to reweight the samples for a next round of weighted behavioral cloning.  The paper is also somewhat theoretically rigorous and provides insight into the problem.   The reviewers pointed out some initial issues related to clarity and the authors did a good job of addressing reviewer concerns.  Ultimately all reviewers agreed that the core innovation of the paper was interesting and empirically worked reasonably well.    One older line of work that I think is quite relevant, but which is not discussed, is the empirically observed \"clean-up effect\", described by Michie and colleagues in the 90s (e.g. \"Learning to fly\" Sammut et al 1992).  This clean-up effect is intuitive and reportedly achieved for free in settings where the learning objective is mode-seeking and the dataset is large, insofar as the mean value of the resulting policy *should* produce actions that corresponds to the average action produced by demonstrators in the same situation.  I think it would be worth discussing how the analysis of this paper relates to this empirical phenomenon. In particular, it would be worth clarifying in what regimes the suboptimality of training from a dataset with noisy examples arises and how likely this is to effect the mean value of the learned policy (for context, it is fairly common in practice to evaluate the student policy in BC settings by only using the mean action value; perhaps this point was present in the paper, and I missed it). From a certain perspective, the innovation of this paper is to accentuate the clean-up effect.  As noted by a reviewer, and subsequently incorporated into the paper, the actual algorithm has some similarities to versions of recent \"offline RL\" algorithms (though of course it does not leverage rewards).  In particular, the motif of performing a weighted regression could perhaps be a bit more thoroughly contextualized by connecting it to other weighting factors (e.g. see Critic Regularized Regression).  That said, I leave this entirely to the discretion of the authors.  The final scores were 8, 7, & 6.  I see this as a strong paper and will endorse it for a spotlight."
    ],
    [
        "This paper proposes Equivariance self-supervised learning (SSL) to also learn equivariance behavior, by adding 4-fold rotations to popular SSL methods. The proposed E-SSL method can be seen as a more general framework than Invariance SSL and as a straightforward extension to popular I-SSL methods. While the proposed method has shown some promise, there were concerns about the novelty, baseline comparisons, and empirical results. The authors have been active in the rebuttal and addressed some of the concerns with new comparisons and experiments. However, there are still some open questions regarding the novelty of the work as noted by the reviewers (e.g. relation to existing SSL methods such as SimCLR and SimSiam), ablations on more datasets and more datasets such as CIFAR-10, ImageNet, and two PhC datasets (to learn frequency responses of photonic crystals), and the efficiency of the proposed methods in terms of training and inference",
        "This paper proposes an extra loss to add on top of the contrastive learning. The contrastive learning seek representations invariant to transformation, while the extra loss the authors proposed encourage representations to be equivariant to the transformation (i.e. retain information about transformation in later representations). While reviewers and I agree this is a sensible motivation, and acknowledge good results that authors have obtained, the fact that most, if not all, improvement is combing from the 4-way rotation transformation is a bit unsatisfactory. Furthermore, this additional loss was proposed before and is actually quite well known, so the actual novelty in the proposed technique is somewhat limited. Nevertheless, this paper provides a comprehensive evaluation, obtaining a reasonable improvement, and makes a good case for using an equivariant seeking loss. The authors are strongly encouraged to release their code (including training details for reproducing ImageNet results) as the improvements they present are central to the acceptance."
    ],
    [
        "This paper proposes to leverage natural language feedback generated by large language models (LLMs) to improve task planning in embodied environments. The authors consider three types of environment feedback, passive and active scene descriptions, in language. They show that using LLMs for embodied planning improves tasks success rate in presence of imperfect low-level control and dynamic environment.  Strengths: - The proposed approach is tested on a large number of complex and diverse domains - The paper is well written and easy to follow.  Weaknesses: - It is unclear which type of feedback should be active at each time step in the planning process. - Evaluation on more complex environments will make the paper stronger. - There is a lack of ablations to demonstrate the effectiveness of the proposed approach.  The authors have addressed most of the concerns raised by the reviewers during the rebuttal. They added additional ablation studies and ablation experiments to the paper to show the importance of incorporating embodied language as a form of",
        "This paper presents a closed loop planning system that leverages LLMs for providing candidate plans given the success of action execution and the world state. Central to the approach is querying the LLM given the instruction and text prompts capturing success of skill execution and a description of the scene.   This is a systems oriented paper demonstrating and evaluating the utility of a LLM for interleaved planning and execution. The paper is well organised and clearly written. The results highlight the utility of LLMs to enable task execution before an explicit learning of a task model (given primitive robot skills amenable to composition). Further, experiments demonstrate contextual plan adaptation and success goal reaching for simulated and real data sets.   The main limitation of the work was observed to be the specialised nature of feedback prompts necessary for successful task execution. A clarification was sought if the proposed system has a principled way to determining the necessary feedback and to what extent the feedback is to be adjusted for long-running plans. In response, the authors clarified that the feedback is not hand crafted. Further,  the authors articulated their contribution towards demonstrating  the ability of LLM-based planners to integrated multi-modal feedback without focusing on the specific problem of determine how much or how best such a feedback may be generated. In response to a reviewer’s suggestion, the authors provided a comparison of models with and without feedback with an increase in the task horizon.   Additionally, the reviewers inquired the degree to which plan recovery is possible in the proposed framework. In response, the authors drew attention to results where plan adaptation occurs when an object falls is no longer in the reachable workspace. The reviewers further requested for a comparison with a baseline that searches over a set of high-candidate plans. As suggested, the authors provided a comparison with a Next Best Decoding that uses the next most likely skill.   Overall, the inclusion of new experimental insights strengthens the paper. A clear articulation of the technical advance in relation to Zang et al. 2022 is also recommended in the main manuscript."
    ],
    [
        "The submission receives 5 reviews form 5 reviewers and all are positive about the proposed dataset presented in the submission. AC reads all reviews and discussions and agree with the reviewers. AC recommends to accept the submission as a spotlight due to its contribution of a massive dataset of videos compressed from many sources and 9 review standards, which will be used to create a single benchmark for video quality. For completeness, AC also recommends to include a small amount of discussion on the limitations of the submitted dataset (i.e., limitations of different aspects of the dataset).",
        "The submission receives 5 reviews form 5 reviewers and all are positive about the proposed dataset presented in the submission. AC reads all reviews and discussions and agree with the reviewers. AC recommends to accept the submission as a spotlight."
    ],
    [
        "The paper studies the problem of infinite-width computations of neural NTKs and NNGPs. It was already known that the dual kernel of a ReLU activation can be approximated using the finite Hermite polynomials under certain assumptions. For the q-homogeneous dual kernel, it was known that there exists a local approximation technique that can perform the computation in the infinite width regime. The current work proposes an approximate method that uses tools from functional analysis to accelerate the computation of NTK with general activation functions. Some of the reviewers felt that the contributions of the paper were incremental, but there was consensus that there were some interesting results that could be of interest to the ICLR community. The experiments also showed promise.",
        "Most prior works on neural kernels have focused on using the ReLU activation. In this work, the authors provide new methods that can approximate multi-layered Neural Network Gaussian Process (NNGP) kernels and Neural Tangent Kernel (NTK) matrices for a wide range of activation functions. All the four reviewers recommended acceptance of the paper."
    ],
    [
        "The paper proposes a transformer-based GAN framework for time series anomaly detection. The masking strategy is based on random masking and entropy-based re-masking. The experimental results demonstrate that the proposed method outperforms a set of deep learning approaches. The paper is well-written and easy to follow. However, the ablation studies are limited to a few datasets with small number of anomalies. For completeness, it would be helpful to include experiments on more datasets with heterogeneous anomaly frequencies.  The clarity and novelty are limited. Although the authors improved the paper during the discussion stage, the paper would benefit from a further revision to improve the consistency and the utility of the proposed components.",
        "This paper proposes a transformer-based GAN method and a two-step masking mechanism for time series anomaly detection. The proposed method is demonstrated on a variety of datasets.   After rebuttals, both Reviewer 73J5 and Reviewer W6VQ remained negative. The main concern is the novelty and significance of the proposed method."
    ],
    [
        "This paper presents Geo-NeuS, a new method for geometry-consistent neural implicit surfaces learning. The proposed method includes a theoretical analysis of the gap between volume rendering and implicit SDF modeling. This paper is well-motivated, and the evaluations are sufficient to support the proposed method. Overall, all the reviewers are positive about this paper.  During the rebuttal, the authors have addressed most of the concerns raised by the reviewers. There are still some concerns about the computational complexity of the method, which the authors should consider addressing in the final version. The paper heavily relies on existing structure-from-motion pipelines to compute the camera parameters, which may not be the optimal solution for solving a multi-view geometry reconstruction problem. The authors should also discuss the limitations of this approach in the revision.",
        "This paper introduces new and useful losses, presents a good experimental setup, supply analysis on the bias, and is clearly written. I encourage the authors to discuss similarities and differences to NeuraWarp and pointcloud->SDF methods in their revision."
    ],
    [
        "This paper presents a significant collection of unlabelled signing data (4.6K hours) across 10 sign languages, which have been pre-processed and converted to pose-keypoints to remove identifiable information. The paper also presents Multi-ISLR a multilingual dataset with label-alignment extracted from 11 other labelled datasets for 7 sign languages. Furthermore, the paper also provides a multi-task model, Sign2Vec, pre-trained on the labelled data, which has been fine-tuned on a number of established benchmarks, and the results show that it is good at least competitive to state-of-the-art multilingual models previously proposed in the context of Indian Signed Languages. Lastly, the work also introduces a dataset for fingerspelling across 7 languages. It's likely that this work will pave the way for new research on multilingual signed language tasks.  **pros:** * The paper provides a significant expansion for available labelled signed data (",
        "This paper presents a significant collection of unlabelled signing data (4.6K hours) across 10 sign languages, which have been pre-processed and converted to pose-keypoints to remove identifiable information. The paper also presents Multi-ISLR a multilingual dataset with label-alignment extracted from 11 other labelled datasets for 7 sign languages. Furthermore, the paper also provides a multilingual model, Sign2Vec, pre-trained on the unlabelled data, and fine-tuned on the labelled data, which shows the SOTA results for known tasks. Lastly, the paper also introduces a dataset for fingerspelling across 7 languages. It's likely that this work will pave the way for new research on multilingual signed language tasks.  **pros:** * The paper provides a significant expansion for unlabelled and labelled signed data (previous work focused only on Indian Signed Languages) * The data gathering procedure is well documented and justified * The experimental results provide evidence of the value of the data.   **cons** * For the SignCorpus there is a lack of a human verification process, that assesses the quality of the pose keypoints; i.e. whether they can be used by native signers to extract the target gloss."
    ],
    [
        "Meta Review: This paper presents a new method for ranking problems with k elements at the top k, where the goal is to find the most highly ranked element with fewer than k non-zero elements. The paper shows that the proposed approach Borda count algorithm has significantly reduced the sample complexity, which is an important result given that sample complexity bounds are often weak for very large-scale problems.   The reviewers found the paper to be well written and easy to follow, and overall the model and the objectives are described clearly with a strong theoretical support.  The main weakness of the paper is that the contribution is a proof-of-concept demonstration, and it only shows the benefit of Algorithm 1 on a very limited set of problems. Nevertheless, the results are non-trivial and the application of the method to more general problems such as recommender systems and retrieval is interesting.",
        "Meta Review: This paper studies the problem of top-K recovery from a fixed set of queries. In each query, the user is presented m items and they select the item with the highest noisy utility. The authors propose a simple solution to this problem, take top-K most frequently chosen items, and prove that it is near optimal. The proposed solution is simple and valid only under strong assumptions, the utility of the query is additive in its items and the item utility noise is independent. Nevertheless, the problem is studied in depth, including a lower bound and comparison to model-based approaches to solving the problem. All reviewers liked the paper and I support acceptance."
    ],
    [
        "This paper presents an approach for hierarchical RL that combines model-based RL with high-level skill learning and composition through hierarchical RL. Dreamer was originally developed as a method for learning reusable hierarchical skills in sequential decision making. This paper presents a more sample efficient method along with ways to combine temporally extended skill policies and the cross-entropy method. Extensive experiments show that the proposed method works well when training from scratch, and is generally better when adapting to new tasks.  Strengths: - The paper is well written and easy to follow - Original and sufficiently empirically motivated  Weaknesses: - No major weakness is mentioned by the reviewers  - The experiments are done in the locomotion domain and show better or comparables results to DREAM. However, it would have been nice to see results in other domains. - More analysis is required to understand how well the different components work together. - How stable is the combination of the different skill learning modules is?",
        "This paper proposes a unified model-based framework for high-level skill learning and composition through hierarchical RL. The proposed approach combines high-level planning in a low dimensional space with low-level skill learning, where each low-level skill is a policy conditioned on the high-level task. The low-level policies are learned by using a mutual information objective. The proposed approach is evaluated on locomotion tasks, and is shown to be overall more data efficient than alternative baselines. The reviewers agree that this work is original and sufficiently empirically motivated for acceptance. Two reviewers were concerned by the experimental setup and the transfer setting that are somehow too simple, but the authors fixed these issues in the improved version based on the feedback."
    ],
    [
        "This paper combines fastspeech with a hierarchical VAE to achieve parallel and high quality text-to-mel syntheisis.  All reviewers agree that the paper is well-written and results are strong. The key claims are that it results in improved speed, and reduced model footprint while meeting the standard requirements of non-autoregressive TTS.  However, there are two main concerns raised by some reviewers. First, the quality of the speech produced by the system is only evaluated on a single dataset. It would be more convincing if experiments were conducted on more datasets. Second, it is not clear if the benefits of the method compared to the existing ones are significant.  Overall, although the paper presents interesting results, it's a borderline paper. More work is needed before it can be accepted.",
        "Non autoregressive modelling for text to speech (TTS) is an important and challenging problem. This paper proposes a deep VAE approach and show promising results. Both the reviewers and the authors have engaged in a constructive discussion on the merits and claims of the paper. This paper will not be the final VAE contribution to TTS but represents a significant enough contribution to the field to warrant publication. It is highly recommended that the authors take into account the reviewers' comments."
    ],
    [
        "2 out of 3 reviewers suggested weak acceptance of this paper while the other 2 suggested weak rejection. However, most of them acknowledged that weak acceptance is within the range of their acceptance threshold. The authors provided detailed responses to the reviewers' concerns and updated the paper to address some of them' concerns, including more experimental rigour in the revised version of the paper. The radiography application is an interesting application that brings together weakly supervised and semi-supervised learning, and the evaluation of the proposed method on chest X-ray segmentation is convincing. I recommend acceptance.",
        "The motivation for using semi-supervised learning in medical imaging is clear in order to reduce the cost of acquiring dense expert annotations. This paper presents an interesting study on applying recent semi-supervised learning methods to chest x-ray segmentation. There are some conflicting reviews here but in general, the reviewers find the work interesting enough to be presented but with too limited technical novelty to justify an oral presentation."
    ],
    [
        "This paper proposes an algorithm for multi-batch RL with nearly minimax optimal regret and nearly optimal O(H + \\log \\log K)$ batch complexity. This is also a lower bound on the iterated logarithm of policy switching. The authors also give a polynomial time implementation and show that the algorithm is nearly optimal in this parameter too.  This paper generated a lot of discussion between the authors and the reviewers and also among the reviewers themselves. After the discussion phase, even though there were some concerns regarding the novelty of the algorithm and its comparison with prior work, everyone agreed that this is a solid contribution and deserves publication. Please take into account the reviewers' feedback to improve the final version of the paper. In particular, it would be helpful to add a discussion about the comparison with PATE and the updates suggested by the reviewers.",
        "The paper studies the batch RL problem, in which the algorithm first decide a switching schedule and then switch the policies based on this schedule. The proposed approach achieves a good regret upper bound matching existing non-batch algorithms (although the lower-order terms are still large). The batch complexity on the other hand matches the lower bound (up to log factors).   The reviewers believe that the theoretical contributions are solid and qualified to be published in NeurIPS. The authors did a good a job in addressing the computation complexity in the rebuttal phase. The meta-reviewer suggests the authors to further clarify presentation issues. Also, it would be good to cite the recent RL theory papers in the tabular setting (including those with a generative model)."
    ],
    [
        "This paper propose a novel self-supervised framework for CP Tensor Decomposition. The idea is to learn a tensor decomposition based on data augmentation for positive samples and the unbiased estimation of negative samples, in addition to data reconstruction. The quality of the decomposition is determined not only by reconstruction error, but by correct clustering on features. The proposed method optimizes the objective by an alternating least squares algorithm with gradient descent, where the iterative method can be implemented in either alternating or least squares fashion. The experiment results on various datasets show its efficiency.  Strengths:  1 - The paper is well written and easy to follow.  2 - The idea of augmenting the training data to train a predictive model and then transferring it to downstream tasks seems novel and interesting.  3 - The experiments are comprehensive and demonstrate the effectiveness of the proposed method.  4 - The improvement over the baseline is significant.  Weaknesses:   1",
        "The authors proposes augmented tensor decomposition (ATD) to adapt data reconstruction towards the downstream tasks, e.g., appropriate feature clustering.  It leverages data augmentation and self-supervised learning, with optimization accomplished akin to alternating least square (ALS).  Significantly superior performance is obtained in experiment, compared with existing CP methods and ALS.      All the reviewers, including myself, find the paper a solid contribution to the methodology and analysis. There were a few concerns and clarification requests, and the rebuttal did a good job addressing them. These additional results and insights can be included in the final version of the paper."
    ],
    [
        "The paper proposes a benchmark dataset for source code understanding and generation consisting of 10 tasks across 14 datasets, 5 of which have been previously published and a new one added. The reviewers were in agreement that this is a strong contribution to the community, with strong baselines (transformer-based models) and a clear description of the tasks and their details. Code intelligence is an important topic and it is crucial for the community to have a standard benchmark dataset. It will also enable researchers and practitioners to compare and learn from each other's work.",
        "The paper proposes a comprehensive benchmark for program understanding and generation consisting of 10 tasks across 14 datasets. All the reviewers agree that this dataset has potentially be used as a standard benchmark to measure progress in this domain. Therefore, I recommend acceptance of this paper."
    ],
    [
        "The paper proposes a regularization term for piecewise linear RNNs that encourages the network to learn line or plane attractors. The paper argues that this regularization alleviates the vanishing and exploding gradient problem for regularized recurrent neural networks. The experiments show the competitive performance comparing to LSTM.  I think the idea is quite novel and interesting. But the experiment section is confusing by missing some explanations. The presentation of the neuron model is not sufficient enough to prove that rPLRNNs find interesting and interpretable dynamics. I encourage the authors to revise the paper based on the reviewer's comments and resubmit it to a future venue.",
        "This paper describes a clever new class of piecewise-linear RNNs that contains a long-time scale memory subsystem. The reviewers found the paper interesting and valuable, and I agree. The four submitted reviews were unanimous in their vote to accept. The theoretical insights and empirical results are impactful and would be suitable for spotlight presentation."
    ],
    [
        "This paper proposes a method for discovering disentangled latent variables by simultaneously learning them with the sparse causal graph that relates them, performing identifiability analysis of the learned latent factors and performing preliminary experimental evaluation on two synthetic datasets. All reviewers agreed that the paper is well written and easy to follow, and the proposed method is novel and interesting. The only major drawback of this paper is that the limited experimental evaluation (only two datasets) and the assumption of permutation-identifiability. However, after rebuttal, most concerns have been resolved and reviewers are in favor of acceptance. I agree with the reviewers and recommend acceptance. Please make sure to incorporate the feedback in the reviews and the additional experimental results in the final version.",
        "The reviewers unanimously acknowledge the clarity of the paper and the relevance of the theoretical contribution. One weakness pointed out by reviewers is the limited experimental evaluation. Overall, this constitutes a good theoretical contribution at the intersection of causal representation learning and nonlinear ICA, which we recommend for acceptance."
    ],
    [
        "This paper presents a dataset for learning representations without access to real images. The paper received four reviews with three recommending accept and one borderline reject. The concerns of the reviewers are fairly well addressed by the authors. The meta-reviewer agrees with the reviewers' assessment and follows their recommendation. This is a useful benchmark and helps the community to develop methods over synthetic data. The dataset is quite large and likely has high value to the community. The authors' rebuttal also addressed many of the other concerns raised by the reviewers. I think this paper is worth presenting at ICLR.",
        "This work presents a method for training neural nets on synthetic data. This data is collected from a collection of thousands of OpenGL programs that rendered images, which are then used for representation learning. The big advantage of this approach is that it avoids of a lot of the biases that are present in natural image datasets. The proposed method is competitive for supervised and unsupervised scenarios. I find the results, especially those with finetuning (as done during the rebuttal period) relatively compelling.   While I agree with reviewer vdrw that, on the whole, the major contribution (an image collection) is not very strong, I still think this kind of approach will be widely interesting to the NeurIPS community. Precisely because the work shows carefully (albeit empirically only) that procedurally generated datasets could be useful for representation learning, especially if you want to avoid the various pitfalls of natural image sets."
    ],
    [
        "This paper studies multi-task reinforcement learning and generalization in the RL setting. The authors propose to express the expected one-step reward for any member of the task family as $phi(s,a,s')^T w$ where $W$ is the task. Then, they propose universal successor features (USF) to approximate the Q-values and use this to interpolate across policies and tasks. This is then used to measure the task-specific performance and error bounds.  The reviewers and AC note the following potential weaknesses: (1) the novelty is marginal compared to existing works on UVFAs and GPI, (2) computationally intractable as the USFs require high-dimensional embedding, and (3) the reported results do not fully generalize to unseen tasks.   The authors did not respond to the concerns raised by the reviewers. Given the current form, this submission does not meet the standard of publication at ICL",
        "This paper addresses an importnant and more realistic setting of multi-task RL where the reward function changes; the approach is elegant, and empirical results are convincing. The paper presents an importnant contribution to the challenging multi-task RL problem."
    ],
    [
        "This paper tackles the task of salient object detection in videos by combining pseudo-label prediction and adversarial noise reduction training. The proposed method adopts cross-frame global matching modules (CFGMM) to exploit temporal information, and uses adversarial learning to suppress temporal noise. Experimental results show that the method can achieve better performance using fewer gts while using less number of samples.  Pros: 1. The problem of video sharpness is important. 2. The paper is generally clearly written. 3. The experimental results demonstrate the effectiveness of the proposed method. 4. The ablation study is useful to analyze the contribution of different components of the method.  Cons:  1. One of the main concerns of the reviewers is that the novelty of the work might not be enough, since the proposed components (e.g., CFGMM, UADDM, etc.) have been used in other semi-supervised classification tasks in the past.  2.",
        "In this paper the authors propose an approach for semi-supervised salient object detection using a combination of pseudo-label prediction and adversarial training, showing improved results on a number of benchmarks. Some concerns about more detailed analysis of aspects of the approach were raised, but seemed to be mostly addressed in the authors’ response. Some reviewers also expressed concerns about there being sufficient technical contributions, but seemed satisfied enough with the analysis and strong positive results."
    ],
    [
        "This paper proposes two new methods, dynamic residual adapters and weighted domain transfer, to tackle the problem of latent domain learning. The idea of using residual adaptors is interesting and novel, and the method shows good performance on small latent domain datasets. The authors' rebuttal addressed most of the reviewers' concerns. As suggested by the reviewers, it would be interesting to include results on large latent domains (e.g., MNIST) in the final version of the paper.",
        "While all reviewers agree that the topic is interesting and the work has merit, several issues have been pointed out, especially by R1 and R3, that indicate that the work is not  ready for acceptance at this stage. the authors are strongly encouraged to continue to work on this topic, taking into account the feedback received."
    ],
    [
        "This paper proposes a method for deep image processing that can be applied without DL to detect anomalies in images. Ground truth from simulations is used to ground-truth image reconstruction.  The reviewers found the paper to be well-written and easy to follow. They also appreciated that the method demonstrated good performance without DL annotations. However, the reviewers also raised important concerns, especially regarding the lack of a comparison to a proper baseline (unanimously acknowledged by the authors in the rebuttal): this is an important point to bear in mind when preparing a final version of this work.  In addition, the improvements over the baseline are not significant, to the point where it is not clear whether the proposed method is a viable alternative to the state-of-the-art in image processing.   Overall, I recommend to accept this paper for ICLR.",
        "the reviewer's opinion was split on this paper, but after rebuttal no major concerns remained so I recommend acceptance. However, the authors should aim to incorporate the answers given to the reviewers concerns in the final version."
    ],
    [
        "Thanks for your submission to ICLR.  This paper presents a method for automatically constructing variational families for models expressed as probabilistic programs.  The method decomposes into a set of control flow paths that collectively have high mass under the prior, and a separate variational family is trained to target the restriction of the model to each control flow path.  During training, control-flow paths with low ELBOs are periodically pruned.  Overall, the reviewers agree that this is a very nice solution to an important problem, and would be a good addition to probabilistically programming languages.   The paper is also well-written and easy to follow.  It should be of interest to the wider ML community.  Good luck!",
        "The reviewers have reached consensus after processing the authors' feedback. They all agree that this manuscript presents an interesting approach to applying variational inference in a setting of probabilistic programming that is of interest to the community. The reviewers raise tangible points that the authors have incorporated into their revision. I recommend that the authors continue to polish their manuscript to clearly address these points in the final version of their manuscript."
    ],
    [
        "The paper presents a through analysis of applying the CLIP architecture to various vision and language tasks.  It shows that the model can outperform ResNet-based and ViT-based architectures. It also provides some suggestions on how to improve the model (e.g. training it with more complex backgrounds). Overall, the paper is well-written and easy to follow. The experiments are comprehensive and can be useful for others building upon the findings of this paper.",
        "Reviewers are in agreement that this work is a useful, clear, documentary piece of work that shows the utility of CLIP on a number of popular V+L tasks.  There is a somewhat persistent concern that simply demonstrating that a stronger visual encoder leads to improvements downstream is not an insightful result on which the community can build."
    ],
    [
        "The paper develops a parallelized algorithm for Frank-Wolfe method for convex optimization with dual dual gradient descent in a framework.  Pros:  - A new method with provable acceleration.  - The paper is well written and easy to follow.  Cons: - The parallelization idea has the flavor of being dishonest. - The experiments are very far away from the theory. - Unclear significance: there seems to be a gap between the theory and the experiments.  The reviewers and AC note the following potential weaknesses: (1) scalability issues with regards to parallelization; (2) presentation issues with respect to the parallelization ideas; and (3) the dual duality gap gap is O(sqrt(eps)) rather than O(1/eps).  AC thinks that this is promising work, but decided that the authors need more works to publish.",
        "The authors design an algorithm for composite stochastic optimization that leverages both smoothness and strong convexity with respect to the same (general) norm, using a stochastic counterpart to recent work by Diakonikolas and Guzman. They then show how to leverage this algorithm and randomized smoothing in order to create an algorithm for constrained smooth convex optimization based on exact gradient evaluations and linear optimization computations. Compared to Frank-Wolfe, the algorithm requires strictly less gradient evaluations and parallelizes the same amount of linear optimization computations.  The paper received generally favorable reviews, with the exception of reviewer 3QVT who did not engage in discussion and whose critique I found unclear. I agree with reviewer rQnJ’s assessment that even though “all the building block are quite known in optimization community (accelerated methods, duality, Bregman distances, smoothing, etc.), the whole approach fits perfectly together and provides the reader with a number of nice and useful observations.” Consequently, I recommend acceptance."
    ],
    [
        "This paper evaluates the transferability of vision encoders pretrained using masked autoencoders on large scale datasets for behavior cloning.  The reviewers lean towards acceptance based on the clear writing, the importance of the problem, and the convincing experiments.  There were some concerns about the novelty of the approach and the lack of comparisons to other methods.  However, as the authors have addressed most of the concerns raised the reviewers lean toward acceptance.",
        "This paper uses a masked autoencoder as visual pretraining for robot manipulation tasks. The paper shows strong results and received positive initial reviews.  The additional experiments provided during the rebuttal strengthen the paper's contribution claim."
    ],
    [
        "This paper studies the group robustness of foundation models. It shows that large scale pretrained foundation models can still have a bad robustness on some group shifts. Then the paper proposed a contrastive adapting method that take advantage of supervised contrastive learning, without retraining from scratch. The effectiveness of the proposed method has been verified experimentally. The paper is well written and easy to follow. The contribution of the paper is significant, and overall, the novelty and significance of the work are above the bar of NeurIPS.",
        "This paper received unanimous recommendations of acceptance from the reviewer. The authors did a good job addressing concerns from the reviewers, especially with the additional ablation studies to decouple the gains from other techniques such as SupCon. The AC agrees with the reviewers regarding the contribution of this paper and recommends acceptance."
    ],
    [
        "This paper proposes a method for automatically discovering synonymous entities from a large free-text corpus with minimal human annotation.  It is not clear which datasets are collected by the authors and which are pre-existing datasets that have been used in other work too. The coverage of prior work has been poor, and the relevant work of Gupta et al. 2017 EMNLP has been omitted. The solution is fairly natural in the form of a siamese network, a class of neural network architectures that contain two or more identical subnetworks.  The paper is full of English mistakes. I suggest the authors to clean up the writing and proofread the manuscript before submitting it again.",
        "This paper presents a model to identify entity mentions that are synonymous.  This could have utility in practical scenarios that handle entities.  The main criticism of the paper is regarding the baselines used.  Most of the baselines that are compared against are extremely simple.  There is a significant body of literature that models paraphrase and entailment and many of those baselines are missing (decomposable attention, DIIN, other cross-attention mechanisms).  Adding those experiments would make the experimental setup stronger.  There is a bit of a disagreement between reviewers, but I agree with the two reviewers who point out the weakness of the experimental setup, and fixing those issues could improve the paper significantly."
    ],
    [
        "MR image segmentation is a clinically relevant problem that has received recent developments. This paper proposes a new approach to achieve state-of-the-art results using a combination of U-Net, memory network and Hough voting from three views. All reviewers agree that the proposed method is novel and well-motivated, and the paper is written well. However, some details need to be clarified before the publication. The paper misses a lot of literature review for instance segmentation in medical imaging. Please address the issues raised by the reviewers in the final version.",
        "All reviewers found interest and merit in this paper, some negative points were satisfactorily addressed by authors. The paper should be accepted."
    ],
    [
        "This paper proposes a method to train hierarchical variational autoencoders with Ornstein Uhlenbeck Semi-groups using smoothing of layer-wise covariances in the implicit variational objective. The paper also presents experiments to demonstrate the effectiveness of the proposed method.  The paper received three positive reviews and one negative review. After the rebuttal, all reviewers converged to acceptance. AC agrees with the reviewers and recommends accepting the paper. Authors should revise the paper accordingly based on the reviews.",
        "This paper develops a smoothing procedure to avoid the problem of posterior collapse in VAEs. The method is interesting and novel, the experiments are well executed, and the authors answered satisfactorily to most of the reviewers' concerns. However, there is one remaining issue that would require additional discussion. As identified by Reviewer 1, the analysis in Section 3 is only valid when the number of layers is 2. Above that value, \"it is possible to construct models where the ELBO has a reasonable value, but the smoothed objective behaves catastrophically\". Thus, the scope of the analysis in Section 3 deserves further discussion. Given the large number of ICLR submissions, this paper unfortunately does not meet the acceptance bar. That said, I encourage the authors to address this point and resubmit the paper to another (or the same) venue."
    ],
    [
        "The paper considers the perturbation-invariant problem of learning node representations that are invariant to small edge perturbations. It achieves this through a data augmentation procedure that samples new “fake” edges and regularizes the GNN equivariant representations to be unable to predict these fake edges, thus allowing the representation to be learned without needing to rely on prediction made by other GNNs.  The reviewers agreed that the paper falls well within the scope of the conference. The state-of-the-art is appropriately identified and even though its novelty is perhaps incremental, its value seems beyond doubt.",
        "The paper is concerned with learning transformation equivariant node representation of graph data in an unsupervised setting. The paper extends prior work in this topic by focusing on equivariance under topology transformations (adding/removing edges) and considering an information theoretic perspective. Reviewers highlighted the promising ideas of the approach, its relevance for the ICLR community, and the promising experimental results (although improvements over prior work are not necessarily significant on all benchmarks).  However, reviewers raised concerns regarding the novelty of the method and the clarity of presentation with respect to key parts of the method. These aspects connect also to further concerns raised, e.g., related to mathematical correctness as well as the significance of the proposed loss function, the benefits of motivating it from MI, and the improvements over GraphTER. The rebuttal didn't fully clarify these points. While the paper is mostly solid, I agree with the reviewers' concerns and -- currently -- the paper doesn't clear the bar for acceptance; it would require another revision to improve upon these points. However, I'd encourage the authors to revise and resubmit their work with considering this feedback."
    ],
    [
        "The paper proposes a method to improve calibration and accuracy by augmenting a classification model with a sparse SVGP.  The reviewers and AC note that the method is straightforward to implement and performs well against the baselines considered on classification tasks for 125 UCI datasets.  However, the reviewers have serious concerns on the limited set of baselines and the paper's claims to generality.  It is not demonstrated whether RED would outperform other confidence scoring and OOD detection methods.  Moreover, AC believes that the authors should provide a good justification for the limited subset of the datasets considered in this study.  Lastly, reviewers also find the writing confusing and difficult to follow.",
        "In this paper, the authors use a GP classifier to detect if the output of a NN classifier has been decided correctly. The GP takes as input the original input vector x and the output of the NN, i.e. the calibrated posterior probabilities given by the NN. It uses that as an input vector for the GP classifier to decide if the sample was correctly decided. The output of the GP will serve as confidence in the output of the NN. The results are comparable/superior with the state-of-the-art and the authors have repeated the experiments with over 125 different datasets. The reviewers of this paper were all cautiously positive about the paper, but all of them pointed towards the reduced novelty of the paper. Also, none of the reviewers were willing to champion this paper as a must-have at ICLR 2021.   For my reading of the paper, I would tend to agree with the reviewers’ comments. Also, I find that using the same NN, rather shallow, with the same configuration for all the datasets seems rather limited. Given that this method is independent of the underlying classifier and that the databases used are low dimensions and a low number of training examples, I would have liked to see what a random forest or a GP can accomplish. Also, I would have used bigger NNs that can be trained to overfit the sigmoid outputs for classification of higher accuracy. I believe that having a diversity of underlying classifiers is more relevant than having 125 datasets. We need to find the best classifier or ensemble and then apply the different mechanisms for estimating if the output is the correct one. Otherwise, the proposed method might only be workable for this specific NN configuration. In the tables, it can be hinted that this might be happening, as about 80% of the cases MCP and RED are indistinguishable in the AUROC values.   Also, for all of these datasets a GP could be used as an underlying classifier, and given the premises of this paper, the authors could check how well calibrate a GP classifier is. Also, there has been considerable work on calibrating NNs when they are trained to overfit. Comparing with those methods should be straightforward, as they provide more information than just a confidence score. This is probably the most influential paper: https://arxiv.org/abs/1706.04599 (1000+ references), but there are some recent papers too.     Finally, if the goal is to use a GP to detect if the classification done by the NNs is accurate, using a GP might be an overkill, as the complexity of the GP, especially for large datasets might end up being larger than the underlying classifier."
    ],
    [
        "This paper proposes a bootstrap approximation based metric for measuring generalization gap in the ideal world compared to the real world. The metric is based on comparing the test loss from training on a finite training set with a sample-efficient method to compute the gap between. The paper conducts extensive experiments to show that the bootstrap gap is small and consistent across different datasets and architectures used for image classification. All reviewers agree that the proposed metric is interesting and the paper is well-written.  However, there are some concerns about the novelty of the metric proposed in the paper, which should be clarified in the final version. Reviewers also find the experimental results not very consistent with the theoretical predictions.  Overall, the paper has some interesting ideas, but it needs a bit more work to be ready for publication.",
        "The paper is proposing a new framework for understanding generalization in the deep learning. The main idea is considering the difference of stochastic optimization on a population risk and optimization on an empirical risk. The classical theory considers the difference of empirical risk and population risk. This basically translates the practical motivation from finding good function classes to finding good optimizers which can re-use the data effectively. Although the paper provides no theoretical result, it provides an interesting empirical study. The paper somewhat demonstrates that SGD on deep networks is somehow good at re-using the same data. I believe this angle is very novel and might hope to future theoretical discoveries. The paper is reviewed by four reviewers and two of them argue its acceptance and two of them argue rejection. After discussion, this status remained and I carefully read and reviewed the paper. Here are the major issues raised by the reviewers:  - R#1: The paper is missing a theoretical study. The implications on the practical deep learning is not clear. - R#2: Choice of the soft-error is particular to the task and how to go beyond soft-max is not clear. - R#3: Finds the paper not novel as well as trivial or hard to understand. - R#4: The choice of soft error is ad-hoc.  I believe the issues raised by R#3 are not justified. First of all, novelty is very clear and. appreciated by other reviewers. Moreover, the paper is rather easy to understand and the results are very farm from trivial. However, the other issues raised by other reviewers are valid. Specifically, soft-error seems to be a limitation of the study. However, the authors respond to this concern and reviewer increases their score. I believe the theory is lacking but the paper is simply showing this novel approach and its empirical validity. A theory to explain this phenomenon would be amazing but not necessary for publication. Similarly, without a theory it is hard to expect any practical implication. Overall, I believe the paper is an interesting and novel one which will likely to lead additional work in the area. Considering we are still far from a satisfying theory of generalization for deep learning and the role of the optimization is clear, this angle worth sharing with the community. Hence, I decide to accept. However, I have some concerns which should be addressed by the camera-ready.   - Claims should be revised and authors should make sure they have enough evidence for them. For example, authors provide no satisfying evidence for random labels or very limited evidence for pre-training. I strongly recommend authors to either remove some of these discussions or present in a fashion which is not a result but part of the discussion for future research. - A section about limitations should be added. Specifically, the soft-error choice should be discussed in this limitation section. - Discussion section should be extended with the pointers to the relevant work on bootstrap literature as well as suggestions to the theoreticians. Not providing any theoretical result is always fine but authors should understanding why is it hard to make theoretical statements and where to search them."
    ],
    [
        "The paper studies how to ensure optimization monotonicity of learning an accurate dynamics model for MBRL.  The reviewers first pointed out that the model shifts. model bias is a mismatch between the samples in the model learning stage and the policy optimization stage. To tackle the same, they formulate a constrained bi-level optimization framework for the MBRL problem with an event-triggered mechanism. They derive a lower bound for the derived policy performance improvement that depends on the one-step dynamics prediction error of the current model.  Although the monotonic improvement for model-based reinforcement learning is an important problem, the reviewers raised some concerns about the presentation of the results, e.g., upper and lower bounds for the obtained improved performance. We encourage the authors to revise the paper based on the reviewers' comments and resubmit it to another venue.",
        "This paper studies the relation between model shift and the performance of model-based reinforcement learning. The paper proposes a new algorithm that leads to empirical improvement over certain data sets. All the reviewers agree that the paper provides useful theoretical insights into model-based reinforcement learning, and the experiments are also consistent with the theory."
    ],
    [
        "This paper presents a reinforcement learning method intended to strike balance between exploration and exploitation. By decomposing the state space into regions and developing policies for solving each region, the goal-generating mechanism for self-exploitation is proposed.  The reviewers and AC note the following potential weaknesses: (1) the clarity of the presentation could benefit from a clear presentation, (2) it is not entirely clear how the proposed approach is different from prior work (e.g., DREAMER and PEORA), and (3) the baselines are weak.  During the rebuttal, the authors addressed some of the concerns, but not all of them. However, the scores for this paper remained borderline (5,5,6,7). After discussion, the reviewers agreed that this paper is not ready for publication at this time, and AC agrees.",
        "This paper introduces Regioned Episodic Reinforcement Learning (RERL), which partitions the state space by generating a diverse set of goals and then explores the state space by learning policies that reach those goals. This idea is a combination of episodic memory techniques and “goal-oriented” reinforcement learning.   After the authors’ responses and the discussion phase, all reviewers converged to recommending the rejection of this paper. The main concerns regarding this paper are:  * Presentation. The proposed approach is not that well justified, some of the claims in the paper are quite imprecise, and there’s relevant related work missing. * Evaluation. The evaluation sometimes feels rushed and is not held in a diverse enough set of tasks, not capturing important properties one would want to capture.  I recommend the authors to pay close attention to presentation, as well as the experiments and analysis in order to make the paper stronger."
    ],
    [
        "The paper proposes an algorithm for learning policies and internal models (\"decision dynamics\") from demonstrations and performs offline experiments on a healthcare dataset to show that the method learns interpretable decision dynamics, recovers biased internal models, and accurately predicts actions relative to prior methods.   The reviewers and AC note the following potential weaknesses: (1) limited novelty in relation to the \"Agent Markov Model\" (AMM) of Unhelkar and Shah (Learning Models of Sequential Decision-Making with Partial Specification of Agent Behavior AAAI 2019), which also uses a state-space model, is modeling agent behavior using a Bayesian approach; (2) lack of comparison with this work in the experiments.  The authors addressed most of the concerns raised by the reviewers in the rebuttal and updated their manuscript.  Overall, the paper presents an interesting solution to an important problem with potential impact in the healthcare domain.",
        "Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning  The topic is maximally timely and important: Understanding human decision-making behaviour based on observational data. Any tangible steps towards this challenging goal are bound to be significant, and those this paper makes.  A Bayesian policy-learning method is introduced for this task, and validated on both simulated data and user exeperiments in a real decision-making task. The novel contribution is on learning interpretable decision dynamics  The paper is written clearly enough..  The updated paper clarified most major concerns the reviewers had. In particular, they added a user study.  The biggest remaining weaknesses are that  - relationship to the AMM model did not become completely clear yet  - the real user study has been carried out with only a small set of users. But a large-cohort study would be too much work to ask for a paper which has also a strong methodological contribution."
    ],
    [
        "This paper presents a hierarchical framework for integrating user feedback for KB construction under identity uncertainty. When KBs are automatically expanded user feedback is crucial to identify incorrect and missing entity attributes and relations. Integrating user feedback into KBs in the presence of identity uncertainty is an important and difficult problem. The proposed method is an algorithmic solution to that problem.  The reviewers and AC note the following potential weaknesses: (1) it is unclear about the algorithm implementation, such as what is the implementation of feedback mention. (2) the human computation aspects of the paper are lacking sufficient explanation in terms of implementation in real settings and a working example. (3) the example for constructing positve/negative feedback is too vague.  In the rebuttal the authors have addressed some of the concerns. However, the reviewers still rate the paper as borderline. After consulting the paper, reviews, and rebuttal, the area chair agrees with the reviewers and believes that the paper is not yet ready for publication",
        "The paper presents an interesting methodology. The results are interesting, however the paper really misses out on an in-depth discussion and reflection of the pros and cons of this approach as well as on a proper related work comparison to similar approaches."
    ],
    [
        "This paper proposes theoretical analysis of the relationship between supervised learning (SL) and self-supervised learning (SSL) in the context of few-shot learning (FSL). It aims to quantify the gap in training loss between SL and contrastive SSL on FSL tasks. The paper claims that the supervised loss is upper bound by SSL loss by a linear relation with respect to balanced class data, whereas the SSL loss has an upper-bound by a differentiable linear function. Empirical results are also provided. However, the reviewers point out that the theoretical results make little sense, the proposed theory is also overclaimed, and the whole study is neither theoretical nor logical. The whole analysis and proof are based upon the two main assumptions: mean classifier and balanced class training data. In general, the presentation of this paper is poor and the equations are hard to read.",
        "This paper proposed to theoretically explain why a pre-trained embedding network with self-supervised training (SSL) can provide representation for downstream few-shot learning (FSL) tasks. The review process finds that the paper may over-claim the results and that the results seem unsatisfactory. Both Reviewer 4 and Reviewer 5 expressed concerns regarding the writing, organizing, and grammar errors of this paper. The paper needs a substantial revision to improve clarity and accessibility. As pointed out by Nikunj Saunshi’s public comment, this paper may benefit from discussing the differences from the previous works, including [1].    [1] Arora et al., A Theoretical Analysis of Contrastive Unsupervised Representation Learning, ICML 2019"
    ],
    [
        "The paper proposes an active learning approach for detecting anomalies in anomaly detection tasks. While the reviewers agree that the paper addresses an important problem, they also note a number of weaknesses, including limited methodological novelty and an inaccurate premise behind some of the claims of the paper's claims. The authors' rebuttal was not able to fully address these concerns. Overall, this paper is not suitable for publication at ICLR and the area chair agrees with the reviewer's assessment.",
        "Following the unanimous vote of the reviewers, this paper is not ready for publication at ICLR. The most significant concern raised is that there does not seem to be an adequate research contribution. Moreover, unsubstantiated claims of novelty do not adequately discuss or compare to past work."
    ],
    [
        "This paper proposes a method for improving clustering using a supervised learning method. The key idea is to learn the metric from the context, combined with off-the-shelf clustering. Specifically, they use the self-attention block module of the multi-head attention based transformer to embed the data and learn a kernel using the ground truth labels. They demonstrate their idea on a toy dataset and present results on the Omniglot dataset.  The reviewers agree that the paper is well written and considers using the context in clustering which is an important problem. On the other hand, they also point out that the approach is not new, there are many previous methods to combine metric learning and clustering, and the experiments don't evaluate a new approach. In addition, the datasets used in the experiments are toyish.  I encourage the authors to revise the paper based on the reviewer's comments and resubmit it to a future venue.",
        "This paper proposes to use context-based metric learning, where an attention/Transformer-based mechanism is used to incorporate neighborhood information for deep learning-based metric learning. This was initially demonstrated on two simpler datasets, although larger ones were added during the rebuttal. On the whole, reviewers appreciated the simplicity and intuition behind the idea, but the consensus among all of the reviewers found several aspects lacking, including: 1) clarity of the descriptions in the paper, 2) novelty compared to existing work, especially that of Set Transformer for clustering, 3) lack of convincing results compared to baselines, or at least analysis/justification for negative results. While the reviewers appreciated the authors' rebuttal and experiments, it did not address many of these concerns. The idea is interesting and seems to hold some promise, so the authors are encouraged to refine these aspects in order to fully explore this idea and submit to a future venue."
    ],
    [
        "This paper proposes a new method for dynamically exiting the forward passes of language models so as to speed up inference. The proposed method is shown to result in a speedup of up to 3x in some cases, and is evaluated on machine translation, summarization and Squad tasks.   All the reviewers are positive about this paper. They agree that the method proposed in this paper is novel and interesting, and that the speedup is useful especially for large language models such as T5. The main concerns of the reviewers have been addressed during the rebuttal, and all the reviewers reach a consensus that the paper should be accepted.  We request the authors to release the code for the camera ready version of the paper asap.",
        "This paper studies the error of early exit in decoding Transformer Language models, and proposes a method CALM to calibrate and accelerate model inference. Experiments on a variety of tasks (summarization, MT, QA) show effectiveness of the proposed method.  All reviewers find the paper solid and the author feedback convincing."
    ],
    [
        "The paper proposes a new architecture and regularization technique for RNNs: the hidden state of an RNN is one of (or a soft weighted average of) a finite number of learnable clusters. This has two claimed benefits:  1) extracting finite state automata is much simpler, and 2) forces RNN to operate like an automata. Authors demonstrate their model in learning simple regular and context-free languages and also in a couple of non-synthetic tasks.  Reviewers agreed that the paper is well-written, the proposed idea is interesting, and the experiments are convincing. There were some concerns about the computational efficiency of the proposed scheme and the lack of baselines on more complex tasks, but the authors addressed those concerns in the rebuttal and convinced the reviewers.   Overall, this is a good paper and I recommend acceptance.",
        "the authors propose to incorporate an additional layer between the consecutive steps in LSTM by introducing a radial basis function layer (with dot product kernel and softmax) followed by a linear layer to make LSTM similar to or better at (by being more explicit) capturing DFA-like transition. the motivation is relatively straightforward, but it does not really resolve the issue of whether existing formulations of RNN's cannot capture such transition. since this was not shown theoretically nor intuitively, it is important for empirical evaluations to be thorough and clearly show that the proposed approach does indeed outperform the vanilla LSTM (with peepholes) when the capacity (e.g., the number of parameters) matches. unfortunately it has been the consensus among the reviewers that more thorough comparison on more conventional benchmarks are needed to convince them of the merit of the proposed approach."
    ],
    [
        "This paper proposes to improve existing machine learning-based domain decomposition solvers, by using a graph convolutional network to learn the preconditioner. Specifically, a TAGConv is trained on the inputs to the domain-decomposed PDE solver, and the output is the boundary matrices of the domain and the decomposition. The authors first learn the parameters in a specific subclass of the Schwarz preconditionaler that generalizes it to unstructured grids, and then fine-tune it by using the associated loss function inspired by Gelfand's formula. The main contribution of the paper is the introduction of a new implementation of the loss function and experimental results on the Helmholtz equation.   The reviewers agree that the paper presents an interesting idea, and note that the idea of using GNNs to find the boundary values of domain-determined solvers is novel. However, the reviewers also point out several weaknesses in the",
        "The paper proposes a scheme to learn preconditioners for domain decomposition solvers. Graph neural network is used to learn interface matrices, and the training dataset consist of many unstructured grids for which optimal parameters are learning.  The loss function is adapted from Daulbaev et.and is based on the Gelfand formula (with average replaced by maximum). Theoretical study is provided. The paper is well-presented, contains a useful and practical algorithm which potentially will be used by many researchers doing numerical simulations."
    ],
    [
        "This paper presents an empirical study of similarity metrics used in example-based explanations methods. The authors conduct an systematic study by adding two new tasks: decision support examples in the training set for a black-box model's prediction and measures of the cosine similarity of the gradients of the loss. The main takeaway is that many of the newly proposed metrics do not even satisfy the requirement for being a \"fair\" similarity measure, as the authors also conclude.   The reviewers raised a variety of concerns on the study methodology, experiments, and findings. Most of them have been well addressed in the rebuttal and the revised version of the paper. I would recommend the authors to go through reviewers' comments once again and make sure that all the comments are reflected in the final version. There are still some unaddressed concerns (e.g. regarding the geometrical explanations) and some unclarities that need to be clarified. Overall, I recommend acceptance.",
        "This paper performs an empirical comparison of similarity-based attribution methods, which aim to \"explain\" model predictions via training samples. To this end, the authors propose a handful of metrics intended to measure the acceptability of such methods. While one reviewer took issue with the proposed criteria, the general consensus amongst reviewers is that this provides at least a start for measuring and comparing instance-attribution methods.   In sum, this is a worthwhile contribution to the interpretability literature that provides measures for comparing and contrasting explanation-by-training-example methods."
    ],
    [
        "This paper studies the problem of stylizing 3d mesh shapes based on a text prompt. The proposed method jointly generates reflectance, geometric and lighting styles using a differentiable renderer using CLIP. Reviewers generally found the work to be technically solid. There were some concerns about the amount of novelty in the work relative to prior work, but the authors adequately addressed these concerns in the rebuttal. Overall, all reviewers support accepting the paper, and so do I.",
        "This paper presents a new CLIP-driven stylization method given an input mesh and text description. Compared to previous works Text2Mesh, the paper introduces a more expressive rendering model based on learnable SVBRDF and normal maps. Many reviewers found the paper easy to follow, the idea promising, and the results visually appealing. They also expressed their concerns regarding the similarity to Text2Mesh, the limitations of the normal maps approach (compared to changing geometry explicitly), and the relighting and material editing of the stylized object. The rebuttal has addressed most of the concerns. The AC agreed with most of the reviewers and recommended accepting the paper.   Please revise the papers according to the reviewer’s comments: (1) change the title according to Reviewer kpuS, (2) add relighting/material editing/view synthesis results, and (3) highlight the pros and cons of the proposed method w.r.t. Text2Mesh."
    ],
    [
        "This paper presents a new explanation method called DGA for attributing a function’s output w.r.t its input features. Distilled Gradient Aggregation (DGA) approach combines the advantages of both Integrated Gradient and FullGrad approaches via a new sequential feature distillation algorithm. This approach effectively addresses the limitations of local approach (FullGrad) that uses a single anchor point to compute attribution. DGA is motivated by problems of some related work in the literature, i.e., Integrated Gradients and FullGrants. The paper identifies pitfalls in two attributions methods, then proposes a novel attribution method that purports to solve the problem. The proposed approach is an extension of FullGrad and achieves better performance than previous methods. The quantitative and qualitative evaluations the authors demonstrate that the proposed approach produces better explanations than previous proposed methods.  The current way the method is presented can be improved to make it more confusing for the audience. We encourage the authors to",
        "This paper proposes a new gradient-based attribution method Distilled Gradient Aggregation (DGA), which combines the strengths of both local and global attribution methods. The reviewers and meta-reviewer found the method novel, and supported by promising results both qualitatively and quantitatively.   During the rebuttal phase, the authors made a _thorough_ effort in response to each reviewer's comments. As recognized by two reviewers (hnze, cvDy), the newly added results and discussions have significantly strengthened the contribution.   The AC recommends acceptance given the paper tackles a critical problem, and presented an effective and convincing method that advances the field of explainable AI.   Authors are strongly recommended to include these new results and writing changes suggested by the reviewers for the final version of the manuscript."
    ],
    [
        "The paper analyses BERT and Transformer models from the perspective of graph theory and proposes a graph fusion method to resolve over-smoothing.  Pros: - New perspective on analyzing BERT by viewing them as graph models - Interesting and novel theoretical analysis  Cons: - The analysis methods is applicable only to analysis on transformers, but can apply to other models as well. - Some of the proposed methods are not novel, and not well-supported in theory and experiments  - Lack of empirical investigation  The authors did not provide a rebuttal.  Overall, this paper received negative scores due to concerns of insufficiently-examined problem, weak experimental investigation, and lack of novelty.",
        "This paper has a deep analysis of the over-smoothing phenomenon in BERT from the perspective of graph. Over-smoothing refers to token uniformity problem in BERT, different input patches mapping to similar latent representation in ViT and the problem of shallower representation better than deeper (overthinking). The authors build a relationship between Transformer blocks and graphs. Namely, self-attention matrix can be regarded as a normalized adjacency matrix of a weighted graph. They prove that if the standard deviation in layer normalization is sufficiently large, the outputs of the transformer stack will converge to a low-rank subspace, resulting in over-smoothing.  In this paper, they also provide theoretical proof why higher layers can lead to over-smoothing. Empirically , they investigate the effects of the magnitude of the two standard deviations between two consecutive layers on possible over-smoothing in diverse tasks.  In order to overcome over-smoothing, they propose a series of hierarchical fusion strategy that adaptively fuses presentation from different layers, including concatenation fusion, max fusion and self-gate fusion into post-normalization. These strategies reduce similarities between tokens and outperforms BERT baseline on a few datasets (GLUE, SWAG and SQuAD).  Overall I agree with reviewers that this is a good contribution."
    ],
    [
        "This work presents an extension to the popular WILDS benchmark for unsupervised domain adaptation. The main contribution is the U-WILDS dataset which provides a large quantity of unlabeled data complementing 8 of the existing multidomain labeled datasets for domain shift. In addition, the paper provides rigorous empirical evaluation benchmarking of existing methods for domain adaptation with the main finding being that most of the techniques performed poorly, except data augmentation for the image problems.   The reviewers found the paper to be well written and easy to follow. The dataset to be a useful contribution to the community and the authors have done a good job addressing the reviewers’ concerns both in the rebuttal and the open-source release.",
        "This paper presents U-WILDS, an extension of the multi-task, large-scale domain-shift dataset WILDS. The authors propose an extensive array of experiments evaluating the ability of a wide variety of algorithms to leverage the unlabelled data to address domain-shift problems. The vision behind sounds quite ambitious and convincing to me, namely, the proposed U-WILDS benchmark would be a useful and well-motivated resource for the ML community, and their experiments were very comprehensive. Although they did not introduce any new methods in this paper, U-WILDS significantly expands the range of modalities, applications, and shifts available for studying and benchmarking real-world unsupervised adaptation.  The clarity, vision and significance are clearly above the bar of ICLR. While the reviewers had some concerns on the novelty, the authors did a particularly good job in their rebuttal. Thus, all of us have agreed to strongly accept this paper for publication! Please include the additional rebuttal discussion in the next version."
    ],
    [
        "This paper studies the training algorithms for multi-layer over-parameterized neural networks. The main contribution is introducing techniques for sketching and preconditioning to improve the per-iteration computational complexity. Although the reviewers acknowledge that the paper has some merits (well-written, well-organized, the presentation is clear), they have raised several concerns about the novelty and the correctness of some claims, as well as the lack of an empirical evaluation. Unfortunately, there was no response from the authors, so the concerns are still there and the reviewers do not think the paper is ready for publication.",
        "This paper studies the performance of second-order algorithms on training multi-layers over-parameterized neural networks. The authors propose an algorithm based on the Gram-Gauss-Newton method, tensor-based sketching techniques, and preconditioning to train such a network, whose runtime is subquadratic in the width of the neural network. While some reviewers provide some weak support, none of them are in strong support, even after the author's response. I think one of the reasons is the lack of empirical experiments. Since the main claim of this paper is an efficient second-order algorithm, some experiments are necessary to back up this claim. Unfortunately, the authors did not try to add such an experiment during the rebuttal. I would suggest the authors add such experiments in the revision."
    ],
    [
        "This paper proposes to reformulate the QA task in SQUAD as a retrieval task and named it as such. The basic idea is to embed the question and the paragraph and train a system to put the correct paragraph close to the question. Evaluation shows that using the residual network and evaluated the use of ELMo word embedding with/without IDF weight. The results showed that there are significant gain when adding the residualnetwork on top of the word embeddings.  The reviewers and AC note the following potential weaknesses: (1) limited novelty. The proposed approach is very similar to Elmo. There have been extensive studies on retrieval methods for multi-paragraph / multi-document reading comprehension. (2) writing and presentation are not very clear. (3) hard to follow the details of the proposed approach.  Overall, the authors did not provide a rebuttal. Therefore, the recommendation is to reject.",
        "I have to agree with the reviewers here and unfortunately recommend a rejection.  The methodology and task are not clear. Authors have reformulated QA in SQUAD as as ranking and never compared the results of the proposed model with other QA systems. If authors want to solve a pure ranking problem why they do not compare their methods with other ranking methods/datasets."
    ],
    [
        "This paper introduces an interesting cooperative-competitive MARL environment involving groups of camera and targets with the objective of transportation. The benchmark environment appears to be scalable with novel components including partial observability and general-sum rewards in an interesting environment. The authors provide extensive baselines for MARL algorithms as well. The majority of reviewers appraised the work positively, and the authors adequately addressed the concerns brought up in the review along with a revision incorporating some components of feedback. I think this is a good addition to the MARL literature and should be accepted.",
        "This paper introduces an interesting cooperative-competitive MARL environment involving groups of camera and targets with the objective of transportation. The benchmark environment appears to be scalable with novel components including partial observability and general-sum rewards in an interesting environment. The authors provide extensive baselines for MARL algorithms as well. The majority of reviewers appraised the work positively, and the authors adequately addressed the concerns brought up in the review along with a revision incorporating some components of feedback. I think this is a good addition to the MARL literature, and the authors should be sure to incorporate all the remaining feedback in the final version of the paper."
    ],
    [
        "This paper introduces a new task of semantic action-conditioned video prediction. The task is to predict future frames given objects and action pairs. The model is built from an attention based capsule network and used a hierarchical feature computation where the video is the intermediate representation of the current frame. The reviewers agree that this paper presents an interesting task that has the potential to spark research in this direction. In addition, the authors propose an interesting architecture that generates extremely good video given some simple instructions. There were some concerns raised by the reviewers about the significance of the new task and the experimental evaluation. The authors have addressed most of the concerns in their rebuttal. After the discussion, all the reviewers are in favor of accepting this paper.",
        "This paper presents work on semantic action-conditioned video prediction.  The reviewers appreciated the interesting task and use of capsule networks to address it.  Concerns were raised over generalization ability of the proposed approach, points on clarity, scalability, and handling of uncertainty/diversity by the method.  After reading the authors' response, the reviewers engaged in discussion.  Over the course of this discussion, the reviewers converged on a reject rating, noting that the concerns raised above were not sufficiently addressed to warrant publication at this stage."
    ],
    [
        "This paper studies why optimization-based adversarial attacks have close to zero target transferability in attack real-world ASR pipelines, which is an interesting phenomenon not well understood. The paper first lists 11 known factors, e.g., smoothness of gradients, and then proposes four more factors that limit the transferability. The authors conduct extensive experiments to verify their hypothesis and derive the conclusion.   All the reviewers agree that the paper is well-written, the study is systematic, and the findings are interesting. Based on the findings, the authors also discuss the takeaways and future directions for the ASR.",
        "This paper explores why adversarial examples do not transfer well in adversarial examples on automatic speech recognition systems. The authors propose a number of potential causes that are then quickly evaluated in turn.  This could be an excellent paper, but in its current form, it is borderline. The main problem with the paper is that it proposes a number of causes for the limited transferability, and then evaluates each of them with one quick experiment and just a paragraph of text. In particular, none of the results actually convince me that the claim is definitely correct, and many of the experimental setups are confusing or would have other explanations other than the one variable that is aiming to be controlled for.  That said, even with these weaknesses, this paper raises interesting and new questions with an approach I have not seen previosuly. So while I don't believe the paper has done much to actually demystify transferability, it does take steps towards performing scientific experiments to understand why it is so hard. And these experiments, while not perfect, can serve as the basis for future work to extend and understand which factors are most important."
    ],
    [
        "This paper proposed a learning approach for robustness to shortcut learning. The paper tackles the problem of shortcut learning by generating synthetic data (“roadblocks”) in a manner which confuses the network while being close to the original training data so as to prevent it from learning shortcut features that lead to poor generalization. The proposed approach is an auto-encoder that learns to manipulate the input samples to remove shortcut information. The approach was evaluated on ColorMNIST, CelebA and BAR benchmarks.  The paper is missing citations of the relevant literature on shortcut learning, simplicity bias, group robustness, and spurious correlations. The authors have added some citations in the revised version, however, it needs re-organization and re-examining. The results on CMNIST are not directly comparable to prior work due to a different model architecture.  Overall, the paper is not suitable for publication at ICLR in current form.",
        "The submission describes a new method to avoid the shortcut learning behaviour in DNNs. After the rebuttal and discussion, most of the reviewers are positive about this submission since the proposed method does not require prior knowledge about the dataset and the strong empirical results for the debasing task. On the negative results, the reviewers argue that the experimental evaluation is not thorough enough. Overall, AC recommends acceptance but asks the authors to perform more rigorous evaluation for the camera-ready version including the fair tuning of the hyperparameters."
    ],
    [
        "This paper deals with a stochastic multi armed bandit problem with a known fairness constraint that each arm should be pulled for at least a fraction of time. The authors propose and analyze a new algorithm that works within this constraint, which converts an unconstrained fair solution into a penalized version with gap-dependent and -independent regrets. The proposed algorithm is empirically shown to be good in experiments.   Overall, this is a well-written paper. The fairness constraint is well-motivated and the problem is interesting. The contribution of the paper is original and significant. The major concern that was raised by the reviewers was about the fairness parameter tau_k, which is known to be influential in the performance of the proposed algorithm. While the parameter has not been formally analyzed, it should be in the paper at the earliest. Another concern is about using the synthetic data only, but the authors have provided additional results in the rebuttal to address this concern.",
        "The paper provides an algorithm for the stochastic multi armed bandit (MAB) problem in the regime with fairness constraints. It continues a line of work that in high level define fairness as a requirement to ensure a minimum amount of exploration for every arm. The main concern I found in the reviews regards the definition of fairness in this paper. Although it follows the same high level narrative of previous works its exact definition and difference from previous papers is not convincingly motivated, and seems to be tailored to the proposed algorithm rather to a real world fairness constraint. This issue could have been mitigated by a novel or generalizable technique, or insightful experiments, but this does not seem to be the case given the reviewers comment about the limited novelty and basic experiments."
    ],
    [
        "In this paper, the authors try to study if we can learn about the human's process of generating new ideas or concepts from embeddings. The authors tested Gaussian model, Preferential Placement (PP) model, and Directional Preferential placement (DPP) model. Many graph generation models are surveyed in the experiments. The experiments on many real-world datasets are conducted.  The idea is worth further exploration, but the technical contribution of this submission seems to be weak. It is not easy to understand the problem formulation and rationale discussion. The paper lacks some key elements.  Another concerns I have is the embedding. The embedding space is not described clearly. I suggest the authors to revise the paper by explaining what is meant by \"semantic properties\" in the paper.",
        "The authors of this work introduced new metrics for node embedding that can measure the evolution of the embeddings, and compare them with existing graph embedding approaches, and experimented on real datasets.  All reviewers agreed that the work addresses interesting problem and that the proposed measures are nove, but there are too many flaws in the initial version of the paper, and despite the thorough responses of the authors, it is believed that there are still too many open questions for this paper to be accepted this year ICLR."
    ],
    [
        "This paper proposes a method of compressing neural radience fields (NeRF's) by learning mappings from latent codes to model parameters such that both distortion/reconstruction quality and the rate get minimized while maintaining the same level of quality in the other parameters. The reviewers think the work is well-motivated and the idea is interesting. However, the reviewers are not convinced that the problem this paper seeks to solve is so relevant to the ML research community that is justifies the lack of novelty. More convincing experiments are needed to demonstrate the practicality of the proposed method.",
        "Description: The paper presents a method for encoding a compressed version of an implicit 3D scene, from given images from arbitrary view points. This is achieved via a function, learning with a NeRF model, that maps spatial coordinates to a radiance vector field and is optimized for high compressibility and low reconstruction error. Results shows better compression, higher reconstruction quality and lower bitrates compared to other STOA.  Strengths: - Method for significantly compressing NerF models, which is very useful since such models are often trained for every new scene - Retain reconstruction quality after compression by an order of magnitude   Weaknesses: - The need for decompressing the model before rendering can be done means reduced rendering speed. This also requires longer training times. - Experiments against other scene compression + neural rendering technique will have further strengthened the papers’s claims  - The techniques used are well established, and thus there is not as much technical novelty."
    ],
    [
        "The authors show that non-convex smooth stochastic gradient descent, with a constant step size, can exhibit bizarre behavior: it could converge to a local maximum, or diverge even in convex settings if the learning rate is too high. While at first glance the results seem to be of somewhat limited significance, the authors provide a detailed and well-designed rebuttal, which convincingly addresses a number of the concerns raised by the reviewers. After an extensive discussion, all the reviewers are convinced that the claims of the paper are correct, and there is a consensus to accept the paper.",
        "Overall, the paper provides interesting counter examples for the SGD with constant step-size (that relies on a relative noise model that diminishes at the critical points), which provide critical (counter) insights into what we consider as good convergence metrics, such as expected norm of the gradient.   The initial submission took a controversial position between the mathematical statements and the presentation of the statements on the behavior of the SGD method in non-convex optimization problems. While the mathematical is sufficient for acceptance at ICLR, the presentation was inferring conclusions that could have been misread by the community.  I am really happy to state that the review as well as the rebuttal processes helped improved the presentation of the results that I am excited to recommend acceptance."
    ],
    [
        "### Summary  The paper presents an empirical evaluation of the role of visual perspective in learning and generalization for physical manipulation tasks. It presents results on six manipulation tasks adapted from Meta-World and shows that carefully placing a camera on the action (or in the hand) improves the generalization performance on these tasks.  ### Strengths  - The paper is well written.  - Performance evaluation is thorough.   - Results on proprioception only: comparison the presented results with the current results in this paper  ### Weaknesses  - There are some clarity issues as pointed out by the reviewers: - Analysis of camera placement for vision-based manipulators is a straightforward followup to an existing prior work [1]. The new paper should not be referred to as a followup. It should instead be an analysis of the perspective that was extracted from the camera by using a hand. - It is not clear what the takeaway from this paper is, as a disembodied",
        "All reviewers consistently agree on the high quality of the research presented in this paper, such that it the paper clearly is significantly above the acceptance threshold of ICLR."
    ],
    [
        "This paper proposes Graph Hawkes Neural Networks (GHNN) which are suited for performing inference in temporal knowledge graphs. By combining the continuous modeling provided by cLSTM with strong assumptions about how events can impact one another, GHNN shows promising results compared strong baselines on the GDELT and ICEWS14 dataset. The reviewers agree that the paper is well written, the model is sound, and the experiments show promising results.",
        "This paper propose Graph Hawkes Neural Networks (GHNN) which are suited for performing inference in temporal knowledge graphs. By combining the continuous modeling provided by cLSTM with strong assumptions about how events can impact one another, GHNN shows promising results compared strong baselines on the GDELT and ICEWS14 dataset."
    ],
    [
        "The paper presents a new dataset and benchmark for the task of tracking any point in a video. The proposed dataset is called TAP-Vid and it has a mixture of real and synthetic data. For real data, human manually annotates the ground truth for several 2D salient points, and for synthetic data, perfect ground truth labels are provided.  The paper received 5 reviews form 5 reviewers and all are positive about the paper. The reviewers find that the paper is well written and clear, the benchmark is well designed and the experimental results are reproducible. Moreover, the authors propose a new algorithm for the dataset's collection and testing which is interesting.  Therefore, I recommend accepting this paper to the NeurIPS 2022 Datasets and Benchmarks program.",
        "TAP-Vid presents a benchmark that will be highly useful for tracking research for tracking arbitrary physical points on surfaces over long video clips. The reviews are all positive, with one reviewer raising ethical aspects in preparing the benchmark.  I find the rebuttal sufficient and adequate and hence recommend acceptance of the paper."
    ],
    [
        "This paper proposes a self-supervised event sequence prediction method called CoLES that uses contrastive learning to learn representations of event sequence related to user behavior. The reviewers agree that the paper targets an important problem, the proposed method is reasonable, and the experiment results are reasonable. However, as pointed out by the reviewers, the improvements over the baselines are not significant enough. We encourage the authors to improve the paper accordingly and resubmit to a future venue.",
        "This work is well written and accurately covers the context and recent related work. It's a good example of how to apply self-supervised training to the event sequence domain. However, the combination of a lack of technical originality (composing a set of previously explored ideas) and significant improvements in results (results with CoLES overlap in error bars with RTD results) limits the impact of this paper.  Pros: - Well written. - Extensive evaluation. - Well formulated problem.  Cons: - Lack of technical novelty. The method appears to be general to all sequences rather than specialized for event sequences so the motivation for this design is not crystal clear. - Minor improvement in results from using the method despite written claims that the method 'significantly outperforms'. - Limited analysis that shows the periodicity and repeatability in the data."
    ],
    [
        "This paper proposes a mean field model of spiking neural networks (SNNs) that abstracts part of the dynamics, by using the Baum-Viterbi algorithm and deriving a latent dynamics model based on the mean field approximation. They use mean field modeling to recover the connectivity of observed SNNs from snippets of 10 sec activity of only some observed neurons.  The paper is well written and an interesting attempt at extracting more interpretable latent models. The approach is novel in the sense that it incorporates the idea of mean field modelling on the net effect of unobserved neurons, and is validated on within model class simulated data.  After rebuttal and discussion, the reviewers unanimously agree that this submission would make a valuable contribution to ICLR.",
        "Dear authors,   Congratulations on your paper being accepted! The reviewers unanimously recommended acceptance. The reviewers made a number of recommendations on how to improve the paper further, in particular with respect to clarity of writing and explaining the motivation behind different analyses. We strongly encourage you use this feedback to improve the paper— if needs be additional clarifications can be added in the supplement. In addition, it would indeed be highly useful to make your source code publicly available, as you indicated in your response.   Best, your AC"
    ],
    [
        "The paper proposes a meta-learning model for classification that produces distributional embedding of the task, and then uses this information to perform few-shot classification.  The paper has been reviewed by four reviewers with three borderline scores leaning towards rejection and one clear accept. The reviewers have raised several concerns, including limited novelty of the proposed method and insufficient experiments. The rebuttal has addressed some of these concerns, but not to the degree that reviewers think it passes the bar of ICLR.   The area chair agrees with the reviewer's assessment and follows their recommendation.",
        "This paper addresses a meta-learning method which works for cases where both the distribution and the number of features may vary across tasks. The method is referred to as 'distribution embedding network (DEN)' which consists of three building block. While the method seems to be interesting and contains some new ideas, all of reviewers agree that the description for each module in the model is not clear and the architecture design needs further analysis. In addition, experiments are not sufficient to justify the method. Without positive feedback from any of reviewers, I do not have choice but to suggest rejection."
    ],
    [
        "We thank the authors for their submission.  General consensus among the reviewers is that this is an interesting work that advances the state of the art in finding equilibrium in continuous-time RL.  However, there is some question as to whether the work is ready for publication in its current form. The work assumes that t, the number of iterations, is fixed at the onset. This is typically not the case in CFR, where the starting point is a random policy and the iterates are random. The authors propose to augment this by sampling from a double neural network, which estimates the current strategy at iteration t+1 and the average strategy after t iterations. While this seems like a reasonable solution to overcome the issue of sample size, it is unclear whether double neural net would scale to much larger games. If so, more evidence would need to be presented to support the claim.",
        "The reviewers agreed that there are some promising ideas in this work, and useful empirical analysis to motivate the approach. The main concern is in the soundness of the approach (for example, comments about cumulative learning and negative samples). The authors provided some justification about using previous networks as initialization, but this is an insufficient discussion to understand the soundness of the strategy. The paper should better discuss this more, even if it is not possible to provide theory. The paper could also be improved with the addition of a baseline (though not necessarily something like DeepStack, which is not publicly available and potentially onerous to reimplement)."
    ],
    [
        "This paper proposes AdaSpeech, a TTS system that can adapt to a custom voice with a high quality output and a low number of additional parameters. The proposed method is based on the TTS model in FastSpeech 2, with several additional components including multi-phonetic acoustic condition modeling and conditional layer normalization.  The authors propose an interesting text-to-speech adaptation method for high quality and efficient customization of new voice. Reviewers generally agree that the empirical results are strong. The paper is well written and the ablation studies are comprehensive. The authors have addressed most of the concerns raised by the reviewers during the rebuttal. Overall, this paper is recommended to be accepted at ICLR 2021.",
        "The paper is about adapting a voice generation model to new speakers with minimal amount of training data. The key insight in this paper is that the voice can be adapted using a small set of variables -- the bias and the variance associated with the layer that normalizes the mel-spectrogram associated with the decoder. Additionally, they characterize voice at the utterance level to capture stationary factors like background acoustic conditions and at the phoneme level to capture factors such as prosody, though there are no explicit constraints to force such representation.  The strength of the paper are: + Simplicity of the approach + Empirical evaluation that demonstrates its effectiveness  The weakness of the paper are: - analysis of what the crucial parameters of the model represent - lack of clarity that is obvious from several back-and-forths between the reviewers and the author.  A few examples include: - “There is also a phoneme-level acoustic embedding which is used in the same way, which at inference is taken from random sentences (why not in training?), and, I guess, is supposed to cover phoneme-level idiosyncrasies of the speaker, although this isn't clear to me.” - “ it is only the speaker embedding that is the input to fine-tuning, and this only via the normalization parameters. (Both the normalization parameters and the speaker embedding itself are fine-tuned.) I am not sure what the speaker-embedding is left to do with all this acoustic-level input, but OK.”"
    ],
    [
        "The paper presents a method that allows for faster learning in sparse-reward tasks by leveraging a single expert demonstration.  The reviewers found the paper to be well-written and generally easy to follow.  They appreciated that the method provides a useful method that could be useful for imitation learning.  However, the reviewers had a number of concerns about the experimental evaluation, including the difficulty of the environments, the lack of baselines suggested by a reviewer, and the significance of the performance improvements.  Overall, I found the contributions to be incremental.  While this is a good paper, I think it falls below the acceptance bar for ICLR.  I encourage the authors to revise the paper based on the reviewer feedback and resubmit.",
        "There was quite a bit of internal discussion on this paper. To summarize: - The idea is very neat and interesting and likely to work - The paper is likely to inspire future work - There are still serious doubts  about the experimental evaluation that is not entirely up to par with current standards   - The reviewers were not convinced 100% by the arguments about the 'custom' environments   - The reviewers were not convinced 100% that the baselines were given their best shot  While the paper has potential to provide valuable input for the community, it needs a bit more work before being presentable at a highly competitive venue like ICLR."
    ],
    [
        "The paper proposes a model-based posterior sampling algorithm and provides a Bayesian regret bound. The proposed method is claimed to be computationally tractable. However, the regret bound is of the order of H^1.5 d T^T where d is the number of parameters of the model. There is no study on fundamental limit. The paper is not ready for publication in its current form. I encourage authors to update the paper based on reviewers' comments and resubmit it to one of the upcoming conferences.",
        "This paper presents a model-based posterior sampling algorithm in continuous state-action spaces theoretically and empirically. The work is interesting and the authors provide numerical evaluations of the proposed method. But the reviewers find the contribution of the work limited."
    ],
    [
        "In this short paper, the authors present a new fully integrated pipeline to diagnose common thoracic diseases and generate radiology reports on chest x-ray images. The proposed method uses CNN for image classification on Chest X-rays and a different CNN-RNN structure is then used to generate reports. Different strategies are used for normal/abnormal cases. The result shows good improvement and many state of the art methods are compared.  The authors however did not made clear what motivated their technical choices compared with Li et. al. and Xue et al. ( 2018) for the particular pipeline, and neither are the methods to generate the reports novel. Furthermore, the datasets used in the evaluation are not novel.  In conclusion, although the paper is well written and the methodology is clear, the improvement over previous work is not significant.",
        "This paper presents a pipeline for automatic interpretation of  medical imaging and learning-based diagnosis. On the one hand, the paper tackles an important and challenging problem, but on the other hand, the validation is very limited and novelty over previous work is unclear. This is therefore a borderline paper."
    ],
    [
        "The paper studies generalization bounds for tuning the hyperparameters of the elastic net and lasso algorithms using multiple draws of train/test splits from a fixed (but arbitrary) problem distribution, and online learning. The authors show that given such an distribution and a set of validation losses, they can show that it requires a relatively small number of draws from this distribution to minimize the average validation loss.   The reviewers and AC note the following potential weaknesses: (1) Reviewer 3 pointed out that exact results are not presented for the lasso and the paper’s main result on the validation loss is not presented in this context (R3). The authors replied that the bound would not imply exact solutions, but provide a generic statement that the number of problems needed is O(sqrt(d) for a certain accuracy; however, this is not a precise statement and could be improved in the future by specifying a precise number of challenges. (2) R3 also",
        "The reviewers agreed that this paper should be accepted -- it studies an interesting and in someways \"overlooked\" problem and seems like it could be a starting point for others to build on. The paper did have some weaknesses. For example, we feel that the lack of experimental results is a missed opportunity -- the reviewers feel the paper would be made stronger by including at least a simple example where the standard approach of grid search + CV fails. Without such an example, it is a bit hard to be convinced of the importance of the problem being studied."
    ],
    [
        "The paper introduces a new technique for density ratio estimation by introducing a non-negative Bregman divergence and a new risk estimator. This new estimator aims at solving the \"train-loss hacking problem\" by learning the ratio between two densities from their samples.  Theoretical analysis and experimental results clearly support the proposed approach.  However, several concerns remain after the discussion among the reviewers. In particular, it is unclear how strong the theoretical claims are, and the writing needs significantly more work to improve clarity. The reviewers are also concerned about the gap between the theory and experiments.  Therefore, the paper is not quite ready for publication yet. The authors are encouraged to revise the paper based on the reviewer's comments and submit it to a future venue.",
        "This paper discusses the likelihood ratio estimation using the Bregman divergence.  The authors consider the 'train-loss hacking', which is an overfitting issue causing minus infinity for the divergence.   They introduce non-negative correction for the divergence under the assumption that we have knowledge on the upper bound of the density ratio.  Some theoretical results on the convergence rate are given.  The proposed method shows favorable performance on outlier detection and covariate shift adaptation.  The proposed non-negative modification of Bregman divergence is a reasonalbe solution to the important problem of density ratio estimation.  The experimental results as well as theoretical justfication make this work solid.  However, there are some concerns also.  The paper assumes knowledge on the upper bound of density ratio and uses a related parameter essentially in the method.  Assuming the upper bound  is a long standing problem in estimating density ratio, and it is in practice not necesssarily easy to obtain.  Also, there is a room on improvements on readability.   Although this paper has some signicance on the topic, it does not reach the acceptance threshold unfortunately because of the high competition in this years' ICLR."
    ],
    [
        "pros: - The paper fits well into the scope of the workshop - The topic is interesting and relevant to the workshop  cons: - There were some concerns by one of the reviewers about the novelty of the approach, but I agree with the other two reviewers that the approach is novel and interesting. - There was initially some concern about the experimental evaluation, but the authors have updated the experimental results in the rebuttal to address this concern.  I think this is a good paper and the topic is of interest to the audience attending the workshop and would like to see it presented at the workshop.",
        "Reviewers agree that the authors propose an interesting new framework for learning ad-hoc communication. There are some recommendations of improved baselines but both reviewers seem excited by the idea and we look forward to having the authors discuss this at the workshop and get important feedback on their work."
    ],
    [
        "The final scores for this submission are borderline, but the reviewers seem to agree on the positives (the contributions of the dataset itself) while the authors have gone through great lengths to address criticisms in terms of number of algorithms compared, the size of the datasets, the ability of the tasks, and the writing quality. Reviewer MHDH was also very thorough to catch an unintended overlap of train and test data, which the authors corrected. Taken as a whole, I believe the dataset and authors have done a great job addresses the perceived weaknesses of the manuscript and dataset. I also believe it is not obvious that deep methods would generalize from passive to active stereo, so I believe this is a worthwhile study.",
        "The final scores for this submission are borderline, but the reviewers seem to agree on the positives (the contributions of the dataset itself) while the authors have gone through great lengths to address criticisms in terms of number of algorithms compared, the size of the dataset, the ability of the dataset to generalize to the real world, and the writing quality. Reviewer MHDH was also very thorough to catch an unintended overlap of train and test data, which the authors corrected. Taken as a whole, I believe the authors have done a great job addresses the perceived weaknesses of the manuscript and dataset. I also believe it is not obvious that deep methods would generalize from passive to active stereo (a concern of reviewer MHDH), so I believe this is a worthwhile study."
    ],
    [
        "This paper studies the problem of unsupervised anomaly detection and proposes a self-supervise, refine, repeat (SRR) approach to filter out anomalies and improve the robustness of the detection by refining the anomaly samples in the training set. The approach is novel and the experiments show promising results on a variety of datasets.   However, there are some concerns regarding the choice of benchmarks and the clarity of the presentation, which make the paper difficult to read for the most part. In addition, some recent works on anomaly detection have also been included in the comparisons, making it hard to appreciate the novelty of the proposed approach.",
        "The paper worked on fully unsupervised anomaly detection and proposed to use self-supervised representation learning to improve the performance of one-class classification. This is a borderline case close to acceptance but cannot make it. Specifically, it is useful, but its novelty is the main issue, since it is not surprising that self-supervised representation learning can improve one-class classification without representation learning (this part is still much of the taste of ICLR) and an ensemble of multiple models can improve upon a single model (which is just \"bootstrap aggregating\" or \"bagging\" used everyday in practice and known to machine learning and statistics societies a very long time ago). After seeing the rebuttal, the concerns were not really addressed well and the issues were only partially solved. Thus, the paper is not enough to guarantee an acceptance to ICLR unfortunately."
    ],
    [
        "The paper studies an interesting problem, and is relatively well written. Personalized PageRank (PPR) is an important metric, and differentially private algorithms are not known. This paper proposes an algorithm which outputs an approximate PPR and has provably bounded sensitivity to input edges. They also propose a sensitivity-bounded algorithm for graph embedding. This is a simple but reasonable algorithm for the commonly used metric. However, the reviewers are not satisfied with the response given by the authors. The randomized response is a weak baseline, and the algorithm should be motivated by novel and substantial new results. The novelty of this paper is limited.",
        "Paper studies computing PPR in differential privacy setting. Given the importance of PPR in real world applications, we recommend accepting the paper as it brings an important problem to the DP community. However, we encourage authors to incorporate the comments from the authors, make sure that all the details of the proofs are made available in the final version, and clarify any comments reviewers raised. In particular, we encourage the authors to adequately address the criticisms of @Reviewer MDNv in the true spirit of science."
    ],
    [
        "This paper studies the generalization property of gradient-based optimization algorithms using PAC-Bayesian bound. They use the standard deviation of the Jacobian of the underlying function in the bound to derive generalization bounds for a number of algorithms including FGD, SODA, stochastic gradient Langevin dynamics, and Gaussian processes.   The reviewers found the general idea of analyzing generalization in this way interesting and novel, and the resulting bounds also provide nice insights into the performance of various algorithms. On the other hand, there were concerns about the clarity of the presentation as well as the experimental evaluation (lack of non-vacuous functions in some of the bounds, and lack of experiments on real data).   After the author response and reviewer discussion, the reviewers decided to mostly accept the paper, with one low score (5) raising their confidence as a result. However, they also pointed out that the paper still needs some more work in order to improve",
        "Authors study generalization properties of gradient-based optimization algorithms via a PAC-Bayesian approach. Based on a data-dependent prior, authors establish a generalization bound for FGD, FSGD, GLD, and SGLD. The authors also provide convincing empirical studies to demonstrate that their results are not vacuous.  - Authors should better motivate the use of their seemingly synthetic algorithms.  - There are many typos in this paper, other than the ones listed by the reviewers. Although the reviewers did not raise this issue, authors should make sure their paper is ready for camera ready if the paper is accepted."
    ],
    [
        "The paper proposes a new method to learn belief models for solving partially observable stochastic multi-agent games. The key idea is to bootstrap partial rollouts instead of full rollouts, to improve the efficiency, and to obtain Monte Carlo estimates of the expected return for every possible action in a given action-observation history. The approach is applied to solving Dec-POMDPs.  The reviewers agree that the main strengths of the paper are the improvement in efficiency and the ability to sample in a large state space, but also raised concerns about the clarity of the writing and the scope of the experiments. The authors have improved the paper significantly during the discussion phase. However, the AC decided that the paper would benefit from another round of revision and resubmission to another venue, and therefore recommend rejection.",
        "This paper has some interesting ideas and is an incremental improvement over previous work. However, it needs further revisions and polishing. The relation to prior work is a bit unclear. Since you mention POMDPs, what would be an equivalent version of your method in POMDPS? Why not compare your algorithm with a state-of-the-art method for small discrete problems? It is also a bit unclear why training a model to predict beliefs would be faster than just calculating them (after all the data must come from somewhere).."
    ],
    [
        "This paper proposes a novel method to improve the transferability of adversarial attacks by increasing the logit margins between targeted and non-targeted classes. The work is highly inspired by the work of Zhu et al. 2021 and introduces three different calibration methods: temprature-based, margin-based and angle-based temperature scaling. The authors perform comprehensive experiments and demonstrate that the combining logit calibrations have significantly better performance than previous methods.   Overall, all the reviewers are positive about this work. The paper is well-written and the effectiveness of the proposed method has been demonstrated through extensive experiments. The vanishing gradient issue in the CE loss function which is commonly used to learn transferable adversarial samples from adversarial examples has been investigated in more detail in this paper.  Therefore, we recommend acceptance.",
        "In this paper, the authors propose novel method to improve transferability of targeted adversarial attacks by enlarging the margin between targeted logit and non-target logits.  Experiments on ImageNet with different methods demonstrated the effectiveness of the method. However, as is pointed out by the reviewers that there exist high overlap between the paper and the existing works, which significantly hinders the novelties of the paper. The paper are expected to clarify the novelty and provide more comprehensive evaluations."
    ],
    [
        "This paper tackles generative modeling via finding push forward functions that iteratively move particles from a reference distribution toward the target data distribution. The velocity fields are solved by minimizing the f-divergence between the particle density at iteration k and the targetData density, which is shown to be in the form of the gradient of density ratio. Reviewers have a consensus on rejection due to unclear motivation, unconvincing theoretical results, and incomplete/imprecise presentation.",
        "The paper proposes a discretization of Wasserstein gradient flow with an euler scheme, and propose a way to estimate each step of the euler scheme using ratio estimators from samples regularized with gradient penalties. Statistical bounds are given to bound the estimated flows from the wasserstein flow.    Reviewers have raised concerns regarding the assumptions under which results present in the paper hold, this was clarified by the authors (goedesic lambda convexity, log sobolev constant for the target density . lipchitizity of velocity fields).  The paper needs a revision to incorporate that feedback and to be in shape for publication.   Other concern were on earlier claims in the paper regarding the monge ampere equation and approximation of the optimal mapping this was addressed by the rebuttal.   Other concerns were also on explaining the relation of the work to score based models and energy based models.   Overall the paper needs to state in a clearer way the assumptions for the theoretical results and to acknowledge the limitations of those assumptions in analyzing the euler scheme."
    ],
    [
        "This paper analyzes the training dynamics of two-layer ReLU networks applied to separable problem data. Although the reviewers have shown some concerns about the technical novelty of the paper, it is felt that the result of this paper is novel and is of interest to the ICLR community. Therefore, I recommend acceptance. Meanwhile, please carefully revise the paper based on the suggestions by the reviewers: they made many careful suggestions to improve the presentation and strengthen the results.",
        "The papers makes progress on the important question of implicit bias in gradient based neural learning. Remarkably they derive reasonable conditions for global optimality."
    ],
    [
        "This paper presents a prompt learning framework for lifelong and few-shot language learning. The reviewers have reacted to each others' comments as well as the authors' response to their views. Overall, there is consensus that this paper presents an interesting take on a challenging problem. However, there are concerns both about the significance of the continual learning problem, and about the experimental results. The latter would have been stronger if the proposed approach could have been demonstrated on a more challenging lifelong learning problem (e.g. summarization or text classification), and/or been compared to a newer generation of prompt learning approaches. The former would also have strengthened the evaluation.",
        "This work defines the new problem of lifelong few-shot language learning where the goal is to continually learn new few-shot tasks and use those to benefit future tasks while not forgetting previous tasks. With larger models, this is an important goal due to the cost of updating and retraining these models. The work also shows superiority to existing approaches like EWC and MAS. After the author's rebuttal, the experimental section is also thorough with evaluation on a good range of tasks and approaches such as adapters showing good results. While this setting appears simpler than the full lifelong-learning setting and the approach combines existing ideas, this work's contribution to the definition and thinking about this problem is valuable. However, the authors should more clearly state the advantages of their approach vs standard prompt tuning (with an emphasis of benefiting future tasks) since two reviewers seem caught up on this point. The other two reviewers comments were addressed by the rebuttal as they stated in their comments."
    ],
    [
        "This paper presents a new benchmark consisting of multiple natural language understanding tasks. All reviewers were in agreement that it will be an impactful resource for the NLP community.  It has a diverse set of tasks and will be a good fit for the NeurIPS 2021 Datasets and Benchmarks Track. The authors also do a good job in the rebuttal period in addressing reviewers' comments and have updated the paper to address specific suggestions.",
        "This paper provides an interesting benchmark for multitask learning in NLP. I wish the dataset included language generation tasks instead of just classification but it's still a step in the right direction."
    ],
    [
        "This paper presents an interesting application of deep learning for Model Correction in Cardiac Electrophysiological Imaging. The physical model is well-motivated and explained, and the data-driven model can be a good addition to the program. However, all data is simulated, so there is really no \"imaging\" involved. Therefore, the significance and motivation of the proposed method need to be better explained. A thorough comparison with existing methods is needed to establish the benefits and limitations of this approach. Finally, the authors should also provide proper link to the literature and explain the novelty of this work.",
        "This work is clear, very original, however it lacks a bit of significance and is more of a proof of concept. Here are the pros and cons I've identified.  Pros : - This work deals with physics-based deep learning which is a very recent subject and one of growing interest for the medical community. - Results on simulated data look promising. - The theoretical part and the implementation is clear, too bad the code is not shared.  Cons : - The responses to the reviewers are very dense, often repeat the same explanations from one reviewer to another and lack relevance. It is not clear what has been changed in the manuscript in particular. - The proof of concept should have been to support in the claims of the authors, as well as the use of simulated data in the title as suggested by the last reviewer - In order to make the work more robust and quantitative, different physical models could have been considered, different Resnet architectures and an application to real data.  This work is extremely interesting but still a little immature. So I suggest an acceptation as a poster."
    ],
    [
        "The paper presents an event prediction method for continuous-time dynamic graphs. The key idea is to predict both the event time and the time step of the event jointly, rather than only predicting one given the other. The paper uses community detection and marked temporal point processes to form a unified model for event prediction. Empirical results demonstrate the effectiveness of the proposed method.  The paper is well-written and the idea of combining event prediction with community detection is interesting. However, there are concerns about the novelty and significance of the contribution. The main contribution of the paper seems to be the use of community detection instead of more traditional event prediction methods. Also, there is a lack of ablation studies to analyze the effect of different choices of the method.",
        "We agree with the AC that this paper is ready for publication. We encourage authors to incorporate suggestions for clarity improvements, in particular those mentioned by reviewer `XRhC`."
    ],
    [
        "This paper proposes a modification of the original Transformer architecture by replacing attention layers and layers in its Feed-Forward Networks with learned shared dictionaries. The proposed model, called DictFormer, has a smaller number of parameters and uses a smaller amount of computational operations while outperforming related work on machine translation and summarization tasks.  The reviewers found the motivation and the idea of the proposed method interesting, but there are few concerns in terms of the presentation. It is hard to judge whether this paper has enough contribution for publishing as the conference paper. Potentially a great paper, but if so it deserves to be much better explained.  During the rebuttal, the authors have also been successful in addressing the concerns raised by the reviewers.  Overall, the paper contains a lot of substance, but it is very dense and hard to follow at a high level. The dictionary of shared parameters could potentially be the key to make the model more efficient and effective in practice, but that part is",
        "DictFormer is a method to reduce the redundancy in transformers so they can deployed on edge devices. In the method, a shared dictionary across layers and unshared coefficients are used in place of weight multiplications. The author proposed a l1 relaxation to train the non-differentiable objective  to achieve both higher performance and lower parameter counts.  All reviewers ended up giving the paper a score of 6 after increasing their scores during discussions. While the results are strong (better performance at much lower parameter counts), the paper is not clearly written. Several reviewers noted that the paper is difficult to understand and has a few unresolved points. For example, the method also ended up performing better than the base transformer model that DictFormer is supposed to compress. There seems to be a lack of understanding about what part of the model delivered the improvements. One reviewer said that this is potentially a great paper that deserves to be better explained. The basic concept of sharing a dictionary across layers should be simple enough to explain well and deserve a better explanation than eq 5.   The authors promise to release the code, which would be necessary for a full dissemination of this work. I recommend accept."
    ],
    [
        "Meta Review: The paper studies data poisoning for off-policy evaluation. The authors propose a new attack problem and an attack method, and provide an attack problem formulation and attack attack technique, as well as empirical results.  They solve the problem by solving the poisoning problem via influence functions, and demonstrate the effectiveness of the method empirically.   The meta-reviewer agrees with the reviewers that the paper is well-written and easy to follow, the poisoning attack is natural and interesting, and the paper provides a principled solution to the problem.  The authors should consider discussing the limitations of the approach in a revised version, especially the modeling side.",
        "Meta Review: This work proposes a data poisoning attack for off-policy evaluation (OPE) methods. It also shows that several popular OPE methods are not robust to data poisoning attacks. The reviewers were all positive on this work, recommending strong accept, accept, accept, and weak accept. They praised the generality of the proposed problem and framework.  One main criticism that arose in several of the reviews was a lack of a stronger baseline comparator. In their response, the authors pointed out the challenge of identifying a suitable baseline, given a lack of previous work in data poisoning for off-policy evaluation. In an attempt to provide a suitable baseline, they developed their own comparator, namely a variant of the Fast Gradient Sign Method. They then showed that their main proposed framework outperforms this comparator. In my view, this response adequately addressed this reviewer critique.  The reviewers also made a number of other relatively minor comments and suggestions, and the authors addressed these in their replies."
    ],
    [
        "This paper proposes a MRF-UNet product to improve the generalization to unseen data. Unfortunately, reviewers pointed out that the technical novelty is very limited, and that the results are not very convincing. Segmentation is a very important problem in machine learning, and this paper aims to improve it.   Authors are encouraged to revise the paper according to the reviewers' comments and submit it to a future venue. We congratulate the authors on the acceptance of their paper!",
        "This paper proposes a MRF-UNet product to improve the generalization to unseen data. The reviewers pointed out the high similarity and overlap with IPMI Brudfors-2019. Moreover, they questioned  the results, which are lower than current state-of-the-art.  Consequently, the practical use of this method seems quite limited. However this paper is well-written and the tackle problem is very important."
    ],
    [
        "The paper proposes to replace the deterministic activation functions used in neural nets with stochastic variants, introducing the concept of q-calculus. The idea is interesting, but in its current form the paper is not suitable for publication at ICLR.  The experiments show that the proposed methods outperform existing methods in terms of training speed and convergence, but the models are not actually trained to convergence. Given that convergence rates are known for deep neural networks, these results would be of interest to the community, and the paper would be more convincing if these results were also shown for simple ReLU networks, as is likely the case in practice.",
        "This paper proposes a new type of activations function based on q-calculus. The reviewers found that the papers is significantly lacking in its presentation, in clarity, and in its experimental evaluation. The motivation of the method raises several significant questions to the reviewers, and the proposed method is not sufficiently compared to existing approaches for (noisy) activation functions. After reviews, the authors have failed to present any updates to their paper."
    ],
    [
        "The paper proposes a Topological graph layer for GNNs to boost the ability of topological structure detection. All reviewers give positive feedback, saying that the paper is well-motivated, well-written, and builds on a good theoretical framework. Authors respond to the main points of criticism from the reviewers and all reviewers eventually agree on accepting the paper.   The paper will be a good addition to the Graph Neural Networks (GNNs) society.",
        "This paper presents a new graph neural network layer that is sensitive to topological structure in the graph. Reviewers all believe the work is technically sound, and the experiments (particularly after author revisions) show clear benefits in cases where topological structure is important. The main questions are about whether the experimental evaluation is sufficient. While there are always more experiments that could be run, I tend to agree with the authors that the chosen experiments support the key claims in the paper, so it seems ok. The other question about the experiments is if they sufficiently convince the reader that topological structure is useful in practice. This seems more mixed. The paper would certainly be improved if there was a motivating application where there was a clear win. For example, molecular structures are used as motivation in the intro, but the best performing method on proteins doesn’t use the topological layer. All-in-all, though, there does appear to be clear improvements on carefully constructed cases, and there appear to be some benefits in real-world datasets."
    ],
    [
        "In this paper, the authors proposed a graph deconvolutional network (GDN) to reconstruct the original graph signal from smoothed node representations and incorporated a denoising component based on graph wavelet transforms. Further graph autoencoders are proposed based on the graph convolutional networks. The paper applies the proposed approach to tasks of graph classification in Table 1 and social recommendation in Table 2. The main concerns from the reviewers are that the novelty is limited, the baseline methods are not well established and the experiments are not comprehensive. There are far better results on these datasets such as GIN.  Authors did not respond to the reviewers' comments. In its current form, this paper is not ready for publication.",
        "The covered topic is timely and of potential impact for many application domains, such as drug design. The paper is well written and presentation is clear. The proposed approach seems to have some degree of originality. Experimental results seem to be generally good, and in the rebuttal the authors have provided further experimental support to their main claim.  There are however some issues that have not been solved by the author’s rebuttal. I think two of them are the most important and related:   i) significance of contribution: although the authors have tried in the rebuttal to explain how the proposed approach differs from related papers, it seems that there are still doubts about the amount of innovation introduced by the paper. This issue could have been mitigated by SOTA experimental results in presence of a proper model selection, that, however does not seem to be the case here (see next point);  ii) model selection: the authors did not clearly explain the model selection procedure in the rebuttal. This is an important issue since it is often easy to get good results by picking the best run a posteriori. Unfortunately in the literature there are highly cited papers where model selection is not performed in a proper way and reviewers very often reject papers just looking at numbers without looking at how the numbers were obtained. So, I believe it is important to accept only papers where model selection is properly done and properly explained, so to allow for reproducibility of experiments."
    ],
    [
        "The proposed Consensus method is an approach for pooling interpretations from different systems and aggregating the results, ranking the interpretations, and voting for the best one. The ground truth is provided in the form of a synthetic dataset.   Pros: - The paper addresses an important problem of evaluating the interpretability of neural networks - The proposed method is simple and easy to implement - Empirical results seem promising  Cons: - Lack of a running example of the method in real-world settings (ImageNet) - The method does not seem to work well for classification tasks where one would expect it to - The explanations provided are generated using synthetic data, which limits the applicability and reproducibility of Consensus. - The explanation provided are based on the synthetic ImageNet dataset, which may not be the best choice for this task  Unfortunately consensus does not provide any practical insights for measuring interpretability, which makes it a borderline paper. The authors tried to address some of the",
        "The reviewers all found that the Consensus method introduced seemed sensible and applauded the authors on their extensive experiments.  However, clearly they struggled to understand the paper well and asked for a clearer and more formal definition of the methods introduced.  Unfortunately, the highest scoring review was also the shortest and also indicated issues with clarity.  It seems like the authors have gone a long way to improve the notation, organization and clarity of the paper, but ultimately the reviewers didn't think it was ready for acceptance.  Hopefully the feedback from the reviewers will help to improve the paper for a future submission."
    ],
    [
        "This paper was reviewed by four experts in the field. Based on the reviewers' feedback, the decision is to recommend the paper for rejection. The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes.  The reviewers appreciated the effort the authors put into the rebuttal period. I thank the authors for engaging with the reviewers and updating the paper to address their concerns.  One of the main concerns of the reviewers is the novelty and the impact of the proposed contribution. The paper combines existing techniques (meta-learning based algorithm and pre-train fine-tuning based algorithm) in a new \"unified framework\". The reviewers found it hard to understand the specific contributions and the novelty is not high enough. Another key concern is the experimental validation. The proposed method is evaluated on only two tasks and the performance of the method is not convincing. It is expected that with more tasks and",
        "This work proposes an approach to unify pre-training-based and meta-learning-based few-shot learning, inspired by dropout.  None of the reviewers support the acceptance of this work, despite the authors' detailed rebuttals, with the majority of reviewers confirming their preference for rejection following the author response.   I unfortunately could not find a good reason to dissent from the reviewers majority opinion, and therefore also recommend rejection at this time."
    ],
    [
        "This paper presents a new model for unsupervised event detection. Its main idea is to control the update rate of the latent states in a hierarchy of RNN layers. The reviewers agree that the method is novel, well-motivated and well-analyzed. The experimental results are impressive, outperforming state-of-the-art methods. Congratulations on having your paper accepted to NeurIPS!  The authors: please carefully revise the paper based on the suggestions by the reviewers: they made many careful suggestions to improve the work and stressed that the paper should only be accepted once these changes are implemented.",
        "Thanks for your submission to ICLR.  This paper considers a variational inference hierarchical model called Variational Predictive Routing.  Prior to discussion, several reviewers were on the fence about the paper, most notably having concerns about some of the experimental results as well as various clarity issues throughout the paper.  However, the authors did a really nice job addressing many of these concerns.  Ultimately, several of the reviewers updated their scores, leading to a clear consensus view that this paper is ready for publication.  We really appreciate your effort in providing additional details and results.  Please do keep in mind the concerns of the reviewers when preparing a final version of the manuscript."
    ],
    [
        "The paper investigates the behavior of diffusion-based deep generative models (DDGMs) and its effect on sample quality. It makes the observation that the reverse diffusion step of DDGMs can be decomposed into two distinct parts: one corresponding to denoising and the other corresponding to generation. Inspired by this observation, the authors propose a new setup called DAED (Denoising Auto-Encoder + Diffusion Model) which is a combination of two parts. The first part generates noisy samples from the pure noise by inputting more signal from a learned data distribution and the second one removes the remaining noise from the signal. Most of the experiments are conducted on CIFAR-10/100 images. The results show that the proposed method is competitive or comparable to the state-of-the-art models on most datasets.   The paper provides an interesting interpretation of DDGM as both a generator and a denoiser. This interpretation is supported by extensive",
        "The paper analyzes diffusion-based deep generative models (DDGMs). The paper postulates that a DDGMs can be divided into two parts, a denoiser and a generator.   After the rebuttal and discussion period, three out of four reviewers supported acceptance of the paper. The reviewers aLmZ, QKfo, and 4jY9 all find the interpretation of a diffusion-based deep generative model as a decomposition of a generator and denoising part interesting. Those reviewers also note that this interpretation is useful as parts of the diffusion steps can potentially be replaced with a VAE, which would make the synthesis more efficient.  The reviewers aLmZ and QKFo also note that one comparison is perhaps slightly unfair in that the number of parameters of the two models considered was different; the authors cleared this up with new simulations showing that matching the number of parameters (as should be done for a better comparison) does not substantially change the conclusions of the experiment.   Finally, reviewer s9uB finds the approach and observations not to be novel and states that similar observations have been made in a recent CVPR paper by Benny and Wolf. While both the paper by Benny and Wolf and the paper under review study denoising diffusion models, the approaches taken by the two papers are substantially different, and both provide value to the community.  I also find the interpretation of the DDGMs as a denoiser and generator to be interesting and useful and therefore recommend acceptance of the paper."
    ],
    [
        "This paper presents Symbolic Reward Machines (SRM), a method for inverse reinforcement learning (RL) for learning the non-Markovian rewards for symbolic transitions of a pre-speciefied automaton. The authors adopt a Bayesian deep learning approach to simultaneously learn a reward approximator, a distribution over the parameters of the reward machine, and a policy to optimize the most-likely reward instance. They demonstrate that the inferred RM outperforms standard reward definition using standard RL approaches, and can be used to ground/concretize expert trajectories in an interpretable way.  After reading the authors' feedback and discussing their concerns, the reviewers agree that the proposed approach is interesting, however they believe that the current manuscript needs to be improved in terms of writing, comparison to prior work, and experimental evaluation to make it stronger.",
        "The paper proposes a framework of Symbolic Reward Machine (SRM), an extension of Reward Machine (RM), for specifying interpretable and explainable reward functions. Then, a Bayesian IRL method is proposed to concretize an SRM using expert demonstrations. Experimental results demonstrate the effectiveness of SRMs in terms of training efficiency and generalization. The reviewers acknowledged that the problem of inferring symbolic rewards is important and that the proposed SRM framework is an important step in this direction. However, the reviewers pointed out several weaknesses in the paper and shared concerns, including (a) limited comparison with alternate approaches to tackle the problem and positioning w.r.t. the existing literature; (b) the domains seem rather simple since they require only a few demonstrations (implying that the holes being inferred might be quite small); (c) the novelty and theory around the SRM representation is not fully clear. I want to thank the authors for their detailed responses. Based on the reviewers’ concerns and follow-up discussions, there was a consensus that the work is not ready for publication. The reviewers have provided detailed feedback to the authors. We hope that the authors can incorporate this feedback when preparing future revisions of the paper."
    ],
    [
        "This paper introduces a NAS technique with an adversarial component, where an adversarially trained generator generates architectures and searches them using an importance sampling-based search method. The proposed method is evaluated on three NAS oracle benchmarks as well as constrained NAS settings. The results show that the proposed method outperforms the state-of-the-art search algorithms proposed for NAS on public benchmarks.  The reviewers agree that the idea of using adversarial learning for NAS is novel and promising. The paper is well-written and the evaluations are thorough. However, some important concerns remain after the discussion among the reviewers. 1) The details about training and the generator architecture are relegated to the appendix. Although there are some promising experimental results, it is not clear whether the given results will generalize to other tasks or datasets.  2) The generator is trained using autoregressive PPO to overcome non-differentiability of the adversarial objective. This is quite a limiting aspect of the",
        "This paper proposes a method for neural architecture search (NAS) based on adversarial methods. It uses a discriminator trained to distinguish between random vs. good architectures, letting the discriminator's scores serve as a reward signal for an autoregressive generator. I agree with AR1: this is a nice and clever idea. Reviewers generally agreed that the method was interesting, e.g. it's quite flexible in that it's able to incorporate constraints, and that the evaluation is rather extensive and shows that the method performs well across the board. Many minor criticisms were raised and addressed well by the authors in their responses and manuscript updates.  The major criticism shared by most reviewers was the high methodological complexity of the proposed approach, and the proportionally small gains shown over much simpler baselines. This criticism remained despite the authors' responses. The method is indeed complex: the same method without any adversarial component already performs well, and many important details of the model are relegated to Appendix A.2. (I would recommend, for example, moving Fig. 2 to the main text if at all possible. Also, the Appendix can/should be included in the main PDF for ICLR, rather than in supplementary material, as AR1 mentions.) It was not clear to reviewers that the adversarial component of the approach has a significant benefit. The authors respond by pointing to Table 7 showing that the discriminator reduces the number of queries and points out that in reality these queries correspond to expensive evaluations. If this is a major selling point of the method (it sounds like it could be), it should be highlighted and analyzed far more -- at least moved to the main text rather than an Appendix -- ideally with a real-world evaluation showing a practical large improvement in overall wall-clock time, rather than a benchmark where these evaluations are free. Perhaps the exclusive reliance on these benchmarks, though undoubtedly useful for quick experimentation, in the end holds back the paper and prevents the method's benefits from becoming apparent to the readers.  As a minor point (also raised by AR1), the paper is formatted incorrectly for ICLR: the font color is off, and more importantly the PDF is unsearchable (text cannot be selected, ctrl-F does not work), which makes it very difficult to quickly reference and review. Please try not to stray from the conference-provided style file for future submissions.  I appreciate the cleverness of the method, the extent of the evaluation, and the thorough responses to the reviews. However, unfortunately with the current presentation, it is too difficult to discern the benefit of the proposed approach from the manuscript. The approach is nonetheless intuitively appealing and seems quite promising, and I hope the authors will take the reviewers' good feedback into account and resubmit the paper in the future."
    ],
    [
        "The paper presents a decision-tree approach to unsupervised clustering of time series / plans based on LTL formulae. The reviewers liked the simplicity of the approach and agree that it would make for an interesting contribution to the workshop. Please try to address the reviewers' comments for the camera-ready version; they made many excellent suggestions and it would be great to incorporate them in the final version of the paper. Also, please try to improve the writing as suggested by one of the reviewers.",
        "The paper presents a decision-tree approach for clustering plan traces and delineate them using linear temporal logic.  Both reviewers agree that the paper is well-written, it tackles a very interesting problem, and the technical methodology is sound. However, the reviewers also indicate two major problems with the paper: 1) the connection to XAIP is unclear; and 2) the work appears to be preliminary and incremental. Generally, the paper’s topic concerns plan summarization, which falls within the umbrella of XAIP, and a preliminary/incremental work is within the scopes of a workshop program. As such, in light of keeping the workshop a fruitful venue for discussion and dissemination of information, I am recommending accepting the paper.  Nonetheless, we urge to authors to reflect on the reviewer’s comments and address them in their revised version of the paper. Specifically, we hope the authors make a clear connection of their method to XAIP. Additionally, as the proposed approach builds heavily on the BayesLTL framework, the authors should include an overview of that framework and also explain the novelty of their approach compared to BayesLTL."
    ],
    [
        "The paper provides a new algorithm for first-order optimization of smooth and strongly geodesically-convex functions on the Hadamard manifolds. It is shown that this new algorithm enjoys the same convergence rate as the Euclidean AGD algorithm without convex constraints, up to multiplicative factors, where the factors depend on the curvature of the manifold. This allows an algorithm to enjoy an \"accelerated\" version of convergence similar to the SGD method up to a large number of factors.  The reviewers found the paper to be well-written and technically sound. Weaknesses of the paper have been addressed by the author(s) during the discussion period.",
        "The paper deals with accelerated methods on Riemannian manifolds. A particular challenge that the paper tries to address, which the AC believes is important, is related to the bounding of the iterates. The paper starts with an explicit bounding constraint on the manifold (and relaxes to the ball constraint for certain manifolds) and shows that the proposed algorithm can respect that while achieving acceleration. The reviewers including this AC see the merits of the paper. However, the paper in its current form is far from complete. A particular concern is on the empirical performance of the algorithm, resolving which should strengthen the paper. I would encourage the authors to build on the discussions and polish the paper accordingly.  Even though the paper has positive scores, the paper in its current form is a borderline paper with significant scope for improvement. To this end, the AC cannot accept the paper."
    ],
    [
        "This paper proposes a method whereby a neural network is trained and used as a data structure to assess approximate set membership. Unlike the Bloom filter, which uses hand-constructed hash functions to store data and a pre-specified method for answering queries, the Neural Bloom Filter learns both the Write function and the Read function.  A major issue raised by the reviewers is the lack of novelty. This paper was already suggested by (Kraska et al. 2018) and studied further in (Mitzenmacher 2018a,b) and subsequent works. The difference in the current paper is that the proposed approach relies on \"meta-learning\" a bloom filter, and the write and read functions are learned separately from the hash functions. It is unclear how much the contribution of this paper is actually novel compared to existing work.   Overall, this paper has some interesting ideas, but is not yet ready for publication.",
        "This work proposes and interesting approach to learn approximate set membership. While the proposed architecture is rather closely related to existing work, it is still interesting, as recognized by reviewers. Authors's substantial rewrites has also helped make the paper clearer. However, the empirical merits of the approach are still a bit limited; when combined with the narrow novelty compared to existing work, this makes the overall contribution a bit too thin for ICLR. Authors are encouraged to strengthen their work by showing more convincing practical benefit of their approach."
    ],
    [
        "This paper introduces CylesGym, a new benchmark environment for reinforcement learning (RL) applied to agriculture and farming. Crucially, the benchmark allows for different crops to be produced over a span of multiple years. This environment could provide a more realistic simulation of the real world than current benchmarks for both prediction and forecasting tasks.  The proposed benchmark outperforms on previous RL environments for an important domain with widespread consequences. Furthermore, the performance is much better than the state-of-the-art baselines in several cases.   The benchmark is clearly highly relevant to the ICLR community and will have great potential for societal impact. Therefore, I recommend acceptance.  However, there are some important concerns raised by the reviewers that should be addressed in the final camera-ready version.",
        "This proposal introduces CylesGym, the first Reinforcement Learning (RL) benchmark targeted at long horizon decision making in agriculture. Crucially, while prior work addresses single-year decision making, CylesGym captures the long term effects that one year's crop has on future generations.   The benchmark is clearly highly relevant and opens up a new frontier for RL researchers, making it a valuable contribution to the field. Furthermore, the benchmark does a good job of highlighting interesting opportunities for RL method development, such as costly information gathering, and evaluating current algorithms compared to baselines.   There was an active discussion between the reviewers and authors of the benchmark which resolved the majority of issues raised in the initial reviews. As a result there is broad support across the reviewers for the paper. A lingering concern is the sim-to-real gap which is mentioned at a number of places in the paper but could be emphasised more.   Lastly, the paper is well written and the evaluation sound. I believe this benchmark will be welcome by the community but I recommend that the authors address the concerns regarding the writing raised by  Reviewer MEYG, in particular regarding the utility for the agriculture community. In general I do not believe that issues which can be addressed in writing should be a reason to reject but those concerns should be addressed for the final version."
    ],
    [
        "This paper studies the problem of simple question answering over new, unseen domains during test time. A domain adaption framework and a question generation method have been proposed to tackle this problem and demonstrate the effectiveness of the proposed approaches. All the reviewers agree that this paper is well-written and the results are convincing.   However, there are concerns about the narrow scope of the paper. This paper focuses on a single domain and a specific task (QA of knowledge graph). It would have been more interesting to study other domains (other than QA) where the test data are generated by other methods. Similarly, concerns have been raised about the fairness of the evaluation. It would be great if the authors can provide more details about the evaluation and give a fair comparison with other approaches.",
        "This paper studies the problem of simple question answering over new, unseen domains during test time. A domain adaption framework and a seq2seq question generation method have been proposed to tackle this problem and demonstrates significant improvements over the previous baselines.  All the reviewers agreed that this paper is well-written and the results are convincing, but the problem is relatively narrow with a focused contribution.  Several reviewers also questioned whether this paper contains enough technical contributions. Some other issues have been already addressed during the discussion phase (long tail relations, presentation issues, and adding more related work).  However, we recommend accepting the paper considering the simplicity and effectiveness of the approach. We think it would lead to more discussion/future work in this direction."
    ],
    [
        "This paper presents a method for injecting linguistic information (for example dependency structures) into BERT, then measure improvements in correlation with FMRI measurements.  The reviewers found the topic and approach interesting.  However, there were concerns about the validity of the experimental setup and results due to the use of non-standard BERT architectures.  There was also concerns about presentation of the paper.  As a result, there was a consensus that the paper should be revised and resubmitted to the next conference.",
        "This paper explores the effect on decoding accuracy (predicting hidden representations from fMRI datasets) from fine tuning models by injecting structural bias.  This paper specifically focuses the attention of BERT on syntactic features of the text, which (for one dataset) appears to improve the decoding performance.  The paper's motivation is strong, and complex concepts are communicated clearly.  The review period was very productive.  There were some questions about analyses, and the validity of the statistical tests, but through some very thorough back and forth with the reviewers, this seems to have been resolved.  There is a good amount of analysis done on the resulting language models to try and determine the impact of finetuning or attention on the models. However, the results on the fMRI two datasets appear to be very different, and it's unclear why (and isn't clearly related back to the extensive language model analyses).  We would have liked to have seen a more thorough analysis of the stark difference in performance, and some convincing explanations for the difference based on the analyses.     P.s. A minor point, but the Wehbe paper uses Chapter 9 of Harry potter, not chapter 2."
    ],
    [
        "The paper studies MCTS, a promising method for finding maximally optimal policies, for which the only regularizer is entropy regularization. The authors show that this can be achieved by using any convex regularization they choose, provided that the convex conjugate is a convex function. This provides a theoretical justification for using any regularization as long as the regularization is consistent with the objective function, as opposed to just regularizing the entropy term. The results apply more generally, however, the paper does not make a clear case for the specific choice of regularization, i.e., it is not clear in what sense this is the right choice relative to other regularization schemes. This lack of clarity is due to the fact that the paper is in the process of being written, and as a result some key definitions and technical details are not introduced properly. As a result, some of the main results are not very clear, and it becomes unclear whether they",
        "Most of the reviewers pointed out a lack of rigor of this submission, unclear contributions, not too convincing claims and empirical gains. I thank the authors for the effort put in revising the paper and responding to the reviewer concerns. However, the reviewers did not deem them convincing enough."
    ],
    [
        "This paper proposes a method to cope with incomplete transcripts in the training set and apply it to the CTC loss. The authors propose to minimize the loss over all possible sub-segments of the input to automatically align the one that matches the available transcript. The reviewers agree that the problem addressed by this paper is interesting and relevant. The proposed idea is mainly based on existing DTW algorithm (SPRING). However it is extended and applied to CTC demonstrating significantly improved results on incomplete labels.  The authors have conducted extensive experiments with simulated data and well covered experimental results. Results demonstrate that the proposed method can handle incomplete labels more effectively than previous methods.   The paper is well-organized and written. Related work is adequately discussed.  During the rebuttal, the authors have addressed most of the questions and concerns raised by the reviewers.",
        "This paper proposes an extension of CTC by considering the wild-card to adjust the label missing issues during training. The authors propose to minimize the loss over all possible sub-segments of the input to automatically align the one that matches the available transcript. It is empirically proved to significantly improve performance over CTC even if up to 40-70% label sequence is missed (overall performance similar to the complete label case) across different tasks.   As agreed by the reviewers, the paper is well presented and the problem is interesting to a broad community. Dynamic time warping with unconstrained endpoints itself is not a new idea and a classical topic for speech recognition (e.g. word spotting). The contribution of the paper is the formal introduction of the approach to CTC and to give experimental results to confirm the effectiveness. Also the use of simulated data weakens the paper a bit.  The decision is mainly based on the clear presentation and fair experimental justification."
    ],
    [
        "This paper proposes to use Lanczos alogrithm, to get approximate decompositions of the graph Laplacian, and further proposes an extension with back propagation through the Lanczos algorithm, in order to train end to end models.  The reviewers agree that the paper is novel and achieves good results on a set of experiments. The main advantage of the proposed method is its ability to generalize well in the presence of a small amount of training data (roughly 8 samples). It achieves better generalization than SOTA graph CNNs with larger training data, and outperforms them on synthetic and real-world datasets.   The almost 10 pages are perhaps a bit excessive considering there was an (informal) 8 page limit, but I agree with the reviewers that it's a good paper overall. It discusses related work in a thorough and meaningful manner.",
        "The reviewers unanimously agreed that the paper was a significant advance in the field of machine learning on graph-structured inputs. They commented particularly on the quality of the research idea, and its depth of development. The results shared by the researchers are compelling, and they also report optimal hyperparameters, a welcome practice when describing experiments and results.  A small drawback the reviewers highlighted is the breadth of the content in the paper, which gave the impression of a slight lack of focus. Overall, the paper is a clear advance, and I recommend it for acceptance."
    ],
    [
        "This paper introduces a new way to learn augmentation policies that is class-dependent and potentially instance-dependent to improve the generalization of deep learning models. The idea of using hidden features of the original input to adapt the augmentation for each instance is novel and efficient. The paper is well-written and easy to follow, and an efficient workflow is designed. Experiments are conducted to demonstrate the effectiveness of the proposed method.   All the reviewers are positive about this work, and we would like to accept it for publication. We encourage the authors to follow the reviewers' suggestions while preparing the final version of the paper.",
        "Reviewers agreed that this work is well-motivated and presents a novel approach for data augmentation around the adaptive augmentation policies. There were some concerns around the lack of ablation studies and unclear performance improvements, which were addressed well by the authors’ responses. Thus, I recommend an acceptance."
    ],
    [
        "This paper attempts to learn embeddings for objects based on affordances, i.e., verbs that could be applied to said objects to realise their meaning.  The main objection from reviewers is that it is not clear what the overall goal of the work is. As a whole, this paper seems to be conflating different aspects together. I encourage the authors to take the reviewers' comments into account and improve the paper accordingly.",
        "This paper is a computational linguistic study of the semantics that can be inferred form text corpora given parsers (which are trained on human data) are used to infer the verbs and their objects in text. The reviewers agreed that the work was well executed, and that the experiments comparing the resulting representations to human data were solid. The method employed has little or no technical novelty (in my opinion, not necessarily a flaw), and it's not clear what tasks (beyond capturing human data) representations could be applied to (again, not a problem if the goal is to develop theories of cognition).   The first draft of the work missed important connections to the computational linguistics literature, where learning about 'affordances for verbs' (referred to as 'selectional preferences') has long been an important goal. The authors did a good job of setting out these connections in the revised manuscript, which the reviewers appreciated.   The work is well executed, and should be commended for relating ideas from different sub-fields in its motivation and framing. But my sincere view is that it does not meet the same standards of machine-learning or technical novelty met by other papers at this conference. It is unclear to me what the framing in terms of 'affordance' adds to a large body of literature studying the semantics of word embeddings, given various syntactically and semantically-informed innovations.  It feels to me like this work would have been an important contribution to the literature in 2013, but given the current state of the art in representation learning from text and jointly learning from text and other modalities, I would like to have seen some attempt to incorporate these techniques and bridge the gap between the notion of affordance in text/verbs (selectional preference) and Gibson's notion of object affordance (what you can do physically with an object) in experiments and modelling, not just in the discussion. Such a programme of research could yield fascinating insights into the nature of grounding, and the continuum from the concrete, which can be perceived and directly experienced, to the abstract, which must be learned from text. I encourage the authors to continue in this direction. An alternative is to consider submitting the current manuscript to venue where the primary focus is cognitive modelling, and accounting for human, behavioural data, and where there is less emphasis on the development of novel methods or models.  For these reasons, and considering the technical scope of related papers in the programme, I cannot fairly recommend acceptance in this case."
    ],
    [
        "This paper proposes using a variational auto-encoder and a GAN to generate synthetic cine MR images to enable segmentation of cardiac MR images without the need for annotation. The reviewers agree that the idea is novel and the results are promising. There are however some concerns regarding the clarity of the paper, as well as the comprehensiveness of the evaluation. The authors are encouraged to address the comments raised by the reviewers to improve the paper for future publication.",
        "This paper describes a way to use VAE to produce more MR images, which in turn contribute to segmentation. Review comments are generally at borderline. The novelty and evaluation of the paper might be limited though."
    ],
    [
        "This paper presents new theorems showing provable stable architectures for RNNs. The reviewers agree that the theoretical results are interesting. However, the experimental results are not a clear conclusion and at times do not follow best practices. Also, the presentation of the proposed model is not clear, and the model itself does not seem novel. Therefore the paper needs improvement to meet the acceptance threshold. We hope the authors will incorporate the reviewers' comments and make a stronger submission next time.",
        "In the context of recurrent neural networks, the motivation of the paper is to explore the \"space\" between fully trained models and almost not trained models, e.g. echo state networks, using a formal approach. In fact, a modular approach has proven to be very successful in many practical applications, and in addition brain seems to adopt this strategy as well. The addressed theoretical issue is stability of the network (i.e., the network implements a contraction map.) Specifically, it is assumed that a network is composed of a set of subnetworks that meet by construction some stability condition, and the problem is to design a mixing weight matrix, interconnecting the latent spaces of the subnetworks, able to give stability guarantees during and after training. Some novel stability conditions are proposed as well as two different approaches to design a successful mixing weight matrix. The original submitted paper was not easy to read, and after revision major problems with presentation have been resolved, although the current version looks more like an ordered collection of results/statements than a smooth and integrated flow of discourse. The revision has also addressed some concerns by reviewers on the role of size and sparsity of the modules, as well as the sensitivity of the stabilization condition on the mixing weight matrix has been experimentally assessed, obtaining interesting results. Overall the paper reports interesting results, however the novelty of the contribution seems to be a bit weak, e.g. stability conditions on recurrent networks (although different from the reported ones) were already presented in literature. Also the idea of exploiting, in one of the proposed models,  the fact that the matrix exponential of a skew-symmetric matrix is orthogonal to maintain the convergence condition during training, is not novel. Moreover, the experimental assessment does not provide a direct comparison, under the same architectural/learning setting, of the novel stability results versus the ones already presented in literature. Empirical results are obtained on simple tasks (using datasets with sequences of identical length), and relatively small networks, which limits a bit the scope of the assessment, as well as it is not clear if the observed improvements (where obtained) are statistically significant (especially when compared with results obtained by networks with the same order of parameters.) The quality of the assessment would increase significantly by considering datasets with sequences of different lengths, and involving more challenging tasks that do require larger networks."
    ],
    [
        "This paper introduces concept embedding models (CEMs), an extension of the concept bottleneck approaches, to improve the interpretability and accuracy of neural network models. CEMs allow the model to implicitly explain the downstream tasks in addition to performing them. The paper is well written, the idea is simple but effective, and the experiments are comprehensive and convincing. Overall, this paper tackles an important research problem and provides a new angle to benchmark neural network performance with concept-based models. Concerns about the empirical results are well addressed during the rebuttal.",
        "This paper proposes Concept Embedding Models, which learn interpretable high-dimensional concept representations to exploit the tradeoff between accuracy, interpretability, and interventions on concepts. Reviewers vote for accepting this paper. The authors are encouraged to further improve this work based on reviewers’ comments in the camera ready and put the new experiments and discussions during the author-reviewer discussion phrase into the final revision, in particular the following:  - Add statistical significance test of experimental results - Compare training costs and model sizes - Better justify the proposed CAS mechanism - Investigate the robustness of learned concepts - Address the fairness concerns raised by reviewers in comparison with baselines"
    ],
    [
        "The paper proposes a method that uses contingency awareness to aid exploration in sparse-reward reinforcement learning tasks. The reviewers obtain great results on hard exploration Atari games and a new SOTA on Montezuma's Revenge (compared to methods which are also not using any external data). The paper is well written and the method is simple and well motivated. The experiment results also speak for themselves. The rebuttal addressed all the major concerns raised by the reviewers.",
        "The paper addresses the challenging and important problem of exploration in sparse-rewards settings. The authors propose a novel use of contingency awareness, i.e., the agent's understanding of the environment features that are under its direct control, in combination with a count-based approach to exploration. The model is trained using an inverse dynamics model and attention mechanism and is shown to be able to identify the controllable character. The resulting exploration approach achieves strong empirical results compared to alternative count-based exploration techniques. The reviewers note that the novel approach has potential for opening up potential fruitful directions for follow-up research. The obtained strong empirical results are another strong indication of the value of the proposed idea.   The reviewers mention several potential weaknesses. First, while the proposed idea is general, the specific implementation seems targetted specifically towards Atari games. While Atari is a popular benchmark domain, this raises questions as to whether insights can be more generally applied. Second, several questions were raised regarding the motivation for some of the presented modeling choices (e.g., loss terms) as well as their impact on the empirical results. Ablation studies were recommended as a step to resolving these questions Reviewer 3 questioned whether the learned state representation could be directly used as an additional input to the agent, and if it would improve performance. Finally, several related works were suggested that should be included in the discussion of related work.  The authors carefully addressed the issues raised by the reviewers, running additional comparisons and adding to the original empirical insights. Several issues of clarity were resolved in the paper and in the discussion. Reviewer 3 engaged with the authors and confirmed that they are satisfied with the resulting submission. The AC judges that the suggestions of reviewer 1 have been addressed to a satisfactory level. A remaining issue regarding results reporting was raised anonymously towards the end of the review period, and the AC encourages the authors to address this issue in their camera ready version."
    ],
    [
        "This paper proposes an interesting idea of using free energy models to capture uncertainty in the environment for surprise minimization in MARL. The reviewers have found the idea interesting and the paper well-written. There were concerns about the practicality of the paper in terms of approximation of approximation error and convergence as well as convergence to local optima of the proposed QMIX algorithm. While these concerns have been somewhat addressed in the rebuttal, I believe the paper would benefit from another round of revision to clarify these points and make it more convincing.",
        "All reviewers appreciated the quality of the paper, its contributions, clarity and theoretical justification, and novelty. I agree with the reviewers in recommending acceptance."
    ],
    [
        "This paper provides a principled analysis of variational inference algorithms based on Gaussian approximation of Variational distributions. The authors establish convergence results for continuous-time dynamics and discrete-time stochastic gradient algorithms under a log-concavity assumption. The reviewers agree that the contributions are novel and relevant, and that the paper is clearly written and easy to follow. There were some concerns about the strength of the assumptions, but the authors seem to have sufficiently addressed those.",
        "This paper proposes a novel method for variational inference based on Wasserstein flows. The key contribution is perhaps the rigorous guarantees that are derived from an assumption of log-concavity. While the initial submission was unaware of some existing work on VI that derives guarantees from similar log concavity or smoothness assumptions, the proof strategy that is given uses novel technical methods, and thus is of interest in any case. Readers would benefit from a detailed discussion that can contextualize this work to previous work, which the authors have committed to doing."
    ],
    [
        "This paper presents a GNN-based method for solving multi-objective integer programs (MOIP) with instance information. The main idea is to solve instance information given the instance variables, constraints, and objectives. To achieve this, the GNN model takes the instance information as input, and then adaptively discards local upper bounds (to update the search region) without calling an IP solver. The authors provide empirical results showing that their method achieves better performance compared to state-of-the-art methods.   The reviewers agree that the paper addresses an important problem, and the proposed method is interesting. However, they also point out several weaknesses. First, the paper seems to be written in a way that does not leave much room for further generalization, e.g., the method is strictly designed for the ODA approach to be solved, which allows it to gains the performance improvements but does perhaps not leave the space for a more generalizable method.",
        "In this paper, the authors exploit imitation learning with a two-stage GNN to learn the reduction rule for ODA to accelerate the solver and reduce the unnecessary computation. The authors evaluate the performances of the proposed method and demonstrate the advantages.    In sum, this paper consider an interesting application of machine learning for optimization and provide a promising solution. All reviewers provide relatively positive feedback of this submission.   Please consider the reviewers' suggestions to improve the submission:  - Justify the MDP modeling with concrete definition of the state and action for the reduction rule for ODA.   - Specify the data set construction and justify the generalization ability in the imitation learning.  - Provide comprehensive comparison, especially with PMOCO."
    ],
    [
        "This paper presents a variant of VAE designed to learn disentangled representations from information theoretic perspective. The idea is to use a recursive disentanglement network to learn the representations. Experiments demonstrate promising results on dSprites and 3DShapes datasets.  The reviewers and AC note the following potential weaknesses: (1) the technical novelty is limited, i.e., the idea is a direct application of the idea of Gated Mixture-of-Experts (DME), while the main contribution is in the downstream analysis and not the model design, (2) there is no clear understanding on how the different parts of the architecture contribute to the performance, both theoretically and empirically, for the proposed method, and (3) there are no clear insights from the experiments to explain why the proposed RecurD outperforms the existing baselines.  During the discussion, the authors addressed some of the concerns raised by the reviewers, for instance, they",
        "This paper proposes an algorithm for achieving disentangled representations by encouraging low mutual information between features at each layer, rather than only at the encoder output, and proposes a neural architecture for learning. Empirically, the proposed method achieves good disentanglement metric and likelihood (reconstruction error) in comparison to prior methods. The reviewers think that the methodology is natural and novel to their knowledge, and are happy with the detailed execution. The authors are encouraged to improve the presentation of the paper, by providing rigorous formulation of the \"Markov chains\" to avoid confusions, justification of the independence assumptions behind them, and more in-depth discussions of the learning objectives."
    ],
    [
        "In this paper, the authors propose a new approach called expected quadratic utility maximization (EQUMRL) to solve the mean-variance portfolio optimization problem. Compared to the existing methods, EQUMRL does not have the double sampling problem and can achieve Pareto efficiency in terms of MV trade-off. Most of the reviewers think that the paper is well-written and the proposed method is sensible. The finance-oriented section is helpful for understanding concepts and motivations from a finance and economics perspective. Although some reviewers have some concerns about the computational difficulties of the proposed algorithm, the rest admit that this is an interesting and novel approach to the important problem of portfolio optimization. Thus, I recommend acceptance of this paper.",
        "This is a borderline paper with some reviewers voted for acceptance and some think it is not still ready. What is clear is more efforts by the authors is needed to make the paper appealing to reviewers with different interests. Changes such as better writing, more in depth literature review, more convincing experiments can definitely improve the quality of the paper. I personally do not think regret analysis is needed for this work, but it was mentioned by a reviewer. I would suggest the authors to use the reviewers' comments, revise their work, and prepare it for future conferences."
    ],
    [
        "The paper presents a new method for fast semantic segmentation in videos.  They first compute features of keyframes, then interpolate intermediate frames based on block-motion vectors, and finally fuse the interpolated features.  The experiments show that the model outperforms one recent, closely related work wrt inference time while preserving accuracy.   Overall, the reviewers like the paper.  It is well-written and easy to follow, and the proposed method is novel and effective.  There are some concerns from the reviewers, i.e., feature warping, bi-directional propagation, and feature fusion.  Most of these concerns have been well-addressed in the rebuttal.  We encourage the authors to keep improving the paper for the camera-ready version.",
        "Strengths: Paper uses an efficient inference procedure cutting inference time on intermediate frames by 53%, & yields better accuracy and IOU compared to the one recent closely related work.  The ablation study seems sufficient and well-designed. The paper presents two feature propagation strategies and three feature fusion methods. The experiments compare these different settings, and show that interpolation-BMV is indeed a better feature propagation.  Weaknesses: Reviewers believed the work to be of limited novelty. The algorithm is close to the optical-flow based models Shelhamer et al. (2016) and Zhu et al. (2017). Reviewer asserts that the main difference is that the optical-flow is replaced with BMV, which is a byproduct of modern cameras.  R3 felt that there was Insufficient experimental comparison with other baselines and that technical details were not clear enough.  Contention: Authors assert that Shelhamer et al. (2016) does not use optical flow, and instead simply copies features from frame to frame (and schedules this copying). Zhu et al. (2017) then proposes an improvement to this scheme, forward feature warping with optical flow. In general, both these techniques fail to achieve speedups beyond small multiples of the baseline (< 3x), without impacting accuracy.  Consensus: It was disappointing that some of the reviewers did not engage after the author review (perhaps initial impressions were just too low). However, after the author rebuttal R1 did respond and held to the position that the work should not be accepted, justified by the assertion that other modern architectures that are lighter weight and are able to produce fast predictions."
    ],
    [
        "The paper proposes a coreset method for Wasserstein distributionally robust optimization (WRDO) by looking at the dual WRDO problem. Theoretical results and experimental results clearly demonstrate the benefits of the proposed method. The paper is well-written, and all reviewers recognize the technical significance of the contribution. Therefore, I recommend acceptance. Meanwhile, please carefully revise the paper according to the suggestions by the reviewers:  - Improve the discussion of the limitations and potential negative societal impact of their work - Clarify the limitations in the final version.",
        "From the reviewers' comments and my own reading of the paper, the idea of bringing the notion of coreset from computational geometry to bear on the WDRO problem is novel and has the potential of further development. The authors should carefully address the reviewers' comments in the revision."
    ],
    [
        "The paper proposes to encode each input dimension as a high dimensional vector and train the classifier to minimize the L2 distance between the vectors. The motivation is that this makes the models more robust to adversarial attacks. The method is well-motivated and easy to follow. However, as the reviewers pointed out, both the motivation and the experimental evaluation is insufficient. In particular, the proposed idea is very similar to the method in \"Stronger Adversarial Robustness of Deep Learning\" (https://arxiv.org/abs/1805.078983) and the authors' rebuttal argues that this paper uses a different set of metrics to evaluate the robustness of the method. It is therefore not fair to compare the two methods under the same experimental setting. Moreover, as pointed out by the reviewers, the paper would be a lot stronger if there was a more thorough investigation of the correlation between gradients in all layers of the models.",
        "This paper proposes a method for improving robustness to black-box adversarial attacks by replacing the cross-entropy layer with an output vector encoding scheme. The paper is well-written, and the approach appears to be novel. However, Reviewer 4 raises very relevant concerns regarding the experimental evaluation of the method, including (a) lack of robustness without AT in the whitebox case (which is very relevant as we still lack good understanding of blackbox vs whitebox robustness) (b) comparison with Kannan et al and (c) lack of some common strong attacks. Reviewer 1 echoes many of these concerns."
    ],
    [
        "This paper received 4 quality reviews. The rebuttal and discussions were effective and answered most of the reviewers' concerns. One reviewer did not respond to the rebuttal, but AC thinks that the authors should include their response to address concerns in the final camera-ready version of the paper. AC agrees that the architecture of the proposed network is Siamese and the performance is not state-of-the-art, but it is a good improvement over existing methods. Overall, AC likes the paper and recommends to accept it.",
        "All three reviewers initially recommended reject.  The main concerns were: 1) weak technical contribution and insight [R1, R2, R3, R4]; 2) incremental novelty (another variation of SiamFC) [R1, R2, R3]; 3) unconvincing experiment results against missing SOTA [R1, R2, R3];  The author's response did not assuage these concerns."
    ],
    [
        "Hyperbolic Neural Networks are neural networks built from Poincaré balls embedded in a network constructed by connecting them to a Euclidean space manifold. The original version of the paper was limited to low-dimensional datasets, but the authors revised the paper to cover more types of datasets, including images, to demonstrate the performance of the proposed method.   The originality of applying neural networks from a manifold to neural networks is an interesting question that has been studied for a while, and this work extends the efforts of Ganea et al. (2017) by introducing a manifold-based variant of the HNN. The paper is clearly written, and it is easy to follow, as mentioned by all reviewers.  The main drawback of the original version was limited novelty, limited technical novelty, and limited technical/experimental novelty, as pointed out by R1 & R4. However, the authors addressed most of these concerns during the rebuttal period, thus,",
        "The paper introduces new methods and building blocks to improve hyperbolic neural networks, including a tighter parameterization of fully connected layers, convolution, and concatenate/split operations to define a version of hyperbolic multi-head attention. The paper is well written and relevant to the ICLR community. The proposed methods offer solid improvements over previous approaches in various aspects of constructing hyperbolic neural networks and also extends their applicability. As such, the paper provides valuable contributions to advance research in learning non-Euclidean representations and HNNs. All reviewers and the AC support acceptance for the paper's contributions. Please consider revising your paper to take feedback from reviewers after reubttal into account."
    ],
    [
        "This paper studies the class collapse problem in metric learning, and proposes a simple method to alleviate it. The authors show that the binary case, where all same-class instances fall to the same center, the proposed method can reduce class collapse by sampling from the representative positive element nearest to the center. In the multi-class case, it is shown that this simple method can improve performance.   The paper is well-written and easy to follow. The proposed method is simple but effective. The theoretical results are interesting, but it is not clear how useful their analysis really is. I suggest the authors improve the theoretical results by using more reasonable assumptions (and avoid strong assumptions such as strong convexity). The empirical results are also good, but not outstanding.",
        "This paper is truly borderline. On one hand, the theoretical contribution seems novel and interesting, however, there appears to be somewhat of a gap between theory and practice.   There is unfortunately another problem. According to the authors, the main contribution of this publication is arguably the introduction of the nearest neighbor as the positive example in the triplet loss. However, the authors seem to be unaware of the history of the triplet loss. It was originally introduced by Schultz & Joachims 2004 as a loss over all triplets.  Weinberger et al. 2005 changed it and use the nearest neighbor as \"target neighbor\", which is called \"easy positives\" here, as the objective of LMNN. In 2009 Chechik et al. subsequently relaxed this positive neighbor formulation to any similarly labeled sample (going back to the Schultz & Joachims formulation) but sampling triplets. The re-introduction of the nearest neighbor as \"easy positive\" was then covered by Xuan et al. 2020.    Unfortunately all of this diminishes the novelty significantly and it is clear that the paper in its current form does not have a strong enough contribution. I do encourage the authors to take a close look at the original LMNN publication and Xuan et al and write an improved re-submission for the next conference that maybe focuses more on the theoretical contribution.  Good luck,  AC"
    ],
    [
        "This paper extends the notion of \"value equivalence\" among MDPs w.r.t. sets of policies and value functions. The paper derives a number of interesting results on how different models in different classes of models relate different policies in terms of the error they incur and error tolerances. The bounds that relate performance of policies across such approximate value equivalent models are also obtained. Overall, the paper is well-motivated, well-written, and provides interesting theoretical results. The authors have also addressed the concerns raised by the reviewers during their response. I recommend acceptance.",
        "A key discussion point in the rebuttal phase was the practical use of the proposed bounds, which two of the three reviewers brought up. The authors in response added an additional section (Section 6) and experiment to address this concern. While some concerns regarding the practical use of these bounds remain, the authors have made a sufficiently convincing case in my view. Hence, I recommend acceptance."
    ],
    [
        "This work introduces a new dataset to measure productive concept learning under uncertainty. The reviewers (and I) agree that this work proposes an interesting task that requires several aspects of compositional reasoning. The task is well-motivated and the dataset is designed using a concept space defined by a language.  The authors also propose several out-of-generalization data splits that test models' ood generalization performance on the CURI dataset. This is an interesting contribution to the community and we look forward to seeing it in the NeurIPS dataset track.",
        "This paper was reviewed by 3 experts in the field. The reviewers raised their concerns on lack of novelty, unconvincing experiment, and the presentation of this paper, While the paper clearly has merit, the decision is not to recommend acceptance. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere."
    ],
    [
        "This paper proposes a way to incorporate task information into multi-task learning (MTL). The hope is that more explicit knowledge of task information will improve MTL.   The reviewers and AC note the critical limitation of novelty of this paper. This paper combines Feature-wise Linear Modulation (FiLM) with a single/multi-modal transformer for a joint multimodal neural network. The results in the paper don't look very good either. The proposed approach is very specific to two tasks, and it's unclear how general the approach is.  AC thinks that this paper needs a lot of work before it is ready for publication.",
        "This paper proposes an approach for improving MultiTaskLearning by providing a way of incorporating task specific information.  Pros: 1) All reviewers agreed that the paper is clearly written 2) Interesting to see a single model for AST, STS (speech-to-speech translation) and MT   Cons: 1) The work is not adequately compared with related work (some important references are also missing) - The authors did perform some additional experiments with T5  and pointed out some drawbacks but this needs to be explored a bit more. 2) The answers about scalability are not very convincing and need more empirical results.   Overall, none of the reviewers were very positive about the paper and felt that while this is a good first attempt, more work is needed to make it suitable for acceptance."
    ],
    [
        "This paper presents a study of how to select and optimize a mix of regularizers for neural network training. The reviewers found the topic interesting and timely, and the paper well written. While there were some concerns on the level of novelty of the work, the majority of reviewers appreciated the importance of the problem being tackled and the strength of the empirical results. I believe the paper will be of interest to the community and recommend acceptance.   I strongly encourage the authors to incorporate the comments from the discussion into account when preparing the camera-ready version of the paper. In particular, it will be important to clarify the relationship of this work to the prior work on mix-and-match (e.g. Balcan et al, NeurIPS 2020).",
        "The paper in its most recent version claims that deep neural networks, when very carefully regularized, outperform methods such as Gradient Boosting Trees on tabular data. This is genuinely surprising to me (in a good way), and I suppose it is as well to the community.  The paper initially received negative reviews with two key remarks that \"The results are somewhat expected.\" (R4, R3, R2). Indeed, the original version mainly stated that very careful regularization helps on tabular data.  Naturally, the reviewers (including myself) seen then as the second key weakness that \"All experiments are run on tabular data.\" (R4, R3).  Based on the reviews, the Authors have clarified and changed their message. I think it is well summarized by R2 \"The paper has been significantly refocused and now sells itself as a way of deep neural networks being competitive versus gradient boosting methods, which are dominating the tabular heterogeneous tasks.\"  As R2 said and was reflected in comments by other reviewers, \"[...] convinced by authors response on paper novelty, technical contribution and (after the re-focusing) potential usefulness to the community\".  Given the new message of the paper, a key new question surfaces. Is this indeed the first convincing demonstration that deep learning can outperform more standard methods on tabular data? R2 pointed out TabNet (see also Google Cloud offering) that already in 2019 claimed \"beating GB methods for the tabular data\". There is also NeurIPS work \"Regularization Learning Networks: Deep Learning for Tabular Datasets\"; their abstract opens with \"Despite their impressive performance, Deep Neural Networks (DNNs) typically underperform Gradient Boosting Trees (GBTs) on many tabular-dataset learning tasks. We propose that applying a different regularization coefficient to each weight might boost the performance of DNNs by allowing them to make more use of the more relevant inputs\". The latter work did not claim to beat GBT. Regardless, the two works should be carefully discussed and compared empirically to in the new version of the work.   I am also not yet fully convinced by the added comparison to GDBT. Arguably, AutoML from the sklearn package is not the most popular way to use GDBT in practice. How would regularization cocktails compare to GDBT from XGBoost, optimized using either random search or bayesian optimization?  Based on the above, I have to recommend the rejection of the paper. The key reason is: *the new reframing of the paper is exciting but warrants a much more detailed and careful evaluation*.  I really appreciate the work the Authors have put in clarifying and changing the message of the paper. I understand this is disappointing that we won't be able to include the work in ICLR. Nevertheless, I hope that the Authors found the feedback useful, and wanted to thank the Authors for submitting the work for consideration in ICLR."
    ],
    [
        "This paper propose a conditioning method for GAN training to improve generated samples fidelity and stabilize training. The proposed conditioning is based on limiting the generator from departing normality function of real samples. It is claimed that this conditioning will not limit the exploration of all modes of real data distribution. The experimental results also support the authors' argument about the improved stability.  While it has been known that tying up the generator and discriminator's latent variables can help stabilize gan training, the proposed method applies a different theory to ensure correlation between real and generated samples project into some subspace; this is intended to prevent instability during training, and according to the authors, it works well. The technique is applied to audio spectrogram generation.  The paper is well-written and easy to follow. The experiments are convincing. The ablation studies are detailed and demonstrate the effectiveness of the proposed technique. Overall, this is a nice contribution to the GAN literature.",
        "The paper proposes a trick for stabilizing GAN training and reports experiment results on spectrogram synthesis. All the reviewers rate the paper below the bar, citing various concerns, including a lack of clarity and unconvincing results. Several reviewers suggest conducting evaluations in the image domain as most of the GAN training techniques are proposed in the image domain. After consolidating the reviews and rebuttal, the area chair finds the reviewer's argument convincing and would not recommend acceptance of the paper."
    ],
    [
        "This paper proposes a new measure of compositionality for learning representations, which computes features such that the closest compositional approximation to a given feature is close (in terms of cosine) to the latent representation of the input x in the context of semantic primitives.  This is done by learning a vector for x that is a vector over primitives, and computes the distance of this vector to the corresponding latent vector when applied to another instance of x. The paper then demonstrates that this measure can be used to assess the composition of learned representations, as well as to select promising candidates for feature learning tasks based on their compositionality.  All reviewers agree that this is a novel and interesting approach to quantifying compositionality, and the paper is well-written. However, reviewers are unanimous in their criticism that the experiments used to demonstrate the utility of the measure are unconvincing: they consider small-scale settings with little compositional structure, and they find the results",
        "This paper presents a method for measuring the degree to which some representation for a composed object effectively represents the pieces from which it is composed. All three authors found this to be an important topic for study, and found the paper to be a limited but original and important step toward studying this topic. However, two reviewers expressed serious concerns about clarity, and were not fully satisfied with the revisions made so far. I'm recommending acceptance, but I ask the authors to further revise the paper (especially the introduction) to make sure it includes a blunt and straightforward presentation of the problem under study and the way TRE addresses it.  I'm also somewhat concerned at R2's mention of a potential confound in one experiment. The paper has been updated with what appears to be a fix, though, and R2 has not yet responded, so I'm presuming that this issue has been resolved.  I also ask the authors to release code shortly upon de-anonymization, as promised."
    ],
    [
        "This paper proposes an MCMC algorithm for approximating the joint posterior distribution of model parameters and true/denoised data given a corrupted data set by including the date as parameterization and a Gibbs sampler. The proposed algorithm is efficient in O(n^2) time and provides theoretical guarantees on its approximation as well as derivations on MCMC's ergodicity. The paper is well-written and the proposed method is interesting. However, there are concerns about its applicability in the presence of corrupted data, namely, DP-induced noise. It would be great if the authors can provide empirical evidence that their proposed algorithm can capture DP noise.",
        "This paper presents a general MCMC algorithm for approximating the joint posterior distribution of model parameters and private data, given output from a differentially private algorithm. The paper provides new tools for Bayesian inference under privacy constraints, which can be useful for the differential privacy community. There are a few suggestions from the reviewers/discussion. First, even though the authors claimed their results are fully general, they should consider toning it down or at least clarifying upfront their \"Record Additivity\" assumption, which seems non-trivial. As one of the reviewers remarked, one of the limitations of this approach is that it will not scale well with high-dimensional data. The AC suggests the authors add this limitation in the discussion of the paper.  Other comments: While not critical, the AC also has a question regarding the following part: - In line 105: the assumption is that the density of the mechanism's output distribution is known. This has nothing to do with what privacy variant you use to analyze the mechanism."
    ],
    [
        "This paper studies primary multi-task learning (MTL) for multimodal emotion detection in the face of conversational data overload. The main challenge paper is trying to solve is on how to select relevant auxiliary tasks that avoid negative transfer from one task to another while optimizing the primary model. To this end, three hypotheses are proposed: whether the pre-processed data can be reused as auxiliary tasks in MTL, whether there is a negative transfer between auxiliary tasks, and whether task-specific mechanisms are necessary for success. Experiments are performed on two existing datasets and also on a fourth, which is the proposed SEMAINE dataset.   All the reviewers agree that the paper tackles an important problem and the experiments are conducted well. However, they also share the concern that the presentation of the paper can be improved (e.g., the analysis of video-conferencing videos is a little bit heavy-handed, the motivation is not very clear, the experiments",
        "The initial reviews for this paper were very borderline. The authors provided detailed responses as well as a few additional results and observations. The authors' responses answered the reviewers' questions and addressed their main comments (including in the discussion of related works as well as with more in-depth analysis in a new Section 5.1). Unfortunately, the reviewers did not come to a consensus.  Overall, this paper extends some current methodology for emotional classification, is well-executed, and provides a reasonably thorough study. The results are somewhat in line with previous results from other fields (and notably NLP), but the authors demonstrate the efficacy of using primary multi-task learning for multimodal conversational analysis.   Unfortunately, this paper also has some flaws as highlighted by the initial reviews. As stated above, the authors did provide a strong rebuttal, but given the different comments raised by the reviewers that spanned many aspects of the paper including motivation, possibly limited contribution and novelty, missing related work, somewhat shallow analysis of the results, I find that another full round of reviewing would be useful to assess the paper.  As a result, this remains a very borderline paper, and given the strong competition at this year's conference, I cannot recommend acceptance at this stage.  I suggest that the authors incorporate some of the discussions from this forum (and especially with respect to related work, new findings, and clearly defining the motivation and contribution of this work) into the next version of their paper."
    ],
    [
        "This paper introduces MorphTE, a word embedding compression method that incorporates morphemes into word embeddings and achieves lossless compression while decreasing the number of parameters.  Experiments are conducted on machine translation, question answering, and natural language inference tasks.  The reviewers find the paper to be well-written and the experiments thorough.  However, the reviewers had concerns with respect to the use of the tensor product, and it is unclear how much generalizable the results of the presented experiments generalize.  Overall, the novelty of the proposed method is limited, and the experimental section could be improved with better baselines and more generalization experiments.",
        "The paper presents a method to compress word embeddings using morphologically-enhanced tensorized embeddings. The main idea is decomposing a word embedding into a tensor product of multiple small vectors. This idea has been explored in previous work [1], the main contribution of this is using *morphological segmentation*, aiming to capture morphological features.   The proposed method is compared to prior work on multiple tasks (machine translation, qeustion answering, etc), overall exhibiting strong performance in terms of compression rate & performance (though sometimes gains are pretty smaller compared to Word2ket (e.g., Table 2)).   During the discussion phase, the authors provided the results with random, non-morpholgically inspired segmenation, which was useful. I’d recommend putting them into the main paper. Experimenting on morphologically rich languages (e.g., Finnish) would be useful. As well as sensitive study towards hyper parameters (e.g., dimensionality of morpheme embeddings) which can easily impact the compression rate & performance.   Overall, the reviewers and AC is positive about the paper.   [1] word2ket: Space-efficient Word Embeddings inspired by Quantum Entanglement https://arxiv.org/abs/1911.04975"
    ],
    [
        "This paper proposes a neural auto-encoder for sentence compression, which consists of a 2-step encoder-decoder network: firstly, the sentence is encoded into a vector which is in turn decoded to a (smooth) indicator vector to mask words in the sentence and the second step is when the masked sentence is decoded into the output.  While the task of telegraphic sentence compression is important and of interest, the novelty of the proposed method is limited, as it is a simple combination of known techniques. Also, the application of these methods to sentence compression on full sentences would make for a more substantial contribution. All reviewers agree that the paper is well written, but the content is not quite sufficient. Therefore it cannot be accepted to ICLR.",
        "This paper presents methods for telegraphic summarization, a task that generates extremely short summaries.  There are concerns about the utility of the task in general, and also the novelty of the modeling framework.  There is overall consensus between reviewers regarding the paper's assessment the feedback is lukewarm."
    ],
    [
        "The paper proposes a framework for federated learning that adaptively adjusts the frequency of the communication rounds and the quantization efficiency in a synergistic way. The reviewers agree that the paper is well written and the problem is relevant. The idea of combining existing techniques to improve communication efficiency is nice. However the reviewers point out that the experiments are insufficient to demonstrate the effectiveness of the framework.  We encourage the authors to improve the paper based on the reviewer's comments and resubmit to a future venue.",
        "Two of the initial reviews of the paper were mildly positive (2 scores of 6), and one was very positive (score of 8). However, these reviews failed to notice some severe issues with the paper, which were detailed by the Area Chair in an Extra Review which was provided late. The severe issues include: clarity of exposition (undefined notation in many places) and theory (vacuous or meaningless theorems and assumptions). I apologize to the authors for not having had the chance to defend against this late review. However, the issues are indeed severe."
    ],
    [
        "The paper presents an interesting idea that aims to explore the interaction between two different types of optimizers: direction and stride of the optimizer. It proposes grafting, a technique that allows the transfer of the overall implicit step size schedule from one tuned optimizer to another (the so-called grafting procedure). The paper demonstrates interesting connections between the steps of the two optimizers and the learning rate schedule. Extensive experiments are performed to demonstrate the effectiveness and utility of grafting.  The paper is well-written and the idea is interesting. All reviewers support the acceptance of the paper.  However, there are some concerns about the experimental setup. Most notably, the lack of motivation for grafting requires more elaboration and specific configurations. The paper can be significantly strengthened if it can demonstrate transferrable learning rate schedules across different tuned optimizers.",
        "The paper proposed Trained ML oracles to find the decent direction and step size in optimization. The process they call grafting. Reviewers raised several concerns about the reliability of ML oracles in general settings which is valid. The rebuttal could not convince the reviewers to change their opinion.  Ideally for an empirical only paper with heavy reliability on ML for critical decisions, to meet the high bar of ICLR there must be several experiments (5-10 datasets or more) on diverse datasets and settings. Also, there should be discussions on when and how the method fails and related discussions. In that sense the paper does not meet the bar for publication."
    ],
    [
        "this is a well executed paper with an interesting application of reinforcement learning to liver tumor ablation planning. The approach is 10x faster than the state-of-the-art and yields significantly better results in terms of placement accuracy.  Some aspects of the experiment are confusing (e.g., the authors report comparable performance to a conventional method while being much faster. A conventional approach to planning cardiac ablation procedure from a fraction of the time may still achieve much better results).  Given the novelty of the approach, the interesting application, and the promising results, I recommend this paper for acceptance.",
        "The work describes the use of RL for trajectory planning for minimally invasive liver tumor ablation. The main motivation is that RL can accelerate planning over conventional methods.  Strengths according to reviewers: * Interesting problem. * Relatively well written. * Good description of RL methodology.  * Interesting results (comparable performance to conventional method, faster inference) * Uses public database, which may facilitate reproducibility and comparisons in future work.   Weaknesses: * Limited novelty with respect to machine learning. Main contribution is rather the idea of using RL to improve the specific application. * Not extensive evaluation.  Initial reviewer concerns regarding weak motivation and clarity were addressed to a significant extent, improving the manuscript, which is reflected to the increased ratings after rebuttal.   After a very productive rebuttal and discussion period, accompanied with significant updates to the paper, there seems to be a concensus that the paper is of acceptable quality for a publication in MIDL."
    ],
    [
        "The paper proposes to add a distance map layer (DML) to improve the robustness of ensembles of neural networks to adversarial attacks. The main concern in robust ML is that many attacks are transferable between models, thus leading to blackbox attacks. To address this issue, the authors derive a new methodology to promote \"orthogonality\" between different ensemble models and show that this improves the rate of transferability. The experiments are extensive and really promising. Overall, the paper is well-written and the experiments are convincing. The authors have answered all the questions raised by the reviewers. After the rebuttal, all the reviewers agree on accepting this paper. So, I recommend acceptance.",
        "The paper proposes a method to improve adversarial robustness by diversifying the ensemble.   Novelty: As pointed out by several reviewers, promoting diversity of ensembles has been done in the literature, but there's still a moderate novelty in proposing the DML layer.   Empirical validations: The original submission lacks many important comparisons (e.g., with [1]). Despite the authors implicitly compared their method with (Pang et al) via Auto-attack in the rebuttal, it will be better if the comparisons are conducted in a well-controlled way to confirm that the improved robustness comes from DML instead of other hyperparameter settings. Further, it is not clear whether the proposed method is robust to hyperparameters.   Based on these, we recommend rejection but encourage the authors to improve their paper based on the comments."
    ],
    [
        "Meta Review: This paper reveals a crucial flaw in the proof of the soundness of the algorithm of the general identifiability problem of Lee et al. (2019), namely the failure of the positivity assumption in the g-identifiability algorithm under graphical identification. This is a critical flaw, since positivity implies that any graphical effect can be identified if and only if the graphical effects are positive (in the so-called positive case). The problem is phrased in terms of a soundness condition, and the paper shows how positivity allows the algorithm to fail in a simple setting.   Pros: - Important insight to shed light on the shortcomings of the recently proposed algorithm - Clear exposition  Cons: - It is not clear if the new algorithm can be used to solve the problem of how to identify certain types of effects. - There are many problems with the way the theory is written.  The authors have addressed many of the technical concerns raised by the reviewers",
        "Meta Review: In this paper, the authors revisit recent work (Lee et al., 2019) on identification of interventional distributions from a set that may include the observed data distribution and/or a set of interventional distributions.  (Lee et al., 2019) proposed a sound and complete identification algorithm for that problem.  The authors point out a critical flaw in that work: the completeness proof relies in a crucial way on absence of positivity.  However, absence of positivity (even including relaxations of positivity proposed by Shpitser and Pearl) results in the proposed algorithm not being sound, as the authors convincingly illustrate with examples.  The authors provide a repair of the algorithm proposed by (Lee et al., 2019), with new soundness and completeness proofs.  The reviewers were unanimously positive about this paper, and their questions were answered by the authors to their satisfaction.  Some reviewers pointed out that in addition to repairing a critical flaw in a recent paper, this work will also encourage authors in the causal graphical modeling community to pay more careful attention to important issues related to positivity or \"overlap\" assumptions."
    ],
    [
        "The paper studies an interesting distributed optimization question: To train an overparameterized model over a set of distributed nodes, what is the minimum number of bits required to reach zero loss? The authors give lower bounds on the amount of information transferred in terms of dimension, number of agents, amount of data, and solution accuracy.  The reviewers found the paper well-written and they agree that the results are novel and tight. The main concern of the reviewers is about the practicality of the algorithm. However, the authors adequately addressed this concern in their rebuttal and after the discussion, the reviewers reached a consensus that the paper should be accepted.",
        "This paper considers the following problem in distributed optimization: To train an overparameterized model over a set of distributed nodes, what is the minimum number of bits required to reach zero loss. The paper gives lower bounds on the bit complexity for two settings: non-convex functions satisfying a PL condition and overparameterized quadratics. The authors then give an algorithm that (1) for PL objectives, has optimal communication complexity (up to logarithmic terms in the dimension of the problem) and (2) for quadratic overparameterized objectives, attains optimal communication complexity (up to logarithmic terms) with high probability.  This paper generated significant discussion in the initial author-reviewer discussion period. Most of the reviewers were quite positive on the paper, and found the results to be interesting and relevant to the community, and found the paper to be well-written. They found the results, which provide near-optimal sample complexity for two settings (PL functions and overparameterized quadratics) to be technically strong, and were impressed by the tightness of the results. One reviewer took issue with certain limitations of the paper, including: - A limitation of the lower bounds in the paper is that they concern only deterministic methods. - The results are only tight with respect to the parameters $D$, $N$, and $\\epsilon$, and are not necessarily tight with respect to $L$ and $\\mu$. - Some related work can be discussed in more detail.  These limitations do not seem to take away from the novelty, and neither I nor the other reviewers were convinced by the other issues raised in the discussion. As a result, I believe the paper is worth accepting as a starting point for future research in this direction. Nonetheless, the authors are encouraged to expand the discussion around these issues and limitations in the final version of the paper, as well as expand the comparison to related work."
    ],
    [
        "This paper studies fair ranking in a non-deterministic setting, where the group memberships of an item are only known probabilistically. The reviewers agree that the paper studies an interesting and important problem and provides interesting theoretical results, with novel techniques for solving it. We thank the authors for their detailed responses and revision, which addressed most of the reviewers' concerns. We encourage the authors to incorporate their responses in the final version of the paper.",
        "This paper looks at the fair ranking problem, a known variant of ranking where group fairness constraints (typically hard, sometimes soft) are imposed on the traditional ranking objective, but where membership of each item to be ranked in a group (aka the sensitive attribute's value associated with that item) is unknown.  The paper provides strong theoretical results and, especially post-rebuttal, strong experimental backing of the setting at hand.  Some assumptions are relatively strong, as surfaced by reviewers (e.g., 3sFW), but by and large reviewers believed the work to be well motivated and complete, and I agree with that."
    ],
    [
        "This paper proposes a method to learn causal structure from observational and interventional data. More specifically, it proposes a 3-phase procedure based on continuous optimization to learn the causal structure over a set of categorical variables via parameter estimation. It reports strong empirical performance on two datasets (one synthetic and one real).  The reviewers and AC note the following potential weaknesses: (1) The paper is hard to follow. The approach suggested fits the network before interventions, simulates the intervention on the fitted network and then again assigns a likelihood score to the network parameters. Thus, it's not a solid approach to learn a causal graph from observational data. (2) The proposed method is not a systematic approach and accordingly it's hard to reason about its use. (3) It's not evaluated on the real-world data.  The authors did not provide a rebuttal. Therefore, the concerns remain and the reviewers do not recommend acceptance.",
        "In this paper, the authors study how to incorporate experimental data with interventions into existing pipelines for DAG learning. Mixing observational and experimental data is a well-studied problem, and it is well-known how to incorporate interventions into e.g. the likelihood function, along with theoretical guarantees and identifiability. Ultimately there was a general consensus amongst the reviewers that without additional theoretical results to advance the state of the art, the contribution of this work is limited."
    ],
    [
        "The paper tests the hypothesis of whether new vision transformers can detect out-of-distribution (OOD) samples. This is an important question that is of great interest to the community, and the authors have done a good job in their rebuttal. The reviewers have raised a number of concerns, such as the somewhat preliminary nature of the conclusions (e.g., ensembling several models) and the limited novelty of the experimental setup. We believe that the paper is still above the bar for publication at ICLR, and encourage the authors to keep pushing the idea forward.",
        "It appears as if both reviewers found some positive aspects and adapting and evaluating known techniques for OOD detection with either transformers or standard CNNs. The results are considered to be not exactly exciting and more work would be required to come to a more insightful conclusion. In summary I believe the paper is not yet quite ready for publication and could be further improved for a future date."
    ],
    [
        "This paper proposes to improve iterative refinement in unsupervised object-centric learning by truncating the gradients after the last refinement step instead of propagating it through the unrolled refinement procedure. The idea is that this will reduce unrollment, which will in turn improve the stability and training tractability of the method. The paper combines existing techniques from two groups of works: Unsupervised Object-centric Learning with Set Representation (UCLR) and implicit differentiation techniques.  The reviewers think the problem the paper considers is important and the proposed method is reasonable. The experiments show the effectiveness of SLATE on multiple benchmarks, including the CLEVR-Mirror, Shapestacks, and COCO-2017 datasets. Reviewers' raised concerns and questions are properly addressed by the author's response.  After the discussion, all reviewers agree that the paper should be accepted.",
        "The paper proposes to treat object-centric models with iterative refinement procedures as fixed point operations and optimize them using implicit differentiation.  Overall, the reviewers find that the contribution of the paper is somewhat novel, although similar ideas have been presented in prior work in different contexts (supervised settings). Only one reviewer was more negative before the rebuttal, eventually increasing their score after discussion with the authors.  I, therefore, recommend acceptance and encourage the authors to address the comments raised by the reviewers in the final version."
    ],
    [
        "This paper proposes a learning-based approach to discover modular concepts (i.e., modular structure) from raw CAD sketches. The authors define a DSL to encode CAD sketches and construct implicit and explicit representations of deep-learning based methods to detect design concepts and generate sketch graphs. Experiments on a large scale CAD dataset demonstrate the effectiveness of the proposed approach for design intent interpretation. The proposed method also is capable of auto-completion for CAD modeling. Overall, the paper is well-written and the approach is interesting. However, there are several major concerns raised by the reviewers: 1) Novelty: The formulation of the problem is clear. 2) Experiments are mainly applied in a domain-specific language (DSL) that is difficult to generalize outside of the given application domain. 3) Evaluation: Performance improvement over baselines on SketchNet is small.  The authors did not provide a rebuttal for most of the concerns. Given the above major concerns,",
        "As summarized by reviewer 5G2f, this paper proposes a novel learning-based approach to discover the modular concepts (i.e., modular structure) from raw CAD sketches. To tackle the problem, the authors first define a domain specific language (DSL) such that modular concepts can be represented in a network-friendly manner.  A Transformer-based detection module takes in a CAD sketch sequence and outputs a a set of latent embeddings, which are further decoded to parameterized modular concepts by a generation module. The whole model is trained in an end-to-end self-supervised manner, using reconstruction loss plus regularization terms.  The authors perform experiments on a large scale CAD sketch dataset and mainly demonstrate its applications for design intent interpretation (i.e., parse modular concepts from a raw CAD sketch) and auto-completion (i.e., complete a partial CAD sketch).  All reviewers recognize the novelty and contribution of this work, and the reviewer-author discussion was quite fruitful as many points, ranging from designer/user interaction, comparison to baseline methods, and issues with the library size are discussed and addressed. With such clear contribution and applicability to the CAD domain, I highly recommend the acceptance of this work."
    ],
    [
        "This paper proposes a two-stage analysis and synthesizer approach for speech restoration. The proposed method shows convincing results for denoising, decliping, dereverberation, bandwidth extension and declipping. Although there are some concerns on the technical novelty and experimental evaluation, the authors addressed most of them well in the rebuttal. After the discussion, all the reviewers agree to accept this paper. So I recommend acceptance. Please carefully revise the paper according to the suggestions by the reviewers in the final version.",
        "PAPER: This paper addresses the problem of learning methods for general speech restoration which generalizes across at least 4 tasks (additive noise, room reverberation, low-resolution and clipping distortion).  The proposed approach is based on a two-stage process, which includes both analysis and synthesis stages.  DISCUSSION: The reviewers wrote very detailed reviews which ask some important questions and point to some potential issues. The authors responded to all reviews, but only addressed a subset of the issues and questions mentioned by the reviewers. Novelty and comparison with previous approaches was one of the issues mentioned by reviewers. SUMMARY: While reviewers are supportive of this line of research, reviewers were also concerned with the novelty of the proposed approach and details of the experiments. In its current form, the paper may not be ready for publication."
    ],
    [
        "In this paper, the authors propose a method to derive counterfactuals, saliency maps, and so called isofactuals using invertible neural networks.  The reviewers found the structure of the paper confusing and lacking in clear elicitation of contributions. Although the authors conducted a qualitative study with quantitative evaluation, the qualitative evaluation is not sufficient to convey the ideas effectively. Also, the results of the human subject study are not very convincing.   It is not clear which attributes such as smiling; gender are important for the classifier's positive /negative attractive decision. It is also not clear what attributes are directly responsible for the interpretability of such decisions. The writing often lacks clarity.  I encourage the authors to take the reviewers' comments into consideration and revise the manuscript to improve the presentation.",
        "All the reviewers agree that the paper presents an interesting idea, and the main concern raised by the reviewers was the clarity of the paper. I believe that the authors have improved the presentation of the paper after rebuttal, however, I still believe that the paper woudl require another round of reviews before being ready for publication, in order to properly assess its contributions."
    ],
    [
        "Meta Review: The reviewers agree that this paper makes a valuable contribution to the study of risk-sensitive decision making in reinforcement learning, using the combination of aleatory risk and epistemic risk. The theoretical properties of the proposed risk estimator are sound, and experimental results corroborate the properties.   The proposed approach is also empirically supported by a variety of experiments.  The main drawback of the paper is, as pointed out by a reviewer, the complexity of the method and the use of a distorted utility function for the Fourier transform. The author's rebuttal includes a number of technical details that were not covered by the reviewers, and I encourage the author to include these in the final version (as also promised in the rebuttal).   Please also take into account the comments about the writing and organization from the reviewers when preparing the camera ready version.",
        "Meta Review: The paper proposes a novel quantitative measure for risk in RL. The measure is sensitive to aleatoric and epistemic risk, and avoids some theoretical issues with previously proposed additive measures of the two types of risk. The paper also proposes a novel risk sensitive RL algorithm (based on ensemble bootstrapping and distributional RL). The method performs well empirically.  Pro: * All reviewers agree that the proposed measure and algorithm is novel, sound, and original.  * 3 out of 4 reviewers agree that the paper is well written.  * The topic of risk sensitive RL is timely and important - 3 out of 4 reviewers rate the potential impact as good (3). * Empirical results justify the theoretical claims and the method performs well compared to other distributional RL methods  Con: * In their initial assessment, reviewers point out minor technical flaws and some difficulties in understanding parts of the empirical evaluation. The authors have commented on the issues raised, but only 1 reviewer has responded to the authors' comments. * PeBL points out a potential shortcoming w.r.t. the training protocol (splitting the data). Authors acknowledge this and point to other papers in the literature using a similar protocol. * The method seems somewhat complicated and could perhaps be presented better - this is based on questions raised by reviewers, and these questions should be helpful for the authors to improve the camera-ready presentation.  **Justification of recommendation:** 3 of 4 reviewers are in favor of accepting the paper. The only (weakly) negative reviewer has raised some major issues that are answered in the appendix of the paper (but the reviewer did not find the appendix) and answered in other sections of the paper (as pointed out by the authors). To me, the authors have adequately addressed all major and most minor comments in their extensive response (including the major issues raised by the negative reviewer) - unfortunately only the most positive reviewer responded to the rebuttal. Taking all this information together I can still confidently recommend acceptance of the paper."
    ],
    [
        "Both reviewers agree that this is a well-written paper with contributions worthy of acceptance. The authors should consider restructuring the paper so that the k-planner is introduced after the definition of the GRD-APK problem, and a safety-enhanced version of the algorithm is provided for the actor-goal recognition design problem. The safety analysis is useful, and the experimental results are convincing. Overall, this paper makes a good contribution to the workshop.",
        "Dear Authors, thank you very much for your submission. We are happy to inform you that we have decided to accept it and we look forward to your talk in the workshop. Please, go over the feedback in the reviews and correct or update your papers in time for the camera ready date (May 24). Best regards HSDIP organizers"
    ],
    [
        "The paper proposes the concept of safety of learning of ML models based on the maximum deviation from a reference model over a pre-specified certification dataset. Interpretable models like trees and generalized additive models are considered. The reviewers find the notion interesting and there is hope that it can be generalized to more general settings. However, they are not convinced that the proposed approach is an efficient way to implement such a concept. Interpretability is an important aspect of safety that deserves more than a single paragraph in a technical report.   We hope the authors will use the feedback from the reviews and discussions to improve the paper.",
        "The authors propose to inspect learned models based on their maximum deviation to a reference model. They evaluate the feasibility of computing this deviation for a number of widely used model classes, including generalised linear models and decision trees. The idea is illustrated in cases studies.   Reviewers all appreciated the novelty and importance of the proposed problem and the contributions made to examine the feasibility of solving it. Their main concerns were regarding the limited discussion on choosing the reference model and the certification set. The authors expanded greatly on this in their rebuttal and in a revision to the paper.   The technical novelty is rather lower but the paper should not have trouble finding an audience in the NeurIPS community due to the broad applicability of the problem under consideration the clarity of the manuscript. I think the added discussion asked for by reviewers is well within what could be expected to be added for a camera-ready version (and indeed, this is already in the Appendix of the revision)."
    ],
    [
        "Meta Review: The paper studies the convergence properties of deep networks in the presence of curvature differences between subspaces in continuous feature spaces. It received three reviews with mixed initial ratings: 4,5,6,7. The main concerns of R1 and R3, who gave unfavorable scores, included issues with the clarity of the paper and doubts about the validity of the empirical studies. In response to that, the authors submitted a new revision with a summary of changes and provided detailed responses to each of the reviews separately, which seemed to have addressed these concerns. R2 raised his/her score to 6 in the discussion and indicated he/she would support acceptance if the paper could be re-submitted with these changes. The AC read the reviews and rebuttal, the paper, and the responses, and found that the concerns of the reviewers were sufficiently addressed and that the paper can be accepted. Thus, the AC recommends acceptance.",
        "This paper presents an intriguing empirical phenomenon in deep learning. They train a variety of architectures for different tasks using different datasets and study the relationship between the learned representations. In particular they collect the representations into a large matrix and take the top left singular vector and measure the cosine of the angle. They show that it is much smaller than one might expect, about 10 degrees or so, and has an approximate monotonicity property as the network is being trained although it does not seem to converge to zero. Moreover this measure also correlates with performance.   The reviewers had divided opinions on this paper. On the one hand, the range of experiments is impressive and truly demonstrates that this is a pervasive phenomenon. On the other hand, it is not so clear what it means. In particular, suppose we have a collection of graphs which have close to the same degree distributions. If we take the top left singular vectors of all the adjacency matrices, they would also have low angles between them. While this is a very different setting and there is no analogy between the experiments in this paper and this toy model, it does raise philosophical questions about whether the phenomenon is meaningful or is a byproduct of something else about the data. This may be a challenging question to answer, but one reviewer brought up a natural next step: One could measure the principal angle between the subspace of the top k left singular vectors across experiments for larger values of k. The authors do bring up the point that the spectrum decays very quickly, so it could be that beyond a certain point the singular vectors behave somewhat randomly."
    ],
    [
        "This paper proposes to learn non-uniform pruning policies in RL to compact the deep neural network and robustify the model under adversarial attacks. The reviewers found the paper interesting and the empirical results convincing. The paper may bring insights and exhibit impact on the network pruning community. However, the equation between L157 and L158 is informal. The authors need to elaborate more on the implications of combining model compactness and adversarial robustness in the writing of the final version of the paper.   The authors are encouraged to address the reviewers' concerns in the camera ready version.",
        "After the discussion phase, the author's resolved (nearly) all problems regarding reproducibility (although the score in the review was not updated). In addition, one reviewer also increased the score to 5 in their reply. In view of the strengths and importance of the topic, I recommend acceptance."
    ],
    [
        "This paper compares intrinsic reward methods for reinforcement learning with human-like motivation, curiosity, empowerment and information gain. The main contribution is to show that a combination of task reward and curiosity as well as empowerment are better at explaining human behavior than just task reward.   The reviewers appreciated the correlation study between the different reward-agnostic metrics and the authors' rebuttal on this. However, all reviewers still had major concerns with the current draft. Mainly, the paper is not clear on the motivation of this paper. I agree with the reviewers that curiosity and exploration is an important topic for RL research and we need more in-depth analysis. The authors are encouraged to revise the paper based on the reviewers' feedback and submit to a future venue.",
        "The reviewers agree that the paper, in its current form, is not strong enough to allow for publication.  There are specific weaknesses that need to be tackled: a better correlation study; a clearer relationship to existing literature (and improvement on the novelty); clearer, more precise use of descriptions.  The authors are encouraged to continue with their work and submit a more mature manuscript."
    ],
    [
        "Reviewers agree that the paper provides a valuable contribution to the machine learning community by providing a dataset with potential applications to proteomics. The paper is well written, and the dataset is easy to manipulate as it is fully annotated and ready for use. There are some concerns regarding the lack of baselines and some of the presentation in the paper. However, given the importance of the topic and the contribution, I recommend acceptance.   The authors are encouraged to add a discussion to the final paper to address these concerns.",
        "Reviews were split. Reviewers agreed on the importance of the domain but differed in how they valued the contribution over ProteomeTools, which the dataset builds upon. A primary concern was lack of baselines/benchmarking. The rebuttal argues that baselines would not add much value since strong methods have been published in prior work. However, my interpretation of the reviewers ask is not to invent new heuristic baselines but to evaluate the prior methods on the newly prepared dataset. The authors do add evaluation of one such model (Prosit) to the revision. Evaluating more models in the same way could strengthen the contribution, and could be part of the ongoing maintenance of the dataset / code.  Overall, however, the majority of reviewers felt the paper does provide significant value beyond ProteomeTools and other prior work, through the new annotations, tooling, and usage recommendations. The revision adds an appendix (G) to clarify these contributions, and it may be useful to move some of that text into the intro of the paper (as I think many readers will want to know what are the main contributions beyond the base dataset). I agree with the majority that there is significant value added and recommend acceptance."
    ],
    [
        "This paper studies multi-objective RL and proposes a new anchor-changing regularized objective based algorithm that asymptotically achieves global convergence in convex and smooth concave scalarization, CMDPs, and max-min tradeoffs. The reviews are all positive and agree that the paper makes a solid contribution. Please incorporate the reviewers' feedback in the final version of the paper, especially the ones on the experiments.",
        "This paper studies multi-objective RL, and in particular the settings of smooth concave scalarization, constraints, and max-min trade-off. The authors propose a framework for these problems called “anchor changing regularized natural policy gradient” (ARNPG) and show $O(1/T)$ convergence with exact gradients. The results do not require some of the assumptions used in related works such as ergodicity. The authors evaluate their approach on tabular environments, Acrobot, and (post-rebuttal) Hopper. The paper is well-written, the results seem correct, and the work provides a nice extension of the recent results on PG convergence to the multi-objective case. This contribution warrants acceptance despite the somewhat limited empirical evaluation."
    ],
    [
        "This paper proposes a method for variance-aware test sets for machine translation. The idea is simple and effective, and all reviewers agree it is an interesting approach that will be useful for the community. The authors release the code for the method and provide results on a large-scale translation task (WMT16-20), and correlation with human evaluations shows that the resulting test sets meet their purpose.  It will be a valuable asset for future research to have these test sets since they can keep track of which components of the system cause the translation systems to differ in terms of metrics and human evaluations.",
        "The paper presents a new evaluation dataset for machine translation, focusing on sampling test examples that can effectively rank different systems. The evaluation set contains a wide range of language pairs (35 language pairs) and shows a higher correlation with human judgments than original, unfiltered datasets.   All reviewers agreed that the paper points out a new perspective on the MT task, and the same idea of filtering evaluation datasets to improve discrimination ability can be applied for other tasks. The paper also includes in-depth analysis, such as what kind of sentences are getting filtered, and how it connects to human paraphrasing. My initial concern about using same models to compute variance and then to evaluate output was addressed during the rebuttal period."
    ],
    [
        "This paper presents a method for data augmentation in graph contrastive learning, where the augmentations are done in feature space such that they do not change the predicted label. The authors develop a metho algorithm for graph representation learning and show competitive results on multiple benchmarks.  All the reviewers agree that the paper is well-written, the method is simple and effective, and the experiments are comprehensive.  Thus, this paper is recommended for acceptance.",
        "The paper finally received three unanimous scores 6/6/7 and all the reviewers think the authors have addressed their initial concerns. The AC also think positive to this work and suggst to accept this paper."
    ],
    [
        "The paper shows that existing GNN defenses are not robust to a broad range of attacks, including some that are much more adaptive than non-adaptive ones. This indicates that the perceived robustness of GNN models is likely to be overestimated. The paper proposes a robustness metric based on the amount of adaptive variation in the attack type. The reviewers found the analysis and demonstration of the practicality of the attack quite interesting and important. There were some concerns about the lack of theoretical analysis of the results, but these were addressed well in the rebuttal.",
        "The recommendation is based on the reviewers' comments, the area chair's personal evaluation, and the post-rebuttal discussion.   This paper provides novel insights into the effectiveness of various defenses proposed for graph neural networks. All reviewers find the results convincing and valuable. The authors' rebuttal has successfully addressed the reviewers' concerns. Given the unilateral agreement, I am recommending acceptance"
    ],
    [
        "The paper studies the problem of how to fine-tune a pre-trained model and obtain better results for both ID and OOD. Two methods, fine-tuning and linear probing, are investigated and compared. Their experiments on several datasets including CIFAR, WILDS-FMoW confirm the intuitions from their theory.   The authors propose a new LP-FT method that combines Fine-Tuning and Fine-Welding and demonstrates its superior performance.  The reviewers find the extensive and detailed toy and benchmark experiments are impressive. The suggested solution by combining linear probing and fine- Tuning also has good performance. However, there are some concerns from the reviewers: 1) Experiments are mostly on small datasets with small classes of images. It would be great if the authors can add experiments on more complex datasets such as ImageNet and Imagenet. 2) It is not clear how the findings in this paper generalize to larger datasets",
        "The paper provides a solid and thorough analysis to the two basic methods of fine-tuning, linear probing (LP) and fine-tuning (FT). The authors provide an important and highly interesting observation about the performance of both in and out of domain (OOD) setting. They validate the known phenomena that FT outperforms LP in the in-domain (ID) setting, but demonstrate that when tested on OOD data, LP is in fact more performant and back this observation with a theoretical and empirical analysis. The remedy provided is also a known, yet slightly less popular technique of setting the final layer (LP) first, then finte-tuning (FT-LP). The authors provide thorough experiments showing that this technique enjoys the best of both worlds, meaning ID and OOD. I found it worth noting that during the rebuttal period the authors provided experiments on additional larger scale datasets and models and the results of the paper carried over to these new setting. The reviews agree that the analysis provided is both interesting and novel. Even though the paper does not provide a new technique, there is a consensus that the understanding it gives on known techniques is a welcome addition to ICLR."
    ],
    [
        "The authors consider online linear regression with convex and strongly convex losses and they show that it is possible to obtain negative regret for such a setting (with a small amount of variance) by curvature of the loss function. This allows the algorithm to have the same regret as the best expert, but with a much smaller variance - which is called \"variance\". The reviewers agree that this is a technically interesting result and the paper is well written. However, there are some concerns about the limits of the applicability of the technique and the clarity of the paper can be improved.",
        "The paper introduces the valuable idea of exploiting strong convexity of losses in online learning, together with variance-based regret bounds for contemporary algorithms like Squint and Metagrad, to introduce negative terms in cumulative regret bounds and make the algorithms useful in many applications such as early stopping in online-to-batch conversion and other settings.   A dominant concern from the reviewers' side was about the amount of (technical) material packed into the paper, which was alleviated by the detailed author response. As a result, the reviewers largely agree that the paper deserves to be accepted -- an opinion which I share.   PS. I request the author(s) to please resolve the incomplete [TODO]s in the paper checklist appropriately for the final version."
    ],
    [
        "The reviewers agree that this paper represents a significant advance in the state of the art for learning-based single-image manipulation. During the rebuttal, the authors further included additional experiments that further strengthen the significance of this work. I recommend acceptance.  PS: I also believe that the paper would be significantly strengthened by including some of the experimental results that were mentioned during the discussion phase.   PS1: The editing effects of edge maps are not distinct from the segmentation effects. The authors need to clarify why the VGGNet-based perceptual loss encourages the model to maintain the fidelity. PS2: It is interesting that the cross-domain editing results are different from those of segmentation maps.",
        "The reviews are a bit mixed. While all the reviewers feel that the paper proposed an interesting mechanism to train conditional generators from a single image and demonstrated good image editing results in the experiments, there are also common concerns about the practicality of the proposed method for interactive image editing. All the reviewers asked for the computation time, and some expressed the concerns about technical contributions. While these concerns were (somewhat) addressed in the rebuttal, the AC feels that it’s a hard sell to bet on the dramatic increase of computational capacity to make the computing time from an hour to realtime. Concerns about novelty also remained. Given the drawbacks, the final decision was to not accept. However, this work is promising and can be made stronger for publication in a later venue."
    ],
    [
        "The submission proposes a variational inference approach that learns latent neural dynamics in input-driven SSM, while controlling the outcome of an optimization algorithm (iLQR) in the recognition model. The optimization problem is formulated as an optimal-control problem, and the latent dynamics and initial conditions are inferred by the generative model, while the control problem is observed by a stochastic SVM.   The submission received mixed reviews, with two weak accepts and two borderlines. The reviewers appreciated the novel formulation of the problem as an optimization problem, the consideration of iLQRs as an input to the SVM, as well as the experimental results showing the advantages of the proposed approach. However, concerns were raised regarding the clarity of the presentation, the strength of the empirical results, and positioning with respect to related work. The authors provided a thorough rebuttal and engaged in discussion, which addressed many of the reviewers' concerns. Two reviewers raised their scores.",
        "The paper introduces a novel control-based variational inference approach that learns latent dynamics in an *input-driven* state-space model. An optimal control solution (iLQR) is implicitly used as the recognition model which is fast and compact. Reviewers unanimously agree on the high quality writing and high significance of the work. This paper advances the horizon of nonlinear dynamical system models with unobserved input, an impactful contribution to the neuroscience and time series communities."
    ],
    [
        "This paper proposes a GOL method for rank estimation using the order constraint and the metric constraint. The order constraint enforces the feature vectors of instances to be arranged according to their ranks, while the metric constraints make the distance between instances reflect their rank. The paper aims to address an important problem in machine learning with a novel and effective approach. The authors have addressed most of the concerns raised by the reviewers during the rebuttal. Overall, the paper is recommended to be accepted at ICLR.",
        "This paper proposes a new approach named geometric order learning (GOL) for rank estimation. Reviewers found that the idea is novel and the paper is well written. The authors have also clearly addressed most questions from reviewers in their responses. Thus, I recommend the acceptance of this paper."
    ],
    [
        "This paper presents a novel approach to learning safe reinforcement learning agents given natural language constraints, and introduces a new test environment called Hazard World, where agents are challenged to navigate a grid world environment to find actions that meet certain constraints. The work is interesting and novel, and the paper includes interesting experiments. However, there were concerns about how well the baselines compare to prior work, and how the work compares to baselines that are task-specific (e.g., constraints are specified in natural language). Overall, the paper is not ready for publication at ICLR.",
        "The goal of the paper is to learn policies that can solve a given task while adhering to certain constraints specified via natural language. The paper closely builds upon prior work on constrained RL and passes the representation of natural language constraints by pre-training an interpreter. Experiments are done in a new proposed 2D grid-world benchmark. Although reviewers liked the premise, the main issue raised is that the way natural language constraints are handled is no different from the way it is done in prior work on constrained RL. The authors provided the rebuttal and addressed some of the concerns regarding paper details. However, upon discussion post rebuttal, the reviewers and AC feel that the paper does not provide clear scientific insight because the natural language part is processed separately from the policy learning part. We also believe that the paper will immensely benefit with results in more complex environments beyond the 2D grid-world. Please refer to the reviews for final feedback and suggestions to strengthen the submission."
    ],
    [
        "The paper provides a framework for benchmarking different pruning methods on their ability to identify strong/weak lottery tickets. The proposed framework is driven by theoretical analysis and questions the current methods for finding very sparse subnetworks in deep neural networks. They question if this is a fundamental limitation (i.e. these very sparse solutions don't exist), or if this are a limitation of current methods in finding such solutions. To answer this question, the authors propose to either \"plant\" known good very sparse subsets in DNNs, or to try and find novel very sparse substitutes.  The reviewers appreciated the novelty of the work and the potential usefulness of the benchmark.  However, the reviewers also raised concerns about the clarity of the writing, the logical flow of the paper, and the experimental details. The revision improved some of these aspects, but not enough to accept the paper in its current form. I encourage the authors to continue to improve the work for future submission.",
        "This paper takes on (in my view) one of the most important questions in the lottery ticket literature today: how small are the smallest lottery tickets that exist in our neural networks? Many methods have been proposed for finding weak lottery tickets (those that require training to reach full accuracy) and strong lottery tickets (those that do not), but we have no idea how close they come to finding the smallest lottery tickets. Moreover, in many cases, we only know how to find lottery ticket subnetworks early in training rather than at initialization. Is this a fundamental limitation on the existence of lottery tickets, or is this simply a limitation of our methods for finding them? I am personally very involved in lottery ticket conversations in the literature, and I believe I can speak with some authority when I say that these are vital questions where any progress is important.  Moreover, these are exceedingly difficult research questions, and (again, in my view) the authors should be commended for taking them on. A naive approach to these questions would involve brute force search over all possible subnetworks, which is infeasible even on the smallest of toy examples, let alone the meaningful computer vision tasks where lottery ticket work typically focuses.  I am sharing all of this information to provide background for my confident recommendation to accept this paper over the many legitimate concerns expressed by reviewers and those that I saw when reading the paper in detail. Those include that: * This paper does not solve any of these research problems in their entirety. * It focuses on toy networks smaller than those traditionally studied in the lottery ticket literature, and it is well known that lottery ticket behavior changes in character at larger scales. * Planting good subnetworks may be an unrealistic proxy for the kinds of subnetworks that actually emerge naturally. * There may be multiple good subnetworks in a network, not just the one that was planted. * The graphs are a bit hard to read. * I find the mix of pruning methods studied, which were designed with very different goals (pruning after training, pruning before training, finding strong lottery tickets), a bit confusing.  **The bottom line:** With all of that said, in my view, the paper asks good questions and provides an initial foothold that other researchers will be able to build on as we seek more general answers. This is similar to the contributions made by Zhou et al., which started the conversation on strong lottery tickets, and potentially even Frankle & Carbin, which kicked off the lottery ticket discussion but got many things wrong. Both papers were good first attempts at solving big problems, and both were highly influential despite their flaws. Similarly, even if this submission isn't perfect in every way, this is among the most important kinds of contributions that a paper can make. For that reason, I strongly recommend acceptance under the belief that this paper will help to foster a valuable conversation in the literature.  P.S. I really, truly, strongly beg the authors to redo their graphs following the style of some of the more user-friendly lottery ticket or pruning papers they have cited (e.g., Frankle et al., 2021). The graphs in this paper were really hard to parse. Really really really hard to parse. They're too small, the y-axis is often squished, gridlines would be helpful, the lines are overlapping in ways that are difficult to distinguish because the colors blend, etc. etc. This is quite possibly the biggest impediment I see to this paper's ability to have broader influence."
    ],
    [
        "The paper introduces a method for embedding the hard-constraints for boundary conditions for physics-informed neural networks (PINNs), which are a new paradigm for injecting the knowledge of governing equations into neural networks. The authors test on 3 PDEs: the heat equation in a battery pack, the Navier-Stokes equation over an airfoil, and a 10 dimensional heat equation. PINNs are an important application for incorporating physics knowledge into deep neural networks and this work is a valuable contribution to the community.   The reviewers and AC note the following potential weaknesses: (1) limited novelty in light of prior art that uses extra fields to transform the original PDE into equivalent forms so that the BCs can become linear; (2) lack of comparison with certain baselines in the PINN literature; and (3) missing details on the parameter choice and the learning rate.  The authors provided a strong rebuttal that addressed some of the reviewers'",
        "The paper considers using neural networks to solve PDEs with complex geometry by incorporating hard constraint into the approximation function class. The method is interesting and useful for practical applications of neural-network based PDE solvers. The authors have adequately addressed the concerns by the referee. The meta-reviewer recommends acceptance of the paper."
    ],
    [
        "This paper introduces an algorithm for learning goal-conditioned policies without extrinsic rewards from the environment. The reviewers all agreed that taking on this problem is important and that the paper has good contributions. The main concerns were around (1) the clarity of the writing, and (2) the lack of a comparison to prior work. The authors did a good job of addressing these concerns in the rebuttal, and two reviewers raised their scores accordingly. Hence, I recommend acceptance.",
        "This paper introduces an unsupervised algorithm to learn a goal-conditioned policy and the reward function by formulating a mutual information maximization problem. The idea is interesting, but the experimental studies seem not rigorous enough. In the final version, I would like to see some more detailed analysis of the results obtained by the baselines (pixel approaches), as well as careful discussion on the relationship with other related work, such as Variational Intrinsic Control."
    ],
    [
        "This paper proposes a graph neural network (GNN) model that can be seen as a minimax optimization of an energy function through channel-mixing matrices. The energy function is parameterized and learned. GNNs with this model learn attractive and repulsive forces in feature space defined by the positive and negative eigenvalues of a symmetric 'channel mixinging' matrix'. The authors present structural constraints on common GNN architectures, allowing them to be interpreted as gradient flows. Empirical experiments on heterophilous graphs show that the proposed model is competitive with existing models when handled heterophily.  The paper is well-written and clearly presented. It builds on similar ideas as outlined in several previous works. The primary value added explored in this work is to the analysis (and empirics) of the ability (and unpredictability of) the ability to handle heterophilic graphs. The experiments has primarily focussed on one while studying on several datasets with",
        "The authors present a graph neural network for heterophilic data using gradient flows. The proposed architecture is quite simple...large sections of the architecture are fully linear dynamical systems rather than neural networks, and still achieve roughly SotA results on standard graph learning benchmarks. There was a significant amount of disagreement between the reviewers. Some seemed to think the strength of mostly linear methods meant that the benchmarks were too easy, but these are standard graph neural network benchmarks. A simple model performing well is not a negative, and can often be useful for puncturing hype (e.g. https://arxiv.org/abs/2206.13211). Simple architectures can also be useful for providing analytic insights which might get obscured in more complex models. Some reviewers seemed concerned about the scaling of certain tools (e.g. graph Laplacian eigenvectors), but these tools are only used for analysis, not for training. Nevertheless, I feel that there were enough general concerns around the paper that I have a difficult time recommending acceptance. Even if the purpose of the paper is primarily to drive analytic insights rather than achieve SotA results on big benchmarks, I would recommend the authors to show how these analytic insights can be used to improve models on big datasets to strengthen the paper."
    ],
    [
        "The paper introduces a new Bayesian approach to deep image prior using mean-field variational inference, where the goal is to enable pixel-wise uncertainty quantification, and mitigate the need for early stopping regularisation.   All reviewers were clearly in favour of acceptance, albeit with a mix of first and last name. The reviewers all agreed that the paper was clearly written, structured and motivated, and that the experimental results were interesting.  The main issues raised by the reviewers were: 1) lack of novelty: the proposed approach is a combination of known techniques, albeit Bayesian; 2) additional steps and calculations than previous works; 3) justification of the method via theoretical results. The authors answered to (most of) these issues in the rebuttal, and I tend to believe that they have addressed the main issues (albeit with a modified title).  Based on the reviewer consensus, I am recommending acceptance of the paper.",
        "This paper introduces a new Bayesian approach to deep image prior using mean-field variational inference, where the goal is to enable pixel-wise uncertainty quantification, and mitigate the need for early stopping regularisation.  The paper defines a prior distribution in a Bayesian setting to learn the parameters of the weight prior, targeting an improvement in the quality of the reconstructed images for inversion problems (i.e., denoising, super-resolution and inpainting).  All reviewers demonstrated full support for the publication of the paper and the questions were more about clarifications about claims, experiments, etc.  I also support the publication of this paper, and encourage the authors to address the main comments by the reviewers."
    ],
    [
        "The paper extends PINNs to stochastic PDEs which contain partially unknown parameters. The key idea is to use polynomial chaos expansions to approximate the solution, by approximating by NNs. The method is mathematically sound and novel. The paper is generally well-written. Reviewers' raised concerns and questions are properly addressed by the author's response. After discussion, all reviewers agree that the paper is above the bar for publication. I also recommend acceptance.",
        "This paper considers extending Physics Informed Neural Networks (PINNs) to stochastic PDEs and thereby be able to quantify uncertainties in their predictions. The authors may consider this opportunity to extend the experimental section to address limitations of the work that has been flagged by reviewers."
    ],
    [
        "This paper proposes a neural network based approach for quantile regression on censored data. The linear approach proposed in the paper is a straightforward application of existing methods. The authors first adapt the sequential grid algorithm of Portnoy 2003 to work with neural networks and develop an algorithm for both sequential optimization and bootstrap weights. The empirical results show the superiority of the proposed method over the state of the art. The reviewers raised several concerns regarding the novelty of the work as well as the complicated nature of the sequential optimization step, which the authors addressed comprehensively in the rebuttal. Based on the reviewers' comments and the author's response, I recommend acceptance of this paper.",
        "This paper studies the quantile regression of censored data. Neural network models are used as the statistical model. Numerical results show the proposed algorithm is computationally efficient and attains high prediction accuracy compared to existing methods. Since reviewers agree that this paper is well written and interesting, I recommend accepting the paper."
    ],
    [
        "The paper proposes a hypothesis testing framework (MaSF) for OOD detection. The main idea is to use spatial, channel, and layer reduction methods (Max-Simes-Fisher, and Fisher tests) to obtain p-values for each layer and channel in CNN from the empirical cumulative distribution. The theoretical analysis and the extensive experiments justify the efficiency and effectiveness of the proposed method. Empirical results show that MaSF achieves comparable or better results than GRAM, ResFlow, and Mahalanobis.  As the framework is novel and results shows good performance both in accuracy and computational complexity, I feel that the study deserves to be published. However, there are several concerns from the reviewers. 1) The approach lacks novelty. 2) The experiments are limited. 3) It is not clear whether the proposed approach can be applied to large-scale data. 4) The writing needs improvement.  I encourage the authors to take the reviewers' comments into account to",
        "The paper considers the empirical distribution of layer/channel in CNN ,and proposes to use global null tests with Simes and Fisher statistics to aggregate the p-values. This method is competitive while computationally efficient. The underlying theoretical insights are discussed in detail.  The paper received mixed ratings, and the discussions weren't active. So, AC carefully read the paper and inspected all reviews. Reviewer a8KZ comments were factually inaccurate in listing references, and lack substantial feedback on the actual content of the paper. Hence, the review was down-weighted.   The other negative reviewer Ni17, as an OoD expert, unfortunately did not offer more feedback to author rebuttals. From what AC comprehends, the authors should have clarified their The theoretical guarantee and compared properly with Liu et. al. 2020 energy-score (ES).  Considering the above, AC feels that the study deserves to be published."
    ],
    [
        "This paper proposes a new method for multi-head attention in transformers which suggests to use collaboration instead of concatenation of multiple heads to reduce the overparameterization of attention heads in Transformer’s multi-headed attention. The authors show that query-key projections are redundant in this setup and propose a reparameterization approach where the parameters of queries and keys are shared between heads.   The method is simple, well-motivated, and the experiments are thorough. It can be easily applied to most existing transformer-based models, including NMT and pre-training models. The results on En-De translation (En-De -> German) and WMT'16 English-German demonstrates that the proposed approach reduces the of parameters without sacrificing performance.  There are two main concerns raised by the reviewers. 1) The computational benefits are not well-discussed. The method requires extensive experiments on multiple tasks and hyperparameters. 2) There",
        "This paper proposes an interesting collaborative multi-head attention (MHA) method to enable heads to share projections, which can reduce parameters and FLOPs of transformer-based models without hurting performance on En-De translation tasks. For pre-trained language models, a tensor decomposition method is used to easily covert the original MHA to its collaborative version without retraining.   This paper receives 3 weak reject and 1 weak accept recommendations. On one hand, all the reviewers agree that the paper is well motivated and the proposed idea is interesting. On the other hand, all the reviewers also commented that the current empirical results and comparisons are weak, which are not enough to support the paper's main claim. From the current results, it is difficult to draw a conclusion that collaborative MHA is better.   Specifically, (i) From Table 2, it can be seen that the proposed method is not effective for pre-trained models, i.e., even if the model size is not reduced much, the performance can be dropped significantly. (ii) More experiments, such as QA, more translation/generated tasks will make this paper more convincing. (iii) More rigorous experiments are needed to justify the practical value of the proposed method. If the authors try to emphasize that they go beyond practical realm, then probably a careful re-positioning of the paper is needed, which may not be a trivial task.   The rebuttal unfortunately did not fully address the reviewers' main concerns. Therefore, the AC regrets that the paper cannot be recommended for acceptance at this time. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere."
    ],
    [
        "This paper proposes a novel communication-efficient algorithm, FedGLOMO, for federated learning. It integrates variance-reduction both at the server and at local client updates. The paper includes theoretical results, as well as empirical results on cross-domain tasks.  The reviewers raised some initial questions about the novelty of the approach and experiments, but the authors adequately addressed them in their rebuttal. All reviewers now agree that this is a good paper fit for publication at NeurIPS.",
        "Meta Review: The authors have addressed the reviewers’ concerns. All the reviewers are not against the publication of the paper. Please add the discussion with the reviewer into the final version, especially the discussion on Assumption 4. The authors should also add the new empirical results too."
    ],
    [
        "This paper makes an attempt at truly unsupervised image-to-image translation, which is an interesting and challenging task. The proposed method TUNIT uses a guiding network that generates pseudo-labels and style codes that are then given to a generator network to generate source images with style consistency, while preserving the details of the reference images. Experimental results look pretty solid on the Unsupervised Imagenet benchmark dataset. However, it is unclear how well the proposed method works in the more realistic setting where the source images have very different styles and domains. The paper misses some details on how the pseudo-label prediction could be improved and the discriminator could be set up properly such that it is possible to achieve the state-of-the-art results without label prediction. Also, the comparison with another method called FUNIT is missing. The authors addressed most of the concerns raised by the reviewers in their rebuttal.",
        "This paper defines a truly unsupervised image translation scenario. Namely, there are no parallel images or domain labels. To achieve robust performance in this scenario, the authors use 1) clustering and 2) generator-discriminator structure to map images from different domains and generate images for target domains.    In all, all the reviewers agree that this definition of unsupervised image translation is interesting. However, there are also several concerns for the real-world practical application and empirical results.  Unlike unsupervised text translation whose target language is known, the truly unsupervised image translation is difficult to make sense without identifying what is the target domain. This limits the contribution of this paper to some specific tasks instead of more general tasks. For the empirical results, the selection of data and the hyperparameter K do not convince the reviewers."
    ],
    [
        "This paper introduces a self-modifying neural network that meta-optimizes the parameters of its own weights.  The reviewers agree that the paper is well written, the idea is interesting, and the authors have addressed most of the concerns of the reviewers. Overall, I recommend it for acceptance and encourage the authors to address the reviewer's points for the camera-ready version.  I also want to draw the authors' attention to the fact that their previous work bioRNNs use meta-training to improve their sensitivity to hyperparameters, which is contrary to their claim in the paper. Their approach also seems to use a hyperparameter that is in fact tuned to their method rather than a fixed value as they state in their abstract, and I encourage them to make a more clear discussion of this in the final version.",
        "This is exciting work that demonstrates the ability of self-modifying networks to solve meta-reinforcement learning problems. The reviewers all agree that this is strong work, and the authors have convincingly addressed most of the concerns the reviewers brought up during the reviewing phase. There are a few lingering questions about the applicability of the baselines, but these are quite minor. The authors have further promised to add analytical comparisons and additional details /motivation on the Hebbian update. Given this, I view this paper quite positively and encourage the authors to integrate the additional experiments and details they mentioned in the feedback stage."
    ],
    [
        "GT-GAN synthesizes regular and irregular time series using various auto-encoders and neural ODEs. It outperforms baselines on time series with missing observations as well as on the irregularly generated data. Reviewers agree that the paper is well written and the proposed method is simple and well-motivated. However, reviewers are concerned that the novelty of this work is not high enough. In addition, the proposed methods rely on various components that have been explored in the time series GAN literature, so it is not clear how useful they are for real-time applications.",
        "This paper presents a new model for time series data that can handle data sampled at irregular time intervals.  The proposed model makes extensive use of continuous time processes in a GAN framework.  Experiment results show that the proposed model consistently outperforms existing approaches.  All reviewers lean on the accept side and I support that consensus."
    ],
    [
        "This paper proposes a new method for object detection that uses dynamic anchor boxes (4D) as priors and layer-by-layer local scale to improve the convergence of DETR. Detailed experimental results and discussion with reviewers are adequate to demonstrate the effectiveness of the method. The paper is well-written and easy to follow. The idea of using positional priors in DETR is simple and novel. The experimental results are convincing. The authors adequately addressed the reviewers' concerns by adding additional visualizations and ablations, which clarified some of the issues raised by the reviewers. Overall, this is a good paper and I recommend acceptance.",
        "Somewhat borderline paper given the scores, but leaning on the side of accepting mostly because the positive (and weak positive) reviews are a little more persuasive. The negative review is a bit of an outlier; the main issues raised in the negative review are that the novelty is on the lower side or otherwise that the work is incremental. These complaints are largely not shared by the other reviewers, and furthermore seem not like deal-breakers. Still a borderline paper, but fairly safe to accept."
    ],
    [
        "The paper proposes a data poisoning attack method that optimizes the loss of a graph neural network by optimizing the graph structure. The main idea is to use the idea of meta-gradients from meta-learning to solve the bilevel optimization problem. The reviewers liked the idea, however, there were concerns about the clarity of the presentation, especially w.r.t. some of the assumptions. Also, two reviewers felt that the experimental results were not convincing enough, and only a small number of datasets were used.",
        "The paper proposes an method for investigating robustness of graph neural nets for node classification problem; training-time attacks for perturbing graph structure are generated using  meta-learning approach. Reviewers agree that the contribution is novel and empirical results support the validity of the approach."
    ],
    [
        "Strengths: The paper addresses an important problem of learning interpretable time series representations using self-organizing maps. The proposed approach is novel and well-motivated. The experimental results are convincing. The paper is well written.  Weaknesses: One reviewer pointed out that the proposed approach might be limited in scope to medical applications. The response mitigated some concerns but the reviewer was not convinced that the approach would be of broader interest to the ICLR community.  Contention: Authors point out that one of the limitations of their approach is that they do not perform clustering based on the time series but rather use a two-dimensional latent space.  Consensus: All reviewers and the AC agree that the strengths overweight the weaknesses. This is a strong paper and should be accepted.",
        "This paper combines probabilistic models, VAEs, and self-organizing maps to learn interpretable representations on time series. The proposed contributions are a novel and interesting combination of existing ideas, in particular, the extension to time-series data by modeling the cluster dynamics. The empirical results show improved unsupervised clustering performance, on both synthetic and real datasets, compared to a number of baselines. The resulting 2D embedding also provides an interpretable visualization.  The reviewers and the AC identified a number of potential weaknesses in the presentation in the original submission: (1) there was insufficient background on SOMs, leaving the readers unable to comprehend the contributions, (2) some of the details about the experiments were missing, such as how the baselines were constructed, (3) additional experiments were needed in regards to the hyper-parameters, such as number of clusters and the weighting in the loss, and (4) Figure 4d required a description of the results.  The revision and the comments by the authors addressed most of these comments, and the reviewers felt that their concerns had been alleviated.  Thus, the reviewers felt the paper should be accepted."
    ],
    [
        "This paper proposes a new loss SuNCTt, which is designed to speed up the convergence of semi-supervised training. The reviewers have a consensus on rejection due to lack of novelty. In particular, the proposed method is similar to the existing NCE in that it is applied to instance discrimination. Moreover, the performance improvement over SimCLR is not clear and the computational benefits are not significant. The rebuttal did not address the reviewers' main concerns.",
        "The paper proposes to speed-up self-supervised learning for semi-supervised learning by combining self-supervised pretraining and supervised fine-tuning into a single objective. The proposed supervised loss builds on Neighbourhood Components Analysis and soft nearest neighbor losses. Most reviewers are concerned about the novelty of the approach and the significance of empirical results. I agree with both concerns. I appreciate the comparison between $\\log \\sum \\exp$ and $\\sum \\log \\exp$, but it seems a simpler cross entropy loss also achieves a similar goal (potentially somewhat slower). I believe adding more experiments comparing different supervised loss functions across different architectures can help improve the paper."
    ],
    [
        "This paper presents a method for feature alignment across different prediction schemas (predictors) in meta-learning for few-shot learning. Reviewers had concerns about lack of clarity, insufficient experiments, and impracticality of the method. Overall, it does not seem that the paper is ready for publication at this time. I encourage the authors to address the reviewers' comments and resubmit a revised version to a future venue.  P.S.: The title of the paper could be changed to reflect the concern that it is not clear from the abstract / introduction what \"schema\" means.",
        "After carefully going through the reviews and rebuttal, and looking at the content of the paper as well, I feel there are some issues with the current manuscript. As also pointed out by AnonReviewer5 and AnonReviewer2, the text lacks clarity. From specifically defining what a schema is, to being more explicit about the limitation of the work.  I understand that the authors are interested in a largely unexplored setting, and hence there might not be a lot of prior work to cement the evaluation protocol. Particularly because of this I think such papers need to be upfront and clear not only in what is the setting and what is the evaluation but also what are the limitations and open problems.   I do agree that there is value in this direction of research, and that the idea of re-ordering the features using attention (which I have to agree it is reminiscent of Bahdanau et al., ICLR 2015 -- though the semantics of it and its purpose makes it novel here) might be a way forward. But I do think for the paper to make an impact (and be ICLR ready) it needs more work both in the writing and maybe on the experimental side as well (consider some more complex task, or be more explicit on what is the common aspect between tasks in the distribution that can allow chameleon to work)"
    ],
    [
        "There are contrasting review rating ranging from 9 to 3. The reasonable concerns about this paper not been well validated for ML community. The proposed datasets has been benchmarked with some classical and some relevant DL methods. The established benchmark motivates future work to address the domain gap on the existing pretraining data and aggregation methods to better model slide-level and patient-level prediction. I think the proposed dataset OpenSRH can be a good contribution to the medical imaging community.",
        "There are contrasting review rating ranging from 9 to 3. The reasonable concerns about this paper not been well validated for ML community. The proposed datasets has been benchmarked with some classical and some relevant DL methods. I have taken into account the expertise of reviewers and their concerns carefully. I do agree with some reviewers opinion about this dataset will be importance to medical CV community. I do agree with authors response \"The open questions for the ML community that OpenSRH may foster innovative discoveries include the following: 1) domain adaptation between SRH images and other histology images such as H&E images in the large scale TCGA project; 2) using multiple instance learning (MIL) to avoid expensive dense patch annotations; 3) different aggregation methods for patch-based training, including clustering, attention, or MIL; 4) self supervised learning and comparing different augmentation strategies for SRH images; and 5) data efficient training of ViT architectures using SRH data. \" Even though the authors have not verified these innovative applications on the openSRH dataset. I will go with acceptance opinion of few reviewers for this paper."
    ],
    [
        "This paper proposes a plug-in method that learns a dynamic prediction error bound for some error-bounded learned indexes. All the reviewers agree that this is an interesting problem and the solution is well-motivated and theoretically sound. With the proposed method, the learned index can make a good trade-off between space and time, improving the efficiency and accuracy. Therefore, I recommend acceptance. Meanwhile, please carefully revise the paper by addressing the reviewers' comments in the camera-ready version.",
        "All of the reviewers recommended acceptance, but the support was lukewarm, with the maximum score being “Weak Accept”. There were concerns about the limited applicability of the proposed method and lack of clarity of some of the arguments in the paper. Although the reviewers appreciated the mathematical foundations and experimental results, the negatives outweighed the positives."
    ],
    [
        "This paper proposes a variance-reduced version of the Greedy-GQ algorithm for off-policy control, based on SVRG. Overall, the sample complexity is improved over the baseline by a factor of 1/eps, and the algorithm achieves better sample efficiency. However, as pointed out by the reviewers, the nested loop structure seems at odds with the single Markovian path of experience. Therefore, it would be nice if the authors could show the cumulative reward versus running time in a clearer way, which demonstrates the performance in a more convincing way.",
        "**Overview** This paper provides a way to combine SVRG and greedy-GQ to improve the algorithm performance. In particular, the finite iteration complexity is improved from $\\epsilon^{-3}$ to $\\epsilon^{-2}$.  **Pros** The paper is well-written. Reviewers believe this is a solid theoretical work on advancing value-based algorithms for off-policy optimal control. It has sufficient theoretical advancement and experiments demonstrations of the methods.   **Cons** Some reviewers are concerned that SVRG is not SOTA. SVRG is not used in practice. The techniques appear to be similar to some existing works.   **Recommendation** The meta-reviewer believes that the paper has solid theoretical contributions. SVRG is a component in the new algorithm to improve the complexity. It does not need to be \"useful\" or \"SOTA\". The paper is also well-written. Hence the recommendation is accept."
    ],
    [
        "The paper proposes Fast Geometric Projections (FGP), a method to certify the robustness of neural networks with ReLU as activation. The authors propose a systematic search over the convex polyhedral regions on which the network is linear. FGP can verify whether in an $\\ell_p$-ball around an input $x$ adversarial examples exist exist or not. Given an input, FGP returns, given a input either one of 2 certificates (robust or not_robust) or abstains from certification.  The paper significantly outperforms prior work. The empirical results are very convincing, showing strong improvements in term of runtimes the method of verifying local robustness and robustness certification of networks with piecewise-linear activation functions.   The authors have adequately addressed the comments of the reviewers, and most reviewers increased/remained their scores. In particular, compared to a previous similar algorithm (Geocert), it seems that FGP has",
        "The paper presents a sound and efficient (but not complete) algorithm for verifying that a piecewise-linear neural network is constant in an Lp ball around a given point. This is a significant contribution towards practical protection from adversarial attacks with theoretical guarantees. The proposed algorithm is shown to be sound (that is, when it returns a result, that result is guaranteed to be correct) and efficient (it is easily parallelizable and can scale to large networks), but is not complete (there exist cases where the algorithm will return \"I don't know\"). The experiments show good results in practice. The reviewers are positive about the paper, and most initial concerns have been addressed in the rebuttal, with the paper improving as a result. Overall, this is an important contribution worth communicating to the ICLR community, so I'm happy to recommend acceptance."
    ],
    [
        "The paper proposes measures of how two types of explanation methods -- rule-based and exemplar-based -- generalize and extrapolate to unseen data regions. Although the problem is important and the authors made an effort to address the reviewers' comments, the paper still does not have enough substance to publish at ICLR. I encourage the authors to take reviewers' detailed comments into account in the writing and improve the readability of the paper.",
        "The paper proposes a novel protocol for examining the inductive biases in learning systems, by quantifying the exemplar-rule trade-off (as measured by the exemplar-vs-rule propensity (EVR) defined in Eq. (2)) while controlling for feature-level bias.   Reviewers mostly agree that the problem studied in this paper is practically relevant and that the two bias measures are potentially interesting and (jointly) more informative than existing measures such as spurious correlation. However, a shared concern among the reviewers (with confidences scores >=3) is the clarity of the exposition (e.g., many key concepts such as the data conditions are informally specified [Section 2 (Reviewer TPBn)], some key messages not clearly conveyed in the main paper [Section 3 (Reviewer RJtk)], and results inconclusive or not sufficiently supported by the experimental results [for both the synthetic setting (Reviewer RJtk) and the real-world setting (Reviewer yoH5)]. Based on the above concerns, the reviewers were not convinced that this work is well supported in its current state to merit acceptance for publication."
    ]
]