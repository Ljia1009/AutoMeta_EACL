Below are multiple reviews of a paper. This paper considers the problem of fast mapping: in a 3d environment, learning to explore an environment to learn a (new) mapping between objects and names. The paper compares several sequence models for this task, and finds that a Transformer-XL and a a 'Dual-Coding Episodic Memory (DCEM)' modelThe paper presents an argument for a multi-modal memory-architecture called DCEM. The proposed DCEM model outperforms baselines on various metrics and ablation. The paper only investigates generalization of object names.The authors use a 3D world to explore grounded language learning. An agent uses RL to combine novel word-learning with stably acquired meanings. They show that a novel, psychologically-inspired memory mechanism is more memory-efficient than Transformers.This paper presents experiments for acquiring words via fast-mapping in an embodied environment. The technical contribution is interesting and solid, but the experiments fail to address some important questions that are yet scoped by the claims.	The paper investigates the capacity for neural language models to perform fast-mapping word acquisition using a proposed multimodal external memory architecture. Much work exists that shows that neural models are capable of following instructions whose meaning persists across episodes (i.e., slow-learning), however much less attention has been paid to instruction-following in a one-shot learning context. Using a simulated 3D navigation/manipulation domain, the paper shows that the proposed multimodal memory network is capable of both slow and one-shot word learning when trained via standard RL.  The submission was reviewed by four knowledgable referees, who read the author feedback and engaged in discussion with the authors. The paper is topical---one-shot language learning for instruction-following using neural models is of significant interest of-late. The reviewers agree that the proposed multimodal memory architecture is both interesting and technically solid. The reviewers raised concerns about the experimental evaluation and the role of embodiment. The author feedback together with discussion with reviewers were helpful in resolving some of these issues. However, the authors are encouraged to ensure that the paper clearly motivates the importance of embodiment to slow learning and fast-mapping, particularly given the large body of work in language acquisition in robotics, a truly embodied domain, which is notably missing from the related work discussion.
Below are multiple reviews of a paper. The authors implement an open-source simulation environment FLEXS to emulate complex biological landscapes. ‘Swampland’ landscapes with large areas of no gradient, are also studied. They also propose a simple greedy-search evolutionary algorithm.In this work, the authors propose a greedy search approach for designing biological sequences in an active learning, batch setting. The algorithm is a fairly standard evolutionary algorithm which identifies the set of candidates at each iteration by adapting the best candidates from the previous iteration.Simple evolutionary algorithm "AdaLead" outperformed several existing methods. There is a lack of exploration to understand why AdaLead is outperforming. Some of the figure labels can be improved.The structure of this paper is somewhat unconventional, the paper would benefit from more rigor and structure. The authors introduce a new algorithm AdaLead to solve the problem of efficient design of biological sequences and FLEXS, an open-source simulation environment for sequence design.	This paper considers the problem of (biological) sequence design and optimization. The authors made an interesting yet important case that in certain sequence design tasks, a simple evolutionary greedy algorithm could be competitive with the increasingly complex contemporary black-box optimization models.  Most reviewers appreciate the design of the open-source simulation environment in benchmarking AdaLead (and other competing algorithms) in a number of biological sequence design tasks (e.g. TF binding, RNA, and protein). However, there is a common concern that the experimental results are not fine-grained enough to explain the outperforming results of the proposed algorithm. There are also unresolved comments on missing important BO baselines in the empirical study. As a purely empirical work, these appear to be important concerns. While these results appear to be useful for the domain of biological sequence design, the reviewers are unconvinced that the proposed algorithm is significantly novel, or the results are sufficiently compelling to merit an acceptance to this venue.
Below are multiple reviews of a paper. The authors of the current submission set out to provide a biologically inspired "neural field" (herein a PDE model) model of the experimental data reported in Wang et al. (2020) The proposed model, unlike those previously proposed, accounts for "phase procession" (cf. phase precession)The authors propose an attractor network model which includes a “feedback inhibition” term that jointly exhibits phase precession and procession in hippocampal place cells. The paper appears to exhibit overall high quality and clarity. The primary weaknesses I see are addressed in “Questions” below.This paper proposed a CANN model with feedback inhibition to elucidate the mechanism underlying phase precession and procession of the firing of hippocampal place cells. Compared to standard CANN models, a feedback inhibition mechanism is used to perturb the steady state. This paper derived analytic formulas of the CANN under different input and feedback conditions.	This paper presents non-trivial and novel theoretical and computational modeling that accounts for experimentally observed phenomena: the theta phase procession and precession. These phenomena are implicated in the neural representation and learning of neuronal networks involving hippocampus. Although the current manuscript does not address the learning and the presentations are limited to a linear track environment, it represents a clear advance in linking spatial and temporal information representations by extending the standard continuous attractor models that do not exhibit phase procession/precession. Furthermore, the model elegantly explains the biologically observed unimodal and bimodal cells. The authors are encouraged to improve the clarity of some parts of the writing.
Below are multiple reviews of a paper. This paper proposes a method called HarmonicGAN for unpaired image-to-image translation. The key idea is to introduce a regularization term on the basis of CycleGAN, which encourages similar image patches to acquire similar transformations.The paper adds a spatial regularization loss to the well-known CycleGAN loss for unpaired image-to-image translation. The regularization is similar to imposing a CRF (Conditional Random Field) term on the network outputs, encouraging spatial consistency.The paper proposes a new smoothness constraint in the original cycle-gan formulation. This enables the translation network to preserve edge discontinuities and variation in the output. This leads to better outputs for medical imaging, image to labels task, and horse to zebra.	The proposed method introduces a method for unsupervised image-to-image mapping, using a new term into the objective function that enforces consistency in similarity between image patches across domains. Reviewers left constructive and detailed comments, which, the authors have made substantial efforts to address.  Reviewers have ranked paper as borderline, and in Area Chair's opinion, most major issued have been addressed:  - R3&R2: Novelty compared to DistanceGAN/CRF limited: authors have clarified contributions in reference to DistanceGAN/CRF and demonstrated improved performance relative to several datasets. - R3&R1: Evaluation on additional datasets required: authors added evaluation on 4 more tasks - R3&R1: Details missing: authors added details.
Below are multiple reviews of a paper. This paper introduces a novel cross-device federated dataset, FLAIR. The dataset consists in 429k images from 51k individual Flickr users. The task consists in classification, with 2 levels of granularity for the classes.This paper proposes a new benchmark for large-scale cross-device federated multi-class image classification problem. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users.This paper builds a large-scale multi-label image classiﬁcation dataset FLAIR. FLAIR includes 429,078 images from 51,414 users, with 17 coarse-grained labels and 1,628 ﬁne- grained labels. FL AIR considers several important non-IID challenges in federThe paper presents FLAIR, a large-scale image dataset for federated learning. The images in the dataset are gathered and filtered in such a fashion that no faces are present to avoid any personally identifiable information. The dataset is collected from real Flickr profiles, which guarantees realistic user splits.The authors provide a large-scale classification dataset for cross-device Federated Learning with two tracks; fine-grained classification 1628 classes and coarse classification with 17 classes. The authors do not provide the NeurIPS checklist in the main article nor in the supplementary. I would advocate for not rejecting the article based on this.	The authors provide a benchmark for federated learning.   The commonly mentioned strengths: - there is a big need in the community for this type of work - easily accessible code - various levels of complexity with different granularity  Regarding the weaknesses, I see no showstoppers - some feedback about the experiments done on the datasets -> this point comes back consistently among all reviewers, in terms of the amount, settings and reproducibility.. The authors are adviced to address this in future work, to keep momentum for the use of the community on this dataset  - there was some discussion about tensorflow and pytorch, but based on the discussion both seem supported - some settings / image types could be better supported  None of these weaknesses seem serious, and quite frankly, we can not expect one dataset to cover all possible settings. Since the reviewers are in agreement about the quality of this work, I recommend them for an oral presentation.
Below are multiple reviews of a paper. The proposed approach formalizes an intuitive understanding of the spread of an infectious disease in a novel way. Experimental results on a (private) real-world dataset are somewhat mixed, but show that MIINT achieves a better true positive rate.This paper formulates the contagious disease into a missing label problem with dependence between each data point. The paper targets an important problem, especially in this pandemic. However, the writing of this paper is confusing and it makes it hard to catch the main contribution.The problem the authors describe is interesting and important. There are some confusing aspects to the paper that make it hard to evaluate the efficacy of the proposed method. The authors' use of the variable e for exposure state is a bit confusing.This paper focuses on contagious disease prediction with the consideration of observed data bias and patient exposure. The paper is not well-written and pretty hard to follow. Due to missing technical details, it is hard to re-implement the proposed models.	This paper studies a timely problem and consider an interesting approach, but overall there were many concerns about technical details and the validity of the framework. The positive reviewer also mentioned concerns about the experiments, which others also found to be an insular comparison with weak baselines. Following the response period, in discussion there are additional concerns arising related to the lack of details, for instance related to possible unidentifiability of the model. As one reviewer discusses,  the authors are attempting to use RNNs to impute missing infection status labels when the missingness mechanism is assumed to be (i) not at random, (ii) playing out over time (as it is unclear whether Y^t is assumed (conditionally) independent of Y^t' with t' << t), and (iii) subject to interference (whether someone is tested is the 'treatment' here since it's a missingess problem and one person's propensity to be tested could causally affect another person's downstream infection status since apparently no Markov independence is assumed. There is also consensus that the writing quality can be greatly improved. Overall this work contains some ideas with potential in a thorough revision
Below are multiple reviews of a paper. This work tackles the task of forecasting dynamics in different domains simultaneously. Using an encoder which is trained to determine the task, the inferred latent vector is then used to adapt a forecasting network to the task. Experiments on three datasets linked to fluid dynamics are then conducted to assess the proposed model.This paper addresses the problem of learning a deep learning model for dynamics forecasting. The proposed model takes a meta-learning approach and proposes to partition data into different heterogeneous domains. The paper evaluates the proposed approach on several datasets and provides some theoretical insights.The paper suggest a remediation for a common problem for dynamics forecasting which is the lack of generalization to other domains/tasks. The author suggest to tackle this with via a 2 component architecture, one for learning the task and one for forecasting.This paper is interested in learning general forecasting models for physical dynamical processes. The paper proposes a decomposition of such a model into an encoder that captures the innate properties of the system, and a forecaster that autoregressively makes predictions conditioned on the encoded properties. This is framed as a meta-learning approach, and is	The paper addresses the problem of domain generalization for learning spatio-temporal dynamics. It proposes a solution where an encoder captures some characteristics of a given environment, and a forecaster autoregressively predicts future dynamics conditioned on the characteristics learned by the encoder. Said otherwise, the forecaster learns the general form of dynamics parameterized by an environment representation extracted by the encoder. The conditioning is implemented via an adaptive instance normalization mechanism. A form of padding is also introduced in order to take into account boundary conditions. The two components encoder and forecaster are trained sequentially. This approach is casted in a meta-learning framework. Theoretical results inspired by multi-task learning and domain adaptation are also demonstrated. The model is evaluated and compared to different baselines on three problems, and for two different settings: varying initial conditions with a given dynamics, and dynamics with varying parameters.  This is a borderline paper. It targets a timely and important problem of domain generalization for dynamic environments. The proposed solution is original and compares well experimentally to several baselines. It allows for better generalization performance for the two test settings considered. In the current version, the paper however suffers from different weaknesses. First there is the imprecision of the arguments and the description of the experiments. Some of the arguments and claims are vague and sometimes abusive, not backed up by evidence. For example, a central claim is that the encoder learns time invariant quantities characterizing the environment when the learned representations indeed change with a time shift in the input for any environment. The same goes for the argument developed for the padding construction. It is claimed to model boundary conditions, but this is not supported by any theoretical or empirical evidence. As noted by the reviewers, the theoretical analysis is disconnected from the algorithmic and experimental developments and does not bring much additional value to the paper. What is more embarrassing is that some of the claims in this section are overstated and induce incorrect conclusions.  From Theorem 3.1 and proposition 3.3, the authors suggest that multitask learning leads to better generalization than learning independently, while this is not formally guaranteed by the results (this is acknowledged by the authors in a later comment). Besides, the conditions of validity are not discussed while they seem to only cover situations for which the train and the test distributions are the same. The same holds for the second theoretical results (theorem 3.4). It is claimed that this result supports the authors’ idea of training encoder and forecaster sequentially, while it does not. Besides, the bounds in this result cannot be controlled as noted by the reviewers and are not useful in practice.  Overall, the paper addresses an important topic and proposes new solutions. The results are promising and it is indeed an interesting contribution. However, inaccuracies and incorrect or exaggerated claims make it difficult to accept the current version of the article. The article would make a strong and innovative contribution if it were written as a purely experimental article with a detailed description of the experiments and comparisons.
Below are multiple reviews of a paper. APT-36K consists of 2,400 video clips collected and filtered from 30 animal species with 15 frames for each video. Three tasks are set up to evaluate several representative models. The results and analysis provide some insights which are useful for researchers in this field.APT-36K consists of 2400 video clips and 36000 frames for 30 animal species. It is the first benchmark for both animal pose estimation and pose tracking.This paper describes the APT-36k dataset, consists of 2,400 video sequences, each on 16 frames of annotated video. The videos are balanced across 15 families of animals (30 species), allowing for estimation of cross-family generalization. The paper is clear, the dataset and ethics are well documented, and the datasetAPT-36K consists of 36K frames, sampled from youtube videos and manually annotated for 53k animal instances. 30 animal species are captured with 80 video clips per species, making this a balanced set.APT-36K consists of 2400 video clips with 30 animal species. The authors set up three tracks (SF, IS, APK) based on their collected dataset.	After careful review, I believe that this paper is a useful contribution to the study of animal pose estimation and tracking. The paper received positive reviews from all the reviewers and the authors have successfully addressed the concerns regarding the lack of sufficient novelty and insufficient benchmarking. The authors also added additional low shot experiments to demonstrate the usefulness of the dataset. Based on this, I think the paper meets the bar for the track and should be accepted.
Below are multiple reviews of a paper. The paper proposes a hierarchical architecture for point cloud generation, which is composed of two diffusion models for shape latents and latent points. The main contribution might be the hierarchical generation architecture.This paper proposes the hierarchical Latent Point Diffusion Model (LION) for 3D shape generation. LION is based on a VAE structure with a hierarchical latent space that includes a global shape latent space and a local point-structured latent space. Exhaustive experiments demonstrate LION outperforms several state-of-theThis paper targets 3D shape generation and manipulation. Similar to previous works PVD and DPM [46,47] It uses a denoising diffusion model on point clouds.Authors present a generative model of 3D point clouds. This is a latent-space diffusion model. The model is demonstrated on various tasks using ShapeNet data.	This paper proposes a latent point diffusion model, LION, for 3D shape generation. The model builds two denoising diffusion models in the latent spaces of a variational autoencoder. The latent spaces combine a global shape latent representation with a point-structured latent space.  Comprehensive experiments are conducted to evaluate the performance of the proposed method.  The authors address the major concerns of the reviewers and strengthen the paper by providing additional empirical results. After the rebuttal, all four reviewers reach an agreement on accepting the paper because of the novelty and the state-of-the-art performance. The AC agrees with the reviewers and recommends accepting the paper.
Below are multiple reviews of a paper. This paper proposes probing BERT representations by projecting them into a Poincare subspace. The proposed approach is used to probe ELMO and BERT for both syntax and sentiment in comparison with the conventional Euclidean probes.In the same vein as Hewitt & Manning 2019, the authors present an extremely lightly parametrized “probe” model to determine the presence of syntactic structure in the embedding space of BERT models. This suggests that the BERT model may operate simply, but on a non-Euclidean manifoldThe paper is also at times difficult to follow on its own, as it relies a bit too much on cited work. The hyperbolic version of the probes consistently out-perform the Euclidean one. The name of the parsing dataset is not even mentioned.This paper proposes probes based on hyperbolic embedding spaces, and compares them to the behaviour of Euclidean probes from recent work. The main result is that these probes allow for better recovery of syntactic properties of sentences from contextualized word embeddings compared to context-independent ones. Similar results are presented  on sentiment analysis	The paper introduces a new method to probe contextualized word embeddings for syntax and sentiment properties using hyperbolic geometry. The paper is written well and relevant to the ICLR community. Reviewers highlight that the proposed Poincaré probe offers solid results, extensive experiments that support the benefits of the approach, and proposes a new approach to analyze the geometry of BERT models. The revised version clarified various concerns of the initial reviews and improved the manuscript (comparison to Euclidean probes, low dimensional examples, new results on edge length distributions etc.). Overall, the paper makes valuable contributions to probing contextualized word embeddings and the majority of reviewers and the AC support acceptance for its contributions. Please revise your paper to take feedback from reviewers after rebuttal into account (especially to further improve clarity and discussion of the method).
Below are multiple reviews of a paper. The paper introduces a variant of backdoor attacks against visual object tracking (VOT) networks. A baseline attack (BOBA) consisting of a classifier backdoor against the classification head of a Siamese network is proposed.This paper investigates a few-shot backdoor attack for single object visual tracking. It is achieved by optimizing a feature loss between benign and poisoned frames and standard tracking loss. The authors empirically show that the presented attack is effective in both digital and physical-world scenarios.This paper proposes a few-shot (untargeted) backdoor attack (FSBA) against siamese network-based visual object tracking. As the first work that relates backdoor attacks against VOT, the paper's motivation is exciting and essential. Although there are still some shortcomings in experimental analysis, this article is a good attempt on	This paper proposes a few-shot (untargeted) backdoor attack (FSBA) against siamese network-based visual object tracking. Contributions can be summarized as follows: First, this paper treats the attack task as an instance of multi-task learning and can be regarded as the first backdoor attack against VOT. Besides, a simple yet effective few-shot untargeted backdoor attack is proposed and achieves significant effectiveness in both digital and physical-world scenarios. This paper reveals the vulnerability of VOT to backdoor attacks caused by outsourced training or using third-party pre-trained models. One weakness is that threat model requires a very strong attacker with ability to modify the training algorithm, but only very simple defenses are considered. Overall, this is a good first attempt at showing vulnerability of VOT approaches.
Below are multiple reviews of a paper. The paper proposes an exploration method for "preference based Reinforcement Learning" methods, where human feedback is incorporated to the training regime. The authors use an ensemle of learned reward models and add an intrinsic reward based on disagreement (or uncertainity) The authors test the idea on robotic manipulation tasks from meta-world.With this work, the authors propose a bayesian active learning approach to the problem of reinforcement learning from preferences. To do this, they model the epistemic uncertainty of the reward function to intrinsically motivate the RL agents to explore.This work proposes an ensemble-based intrinsic reward to improve exploration in preference-based RL. The key idea is to incorporate uncertainty in teacher preferences as an intrinsic reward. An ensemble of reward functions is used to capture this uncertainty.The paper is well written and clear to understand. The method can be considered sound, as it is based on established building-blocks. The evaluation is ok, but more domains should be added for allowing to derive more general conclusions.	This is a borderline paper. The scores were initially below the bar. The novelty of the work is limited and there are strong claims in the paper that should be revised. The authors can also do a better job in positioning their work with respect to the existing results. However, the authors managed to address several questions/concerns of the reviewers and convince them to raise their scores. I would strongly recommend the authors to address the rest of the reviewers' comments, especially those related to strong claims and connection to related work, and further improve their work in preparing its final draft.
Below are multiple reviews of a paper. This work attacks the important problem of learning PDEs with neural networks. To this extent, it proposes a neural network architecture where the linearity is not applied in the Fourier space but in the state space. This allows the network to implicitly learn the partial differentials of the equation, and results in a parametrization whichThe authors proposed a novel neural Fourier operator that generalizes between different function discretization schemes. It achieves superior performance in terms of speed and accuracy compared to learned baselines.Fourier neural operator uses a convolution operator defined in Fourier space in place of the usual kernel integral operator. Each step of the neural operator amounts to applying a Fourier transform to a vector (or rather, a set of vectors on a mesh) and performing a linear transform on the transformed vector. Experiments demonstrate that theThe manuscript proposes a neural network for solving partial differential equations. This is performed by a supervised learning of a mapping between the PDE coefficients (a) and the solution (u) The motivation for replacing the kernel function (3) by a convolution operator is not entirely clear.	Pros: - Provides a practical technique which can dramatically speed up PDE solving -- this is an important and widely applicable contribution. - Paper is simultaneously clearly written and mathematically sophisticated. - The experimental results as impressive.  Cons: - There were concerns that the paper lacks novelty compared to Li et al 2020b, where the underlying theoretical framework was developed. The primary novelty would seem to be: - - using Fourier transforms as the specific neural operator - - the strength of the experimental results  Overall, I recommend acceptance. I believe the techniques in this paper will be practically useful for future research.
Below are multiple reviews of a paper. This paper presents a novel method to conduct multimodal contrastive learning for sentence encoders. The method is simple and generalizable, i.e. not only applied to vision but also to other modalities like audio.This work drives a plausible approach for enhancing unsupervised sentence embedding learning. Motivated by the previous success of Lu et al. [33], Transformer models can transfer knowledge by learning from another modality, e.g. vision or audio. The text part uses the same training paradigm as SimCSE, while an additionalThis work is an extension of existing contrastive sentence representation learning. Instead of only using text data, this work further bring the other modality to improve the model performance. The extra modality data share the same encoding backbone models and similar contrastive learning losses.This paper studies the non-linguistic supervision to contrastive-learning-based sentence embedding learning. The author proposes a Transformer-based multi-modal framework. Experiments on various semantic textual similarity tasks show the effectiveness of the proposed method.This paper presents a contrastive method for learning sentence embeddings that incorporates additional modalities using unaligned data. The method follows the SimCSE approach of clustering similar sentence representations and expands upon it by additionally clustering visual or audio input. Because the approach does not require aligned data between the text and additional modality, the	This paper improves contrastive learning of sentence embedding by using unpaired examples from the image or audio modality.  Reviewers liked the significance of this work due to its simplicity and general applicability, but some questioned the amount of improvement and advocated for the inclusion of low resource languages. The authors included Chinese, which is non-European but not low resource.
Below are multiple reviews of a paper. This paper proposes a NMF formulation where A and F are different types of information extracted from social datasets. In the honeybee example the authors highlight, A represents the spatial relationship between bees, and F encodes the age of the bees.The authors introduce a novel method for non-negative matrix factorization for timeseries. The model leverages consistency of individuals over time by forcing the factors to be linear combinations of a small set of temporal basis functions. The authors claim that this interpretable representation of individual bees is valuable for understanding social dynamics in the colony.The authors propose a factorization method for exploratory analysis in temporal graphs / social networks. Some of these ideas might be under the surface in time-shifted tensor decomposition models (linked below) I think the core idea is interesting, but I have mixed feelings about the method and some of the analyses.The authors present a matrix factorization model to jointly characterize the lifetime interactions of thousands of bees over generations. Although not directly addressed, the authors appear to be trying to solve a *tensor* factorization problem, not just the special case of a matrix.	The authors present a matrix factorization for the social behavior of honey bees in a hive. All the reviewers appreciated the interesting application.  However, substantial concerns were raised about the model motivation and the interpretation of the learned factors. To quote one reviewer, "Some of these bells and whistles may not even be needed, so simplifying the model and streamlining the text would go a long way for me." Another said, "The paper requires more principled motivation for the choices the authors made as well as cleaning up the notation."  The authors did address some of these concerns in discussion, but there are too many lingering concerns to recommend acceptance.  Given the unique application of this paper, the authors might also consider a journal that specializes in computational biology instead.
Below are multiple reviews of a paper. The paper is generally well written, only has a few minor problems with structure, and as far as I know adequately references prior work. The method shows consistently good results in comparison to supervised and other semi-supervised approaches.I found the core idea (2 decoders specialised to perform 2 different tasks) very interesting, and I overall like the paper. The paper is well written. I detailed the paper weaknesses point by point in the section below. I feel there are 3 major points that should be addressed. If authors solve them, I see noThe papers seek to leverage morphological methods to improve segmentation, which is a relatively unexplored field. The authors report significant improvements in the two benchmarks they tested their method. The paper is long (16 pages), many figures are small and have poor quality.	The paper proposes a semi-supervised segmentation technique which uses consistency regularization via different morphological feature perturbations to increase performance with unlabelled data.  It consists of an encoder and two-head decoders. One decoder learns positive attention to the foreground regions generating dilated features using atrous convolutions. The other decoder learns negative attention to the foreground on the same image thereby generating eroded features using skip connections. A consistency regularization is then applied on these paired predictions of an unlabeled image to improve performance. The method is evaluated on two different datasets, and the authors compared the proposed method with other methods from the literature, and reported superior results.   During the rebuttal phase the authors made significant efforts to revise their manuscript especially to improve clarity of their presentation and after rebuttal, all reviewers agreed for weak acceptance. I also agree with this decision and support publication of this paper.
Below are multiple reviews of a paper. This paper proposes a multimodal VAE model for the problem of generalized zero shot learning (GZSL) In GZSL, the test classes can contain examples from both seen as well as unseen classes. The proposed model is very similar to the existing ones. The experimental results are quite underwhelming.The paper proposes an approach to generalized zero-shot learning by learning a shared latent space between the images and associated class-level attributes. The authors propose ‘modality invariant variational autoencoders’ which allows one to perform shared manifold learning by training VAEs with both images and attributes as inputs.The paper considers the problem of (Generalized) Zero-Shot Learning. Most zero-shot learning methods embed images and text/attribute representations into a common space. The main difference here seems to be that Variational AutoEncoder (VAEs) are used to learn the mappings that take different sources as input.	The paper addresses generalized zero shot learning (test data contains examples from both seen as well as unseen classes) and proposes to learn a shared representation of images and attributes via multimodal variational autoencoders.  The reviewers and AC note the following potential weaknesses: (1) low technical contribution, i.e. the proposed multimodal VAE model is very similar to Vedantam et al (2017) as noted by R2, and to JMVAE model by Suzuki et al, 2016, as noted by R1. The authors clarified in their response that indeed VAE in Vedantam et al (2017) is similar, but it has been used for image synthesis and not classification/GZSL. (2) Empirical evaluations and setup are not convincing (R2) and not clear -- R3 has provided a very detailed review and a follow up discussion raising several important concerns such as (i) absence of a validation set to test generalization, (ii) the hyperparameters set up; (iii) not clear advantages of learning a joint model as opposed to unidirectional mappings (R1 also supports this claim). The authors partially addressed some of these concerns in their response, however more in-depth analysis and major revision is required to assess the benefits and feasibility of the proposed approach.
Below are multiple reviews of a paper. The authors in this paper address a challenging, and interesting problem in the current deep neural network literature. It is widely believed that neural networks essentially memorize, thereby overfit to training samples. This paper proposes a relatively clean and straightforward formulation to compute the training data points.This paper proposes a new method for reconstructing parts of the training data from a given trained homogeneous binary classification network. It relies on a theoretical result by Lyu and Li as well as Ji and Telgarsky. The resulting approach is tested in various contexts for a 2d toy example and a binary MNIST image classification.This paper gives a principled and novel scheme for reconstructing training set image only use parameters of a network. The approach is elegant and principled and the results are convincing. One thing I am wondering about is other more complicated network architectures.The paper deals with an interesting problem. Reconstructing training data from weights. Mostly, it has been attempted to reconstruct data based on logit outputs. The paper has far reaching impact on privacy.	This paper proposed a new algorithm to reconstruct a subset of training examples from a trained homogeneous binary classification neural network. Although there are still some limitations such as the zero training loss and homogeneity assumption, as well as limited experiments beyond MLPs, the reviewers also acknowledge that this results is very interesting and reveals an important property of deep neural networks that could potentially have far-reaching implications for privacy and security.
Below are multiple reviews of a paper. Proposed point spatio-temporal (PST) convolution operates on "point tubes" It decouples space and time through a shared spatial convolution at each timestep, followed by a temporal convolution. The proposed method is technically novel and principled.This paper aims to process the point cloud data in a convolution manner. Authors propose the PST convolution and deconvolution operations to handle the different tasks such as the classification and segmentation on point cloud.The paper introduces point spatio-temporal convolutions, which are used for the feature extraction of point cloud sequences. A trainable kernel is used which is applied locally as a continuous convolution. The authors claim that in this way the network will achieve a better understanding of the dynamics of the input.	The paper presents a construction for deep learning on point clouds that evolve over time. The key characteristics of the data are irregular sampling in the spatial domain and regular sampling in the temporal domain. The presented construction addresses both these aspects of the data. The review by R3 was negative but was addressed by the authors and R3 did not participate in the discussion. The AC supports acceptance.
Below are multiple reviews of a paper. This paper builds upon the observation by Nakkiran and Bansal, 2020 and proposes a theoretical framework to study conditional samplers. The authors formally define concepts of conditional sampling from a learning perspective.The paper establishes the theoretical framework for studying samplers that are defined as a learning algorithm creating models whose aggregated prediction distribution is close to the Bayes optimal via repeated training with independent samples. The paper additionally provides theoretical guarantees for the sampler and the teachers.This paper supplements the empirical results of Nakkiran and Bansal by providing a theoretical framework for analyzing the conditional sampling behavior of overparameterized networks. The authors show that obtaining a noisy sampler can be more sample efficient than a good classifier.The paper offers a theoretical framework for studying learning with label noise. It shows how to leverage multiple teachers to approximate the Bayes optimal classifier. Labeling a large external set requires a larger unlabeled  data set from the same domain.	The paper develops a theoretical framework (in the context of learning theory) for training overparameterized networks with label noise, and shows that, in the context of ensemble distillation, teacher networks need not be good classifiers as long as they are good conditional samplers (in the sense defined in the paper).  This is a primarily theoretical paper, with limited empirical results. All reviewers are positive about the paper: one reviewer recommends acceptance (7), the other three recommend weak acceptance (6). The reviewers are positive about the theoretical aspects of the paper, describing them as interesting and technically sound, but are less convinced about the practicality of the theory or the significance of the empirical results.  Given that the theoretical contribution of the paper seems significant and no concerns have been raised about the soundness of the theoretical arguments, I'm happy to recommend acceptance.
Below are multiple reviews of a paper. The main contribution of the paper is the proposal of the generalized softmax function, to model the joint distribution of all modalities and the label. This joint distribution leads to computationally efficient conditional distributions. There are a few concerns about the approaches and the evaluations in this paper.This submission proposed a maximum likelihood estimation framework combined with a generalized softmax function to resolve multimodal emotion recognition with missing modality. The end-to-end nature of this framework makes it more efficient than previous works.It is also important to mention that the proposed method was tested only to show how a person could have been able to make a difference in the outcome of the game. This is not the first time that a player has made a huge impact on the game, but it is the first of many times. It is also the first	Three experts reviewed this paper and all recommended rejection. The rebuttal did not change the reviewers' recommendations. The reviewers was not excited by the proposed probabilistic framework and raised many concerns regarding the comparison with baselines and competing methods, limited size of datasets, and limited scope of one dataset for one task. Considering the reviewers' concerns, we regret that the paper cannot be recommended for acceptance at this time.  The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere.
Below are multiple reviews of a paper. This paper addresses the problem of obtaining more compact CNNs by a parameter sharing method. Experiments are performed on CIFAR and ImageNet datasets, using some popular CNN structures for evaluation.This method proposes to decompose convolutional filters using a low rank filter basis. This is developped to save computational costs whilst maintaining performance. The authors compared their method against ResNet, MobileNet and DenseNet.The authors proposed a parameter-sharing method among repetitive convolution layers. The experimental results show some improvement about the number of parameters and FLOPs. The authors also claimed that orthogonality regularization can reduce the potential vanishing/exploding gradients problem.The method reduces 10.01M parameters of ResNet-34 with almost the same error rate. The method is more effective for DNN architectures without using separable convolution. A classic problem, exploding/vanishing gradients, is alleviated by keeping a variable W_basis close to orthogonal.	I agree with the concerns raised by the reviewers. In particular, the issues of novelty and experimental evaluation (mentioned in the revision summary) remain the major weak points of the paper. My impression is that the changes made in the revision represent a significant experimental addition to the paper, one which might merit a full pass through peer review, and one which in any event did not alter the reviewers' scores. While I think this paper has something to contribute (and the empirical results suggest the method may outperform competitors), I think it would be improved by a rewrite (and possibly a restructure) that makes the part that is your contribution much more clear. For example, in the abstract, it's only in the sentence "We show both theoretically and empirically that potential vanishing/exploding gradients problems can be mitigated by enforcing orthogonality to the shared filter bases" that we actually get to the part that is really novel about this contribution (the "enforcing orthogonality"): that would ideally be much earlier in the abstract.
Below are multiple reviews of a paper. This paper studies the problem of classification-based online imitation learning. It shows a negative result that any proper learning fails to achieve sublinear regret. The paper proposes a clear convex combination to construct mixed policy class.The authors provide (1) an impossibility result for obtaining sublinear regret in general online learning settings, and (2) present an online linear optimization algorithm. The use of "separator sets" by the authors seemingly opens up a couple fun algorithmic questions that can take advantage of existing research.This paper studies the fundamental problems of classification-based online imitation learning. A framework called COIL is developed, and several contributions are achieved. I believe such results could help us better apply imitation learning algorithms in practice.This paper investigates the fundamental feasibility and statistical limits of designing oracle-efficient regret minimization algorithms. The paper shows that any proper algorithm is unlikely to achieve a sublinear regret. Inspired by this observation, the paper propose an improper online learning framework.	This paper studied imitation learning in the classification setting. The paper shows that using proper online learning algorithms is not sufficient to obtain sublinear regret, and devises an improper learning framework that relies on online linear optimization resulting in provably efficient algorithms.   All the reviewers appreciated the theoretical novelty and are unanimous in their decision to accept the paper. Please incorporate the reviewers' feedback and the resulting discussion. Adding in some basic experimental results (outlined in the "Experimental plan" comment) would strengthen the paper.
Below are multiple reviews of a paper. This paper proposes a 3D molecular generative model DESERT for structure-based drug design in a zero-shot manner. The method involves two stages: first sketching the molecular shape in the protein pocket, then generating molecules based on the shape.This paper proposes a zero-shot drug design method based on sketch. Using only information about the shape of the protein pocket avoids some of the limitations of the data set and binding simulations. The paper is not clear enough in the method description, only the design of the encoding and decoding method and the model used are given.This paper presents a new framework and pre-training scheme for designing pocket-conditioned ligands. The model were trained over billions of molecules in ZINC database and achieved state-of-the-art results. Many details are missing, especially how the post-processing is done.	The paper makes a novel contribution to methods for generating novel molecules from scratch. The core idea is to generate a shape that fits the molecular pocket without looking at the protein structure.  Two out of three reviewers recommended acceptance. Reviewers emphasize that the method is innovative and interesting, and the empirical performance appealing (especially given that only the shape information is provided to the model). Strong performance is enabled by good design choices made across the paper, such as including the pretraining stage.  The reviewer that recommend rejection raised issues related to the novelty and clarity of the paper. However, I believe the paper is sufficiently clear and novel to meet the bar for acceptance.  Overall, it is my pleasure to recommend acceptance of the paper.
Below are multiple reviews of a paper. The problem of collaborative decision-making is relevant to the multiagent planning community at NeurIPS. The experiments and empirical results were also extensive and used reasonable benchmark problems and baselines. The limitations of the approach are adequately described. I strongly encourage you to continue this work.The paper looks at the problem of designing a framework to support collaboration between an autonomous system and a human supervisor. The human is assumed to be a potentially suboptimal agent with full observability, while the agent is expected to operate under partial observability. The method proposes to use the action suggestions, by using the human policy as partThis paper presents a model and experiments to demonstrate the usefulness of (possibly intermittent and/or incorrect) human action suggestions on a POMDP-based system. Simulated experiments on a discrete state problem with an offline generated policy show some improvement using suggestions from a human with an omniscient view.	The paper considers a collaborative decision-making setting in which one agent can suggest actions for a listening agent to execute. The listening agent is not bound to take these suggested actions. The paper models the listening agent's decision-making process as a POMDP, treating the suggestions provided by other agents as observations (i.e., dependent only on the state) that are used to update the belief state. The paper describes two representations of the suggested actions and presents empirical results on simulated domains that demonstrate that the listening agent's performance improves when following the suggestions of a perfect oracle, while it degrades given imperfect suggestions in proportion to the level of noise.  The paper was reviewed by three researchers who read the author response and discussed the paper together with the AC. The reviewers largely agree that the collaborative decision-making problem as formulated is interesting. The reviewers find that the idea of formulating suggestion-following as a POMDP with suggestions modeled as observations is clever, and that the description of the proposed formulation is clear and easy to follow. The two formulations of the observation function are reasonable, albeit very simple initial models, though the paper does not provide much insight into when one should be used over the other. A primary concern with the paper is that it only provides empirical results. The work would have significantly benefited from theoretical results, which would help to understand how the method would generalize to other domains.
Below are multiple reviews of a paper. This paper investigates how the choices that can be made to leverage the FP8 format. The choice of the number of exponent bits is driven by the severity of outliers in the network. A sensitivity study on quantization-aware training is also carried out.The paper is overall well written and easy to follow. The discussions on the effect of using different #bits for the mantissa and exponent to the quantization error are also intuitive. Some parts of the method and experiment sections need some more clarifications.The paper provides a rigourous approach to proving that FP8 outperforms INT8 in inference. 5M2E is found to minimize MSE of normal distributions, and thus is of particular interest. The results of the analysis and simulation are in close agreement.FP8 format quantization algorithm is realized based on a common FP32 deep learning framework. Experiment results show that FP8 format is better than INT8 format. The major weakness of this work is the lack of novelty and insufficient comparison with baselines.	This paper had mixed reviews.   One very positive expert reviewer (8) pointed out this paper used a rigorous approach to showing than FP8 can outperform INT8 in inference, which I agree is very interesting and useful.   Another reviewer gave borderline acceptance (5), and I did not find any remaining concerns following the authors' response.  One reviewer gave borderline reject (4), but I did not find any remaining coherent major concerns following the authors' rebuttal. Also, this reviewer seemed less experienced, so I down-weighted this reviewer's score.   Another reviewer gave borderline reject (4) with the following remaining concerns:  (1) "I think this scheme does not show advantages over the existing work. " But I don't think this is true, since as far as I know previous work did not show such an advantage of FP over INT.  (2) "The practical application of the algorithm in this paper will bring extra overhead. " I agree the authors should give more details here (especially for flexible), but at least for the flex bias method, the extra overhead seems quite reasonable (as this is similar to the standard method used for INT), so I'm not sure what is the issue.    (3) "it is a very intuitive view that we should adopt a format with more exponent bits on the data with a large distribution range".  But the authors' response correctly said this is not true (as a uniform distribution would be better represented using INT, no matter what it's range), and is not what they are saying.   Therefore, I think the reviewer had some errors in understanding here, and so I down-weighted this reviewer's score.  Also, the following paper seems relevant: A Block Minifloat Representation for Training Deep Neural Networks, ICLR 2022
Below are multiple reviews of a paper. The paper under review is a very technical contribution to the study of group-equivariance of convolution kernels. The application section is in particular way too sketchy to convince the novice that this impressive work will be useful to the machine learning community.The paper considers Group Equivariant Convulation Neural Networks (GCNNs) which are convolutional neural networks that are equivariant wrt group symmetries of the underlying space. The equivariance requirement places constraints on the parameterization of the corresponding CNN. The results obtained here are significant for any learning problem where thereSteerable CNNs are similar to CNNs but replace channels with G-reps and enforce an equivariance constraint on the kernels. The problem of finding a basis for the space of steerable kernels is non-trivial and critical for constructing G-steerableCNNs. This paper is a significant contribution toThe paper explains how to use well known techniques from physics in constructing convolutional neural networks with a group symmetry. The results were correct, but the paper reads like a compilation of material from the many math and physics textbooks on the topic.	Reviewers generally agree that the main result of the paper, which generalizes the classical Wigner-Eckart Theorem and provides a  basis for the space of G-steerable kernels for any compact group G, is a significant result. There are also several concerns that need to be addressed. R4 notes that the use of the Dirac delta function (e.g. Theorem C.7) is informal and mathematically imprecise and needs to be fixed. R1 notes that it would be helpful to at least describe how this general formulation can be applied in machine learning.  Presentation and accessibility: the current version of the paper will be accessible to only  a small part of the machine learning audience, i.e. those already with advanced knowledge in mathematics and/or theoretical physics, in particular in representation theory. If the authors aim to make it more accessible, the writing would need to be substantially improved.
Below are multiple reviews of a paper. The paper studies the random covariance matrix of infinite depth and width limit of initialized deep neural networks. Using recent work on deep kernel shaping, the authors show that shaping activation function leads to non-trivial stochastic differential equations.Infinite-depth-and-width limits for the covariances of activation layers are derived for neural networks with ReLU-like and smooth activation functions at initialization. The behaviour of these approximations seem to mimic those of finite NNs. The theoretical analysis is extensive, and the presentation is (mostly) excellent.The authors claim that the modeling of covariance and depth has a significant improvement over the NNGP regime. The evidence is not strong enough to justify the necessity of “reshaping” in NN literature.This paper is theoretical and studies the behavior of neural networks in the shaped infinite depth/width limit. The distribution of the covariance matrix closely follows the distribution predicted using the SDE theory developed here. The paper provides a creative theoretical contribution.	There is a clear consensus to accept this manuscript.  The results are impressive, and have a nice theoretical orientation that will allow the results to have continued impact as the field advances.  There are some minor errors by the authors in the discussions, which are worth the authors being aware of before submitting their final version.  In particular, they state that:  "The authors of [2,3] considered a bounded activation function in the infinite-width limit with large depth, in which case their variance  V ℓ α α  always converged to a finite fixed point when depth is large [2, eq. 3]. Their chaotic and ordered phases are then defined by the behaviour of the correlation fixed point [2, eq. 5], which in turn determines the behaviour of the gradient [2, eq. 16].  In our case, shaping the activation leads to an unbounded function, and consequently the variance  V ℓ α α  is not always bounded - even if we take the same limit as [2] (but shaping depends on depth instead like the DKS/TAT papers), in which case we get an ODE with finite time explosion. Intuitively, if we drop the Brownian motion from eq. 18 and consider  d X t = b X t ( X t − 1 ) , d t , ,  which is the logistic ODE, and has a finite time explosion if  X 0 > 1  and  b > 0 . At the same time, due to shaping, our correlation  ρ t α β  will actually be able to avoid the fixed point (i.e., non-degenerate). So the gradient will be well behaved from the perspective of correlations (we are in the critical regime defined by [2]), but it may still explode due to variances exploding.  References Novak, R., Xiao, L., Lee, J., Bahri, Y., Yang, G., Hron, J., Abolafia, D.A., Pennington, J. and Sohl-Dickstein, J., 2018. Bayesian deep convolutional networks with many channels are gaussian processes. arXiv preprint arXiv:1810.05148. https://arxiv.org/pdf/1810.05148.pdf Schoenholz, S.S., Gilmer, J., Ganguli, S. and Sohl-Dickstein, J., 2016. Deep information propagation. arXiv preprint arXiv:1611.01232. https://arxiv.org/pdf/1611.01232.pdf Yang, G. and Schoenholz, S., 2017. Mean field residual networks: On the edge of chaos. Advances in neural information processing systems, 30. https://arxiv.org/pdf/1712.08969.pdf "  And while [2] states they consider bounded activations, it is not used or necessary and is not used in [3] or subsequent more recent work that discusses the edge of chaos further; see for instance: Activation function design for deep networks: linearity and effective initialisation by Murray et al. and On the impact of the activation function on deep neural networks training by Hayou et al.
Below are multiple reviews of a paper. The proposed modulator is easy to implement and applicable to (almost) all network architectures. It is unclear whether the modulator weights are shared along the depth of a CNN layer, i.e. between feature maps.The idea is to multiply the output of the linear combination by a "modulator", prior to feeding it into the activation function. The idea is demonstrated on basic vision and NLP tasks, showing improvements over the baselines. But the writing needs to be reworked, the experiments to be consolidated, and the link to neuronal modulation toThis submission proposes a modification of neural network architectures that allows the modulation of activation functions of a given layer as a function of the activations in the previous layer. The author provide different version of their approach adapted to CNN, DenseNets and LSTM.This paper proposes a scalar modulator adding to hidden nodes before an activation function. The authors claim that it controls the sensitivity of the hidden nodes by changing the slope of activationfunction. The experiments the authors showed were with only 2 layer CNNs and 1 layer LSTM.The paper introduces a new twist to the activation of a particular neuron. They use a modulator which looks at the input and performs a matrix multiplication to produce a vector. That vector is then used to scale the original input before passing it through an activation function.	The paper adds a new level of complexity to neural networks, by modulating activation functions of a layer as a function of the previous layer activations.  The method is evaluated on relatively simple vision and language tasks.  The idea is nice, but seems to be a special case of previously published work; and the results are not convincing.  Four of five reviewers agree that the work would benefit from: improving comparisons with existing approaches, but also improving its theoretical framework, in light of competing approaches.
Below are multiple reviews of a paper. The benchmarks are surrogate-based, provided using the ONNX format, and have low memory requirements. As far as I can see the results are technically sound, but I was not able to run the experiments myself for further analysis. In general, the paper is clear and well written. However, something went wrong with the references whichThe paper proposes YAHPO-Gym, a surrogate-based benchmark for (multi-objective) multi-fidelity hyperparameter optimization problems. The diversity of the instances for each benchmark collection is not studied. The paper seems to be a not complete with several missing references.This paper proposes a benchmark tool for hyper-parameter Bayesian optimization. It is based on using a surrogate model to predict the unknown target function. This model is a neural network that has been trained with a large number of instances of the original problem.This paper presents the YAHPO gym system as a benchmarking tool for multi-objective and multi-fidelity hyperparameter optimization. This benchmark makes use of surrogate functions instead of real evaluations or tabular benchmarks. The results indicate that the surrogate function based benchmarks are more faithful to the real evaluation based benchmarks compared to theYAHPO_GYM is clearly presented with every small detail is nicely covered. The reproducibility list is filled out fully, the answers are clearly justified. Installation is a slightly challenging task as it requires cloning the second GitHub repo.YAHPO Gym is a surrogate-based benchmark for hyperparameter optimization. It allows us to use multi-objective and multi-fidelity settings. It has a big potential impact on the field of AutoML.	This work proposed a new HPO surrogate benchmark for 14 scenarios and filled the gap of benchmarks in the multi-objective and multi-fidelity setting. The paper is clearly written and conducted experiments to demonstrate its usefulness. It also provided analysis on several interesting questions such as tabular vs surrogate; multi-fidelity vs full-fidelity. It is open sourced and being integrated into a larger benchmarking framework (HPOBench). I think it will make a good contribution to the HPO community.
Below are multiple reviews of a paper. The authors present a stochastic algorithm for selecting a subset of a large dataset. The algorithm is a two-step process, first selecting a set of "candidates" based on individual features, then filtering to a final subset which may account for interactions between candidate items.This paper proposes a stochastic subset selection method for reducing the storage / transmission cost of datasets. The proposed method seems to be more general than competing methods, such as coreset.The paper includes a broad set of experiments, but I have some questions and concerns regarding the baselines and the proposed SSS method. Using the Concrete distribution enables differentiability, but Algorithm 1 seems to implement the candidate selection and AutoRegressive Subset selection steps in ways that eliminate differentiability. Some aspects of SSS seemStochastic subset selection (SSS) is a method to learn to compress a set $D$ by selecting a subset $D_s$ such that the loss of a task is as close as possible to the loss if the task had been performed on the original $D$. The paper show how this general method can be applied	The paper proposed a two-stage method to select instances from a set, involving candidate selection (learning a function  to determine a Bernoulli probability for each input) and AutoRegressive subset selection (learning a function  to generate probabilities for sampling elements from a reduced set); both stages use the Concrete distribution to ensure differentiability. The experiments show the performance of the proposed method on several use-cases, including reconstruction of an image from a subset of its pixels, selecting sparse features for a classification task, and dataset distillation for few-shot classification. I read the paper and I agree with the reviewers that in its current format the paper is hard to follow. I strongly encourage the authors to add more discussion and intuition on the proposed method and extend the experiments with more baseline comparison and ablation studies in the revised version.
Below are multiple reviews of a paper. In this paper, the authors propose a method to close the generalization gap that arises in training DNNs with large batch. The author reasons about the effectiveness in SGD small batch training by looking at the curvature structure of the noise. The proposed method is shown empirically to achieve both comparable generalization and the training speedupThis paper proposes the method which improves the generalization performance of large-batch SGD by adding the diagonal Fisher matrix noise. It is shown that gradient descent with the diagonal noise is faster than it with the full-matrix noise on positive-quadratic problems.It has previously been observed that training deep networks using large batch-sizes leads to a larger generalization gap compared to the gap when training with a relatively small batch-size. This paper proposes to add noise sampled from diagonal "empirical" Fisher matrix to the large batch gradient as a method for closing the generalized gap.	Dear authors,  Your proposition of adding a noise scaling with the diagonal of the gradient covariance to the updates as a middle-ground between the identity and the full covariance is interesting and tackles the timely question of the links between optimization and generalization.  However, the reviewers had concerns about the experiments that did not reveal to which extent each trick had an influence. I would like to add that, even though the term Fisher is used for both the true Fisher and tne empirical one, these two matrices encore very different kind of information. In particular, the latter is only defined when there is a dataset. Hence, your case study  (section 3.2) which uses the true Fisher does not apply to the empirical Fisher.  I encourage the authors to pursue in this direction but to update the experimental section in order to highlight the impact of each technique used.
Below are multiple reviews of a paper. The problem studied is interesting and important for the privacy community. Excess risk upper bound is probably quite loose, so improving that may not necessarily improve actual excess risk. log(N) improvement may be an artifact of the analysis, and not an inherent advantage of dynamic schedules.The paper investigates the idea that a dynamic privacy schedule of decreasing noise can help private gradient descent. The main contribution is a theoretical analysis of aDynamic privacy schedule.The paper studies private gradient descent when the noise added to each of the iteration is dynamically scheduled. The paper considers Polyak-Lojasiewicz's condition, a more general form than strongly convex loss function. I find some of the comparison misleading.Private gradient descent has been shown in the literature to leak private information. Given a fixed privacy budget R, private gradient descent adds noise to the gradients at each round. Experimental results show that dynamic privacy schedules lead to enhanced accuracy.	This work proposes algorithms for solving ERM with continuous losses satisfying the PL condition. The first algorithm achieves that by using a chainging noise variance and thus the paper frames the contribution in terms of the advantages of non-constant noise rate.  The problem is a well-studied one and the result is a nice if relatively modest improvement over Wang et al. However, as pointed out in reviews, in the context of convex optimization the same rate has already been established (Feldman,Koren,Talwar STOC 2020). This work is cited and briefly discussed but the discussion only includes one of the algorithms in the paper (that does have an additional log N factor). The overall assumptions in this paper are not comparable (weaker in some ways and stronger since they only require PL instead of strong convexity) but still the overall the contribution appears to be incremental.
Below are multiple reviews of a paper. This paper tackles the problem of generalizing to out-of-distribution human behavior when using sim2real methods to develop assistive robotics capabilities. The authors propose the Prediction-based Assistive Latent eMbedding (PALM) framework.This paper addresses the problem of sim2real in the context of assistive tasks. If the diversity of behaviors is not properly captured, trained agents may encounter out-of-distribution policies at test time. The authors offer empirical evidence to support that the latent representation may be interpreted and leveraged using human policies.The paper focuses on learning latent representations for generalization in assistive tasks such as reaching and itch-scratching. The assumptions need to be very clearly specified in the paper and the claims should be carefully considered and re-worded.The PALM framework learns an encoder that maps a history onto a latent code. Experiments show that PALM policies lead to good performance on test human policies on an assistive reacher and assistive itch scratching task.	This paper considers the task of training policies for human-robot collaborative tasks and observes the need for out of distribution generalisation for human policies as a pre-requisite for training. The authors present an approach for learning a latent representation for human policies that may be adapted online.   Reviewers consider the motivation compelling and highly relevant for assistive robotics applications. In particular, reviewers consider the idea of learning a latent space for human policies as elegant. Further, thorough comparisons with related efforts strengthen the paper’s arguments.   The primary weakness of the paper is that the tasks used to evaluate the approach are relatively simple (reaching and itch scratching). This raises the question of whether and to what extent the method can scale to more realistic tasks. Any experiments to suggest that the approach can bridge the sim2real gap have been suggested since the current results are purely in simulation. A better technical exposition of the test time adaptation has also been suggested.   During the rebuttal phase,  the authors provided additional clarification/results for key reviewer questions such as mechanism for generalisation, overfitting, choice/training of encoders and their inclusion strengthens the overall paper. The major quantitative evaluation is on moderately complex tasks (e.g., itch scratching) supplemented by a user study. The user study is conducted in lab scenario (not with real users) and the setup bears resemblance to human studies in other human-collaborative domains (such as driving, collaborative assembly etc.).   Overall, the paper contributes an approach for learning latent representations from interaction data that can be adapted online based on distribution shifts observed online. The manuscript can be strengthened by a clearer exposition on the mechanism/nature of generalisation attained, mechanisms for preventing overfitting and and an analysis of potential scalability to complex scenarios. Further, since the learning problem is scoped towards the specific domain of assistive tasks (as opposed to general robot tasks), a clearer setup of the problem context and a statement on the scalability of the results to end-users may also be considered by the authors.
Below are multiple reviews of a paper. This paper gives a high probability excess population risk bound for differentially private optimization algorithm under $G$-Lipschitz, $L$-smooth and PL condition with gradient perturbation. The algorithm is empirically evaluated on a number of datasets and achieved noteworthy results.The paper achieves high probability excess risk bound with rate O(1/n) w.r.t n for DP models via uniform stability by using Generalized Bernstein condition under G-Lipschitz, L-smooth, and PL condition. The authors also show the experimental better accuracy results of m-NGP compared toThis paper analyzes the utility bounds of the gradient-perturbation based DP algorithm. The results are sharper than previous analyses in different settings. Experiments on real datasets are performed to evalute their proposed algorithm m-NGP.This paper extends the results in Klochkov & Zhivotovskiy 2021 to the DP case. It proves the first $O(1/n)$ high probability excess population risk bound for differentially private algorithms. The paper is well-written and easy-to-follow.	The paper gives high probability bounds on excess risk for differentially private learning algorithms, in the setting where the loss is assumed to be Lipschitz, smooth, and assumed to satisfy the Polyak-Łojasiewicz (PL) condition. The key idea in the paper is to leverage the curvature in the loss (PL condition) and the generalized Bernstein condition.   Authors show that they get sharper bounds of the order \sqrt{p}/(n\epsilon) when the loss is assumed to satisfy the PL condition besides being convex Lipschitz/smooth. Without using some curvature information about the loss function, the best upper bounds we can get are in the order of \sqrt{p}/(n\epsilon) + 1/\sqrt{n} — and this is tight at least in terms of the dependence on n given the nearly matching lower bounds — in fact, the dependence on n is tight as it matches the non-private settings.    So, I find it a bit misleading when authors say that they improve over the existing results. That statement is not true in its generality — it is true that we can leverage the PL condition to give faster rates but that is not the setting of prior work. Again, the bounds that authors compare against are for smooth/Lipschitz convex loss functions and without any assumption on the curvature of the loss.   If we do look at the literature for when and/or how can curvature help, we can compare against the existing bounds for strongly convex losses. The best-known result in the setting that is most closely related is that of Feldman et al. (STOC 2020): https://dl.acm.org/doi/pdf/10.1145/3357713.3384335. As we can check from Theorem 4.9 in that paper, the bounds we get are in the order of 1/n + d/n^2 which is actually better — not surprising since PL condition is a weaker condition. There is merit to the results in this paper but the current narrative is quite misleading and a more careful comparison with the existing literature is needed. The bounds are hard to parse — for example, what is the dependence on the strong convexity parameter (\mu)? It would also help to instantiate specific loss functions so that we can fix some of the parameters in the bound to have a clear comparison with the existing bounds.
Below are multiple reviews of a paper. The paper introduces novel results on the optimization and generalization of three-layer networks, optimized with a variant of gradient-descent. The goal of the analysis introduced in the paper is to obtain bounds that improve over the bounds obtained using the NTK framework.This paper makes contributions into two main category: Algorithmically, it propose a projected SGD algorithm that can, in polynomial number of iteration, reaches a solution that generalizes. In terms of generalization, it proposes a new generalization bound with data-dependent complexity measure that goes beyond NTK regime. Another generalizationTheoretical paper presents a theoretical analysis of a 3 layer neural network with ReLU activations. The paper present quite an interesting analysis and packs a lot of material in 9 page of main text and 101 pages of Appendix material. While it is generally well written, it is not very accessible for a casual ICLR reader with noThis paper studies the optimization and generalization of a three-layer neural network trained by a projected SGD algorithm. In this setting, the network runs beyond the NTK regime. It can achieve feature learning, and better generalization performance than NTK.	This paper goes beyond the NTK setting in analyzing optimization and generalization in ReLU networks. It nicely generalizes NTK by showing that generalization depends on a family of kernels rather than the single NTK. The reviewers appreciated the results. One thing that is missing is a clear separation between NTK results and the ones proposed here. Although it is ok to defer this to future work, a discussion of this point in the paper would be helpful.
Below are multiple reviews of a paper. MIL with defined costs seem to perform better than the state of the art. Any unsupervised algorithm to re-organize data (roughly) and put it into the training will improve the results.This method presents an end-to-end solution to whole-slide image classification. It is a relevant context in computational pathology research, where manual annotations are often scarce and time-consuming. The authors should clearly show the difference between their method and the CLAM method.The paper is clearly written and reads quickly, which is appreciated. The experiments are comprehensive, with some ablation studies included. A nice review of an expert on the clinical meaning of the regions to which the method attends is provided also in the appendix.The method is new, interesting, and well described. The achieved results are good and significant for the research community. The main weakness of the paper is the lack of details about the processing time.	The paper proposes a framework for classification of whole slides images, where the DNN essentially relies on patch processing (as is the norm). The paper proposes an aggregation module that relies on a DNN to perform a weighted average of the patch representations (Section 3.2). The paper claims end-to-end learning, but this involves a sampling step that hasn't been shown to be suitable for the purpose.
Below are multiple reviews of a paper. MABSplit estimates the best split by drawing n' < n independent examples. It takes O(n log(n) time for a fixed feature, where n is number of training instances.A splitting criterion for fitting decision trees is proposed based on multi-armed bandits as to improve training efficiency. To this end tuples of features and thresholds are each considered an arm and pulled for an instance.The algorithm considers the selection of decision stumps using bandit algorithms. Empirical evaluation on the MNIST dataset show that the proposed selection technique results in much faster tree algorithms. The theoretical guarantees seem fairly straightforward.The paper "MABSplit: Faster Forest Training Using Multi-Armed Bandits" proposes to estimate the performance of the splits during DT induction instead of evaluating them exactly. The paper has a solid theoretical background and a novel algorithmic contribution, but lacks a thorough experimental evaluation.	The reviewers agree that from a decision tree induction point of view, this paper provides a solid methodological approach in contrast to prior heuristics-based approaches. They found the author feedback satisfying, specifically, the additional experiments showcase that the proposed method generalizes most likely beyond development datasets.  We ask the authors that in the final version, please make a pass over the paper to incorporate the author-reviewer discussions.
Below are multiple reviews of a paper. This paper proposed a new method for blind image denoising using a "GAN2GAN" network. Different from previous work noise2noise, the proposed method only needs single noisy images to train the network. The results showed significant improvements over its competitor noise2void.This paper addresses a challenging task of blind image denoising where a single noisy image is provided with assumption that it is zero mean, additive and independent from the original image content. The experiments were done with extensive datasets and baselines.The motivation of using the proposed network design is not clear. Using more generators will lead to larger capacity models than existing methods. The proposed results still contain significant noise residual as shown in Figure 4.This paper proposes a framework to train a network to remove noises, which are zero-mean, additive and independent of the clean image. They mathematically prove that a network, which is trained from pairs of images generated by adding simulated noises into the noisy image, can remove noises.	Summary of discussion: Three reviewers rated the paper Good (7) while Reviewer2 disagreed. R2's criticism was focussed on how this work is placed within existing/related literature, and no technical problem was identified. The authors have addressed some of R2's comments/concerns, R2 has not participated in the discussion.  Novelty and contributions: Overall the reviews seem consistent with an incremental paper which is technically valid, improves the state of the art on a reasonably difficult task. However, it does not appear from the reviews that the paper substantially advances our understanding of machine learning more broadly beyond this specific application.  Experiments: There is some disagreement among reviewers on the adequacy of the experiments, with at least two reviewers calling for experiments involving 'natural photos'. I believe the author's responses adequately address these concerns: they pointed out that the key selling point of their paper is the ability to model structured noise which is less relevant in natural photos.  On the balance of things, I think this paper should be accepted, but I wouldn't argue if it did not make the cut due to its narrow scope. For this reason, I recommended poster presentation.
Below are multiple reviews of a paper. This paper proposes a customisation strategy named "Split-Max" for federated learning. Split-Max can adjust the model size according to the devices' budget while maintaining good accuracy and robustness.Split-Mix is a Federated Learning strategy aimed at easing the problems that arise when a heterogeneous pool of devices/clients collaboratively train a global model. Split-Mix trains a model that can later on be customized in terms of model size and robustness. All base models are trained on all clients (should these meet theThe proposed approach can train both accurate and robust models in a joint fashion, where all but batch-norm layers are shared for efficiency. It's not perfectly clear how the split and aggregation are done in the proposed approach. The assumption about the computational resources of clients would be better clarified.The paper proposes a new federated learning scheme that is suitable for devices with heterogeneous resources. The proposal, namely Split-Mix, trains multiple models of different sizes and adversarial robustness levels, tailored to the budget of each device.	This paper proposes a federated learning (FL) scheme that is suitable for clients/devices with heterogeneous resources. The scheme Split-Mix trains multiple models of different sizes and adversarial-robustness levels, which are tailored to the budgets of the individual device. Empirical results show encouraging results.  It is clear that FL will have to work with clients with diverse resources, a point that is appreciated. Indeed, it is anticipated that widely-dispersed inference will have to deal with a highly-heterogeneous mix of clients. The study is quite thorough. One aspect that is not convincing in the experiments is the budgets being exponentially distributed: having a strong concentration around a mean (with something like a Gaussian tail), or a power-law distribution, would be more suitable.
Below are multiple reviews of a paper. This work revisits a famous counterexample on the convergence of Adam. The paper is well written and the logic of it is convincing. This work truly does merge the gap between theory and practice in non-convex stochastic optimization.The paper starts off from the recent realization that there exists divergent examples for any set of hyperparameters for algorithms in the Adam family. It sets out to study the effect of the beta2 parameter on convergence for a fixed specific problem. The paper is well-written, clear and easy to read.The paper studies one of the most popular algorithms in machine learning: RMSprop. By proving the convergence without using "bounded gradient" assumption, the authors establish a transition from divergence to non-divergence for RMSProp.	The paper shows convergence results for RMSprop in certain regimes. The reviews are uniformly positive about this paper and I recommend acceptance.
Below are multiple reviews of a paper. The paper discusses a method for generating long videos in which new content is introduced as the camera moves forwards. It has been shown that training at high res both in space and time is prohibitively expensive.The paper addresses the problem of video generation with a focus on longer time horizon videos which require consistency. The key observation is that the main components for temporal consistency are preserved at lower spatial resolution. The authors propose using a hierarchical architecture to first create long low-resolution video, followed by sliding windows to create higher resolution videos at shorter time-The paper presents a video generation model that is capable of producing new content (e.g., new object or scenery), object motion, and changes in camera viewpoint over time. The proposed model outperforms prior methods especially qualitatively on aspects including generating plausible dynamics and object persistence.The authors provide some analysis of the color dynamics of the real dataset and the generated videos using different methods. The main strategy proposed by the author is to increase the real video lengths seen by the discriminator by reducing the resolution.	All four reviewers enjoyed this paper and were particularly impressed by the videos provided in the supplementary material. The results are very impressive indeed. The reviewers also agreed that using a multi stage approach was interesting and effective. The two new datasets were deemed useful to the generation community and the proposed metrics and human evaluations were appreciated by the reviewers. A few smaller concerns included a missing failure analysis and some clarifications questions which were addressed in the rebuttal. Given the above, I recommend acceptance.
Below are multiple reviews of a paper. This paper seeks to explore and understand the improved performance of Neural Networks trained with additional parameters. They analyze the magnitude, correlation, and movement of weights during training and propose a hypothesis that the weights which can be pruned during inference provide degrees of freedom in the loss landscape. Based on this, they explore and recommend a methodology for sparse trainingThe authors show results on multiple benchmark datasets highlighting their performance and how new sparsity-oriented hardware works well with their algorithms. The code is not available (as far as I can see) I would like to see confidence intervals on the different model performances.This paper studies the training of sparse neural networks and the effect of extra parameters (dense connectivity) during training. Though this work has quite a bit potential to impact and inspire future research, I found few things confusing and have questions about its novelty.The authors proposed a new point of view to explain why deep learning models often require more weights are needed to train models rather than to run inference for tasks. The main content of this viewpoint is that more weights during training can expand the search space, create extra degrees of freedom for search, and form new optimization paths.	The reviewers were generally split on this paper. On the one hand, reviewers generally appreciated the clear presentation, discussion, and explanations, and the experiments. On the other hand, most reviewers commented on the lack of comparative evaluation to other works, including works that are related conceptually. While the authors have a potentially reasonable argument for omitting such comparisons, in the balance I do not believe that the reviewers were actually convinced by this. Particularly when the novelty of the contribution is not crystal clear, such comparisons are important, so I am inclined to not recommend acceptance at this point (though I acknowledge that the paper is clear borderline and could be accepted).
Below are multiple reviews of a paper. Theoretically, they claim their work enjoys a tighter suboptimality bound in linear MDPs. This paper targets the robustness issue for Q value via perturbing the states.The paper investigates the problem of training robust RL agents with offline datasets. It claims that regularizing policy and value networks to have similar values against adversarial perturbations can achieve state-of-the-art performance.The authors propose an approach to offline reinforcement learning that is robust to small perturbations in the observation space such that the changes are not detrimental to the performance of the final policy. The achieve this by encouraging the value estimator network to be smooth over the state space while being conservative on out of distribution samples.This paper proposes RORL: offline RL algorithms with conservative smoothing. Motivation is clear and the proposed method sounds reasonable. The authors handled my major concerns on approximation and experiments by providing additional responses and adding more experiments.	All reviewers agree that the author's response has addressed their primary concerns. Reviewer frMM had two reservations that resulted in a borderline rating 1) concerns about how the adversarial samples were generated and 2) a request for evaluation on AntMaze. The author's followup response and further experiments address 1 and partially 2. It would be great to see RORL results on AntMaze in the final version.  Overall, the performance of RORL is competitive with state-of-the-art methods on Mujoco and Adroit tasks with fewer ensemble elements needed. The main benefit is on improved performance against adversarial attack, where RORL significantly improves over existing methods. I think the paper makes a nice contribution that the community will find valuable.  I encourage the authors to think carefully about how to integrate the additional experiments into the paper to resolve the questions raised by reviewers.
Below are multiple reviews of a paper. This paper studies modeling and training choices when designing a single model based on ConvNets and transformers for audio-visual representation learning. It proposes ablations for which weights/layers to share across modalities. The models are pretrained on Kinetics-700 and AudioSet and evaluated on UCF101, ESC-50,The authors present a method for learning audiovisual (AV) representations from videos using a Transformer-based model architecture. The AV representations are learned by training the network to solve two self-supervised pertaining tasks, and subsequently evaluated on various audio/visual downstream tasks.The paper is a nice read. It builds on a line of research on multi-modal video understanding that utilises transformers where these works: 1) fix one of the transformer models (e.g. BERT) and 2) utilise tokens and thus do not train the approach in an end-to-end fashionThe proposed model indeed has some merits (e.g., parameter sharing and negative sampling). However, to me, the technical novelty of the paper is incremental. With an additional multimodal transformer model, the proposed method fails to greatly improve performance. The unfair experimental comparison has been fixed.	Three out of four reviewers are positive about the paper after the author response and during the discussion.  Strengths include * The proposed method for parameter reduction in transformers allows end-2-end learning cross-modal representations especially on long videos, which has not been possible before * Good performance on audio and video understanding * Extensive set of ablations  Concerns include a somewhat incremental nature of the paper and the still large computational resources to run the experiments. I think, both, the ideas and results are interesting to the community and recommend accept.
Below are multiple reviews of a paper. This paper studies how human-interpretable are the concepts learned within the representation space of self-supervised models. It argues that linear probing methods are unable to identify whether a representation space contains a specific concept because the input might contain multiple confounding concepts. Instead, it proposes a “reverse linear probe” moving from which maps combinationsThis paper presents an approach to investigate the semanticity of representations learned via self-supervision applied to images. The approach measures (via mutual information) how well a linear model can map a vector indicating image attributes (e.g. objects, texture, etc) to clusters within the representation space. The authors apply this method to recentThe paper aims to measure the interpretability of the visual representations learned by the recent self-supervised models. The “interpretability” is the mutual information between the feature clusters and a set of visual concepts that can be interpreted by humans. The mutual information is approximated by the proposed Quantized Reverse Probing.The paper proposes a method for characterizing the "meaning" of the representation learned by a given model (interpretability) It proposes reverse linear probing, a post-hoc method that aims at predicting a quantized version of the internal representation from semantic label.	This paper proposes a method for inspecting and interpreting the visual representations learned by self-supervised methods.  The method is conceptually simple and intuititive, the authors assume that concept labels for the images are available, and then go on to learn a mapping between the learned image vectors and the human-provided descriptions of the images. The key insight is to learn a reverse mapping, i.e., to map label vectors to representation vectors. Specifically, feature vectors are quantized using k-means to obtain clusters;  images are labeled (automatically) with a diverse set of concepts from expert models trained with supervision on external data sources, and  a linear model is trained  to map concepts to clusters, measuring the mutual information between the representation and human-interpretable concepts.  Reviewers raised some questions regarding the relation of the approach to topic models, the difference between reverse probing and linear probing, implementation details and computation. The authors addressed reviewers comments convincingly with additional experiments and/or explanations.
Below are multiple reviews of a paper. The paper compiles a dataset from various sources into one unified format for use in downstream research. This dataset can be used for pre-training (since it is not labelled for any specific purpose) and can provide useful insights into various social issues and data-related insights.The paper presents a dataset of open-source English-language legal and administrative data. It covers court opinions, contracts, administrative rules, and legislative records. Unfortunately, it contains mainly US/Canada legal domain.Privacy and toxic content is a problem for training material in large language models. The paper investigates the issue by curating and using a large open source legal dataset. The data has already been filtered through legal and administrative processes.The paper studies responsible data filtering practice for AI researchers. The released corpus is comprehensive and will be useful for studying legal AI. The accompanying PoL-BERT language models do not seem to be trained optimally and their usefulness may be limited.	The reviews are generally positive (though somewhat short), and a large pre-training corpus for legal text will likely be useful for NLP research. One reviewer gave a reject score (5) with the following two weaknesses:  A) The dataset comes from a wide spectrum of law-related data sources, which may differ substantially and hence limit the usefulness of the dataset.  B) Privacy   I am not too worried about Point A because large language models seem to be able to learn from diverse data sources.  Regarding Point B, the separate ethics review mentions the privacy concerns as well but finds that the submission sufficiently discusses this concern and sees no serious ethical issues.  Hence overall I recommend accepting the paper.
Below are multiple reviews of a paper. The paper presents a new task: open-set single domain generalization. The experiments show the proposed method could largely improve the accuracy for unknown classes in the target domain. The paper is well-written and is technically sound and the proposed problem makes sense.In domain generalization (DG), label set of target domain is that of source domains. If there are unknown classes in the target domain, existing DG methods cannot handle this situation. This paper considers a more challenging problem: open-set single DG (OS-SDG)Open-set single domain generalization is a novel, challenging, but practically important problem setting. Experimental results show that the proposed scheme can facilitates the capability of existing methods on detecting unknown-class data.This paper proposes a new method called CrossMatch for open-set single domain generalization where only one source domain is available to train the model. CrossMatch designs a new strategy to generate auxiliary samples for unknown classes and develops a novel consistency regularization.	The paper presents a new problem: open-set single domain generalization, where only one source domain is available and unknown classes and unseen target domains increase the difficulty of the task. To tackle this challenging problem, this paper designs a CrossMatch approach to improve the performance of SDG methods on identifying unknown classes by leveraging a multi-binary classifier. CrossMatch generates auxiliary samples out of source label space by using an adversarial data augmentation strategy. Then, the paper proposes a cross-classifier consistency regularization that minimizes the multi-binary classifier's output and one-vs-all multi-class classifier's output.   The proposed OS-SDG is an interesting and realistic problem. However, since it is way more challenging, the optimal solution to it remains elusive. Some reviewers think the method might be heuristic and lack theoretical guarantees. Nevertheless, the results are promising and the paper makes a first step toward the challenging OS-SDG problem. Another concern is that the CCR loss needs more ablation studies to further analyze its role. Though the authors have added more explanation of this part, I suggest the authors put more ablation studies in the final supplementary document.   Overall, the paper is novel and interesting.  I would recommend acceptance of this paper given its novelty and impressive performance, but I highly suggest the authors add more ablation studies in the final supplementary, as suggested by the reviewers.
Below are multiple reviews of a paper. The authors of this paper propose a linear-time algorithm for maximizing monotone and submodular functions under knapsack constraints. The proposed algorithm extends the threshold-greedy algorithm for cardinality constraints.The paper studies (mainly monotone) submodular maximization subject to various types of constraints. In particular, the authors focus on deterministic algorithms that achieve constant factor approximation to the optimal solution while needing only linear time to terminate.In this submission, the problem of maximizing a submodular function subject to a knapsack constraint is considered. There is a lot of literature on this problem and several approximation algorithms are known. An approximation algorithm with a guarantee of 1/2-eps is developed whose running time is linear in n.The paper studies the problem of submodular maximization under cardinality/knapsack constraints. The goal is to maximize the function value, for cardinality constraints, the algorithm is allowed to select up to k elements. The approximation ratio is optimal, but the stochastic greedy algorithm has better oracle complexity.	Overall, this paper achieves strong and interesting results regarding the query complexity of submodular maximization. One reviewer was concerned that the lower bound result was maybe a folklore result that is easy to prove. However, sufficient evidence to justify that claim was not provided and other reviewers did not share the same concern.
Below are multiple reviews of a paper. The authors propose two key ideas. The first is using the UCB algorithm to identify strong feature interactions in a computationally efficient way. The second is that of using the identified pairwise interactions to build a lightweight GAM-like model that they call ParaACE.The authors claim that their method interaction discovery method is free of ad-hoc assumptions with good detection accuracy and stability. The paper has several strong points as follows: The simplification of the problem to best k arms leads to a more computationally feasible solution.The paper proposes to detect pairwise estimation using a more efficient evaluation of Hessian values via sampling. The desire to consider hessian (and second derivatives in general) as the interaction strength is natural and has been discussed in the literature.The paper handles the important area of model that can be interpreted using feature interactions. The authors chose to use the problem of multi-arm bandit, solving it by UCB algorithm with good speed and accuracy. A lightweight and interpretable deep learning model (called ParaACE), built using alternating conditional expectation (ACE) method is the	This paper tackles the problem of feature interactions identification in black-box models, which is an important problem towards achieving explainable AI/ML. The authors formulate the problem under the multi-armed bandit setting and propose a solution based on the UCB algorithm. This simplification of the problem leads to a computationally feasible solution, for which the authors provide several theoretical analyses. The importance of the learned interactions is showcased in a new deep learning model leveraging these interactions, leading to a reduction in model size (thereby competing against pruning methods) as well as an improvement in accuracy (thereby competing against generalization methods). Although the proposed approach essentially builds on the specific UCB algorithm, it could likely be extended/modified to other (potentially more efficient) bandit strategies. A drawback of this work resides in the experiments being entirely synthetics. In order to close the gap with practice, experiments on real datasets of higher dimensionality should be conducted.
Below are multiple reviews of a paper. The paper proposes an unsupervised domain adaptation method for semantic segmentation named "EasyAdap" The method's key idea is to combine feature-space distribution alignment (similar classes have similar features across domains) and output-distribution alignment (model produce similar output distributions on source & target domain) The paper makes a convincing argument thatThe authors propose EasyAdap method. The consists of the following three modules: Source Training, Semantic Clustering, and Self training. Easy adap doesn't seem to have a better performance than the SOTA baseline.The authors present a method for unsupervised domain adaptation. EasyAdap runs multiple iterations of self-training and semantic clustering. The authors compare with many other methods and show strong performance.	The authors proposed an unsupervised domain adaptation method for semantic segmentation based on self-supervision and self-training strategies. The method was evaluated on autonomous driving datasets, and showed strong performance compared to other methods.  While most of the reviewers agree that the method show convincing results, with strong performance in multiple settings compared to other methods and with a comprehensive ablation study, they brought up three important areas to improve:  (1) Better clarity is needed for the main algorithm, such as better explanations of self-training vs self-supervision and Fig 1.  (2) The paper lacks explanation of why it can outperform the baselines especially its predecessor [10].  (3) The claim of the method is "easy" is hard to justify.  During the reviewer discussion, most reviewers agreed the authors have addressed the weakness in the revised paper, and the story lands better after shifting from easy-to-use method to a lower-complexity method. Reviewers agree that this paper is of interest to the community, but has limited technical contribution. For the above reason, we recommend accepting the paper as poster.
Below are multiple reviews of a paper. The paper describes a probabilistic approach to quantifying uncertainty in DNN classification tasks. The model definition needs clarification. The whole model description does not always follow the usual nomenclature.This paper proposes a new framework for out-of-distribution detection, based on variational inference and a prior Dirichlet distribution. The motivation of the proposed approach is clear, and I agree with the attempt to regularize the network output.This paper provides a new method that approximates the confidence distribution of classification probability, which is useful for novelty detection. The paper is clear and well-motivated, but I find the notation sometimes confusing and inconsistent.	The paper proposes a new framework for out-of-distribution detection, based on variational inference and a prior Dirichlet distribution.  The reviewers and AC note the following potential weaknesses: (1) arguable and not well justified choices of parameters and (2) the performance degradation under many classes (e.g., CIFAR-100).  For (2), the authors mentioned that this is because "there are more than 20% of misclassified test images". But, AC rather views it as a limitation of the proposed approach. The out-of-detection detection problem is a one or two classification task, independent of how many classes exist in the neural classifier.  In overall, the proposed idea is interesting and makes sense but AC decided that the authors need more significant works to publish the work.
Below are multiple reviews of a paper. The paper proposes the anisotropic version of randomized smoothing. Evaluation metrics based on the volume of the certified region are proposed.The authors extend the standard (isotropic) l_1/l_2 randomized smoothing certificate to anisotropic smoothing distributions. They propose to maximize the volume of the certified region for each sample independently, using a memory procedure to preserve soundness.The paper is well written and easy to follow. I have concerns about the data dependent nature of the algorithm. I believe a direct comparison and the claim to be SOTA is unfair.The authors provide a technique for a data-dependent randomized smoothing that provides anisotropic certificates of robustness. This work significantly advances the state of the art, even in the isotropic setting. The analysis is clean, the results surprising, and the experiments are thorough.	The paper proposes the anisotropic version of randomized smoothing. Evaluation metrics based on the volume of the certified region are proposed, allowing comparisons with the certified regions provided from isotropic randomized smoothing. Experimental results show the usefulness of introducing anisotropic randomized smoothing as it certifies larger regions.  Strengths: + The paper is well written, polished, and easy to follow. + The anisotropic part of the proposed approach is well-motivated. + The evaluation section is quite thorough and obtains SOTA results.  Weaknesses: - The sample-wise (data dependent) part has several issues making it unsuitable to use in practice. The authors already discuss a know issue of data-dependent classifiers which when not tackled can lead to certificates that are not sound. To address the issue they adapt the memory-based procedure introduced in Alfarra et al. While this procedure does make the certificate sound it has other problems. For example, an issue is that the memory makes the certificate dependent on the order of the incoming test samples. This provides a new avenue for attack, i.e. the adversary can optimize the order of the test samples to decrease the utility of the final obtained smoothed classifier. In addition, the success of this memory approach also somewhat depends on the "sparsity" of the test samples. Namely, by using a small test set since the samples are in a high-dimensional space the distance between them tends to be bigger than the (proxy) radii of the certified regions. However, in a real-world application we are likely to have many more test samples which would increase the number of intersections when running Algorithm 1. Although the authors provide opposite empirical evidence on a specific dataset, it is not very clear how general it is for other datasets.  - Some of the theoretical results are not novel as they follow directly from prior work (as acknowledged in the paper).   - Another issue with the proposed approach is the optimization procedure described in section C. The optimization suffers from issues such as: inconsistent estimation due to clamping and not using confidence bounds, sensitivity to initialization, high gradient variance, etc.
Below are multiple reviews of a paper. The paper builds on the work of ref. [34], and provides interesting insights into the theoretical aspects of how a dynamics model helps generalize out-of-distribution. The paper demonstrates an effective implementation of a simple/natural idea, is well-written, and should be of great interest to the audience at this conference.This paper shows, both theoretically and experimentally, that a locally factored dynamics model improves sample efficiency and out-of-distribution generalisation. In addition, this paper further proposes a Model-based Counterfactual Data Augmentation model to generate counterfactual transitions for RL.MOCODA is a generalization of the CODA framework for augmenting the training dataset of an offline-RL agent with samples generated using the parent distribution and locally factored dynamics. It is evaluated on continuous control tasks from the 2D Navigation and the HookSweep2 environments.This paper proposes a model-based data augmentation approach named MoCoDa. The approach exploits the local factorization in state-action space. It is inspired by causality and factored MDP literature to generate transitions for policy learning.	The paper suggests to improve sample efficiency and out-of-distribution generalization in RL by learning locally factored world models, and use these models to generate counterfactual data to train on. The key assumption is that the environment model is the right model to factorize (as opposed to, say a policy or value function) and that this model will generalize out of distribution when performing the relevant interventions. All reviewers were in agreement the paper was well written and presented an interesting idea with sound empirical verification. Several comments pointed to an unclear definition of 'counterfactual' used in the paper (as the authors point out, it means different things depending on whether adopting a potential outcome or DAG framework) - please make sure this is clear in the final version, as well as a clear explanation of the distinction with CODA.
Below are multiple reviews of a paper. The paper studies how to use location information (geographical location) of images to help with image classification tasks. It argues that the euclidean space does not preserve distances and has distortions whereas a spherical coordinate approach would not have the inherent problem.This paper proposes a strategy for learning a location embedding. The idea is to first encode the location into the double Fourier sphere basis (or a subset) and then pass this through a multilayer perceptron.This paper explores developing location encodings for sphericalsurfaces and their application to tasks in geo-aware image classification. The authors propose a method for encoding spherical sphericallocations into a higher dimensional space (based on Double FourierSphere) that preserves distances. The proposed method is demonstrated for three tasks and evaluated using seven datasets.This paper proposes a positional embedding method for GPS coordinates, which lie on a sphere. This paper also gives a family of loss functions to enable self-supervised training. It's interesting to have a positional encoding method for spherical coordinates.	In spite of some slightly mixed scores (with one borderline positive review), scores are ultimately lukewarm and tend toward negative (and furthermore, reviews are broadly in agreement as to the issues they raise). Main issues center around low significance of the results, and issues with the presentation that need to be addressed.
Below are multiple reviews of a paper. The paper considers sequential decision making in a bandit scenario with biased feedback. The goal of the player is to choose actions sequentially, minimizing the regret compared to the optimal action. The algorithm attempts to de-bias the observations, by deliberately sampling suboptimal actions.The author studies the effect of biased linear bandit feedback on fairness in decision making. The authors establish tight minimax lower and upper regret bounds for this problem, while augmenting that with gap-dependent regret upper bounds.The authors study the linear bandit problem with biased feedback. They develop a phase-based elimination algorithm that uses ideas from experimental design to correct the bias.	The authors study a linear bandit problem with biased feedback, develop an algorithm and bound the corresponding regret. The bandit problem they study is meaningful and highly relevant. I therefore recommend to accept the paper.
Below are multiple reviews of a paper. This work studies the problem of online or incremental learning in temporal graphs (dynamic networks) It asks whether past data can be discarded/ignored without losing predictive accuracy under the assumption that there is the presence of a distribution shift. The contribution and novelty of this work is unclear. Many important related works are missing.The paper tackles the problem of layer decoupling in GNN training, which is an important problem when training large-scale networks. The paper proposes two strategies: decoupled technique and lazy-update. While I think the first strategy is a good supplement to the previous work, I do feel there are some points that are notThis work empirically evaluates the sliding-window strategy for training GNNs with temporal graphs. One may cast the temporal nature of the graph data in an online setting. The findings are: (1) incremental training is necessary to account for distribution shift.Temporal graphs can naturally model many real-world networks, and many graph neural network (GNN)-based methods have been proposed recently. Existing temporal GNNs can handle vertices and edges appearing / disappearing over time, but not vertex classes. This paper precisely considers this problem, and compiles three vertex classification datasets for future	This is an empirical paper that proposed a few different settings for applying GNNs on temporal data, including what context window to use, code-start vs warm-start, incremental training vs static.  This paper also proposed and released a few more temporal graph datasets, which could be useful.  The consensus assessment of the reviewers is that the contributions of this paper are incremental, and the results are expected and not exciting enough.  I want to in particular point out that the results highlighted in the paper, that a GNN with window size 1 is sufficient to recover 90% of the performance of the model on full graph, is probably not the correct message to communicate.  This either indicates that the data and task used in the benchmarks do not require sophisticated long-horizon temporal information (which makes the comparison between any methods uninteresting), or it indicates that the metric is not sensitive enough to sufficiently distinguish models trained with different settings.  I would recommend rejection and encourage the authors to improve this paper.
Below are multiple reviews of a paper. The paper is beyond my expertise. I cannot give any solid review comments regarding the techniques that are better than an educated guess. The quality of writing requires improvement, especially literature review and experiment analysis.The algorithm is interesting, quite simple and nice. The paper is however very superficial in terms of experiments, or applications of the proposed scheme. Most importantly, the fit with the main scope of ICLR is far from obvious.The main contribution of this work is not significant enough. The experiments are incomplete and not convincing. The background of the problem is not sufficiently introduced. Many details of the experimental settings are missing.	The approach/problem seems interesting, and several reviewers commented on this. However, the experimental evaluation is quite preliminary and the paper would be helped a lot with a connection to a motivating application. All of the reviewers pointed out that the work is not written in the usual in the scope of ICLR papers, and putting these together at this time it makes sense to reject the paper.
Below are multiple reviews of a paper. The paper is an interesting application of Equilibrium Propagation to meta-learning. It suggests a biological implementation/approximation of backpropagation-through-learning (BPTL) Overall, the paper is very thorough and rigorous, both theoretically with numerical validation of the theoretical results.The paper provides a novel approach to meta-learning. The new approach is more biologically plausible than existing approaches. The paper is well written and the authors conducted an informative theoretical analysis of their approach.The proposed method is simpler than the existing meta-learning methods including MAML and iMAML because it estimates the meta-gradients using only partial derivatives rather than second-order derivatives or inverse Hessian. Also, the proposed method matches or outperforms the reference methods on various benchmarks even its simplicity.Paper addresses the problem of performing meta-learning when facing different tasks by introducing a general-purpose rule that aims on biological plausibility. The main idea of contrastive meta- learning here is to run the underlying algorithm twice: once by learning the original presented task and once to learn "augmented" version of the task that includes	The Reviewers appreciated the novelty factor of the contrastive meta-learning algorithm proposed in the paper, the theoretical analysis establishing a formal connection with equilibrium propagation, and the appealing features of the resulting meta-learning procedure, which include memory and computation efficiency, as well as the fact that the algorithm affords a biologically-plausible implementation that only requires locally available information for parameter updates. To concretely showcase these properties the paper demonstrates two instantiations of the proposed algorithm that are mechanistically realized through synaptic consolidation and top-down neuronal modulation, respectively. Finally, the paper validates the algorithm on standard few-shot learning benchmarks. The main weaknesses of the paper identified by the Reviewers are the empirical evaluation, which would benefit from a more extensive comparison between methods and more experiments on more challenging meta-learning datasets, and the discussion on the candidate neurobiological substrate for a brain implementation of contrastive meta-learning, which would benefit from a more detailed and systematic description. These limitations however do not substantially detract from the overall quality, relevance and interest of the paper, which Reviewers unanimously recommend for acceptance.
Below are multiple reviews of a paper. This paper presents the first dataset focused on keyphrase generation for the French language. Previous works usually relied on unsupervised methods to perform extractive keyphrase generations.The paper proposes a new dataset for multilingual keyphrase generation, Papyrus. Papyrus includes 16,247 pairs of abstracts and key phrases. The multilingual corpus is collected from Papyrus, a repository of documents.This paper introduces four versions of the Papyrus dataset which focus on keyphrase generation (KPG) The four datasets are Papyrus-e, which includes English examples, Pap Cyrus-f, which including French examples, and Papyrus -m and -a. In general, their models outperform the state-of-the-This paper introduces a new multilingual keyphrase dataset and present a BART-based baseline with discussions. Keyphrase generation is valuable task, and having a suitable data set will be helpful to the community.The paper proposes a multilingual keyphrase generation dataset with four versions (Papyrus-e, Papyrus-f, Pap Cyrus-m, Pap Seymour-a) English and French comprise 29.2% (25.9% + 3.3%) of languages used on the internet.Papyrus contains 16k pairs of abstracts and keyphrases essentially for English and French. The authors release four versions of this dataset with different language configurations. Using multilingual Papyrus, they train the BART model, which shows better results for French, Spanish and Polish keyword extraction datasets.	This paper presents the dataset Papyrus, consisting of abstracts and keyphrases extracted from institutional reports from the Université de Montréal. The dataset is mostly in two languages and was generated using straightforward, yet easily extensible methods for extraction. This is one of the first datasets that expands KPG beyond English. Although limited in coverage, it sets the tone for generalization of techniques beyond English.   **pros**  * Expands the field of KPG to other languages beyond English. * The methods for extraction are straightforward. * Given its origin, the quality of the data is expected to be high. * A portion of the data has been validated through human evaluation.  **cons** * The coverage of the dataset is mostly limited to English and French. Other languages aren't well represented.
Below are multiple reviews of a paper. The paper proposes a new watermarking framework for text generation APIs. Compared with the existing framework, the new framework increases stealth by minimizing the distortion of overall word distributions and incorporating high-order linguistic features.In imitation attacks, little work has been done to protect the IP of text generation APIs. This work identifies and addresses a major weakness in He et al., and proposes a more invisible watermarking algorithm. The proposed watermarks have negligible adverse impacts on the utility.This paper presents a simple but effective approach (called CATER) to protect the IP of text generation APIs under imitation attacks. This idea can stamp watermarks on imitation models by altering the distribution of semantically equivalent words. Unlike the previous work, they propose to conditionally watermark the victim’s outputs so that it is infConditional wATERmarking (CATER) is based on linguistic features (e.g., part-of-speech and dependency tree) Strengths: CATER is robust against white-box attacks. Weaknesses: Experiments are limited.	The authors propose a watermarking technique (CATER) to claim ownership of text generation APIs in the presence of imitation attacks. Their main idea is based on the observation that in the state of the art by analyzing the word frequency in API responses as well as publicly available data, an adversary's odds to learn the watermark increases. To remedy this, CATER conditionally watermarks the response to prevent the adversary from deciphering the watermarking keys.   Reviewers found the topic of the paper timely, is writing clear, and the overall contribution sound and of interest to the community.
Below are multiple reviews of a paper. This paper presents an online Experience replay (ER) based continual learning technique to mitigate forgetting of the past data. When the relative size of replay-memory is smaller as compared to the size of the incoming task, memory overfitting can occur. The proposed method is evaluated on a suite of computer-vision tasks and is shown to outperformThe paper studies the effect of data augmentation in online continual learning. It proposes *repeated augmented rehearsal*, a simple method. The results of the proposed method are very convincing.The authors show that the amount of iteration on an incoming batch in Repeated ER helps with the underfitting of the data at the expense of more overfitting on the buffer. The main limitation I see is that the method requires prior knowledge of data augmentation techniques, which makes it less general than other OCL methods.The paper addresses a rehearsal-based approach for online continual learning. Inspired by the investigation, the paper proposed a simple, novel method called repeated augmented rehearsal. The experimental results support the effectiveness of the suggested method.	This work considers rehearsal-based methods in continual learning and revisits revisits the rehearsal dynamics. Most reviewers praised the analysis of overfitting/underfitting in replay-based methods and the presentation. The proposed repeated rehearsal with data-augmentation was shown to be effective in empirical evaluations and the ablation studies. Finally, the authors addressed on of the main concerns raised by the reviewers, namely the relation to the reweighted ER baseline, during the rebuttal.
Below are multiple reviews of a paper. This paper aims to transfer fairness under distribution shift. Given the powerful self-training tool to solve the distribution shift problem, the authors first identify a sufficient condition for fairness transfer. They then propose an algorithm with fair consistency regularization. Experiments on synthetic and real datasets demonstrate the effectiveness in terms of fairness and accuracy.The paper deals with a highly relevant topic (fairness and distribution shift) that remains largely unexplored. The authors select one measure of fairness equal opportunity odds, that is very relevant and widely used but without any social/redistributive justice justification.This paper proposes to use consistency regularization to improve fairness in ML models under distribution shifts. The paper extends upon LAFTR (an adversarial learning algorithm for fairness) and FixMatch to impose the consistency constraints via self-training.	The reviews are a bit divergent. While all the reviewers appreciate the clarity of the paper and the theory-inspired proposed algorithm, they raised some concerns e.g., on the assumption employed for obtaining a theoretical result, as well as on marginal (or worse) EO fairness performance in some cases. Although concerns on the fairness performance improvement in light of the employed metrics are still unresolved, many of the concerns are properly addressed, and with regard to the writing quality and insights, I believe that the paper is worth being published. Hence, I recommend the acceptance of this paper.
Below are multiple reviews of a paper. This paper approximates several nondecomposable functions (AUC and F1-score) as linear programmings and uses them as loss functions for network training. The experiments emphasize the condition when the positive/negative examples are imbalanced, and demonstrates the superiority of the proposed methods to cross-entropy loss.This paper addresses the classical topic of directly optimizing non-decomposable loss functions. Since these metrics can be computed via linear programs, it is sufficient to compute gradient through the LP solver. In experiments, the resulting implementation outperforms the cross-entropy loss and mildly outperforms one recent baseline.This paper shows how some nondecomposable functions can beinterpreted as solving combinatorial optimization problems. The AUC experiments in Table 1 outperform [Liu 2019], which also optimizes for the AUC.Non-decomposable losses in machine learning can be rewritten as linear programs, whose constraints depends on the model output. This is the case for AUC, multi-class A UC, F-score, and to some extend NMF. The authors propose to directly backpropagate through the LP resolution to minimize non-dec	This paper shows that various discrete loss functions can be formulated as an LP. It proposes to relax the constraint Ax = b, x >= 0 using a soft constraint and following Mangasarian, proposes to solve the relaxed problem using Newton's method. Backpropagation through these iterations is further proposed. The main motivation is that this results in a GPU-friendly implementation.  I think the proposed approach is novel. However, as pointed out by reviewers, the current writing lacks clarity and the experiments are quite weak. There is now a wealth of methods for differentiating through an LP using implicit differentiation, smoothing (which the present paper is a form of, see below) and perturbations. It is important to compare to these methods. The paper also ignores a large literature on convex surrogates for ranking metrics.  I recommend the authors to strengthen the writing and experiments, and to resubmit to a top-conference.  Additional comments by the AC -------------------------------------------  As the sentences "Hence, solving such LPs using off-the-shelf solvers may slow down the training process" or "Often, this would involve running the solver on the CPU, which introduces overhead" indicate, the authors seem to imply that LPs need to be solved in canonical LP form, min_x <c,x> s.t. Ax <= b, x >=0, using an off-the-shelf LP solver. This is not how many LPs are solved in practice. For every loss, there will always be an ad-hoc solver for the corresponding LP. For instance, the Hungarian algorithm for the Birkhoff polytope.  The paper is missing an important reference: SparseMAP (https://arxiv.org/abs/1802.04223). In this paper, the authors add regularization to the primal LP and use Frank-Wolfe or active set methods to solve the problem.  Equation (6) corresponds to relaxing the hard constraint Ax=b, x>=0 with a soft one. This approach is in a sense opposite to SparseMAP. Indeed, relaxing the constraints in the primal is equivalent to adding regularization in the dual LP (see, e.g., https://papers.nips.cc/paper/2012/hash/bad5f33780c42f2588878a9d07405083-Abstract.html). Speaking of (6), the authors should clarify that it's a convex objective.  In section 2, the authors review a number of losses which can be written as an LP. It would be better to explicitly state what are A, b and c for each loss (or g, h, E, F, p, B, G, q).  The matrix A could potentially be huge, depending on the LP. Do you need to materialize it in memory in practice? This would limit the approach to relatively small LPs.
Below are multiple reviews of a paper. Graph Convolutional Networks (GCN) to explicitly represent and use relational data in dialog modeling, as well an attention mechanism for combining information from multiple sources. The main claim is that the proposed model outperforms the current state-of-the-art on a goal-oriented dialog task.The paper proposes a Graph Convolutional Network-based encoder-decoder model with sequential attention for goal-oriented dialogue systems. The model consists of three encoders for a query, dialogue history, and KB, respectively, and a decoder with a sequential attention mechanism. The proposed model attains state-of-theThis is a well-written paper (especially the introduction) with fairly extensive experimentation section. It'a very possitive for me that you resort to more than one set of figures of merit. There are some parts that could be made more clear.	This paper describes a graph convolutional network (GCN) approach to capture relational information in natural language as well as knowledge sources for goal-oriented dialogue systems. Relational information is captured by dependency parses, and when there is code switching in the input language, word co-occurrence information is used instead. Experiments on the modified DSTC2 dataset show significant improvements over baselines. The original version of the paper lacked comparison to some SOTA baselines as also raised by the reviewers, these are included in the revised version. Although the results show improvements over other approaches, it is arguable BLEU and ROUGE scores are not good enough for this task. Inclusion of human evaluation in the results would be very useful.
Below are multiple reviews of a paper. QDROP randomly drops quantization during post-training quantization (PTQ) reconstruction to pursue the flatness from a general perspective. The authors claim a new state of the art for PTQ on various tasks including image classification, object detection for computer vision.The authors proposed a random dropping quantization method at the post-training stage to achieve a low bit quantization network. Experimental results on many tasks and models show the QDROP's advantages.This paper aims to analyze how activation quantization affects the PTQ process. Theoretical analyses are well-balanced with empirical observations. The novelty of the QDrop algorithm itself is moderate and simple. The intuition behind it is critical.This paper proposes the post-training quantization for extremely low-bit neural networks. By considering the activation quantization during reconstruction, the presented QDrop randomly drops the quantization of activations with higher loss flatness.	This paper proposes a simple, theoretically motivated approach for post-training quantization. The authors justify its effectiveness with both a sound theoretical analysis, and strong empirical results across many tasks and models, including a state-of-the-art result for 2-bit quantized weights/activations. All reviewers agreed the paper is worth accepting, with 3/4 rating it as a clear accept following the discussion period, and the fourth reviewer not giving strong reasons not to accept.
Below are multiple reviews of a paper. The idea to consider uncertainty is interesting and it helps to select the most meaningful points for updating the model. The description of the methods could be more clarified. The improvement of the method seems to be mainly the way of selecting data points.The paper is mostly well written and clearly sets out to explain and propose a solution to the problem selecting valuable samples for annotations. The results, as they are presented, do not give me significant confidence on the relative performance of this method.Algorithm could be used in any domain not only for the mdedical image such as X-ray. Various public datasets in the general domain should be used as another extra validation set.There are many tasks that utilize informativeness and representativeness properties to select data. The methods design still needs more analysis and insights. The experiment should be complementary analysis.	This paper proposes an online active learning for chest x-ray image annotation. It claims three novelties: 1) it improves the classification performance with fewer manual annotations than current approaches; 2) it selects informative uncertain samples; and 3) it assigns pseudo labels for high-confidence samples  in an online model update strategy. The majority of reviewers support the publication of this paper, where the main strengths are the paper writing, the importance of active learning for annotation costs savings, and generalisation of the method to other domains. The reviewers also identified a few problems, namely lack of novelty, unclear and incomplete experimental results, lack of statistical evaluation, and poor review for active learning papers.  Despite these issues, I believe the paper is valuable for publication.
Below are multiple reviews of a paper. This article solves the Dec-POMDP problem, based on MAAC and QMIX algorithms. When the agents are homogeneous and optimized only through team rewards, it is easy to learn similar policies for each agent. If each agent can complete different parts of the overall goal, the joint policy that converges to is obviously betterThe paper discusses an analysis of the emergence of individuality in a multi-agent system based on reinforcement learning. The reviewer struggles to see this mechanism particularly insightful. The choice of the mechanisms (MAAC, QMIX, etc.) is not sufficiently discussed by the authors.This paper tackles the problem of exploration in multi-agent RL. The authors propose to shape the reward using the output of a classifier. The proposed reward shaping term can be integrated into two popular MARL algorithms.This paper contributes a method based on reward-shaping to encourage the emergence of distinct agent behaviors. They propose to learn a classifier that predicts agent identity given the agent's observation, and use the classifier probability as an intrinsic reward that is added to the environment reward. They provide two regularizers to help kick-start the positive	This paper introduces a method to increase diversity/individuality of agents in a MARL setup, based on intrinsic rewards coming from a classifier over behaviours.  Reviewers tend to agree that this is an important/interesting problem, which is related to exploration, a central problem in reinforcement learning. Several reviewers point out that the paper is well written. I appreciate that the authors have been responsive to reviews and have answered and/or addressed several points of concern of the reviewers. The proposed method performs well on the experiments carried out.  Reviews still point out several things that could be improved. The experiments mostly report reward curved, and only few results are actually clearly pointing out the individuality between agents. The fact that this method outperforms the baselines is good, but does not prove individuality and may simply be due to the authors spending more time on the tasks, or other undiscovered phenomenon. A reviewer is concerned that this extra reward could encourage trivial behaviours, and it seems clear that it will if the relative weight of the intrinsic reward is too high. This should be discussed more. Finally, a reviewer points out that classifier-based intrinsic reward for diversity already exists in published works and that this paper is incremental work.  The average score for this paper is very close to the acceptance threshold, but based on the reviews I recommend to reject this paper for ICLR 2021. I am confident that when the authors address further the reviewers concerns and improve the experimental results, this paper will be published in a future venue.
Below are multiple reviews of a paper. This paper proposes Causal Anonymous Walks (CAWs) that are extracted by temporal random walks and work as automatic retrieval of temporal network motifs. CAWs adopt an anonymization strategy that replaces node identities with the hitting counts of the nodes based on a set of sampled walks. CAW-N was evaluated to predict links over 6The proposed Causal Anonymous Walks (CAWs) work as temporal motifs to represent the network dynamics. The CAWs can be further encoded by the proposed CAW-N which supports online training.The proposed causal anonymous walks (CAW) is the key contribution of the paper. The set-based anonymization is adopted to allow temporal and structure information in a temporal network can be retained in the CAWs. The sampled CAWs are then used to learn RNN for the link prediction.The authors leverage the causal anonymous walk to capture the topological laws of the dynamic graph, while not requiring to memorize node identities. The contribution is solid as it complements the TGAT when the node/edges features are less important. The numerical results also compare favorably to the baselines.	The paper introduces a new method for encoding dynamics of temporal networks.  The approach, while not ground-breaking, is interesting and the results are fairly convincing.  The submission raised a number of concerns from the reviewers. They questioned the complexity of the proposed approach (R3 and R4), the clarity/readability (R2 and R1), and appropriateness of the link sampling strategy (R2), as well as raised several more minor (from my perspective) issues. I believe that the authors adequately addressed most of these concerns in their rebuttal and the revision.  R2 has confirmed that they read the rebuttal and raised their score to strong accept. Unfortunately, the other reviewers have not engaged during the discussion period, and it is unclear if they are satisfied with the clarifications and changes. Nevertheless, after reading the authors' responses and skimming through the manuscript, I believe that most concerns have been addressed, and this is a good paper that deserves to be accepted. That being said, the issue of readability has been raised by the reviewers, and, while I do not think the paper is unreadable, I do agree that there is much room for improvement. I would encourage the authors to polish the manuscript for the camera-ready version, as well as try to address the remaining concerns raised by the reviewers.
Below are multiple reviews of a paper. This paper tried to suggest 2 benchmarks describing each case and analyze the trade-off between them by evaluating several unsupervised learning algorithms. Main contribution of this work is to find out that the negative sampling is key to building human-like learning models.This paper explores the gap between computer vision models and human vision and learning systems on real-time learning and life-long learning. Several self-supervised methods are evaluated and the results are presented. The reasons behind the difference of different methods are discussed.The paper draws a comparison between how humans and unsupervised learning algorithms learn. Two benchmarks were proposed: one is based on real-time learning, while the other is on life-long learning.The paper presents two benchmarks for human-like real-time and lifelong learning. Real-time learning benchmarks focus on comparing the visual classification behavior of unsupervised learning algorithms with that of humans captured in different sessions. Lifelong learning compares the continuous learning behavior of various un supervised learning methods by training them on first-person videos ofThe paper tackles an important challenge of human-like lifelong learning from a complementary perspective of short and long-term knowledge acquisition and retention. The content is extremely dense, crucial details on the exact experimental set-up, considered methods and evaluation are missing, particularly when inspired form prior works that not everyone will be aware of.	The two presented benchmarks for human-like real-time and life-long learning by incorporating perspectives from short-term and long-term knowledge acquisition and retention are highly interesting and useful for further research in the area of (unsupervised) human-like learning. The work is very well written and presented.
Below are multiple reviews of a paper. This paper considers the resources allocation problem where each of $n$ receivers has to be allocated a fixed fraction of items. In this model the optimal allocation rule that maximizes social welfare can be model as the solution to a semi-discrete optimal transport (OT) problem.The SGD method is not new, but serves the purpose adequately. It does not show  how the optimal transport properties play roles in the solution. The appendix is not well written.The paper studies a fair division problem inspired by Facebook’s blood donation program. The paper reduces this problem to a form of optimal transport. The authors test these algorithms on synthetic and semi-synthetic data.The authors consider the problem of allocating a distribution of items to $n$ fixed individuals (named "receivers") subject to a fixed fraction constraint. The goal is to maximize the expected utilities of the individuals, while maintaining the constraint that each individual is matched at least $p_i$ of the items in expectation. The	Executive summary:  The problem considered in this paper is as follows: There is a distribution over items X \subseteq [0,\bar{x}]^n where x_i denotes the value of the item to recipient i. There are also matching constraints {p_i}_{i \in N}, which require that each agent should be matched a p_i fraction pf the times. The goals is to maximize the sum of recipient utilities subject to the matching propability constraints, and also satisfying that no recipient i envies another recipient by more than a factor \gamma_i.  It is shown that this problem can be solved as a semi-discrete optimal transport problem. They also give a stochastic optimization algorithm which converges at rate O(1/sqrt(T)), and a PAC-style sample complexity result (showing that with O(n/eps^2) samples an eps-approximate solution can be found with high probability).  Discussion and recommendation:  This paper is a bit out of my comfort zone, so I am mostly relying on the reviews, which are rather positive and supportive of the paper. The connection to optimal transport is appreciated, and the approximation results (while rather standard) seem to find their audience as well.  Weak accept.
Below are multiple reviews of a paper. The proposed approach is potentially interesting and has been shown to work well in an experimental setting. The proposed model and algorithms are novel but quite incremental with respect to the state of the art. The form of openness considered in the paper is rather restrictive."The idea to integrate the communication acts in the planned strategy seems very promising, as also confirmed by the experimental results" "The second scenario is the only one in which the proposed algorithm did not outperform the baseline"The paper contributes new data about the relative costs and benefits of inter-agent communication. It seems to show that nested agent modeling and communication are incompatible, which to me is a flaw in the overall agent model.The two contributions are (1) an enhancement of a previously-developed model of multi-agent POMDPs with communicative actions, and (2) an extension of a Monte-Carlo tree search algorithm. Although technically sound, both contributions (enhanced model and enhanced algorithm) seem to be straightforward and incremental.	Meta Review: The reviewers felt that this paper offered a valuable contribution to the area of multiagent planning, and specifically in the use of communication in interactive POMDPs to handle certain forms of “open systems” (involving the presence/absence of other agents). There was an appreciation for the novelty of the problem, the new algorithm proposed (an extension of MCT to handle the “open” setting), and the empirical evaluation. The reviewers raised some questions about the general novelty vs. incrementality of the approach, and made a number of suggestions that could greatly improve the presentation and emphasis in the paper. The author response clarified a number of questions and convinced the reviewers that paper revisions would be forthcoming that would enhance the impact of this work. The authors are strongly urged to make the revisions suggested (and discussed in their rebuttal).
Below are multiple reviews of a paper. The proposed ideas are quite interesting, and integrates nicely into NN architectures. The 'optimal' choice of the power of the Laplacian, in 3.5, is eluded.The paper proposes to use a regularization which preserves nearest-neighbor smoothness from layer to layer. Experiments on CIFAR-10 show that the method improves the robustness of the neural networks.The paper is overall well written, and the idea involving the Laplacian of the similarity graph is interesting. Experimental results still seem not convincing to me. It would be very helpful if the computation process and the discussions can be separated here.	The paper proposes a new graph-based regularizer to improve the robustness of deep nets. The idea is to encourage smoothness on a graph built on the features at different layers. Experiments on CIFAR-10 show that the method provides robustness over very different types of perturbations such as adversarial examples or quantization. The reviewers raised concerns around the significance of the results, the reliance on a single dataset and the unexplained link between adversarial examples and the regularization. Despite the revision, the reviewers maintain their concerns. For this reason this work is not ready for publication.
Below are multiple reviews of a paper. This paper presents the disparate impact on semi-supervised learning. The sub-population that has a higher baseline accuracy tends to benefit more from SSL. The paper has high ethical value.This paper analyzes the discriminative performances of semi-supervised learning (SSL) on different subgroups. The paper first proposes a unified loss for analyzing the SSL frameworks. Experiments show overall consistent results with the main message from the theory.This paper aims to theoretically study the 'Matthew effect' (or disparate impact) of semi-supervised learning (SSL) Theoretically analyzing the varied performance over different sub-populations may help design a better SSL method.The paper claims semi-supervised learning (SSL) does not uniformly improve performance on all the constituent (latent) sub-population of the group. The authors argue intuitively and theoretically for the likely cause. They provide empirical evidence that can support their main claim.	The paper analyses theoretically the 'Matthew effect' (disparate impact) in the setting  of the semi-supervised learning and its effect on fairness and performance.   All reviewers agree that the paper deals with a very interesting topic and important problem.  The paper discusses and presents a thorough and convincing analysis of the effect. There were multiple concerns raised mainly around the lack of clarity at parts of the paper. The authors did a very good job at resolving those and bringing their submission to a good standard.  In the rebuttal I was glad to see a great dialog evolving among the authors and reviewers.  I congraultate both sides.   Happy to recommend acceptance.
Below are multiple reviews of a paper. Bounds are derived from PAC-Bayes generalization bounds. The connection between PAC- Bayesian bounds and information theoretic ones is one that is, by now, well understood. The bounds displayed here for the case where empirical risk is zero are particularly interesting.This paper presents a new family of information-theoretic generalization bounds in terms of the disintegrated, sample-wise, evaluated conditional mutual information (CMI) The information measure depends on the losses incurred by the selected hypothesis rather than on the hypothesis itself. In some scenarios, this novel bound results in a tighter characterization of theThis paper derives new information-theoretic generalization bounds based on sample-wise evaluated CMI. The square-root bound and the linear bound are tighter than existing bounds. The binary KL bound is empirically shown to be superior for low-training loss settings.This paper considers the problem of providing generalization bounds based on the information-theoretic measures. The authors provide some numerical results showing that their bounds are not vacuous in DL settings. The results on the binary KL bounds are completely novel, and have not been reported before.	This paper presents a novel sequence of results providing generalization bounds for multi-class classification within PAC-Bayesian framework. These results extend and improve some of the existing bounds. Under some assumptions, these results give a tighter bound for multi-class classification with deep neural networks than previously existing results.  These results are of interest to theoretical ML community and a valuable contribution to the conference.
Below are multiple reviews of a paper. The authors test their technique (in a Rainbow DQN agent) on Atari levels under data limited setting and show that their technique, albeit slighlty, outperforms previous techniques. Overall, I think the technique presented in this paper is well-motivated and addresses an important problem in RL.The paper studies the question of recovering representations that are equivariant under the agent's action and under the symmetries of the environment. The authors propose 3 losses that encode the constraints of the latent state and state-action embedding, as well as the invariance constraint of the reward.This paper presents a latent variable model for representation learning in RL. It takes into consideration both equivariance to an agent’s action and symmetry transformations of the environment.The paper focuses on the problem of incorporating symmetries into RL agents’ representations to improve data efficiency. It proposes a model-based representation learning method parameterized by a group action that is based on encoding states and state-action pairs as elements of the group's representation in latent space.	This paper proposes to learn a latent space representation such that some linear equivariance and symmetry constraints are respected in the latent space, with the goal to improve sample efficiency. One core idea is that the latent space is also the same as the space of linear transformation used in the constraints, which is shown to simplify some of the mathematical derivations. Experiments on the Atari 100K benchmark demonstrate a statistical improvement over the SPR baseline when using the SE(2) group of linear transformations as latent space.  Following the discussion period, most reviewers were in favor of acceptance. However, one reviewer remained unconvinced, and after carefully reading the paper, I actually share the same concerns, i.e., that it is unclear under which conditions the proposed approach actually works, and what makes it work. I believe that, as a research community, we should value understanding over moving the needle on benchmarks, especially when proposing such a complex method as this one (see Fig. 5).  More specifically:  1. The method is only evaluated on Atari games, showing some improvements when using SE(2), and arguing that there are corresponding symmetries in such games. There is however no analysis demonstrating (or even hinting at the fact) that the proposed technique is actually learning to take advantage of such symmetries (NB: I had a quick look at the animation added by the authors in the supplementary material, but I do not see if/how they help on this point). Even if analyzing representations on Atari may be tricky, I believe that given the motivation of this new algorithm, it *must* be evaluated on some toy example (e.g., the pendulum mentioned throughout the paper) to validate that it is learning what we want it to learn (although I also agree with the authors that experimenting on a more complex benchmark like Atari is equally important).  2. The idea of embedding states into the same space as transformations is interesting, and brings some advantages when writing down equations, as demonstrated by the authors. However, there is no justification besides mathematical convenience, and it doesn't seem intuitive to me at all that why this should be a good idea, considering that it ties the state representation to the mathematical representation of group transformations. For instance, what does the spcial group element $e$ mean for a state? And this coupling makes it difficult to interpret the effect of using a different group of transformations: for instance when moving from GL(2) to SE(2), is the observed benefit because we are using only specific transformations, or simply because we are reducing the dimensionality of the state embedding? (note that in Fig. 4(c) the MLP variant has similar performance to GL(2), and based on my understanding they use the same embedding dimensionality  ==> I believe it would be important to check what would happen with an MLP variant using the same dimensionality as SE(2))  3. The effect of the $L_{GET}$ loss is not convincing, as pointed out by several reviewers. I think it would have been an opportunity for the authors to investigate why, especially since it seems to work in some games and not others. But just focusing on "here are the 17/26 games where it works better" doesn't really bring added value here. Do these games have some specific properties that make them better candidates to take advantage of $L_{GET}$? This could have been a very interesting insight if that was the case, but as it is now, I am not sure what we can learn from that.  4. There are several implementation "details", some moving the final algorithm farther from its theoretical justification, that are not ablated, making it difficult to understand their impact (ex: using target networks, the choice of the value of M, using projections onto the unit sphere of some arbitrary dimensionality, how the $s'$ state is chosen in $L_{GET}$)  As a result, we have here an algorithm with some interesting theoretical background, but with a lot of moving components which -- when properly tweaked -- can lead to a statistically meaningful improvement on Atari 100K -- without really understanding why. I believe this is not quite enough for publication at ICLR, and I would encourage the authors to delve deeper into the understanding of their algorithm, which I hope will bring useful insights to the research community working on representation learning.
Below are multiple reviews of a paper. The paper proposes a novel approach for solving MORL problems while considering uncertainty in the Pareto frontier. The contributions are interesting and novel, but the paper has several flaws which make it not ready for acceptance.This paper seeks to train multi-objective RL policies that are robust to environmental uncertainties. There are two main contributions: a novel approach to solve this problem, and a novel metric to evaluate Pareto fronts. The proposed approach, called BRMORL, consists of training a protagonist policy that maximizes utility alongside an adversarialThe paper proposes a robust multi-objective RL approach and a non-linear utility metric to enforce an accurate and evenly distributed representation of the Pareto frontier. Robustness is obtained by formulating the problem as a two-player zero-sum game.This paper proposes a framework to tackle uncertainty in multi-objective optimization of reinforcement learning problems. Uncertainty is represented as an adversary over preferences. Fitness is measured by a multi-Objective quality indicators while Bayesian optimization is used to bring improvements. The proposed method is evaluated on four benchmark problems.	The paper studied multi-objective reinforcement learning (MORL), and provided a Bayesian optimization approach for challenging MORL scenarios in several simulation environments. The reviewers generally find it interesting to account for robustness in a MORL setup, and all appreciate the algorithmic contributions. However, there were shared critical concerns among \ reviewers in the technical clarity and positioning of the work.   The paper has gone through substantial changes during the rebuttal period, which addressed some concerns regarding the experimental details; however, the major revision raised further issues that affects the clarity of the work. The reviewers are hence unconvinced that the paper is ready for publication. In addition to addressing the existing comments on clarifying the experimental details and properly positioning the work against prior art, a reorganization and optimization of the main content would be beneficial for future submission.
Below are multiple reviews of a paper. The authors propose to improve generalization ability of GNN's for the task of graph classification via a causal theoretic analysis. The idea to use a causal graph and the accompanying theory to explain the label associated with the graph is interesting. The paper is well written and easy to understand.This paper proposes to address the limitation of current interpretable graph neural networks over out-of-distribution data. The intrinsically interpretable GNN is investigated by identifying the invariant rationales corresponding to environment-invariant causal patterns.This paper proposes a novel algorithm DIR that allows the learned GNN model to make predictions based on causal patterns. On both synthetic and real-world datasets, DIR outperforms the related baselines consistently.	The work proposes a method to learn graph representations based on subgraphs that are invariant to spurious subgraphs. The reviewers found the paper easy to read and the theory interesting, well explained and justified. The reviewers seem happy with the existing and new experiments that came during the rebuttal phase. I too found the paper interesting and mostly well-written.   Besides the corrections done during the rebuttal, in further discussion with the authors, I raised a concern that the work must make additional assumptions about the support of the induced subgraph distributions that were not clearly stated in the paper: The work makes the assumption that there is enough training data such that all spurious induced subgraph patterns $S$ that are smaller than the truly correlated induced subgraph $C$ can be identified as spurious. The authors promised to make this into a clearly demarcated assumption since it a key requirement for the method to work.
Below are multiple reviews of a paper. This paper only performs a comprehensive ablation study to assess the advantage of using the parallel transformers. This paper lacks a comparison with other methods of domain generalization. Authors claim proposed method is only suitable for segmentation tasks in tubular objects.The article is well written and tackles a very interesting problem for the community in vessel segmentation. The VFT architecture description lacks details. The authors should have tried to train their approach on another dataset than drive and test it on the two others.The idea of using the Hessian matrix, its eigenvalues, and eigenvectors for vesselness analysis is not novel and was explored in the past. The authors use public datasets, which increases the reproducibility.The design of hypothesizing that the minor eigenvector of the Hessian matrix sufficiently represents the vessels looks interesting to me. The number of compared methods in Table 2 are limited. Previous domain adaption methods are encouraged to be presented in the revision to strengthen the whole paper.	The authors have clearly clarified the issues raised by the reviewers. Overall, all reviewers are satisfied with the response given by the authors and are glad to see that the quality of the paper has been improved substantially. The rebuttal looks reasonable and correct to me.
Below are multiple reviews of a paper. This paper presents an investigation of perplexity-efficiency tradeoffs in deploying a QRNN neural language model to mobile devices. The top-line 40% savings for 17% perplexity increase seems fairly weak to me.This paper proposes to evaluate the accuracy-efficiency trade off in QRNN language model though pruning the filters using four different methods. During evaluation, it uses energy consumption on a Raspberry Pi as an efficiency metric. Directly dropping filters make the accuracy of the models worse.In this paper, the authors investigate the accuracy-efficiency tradeoff for neural language models. The authors consider the QRNNs and SRUs for this purpose and use standard datasets for their analysis. I am torn about this paper. On one hand, I feel that the analysis is interesting, thoughtful and detailed; the power usage statistics bring	The area chair agrees with the authors and the reviewers that the topic of this work is relevant and important. The area chair however shares the concerns of the reviewers about the setup and the empirical evaluation: - Having one model that can be pruned to varying sizes at run-time is convenient, but in practice it is likely to be OK to do the pruning at training time. In light of this, the empirical results are not so impressive. - Without quantization, distillation and fused ops, the value of the empirical results seems questionable as these are important and well-known techniques that are often used in practice. A more thorough evaluation that includes these techniques would make the paper much stronger.
Below are multiple reviews of a paper. This paper proposes a planning algorithm for a restricted class of POMDPs. Sensing decisions do not have any bearing on the hidden state evolution, or any material cost in terms of reward. The key observation is that the entropy minimization step is submodular and can be approximated greedily.This work addresses the problem of decomposing the observation acquisition from action planning in POMDPs. Unfortunately, the paper has two major weaknesses. First it is hindered by a confusing motivation, and the lack of clarity on the real purpose of the work is a problem throughout. Second the experiments are insufficient given current standards in the literature.The authors propose a new form of POMDPs called AP2-POMDP, which takes active perception into account. The authors also propose a novel perception-aware point-based value iteration to calculate the value function.	This was a borderline paper and a very difficult decision to make.  The paper addresses a potentially interesting problem in approximate POMDP planning, based on simplifying assumptions that perception can be decoupled from action and that a set of sensors exhibits certain conditional independence structure.  As a result, a simple approach can be devised that incorporates a simple greedy perception method within a point-based value iteration scheme.  Unfortunately, the assumptions the paper makes are so strong and seemingly artificial to the extent that they appear reverse engineered to the use of a simple perception heuristic.  In principle, such a simplification might not be a problem if the resulting formulation captured practically important scenarios, but that was not convincingly achieved in this paper---indeed, another major limitation of the paper is its weak motivation.  In more detail, the proposed approach relies on decoupling of perception and action, which is a restrictive assumption that bypasses the core issue of exploration versus exploitation in POMDPS.  As model of active perception, the proposal is simplistic and somewhat artificial; the motivation for the particular cost model (cardinality of the sensor set) is particularly weak---a point that was not convincingly defended in the discussion.  Perhaps the biggest underlying weakness is the experimental evaluation, which is inadequate to support a claim that the proposed methods show meaningful advantages over state-of-the-art approaches in important scenarios.  A reviewer also raised legitimate questions about the strength of the theoretical analysis.  In the end, the reviewers did not disagree on any substantive technical matter, but nevertheless did disagree in their assessments of the significance of the contribution.  This is clearly a borderline paper, which on the positive side, was competently executed, but on the negative side, is pursuing an artificial scenario that enables a particularly simple algorithmic approach.  Despite the lack of consensus, a difficult decision has to be made nonetheless.  In the end, my judgement is that the paper is not yet strong enough for publication.  I would recommend the authors significantly strengthen the experimental evaluation to cover off at least two of the major shortcomings of the current paper: (1) The true utility of the proposed method needs to be better established against stronger baselines in more realistic scenarios.  (2) The relevance of the restrictive assumptions needs to be more convincingly established by providing concrete, realistic and more challenging case studies where the proposed techniques are still applicable.  The paper would also be improved if the theoretical analysis could be strengthened to better address the criticisms of Reviewer 4.
Below are multiple reviews of a paper. The paper investigates intersection of federated learning and distant supervision of knowledge graphs from texts. The main innovation is a simple yet empirically effective denoising rule that selects only the sentences deemed to be the most reliable for learning.This paper addresses relation extraction problem for distributed platforms for privacy concerns. Authors propose to leverage federated learning with denoising techinques for better performance. The relation extractor is set to the conventional piece-wise CNN.The proposed Lazy Multi-instance Learning approach identifies reliable sentences for the same entity pairs across platforms to denoise distantly supervised data. The proposed approach has been applied on two relation extraction datasets and has reported gains.This paper explores relation extraction with distant supervision in the federated setting. It focuses on handling the label noise problem from automatic distant supervision by Multiple Instance Learning-based methods and proposes Lazy MIL.This paper introduced a new federated scenario for distantly supervised relation extraction where extractions come from multiple private resources. By only sharing scores rather than the full text, data privacy is protected. Experiments over two datasets show promising results.	The paper studies Distantly Supervised Relation Extraction(DSRE) in distributed settings. Though DSRE has been studied in Centralized setting it has not been studied in distributed platform. This  paper leverages the federated learning setup for this problem and proposes to use Lazy MIL for this purpose.  The paper  identifies the main challenge as label noise but does not attempt to characterise the severity of the problem vis-a-vis the centralised setup.  Though intuitive but a formal approach would have helped in understanding the importance of the derived results better.
Below are multiple reviews of a paper. This paper aims to address challenging stable crystal materials generation problems via diffusion variational autoencoder with graph representation learning. Several recent advances in generative models and GNN are combined together to develop the entire workflow from data distribution learning to sample generation.The paper proposes a score-based Diffusion Variational Autoencoder to generate the periodic structure of stable materials. The proposed model is SE(3) equivariant and periodic boundary condition-sensitive.The paper proposed a new generative model for 3D periodic material molecular structure. Experiments demonstrate the model can successfully generate valid and realistic material. The paper is well-written and easy to follow.The paper proposes an approach to generate stable crystal structures using variational autoencoders without having to train on out-of-equilibrium data. The approach is well motivated and novel.	This paper introduces a model, named Crystal Diffusion Variational Autoencoder (CDVAE), that can learn to sample valid material structures. It accounts for known symmetries (SE(3), permutation) of the structure via SE(3)-equivariant GNNs.  The proposed model is a complicated combination of many existing models / modeling techniques (VAEs, NCSNs, diffusion models) but it is not entirely ad hoc; the revised paper does a reasonable job in justifying the many different modeling choices made.  Existing model components, often designed in the context of molecule generation, do not account for the periodicity of the crystal's lattice structure; so this paper introduces modifications to account for this periodicity.  The paper evaluates the model on several datasets and also introduces new benchmarks that can be used for further research. The experimental results look promising but there are a few remaining clarity issues with the metrics used (cf. reviews).
Below are multiple reviews of a paper. This paper gives further analysis on dropout and explains why it works. Hinton et al. already showed some analysis. This paper also introduced a new gradient acceleration in activation function (GAAF)The experiments section 5 presents very weak results. Authors randomly introduce BatchNorm into one of the experiment. The experimental details are almost nil.The proposed resolution, to add this discontinuous step function in (7) with floor is a very interesting idea backed by good experimental results. However, I think the main effect is in adding noise, since the gradient with respect to this function is not meaningful.	Reviewers are in a consensus and recommended to reject. Please take reviewers' comments into consideration to improve your submission should you decide to resubmit.
Below are multiple reviews of a paper. LIPS is a platform for users to perform simulations of spcefic kinds, power grid and the pneumatic. ML models are used to fit some controlling parameters used in the simulation engines. Physical simulations are becoming an important interface marrying ML and Science.This paper presents a benchmark for applying machine learning techniques to speed up industrial physical simulation. The evaluation criteria effectively target metrics to compare against existing state of the art methods. The authors provide an API for access to the data and scripts to reproduce results.The paper introduces a set of datasets for learning the industrial physical simulation. The proposed datasets are targeted at two real-world applications: power grid and pneumatic simulation of tires.This paper proposes a simulation for industry use cases (e.g., Power System Operators) as opposed to general-purpose simulation tasks. They also provide an open-source benchmarking suite and a public leaderboard.	This work introduce a new benchmark to evaluate machine learning techniques for physical simulation. Based on two real-world applications (power grid and pneumatic simulation), the authors clarified the research questions and define evaluation metrics. Existing ML-based methods do not perform well on the proposed datasets. Overall all reviewer agreed that this work proposes a promising benchmark and I think the proposed benchmark can be useful in real-world application. Even though one reviewer has some concerns on details and setups, the authors provided detailed response to address them. For this reason, I'd like to recommend accept.
Below are multiple reviews of a paper. This paper proposes gradient based weighting strategies for synchronous (SPFL) and asynch (PLGA) personalized Federated Learning (FL) Authors also provide experimental results comparing their methods to baselines on many benchmark datasets.This paper proposed a personalized federated learning algorithm. It takes into account the similarity of gradient of different users to update the model. The authors study their method in various numerical settings.This paper proposes two methods for personalized federated learning. The two approaches are SPFL (synchronous) and PLGA (asynchronous) The approaches are illustrated on small image classification tasks. The proposed approaches and initial results presented seem promising, but they are very far from solving the problem.This paper proposed two personalized federated learning algorithms: SPFL, PLGA. The proposed method requires modeling the pair-wise similarity between each client. This requires maintaining a potential large matrix, maintains the identity of each client, and cannot be applied to new clients.	This paper proposed a personalized federated learning algorithm which takes into account the similarity of gradient of different users to update the model. Although the ideas presented are intuitive, the algorithms have fundamental limitations, for example, they may cause large overhead of memory, communication and computation, and are unsuitable for privacy-preserving machine learning. In addition, there are no rigorous analysis and the experiments are not convincing. This is a clear rejection.
Below are multiple reviews of a paper. This work proposes a model architecture for reading comprehension based on a large number of binary features corresponding to propositional overlap. These features are arranged into tables which are passed into a few convolutional filters to yield representations. The results are unclear what we can learn from the results.The paper presents a model for the supporting sentence prediction task in machine reading comprehension. To enhance interpretability of the model, the paper proposes to use the semantic relations among a question, target sentence, and sentences in an article as features.The paper proposes to use the predicate argument structure of sentences in order to improve the results of a question answering system on the HotpotQAdataset. The main contribution is a method to encode whether the fillers of predicate arguments match across supporting sentences and the question.The authors propose a method for adding interpretable semantic features for a Machine Reading Comprehension model. The goal is to use semantic role labeling annotation to produce features used on a neural model for a language downstream task. The study shows that the semantic features used to train Question Answering model performs comparable to related work.	All reviewers agree that this paper does not meet the bar for ICLR. The reviewers provide detailed feedback to the authors on how to improve the writing as well as the overall content of the paper.
Below are multiple reviews of a paper. BadPrompt is designed as a lightweight and task-adaptive few-shot backdoor attack against continuous prompts. There are two main modules in BadPrompt: 1. trigger candidate generation and 2. adaptive trigger optimization.This paper investigates backdoor attacks on the continuous prompt learning paradigm. Authors assume the attacker can access the downstream data and model, returning a backdoored model to the users. Existing attacks fail due to the few-shot setting of prompt learning.We propose BadPrompt, a lightweight and task-adaptive algorithm for applying backdoor attacks in the form of prompts. It generates candidates for triggers that are invisible and adaptive to the samples that are most effective for attacks. They use Gumbel Softmax to approximate the sample vector for the trigger.This paper studies a backdoor attack on continuous prompt-based learning. It first reveals that the effects of some simple and typical backdoor attacks are limited in few-shot learning settings. Then it proposes BadPrompt to generate some efficient triggers.	This paper conducts a study on the vulnerability of the continuous prompt learning algorithm to backdoor attacks. The authors have made a few interesting observations, such as that the few-shot scenario poses challenge to backdoor attacks. The authors then propose BadPrompt for backdoor attacking continuous prompts. Overall the paper is well-written, and the perspective and insights provided in the paper are interesting and could be valuable to the community.
Below are multiple reviews of a paper. The paper touches a relatively important problem in deep RL, namely how to reduce variance of policies with different random seeds. The experiments on MuJoCo robotic control tasks have shown the effectiveness of the proposed methods. The author has resolved most of my conerns and agreed to update the manuscript to address the issues.The paper posits that the Bellman optimality operator has multiple fixed-points. It becomes apparent that in defining a discounted MDP, the paper allows discount factors in the infinite-horizon setting contrary to conventional wisdom in RL.This work proposes to help a policy network stably find a stationary policy by making an analogy between an MDP and a quantum K-spin Ising model. The paper empirically evaluated the performance of the newly proposed method on 6 MuJoCo tasks.This paper aims to resolve the challenge that Bellman's optimality equation has multiple fixed points, which leads to instability in deriving its solution. To this end, the authors first observe that the evaluation of cumulative reward function can be reformulated into a K-spin Ising model. The authors then propose to use the energy of such	The paper proposes to add a regularisation term H to RL algorithms in order to work around issues caused by the multiple fixed points of the Bellman’s optimality equation. The added H term is inspired by quantum field theory, specifically the K-spin Ising model. All reviewers thought this was an interesting idea, but by the end of the review period, there remained some problems with this paper. Indeed, this paper is not a theory paper, and there is no mathematical proof that the added H term does accomplish the stated goal of variance reduction. This leaves us with empirical evidence. Unfortunately, as was pointed out by reviewers, "Experiment is limited to the 6 MuJoCo tasks", which is not enough to convince that the algorithm should generally work. Finally, many reviewers were confused by the claim that PPO solves the Bellman Optimality Equation. By the end of the review, not all reviewers were convinced this problem had been resolved. This point should be clarified, and it would be better for the paper to go through a new round of reviews before being accepted for publication.
Below are multiple reviews of a paper. This paper proposes a novel convolution-based architecture that could utilize convolutional attention in an effective way to encode contextual information for the segmentation task. The main contributions of this paper are (1) a new tailored network architecture (SegNeXt) that envokes spatial attention via multi-scale convolution features.This paper presents SegNeXt, a new convolution-based model for semantic segmentation. The authors evaluate their proposed architecture on several datasets like ADE20K, Cityscapes, Pascal VOC, Pascal context, COCOStuff and iSAID.This paper presents SegNeXt, a simple convolutional network architecture for semantic segmentation. The main contribution of this paper is replacing the standard convolutions and self-attention with the spatial attention proposed in this paper. Experimental results demonstrate that SegNext surpasses current state-of-the-art transformer-basedConvolutional attention is a more efficient and effective way to encode contextual information than the self-attention mechanism in transformers. SegNeXt improves the performance of previous state-of-the-art methods on popular benchmarks.	Four knowledgeable referees reviewed this submission. The reviews raised concerns about the novelty of the proposed approach (rY1T, S4w5), the motivation of the model design and properties (mij9, r2Bq), and the empirical evidence to support some of the effectiveness and efficiency claims (rY1T, r2Bq, S4w5). The rebuttal addresses the reviewers' concerns by (1) highlighting the differences of the proposed approach with ConvNext, (2) providing additional comparisons with state-of-the-art methods as suggested by the reviewers, (3) performing ablations of the MSCA design which empirically emphasize its advantages, and (4) partially clarifying the motivation. The authors engage in discussion with the reviewers and provide additional clarifications (e.g. what will be introduced in the main body of the paper, and whether the code will be released). During the discussion phase, the reviewers show some hesitations wrt novelty of the proposed approach which is perceived as incremental wrt ConvNext. However, the reviewers agree that the paper is well written, the approach is simple and appears effective, and the experimental evidence is extensive and supports the claims made in the manuscript. The reviewers appreciate the benchmarking efforts of this work and lean towards acceptance. The AC agrees with the reviewers' assessment that the strength of this paper lies in its extensive experimental validation, and recommends to accept.
Below are multiple reviews of a paper. The authors investigate the value of fully connected layers at the end of convolutional neural networks in the small data regime. They demonstrate that the addition of these layers significantly improves model quality.This paper proposes a training method that involves a module plugged into the final features of a backbone as an additional classification head for joint training with the existing classification head. Along with the original head, the newly added head also pass through the softmax for the cross entropy loss. The training is performed with the summation of the two cross-This paper shows that one can improve accuracy in the low-data regime by adding fully connected layers to CNNs during training and distilling knowledge to a classification head. I found the method proposed in this paper very interesting and the results showed clear improvements over the base network. However, the lack of knowledge distillation baselines and theoretical backing	The paper shows that using final fully-connected layers helps the generalization of convolutional neural networks in low-data regimes. The addition of these layers significantly improves model quality resulting in a network with the same number of parameters and better generalization performance.  Initially reviewers had mixed evaluation of the paper. All the reviewers saw that the proposed method is simple and easy to follow, at the same time providing clear improvements over baselines. Also agreed that the results are "significant" and "surprising" effect. There were some concerns raised by the reviewers but the author's rebuttal mostly addressed and improved the paper with sufficiently more experiments and analysis supporting the main claim. Reviewer `DX6o` mentioned that there are few updates promised by the authors which can't be validated until camera ready but it does not seem to warrant block publication.   The Author-Reviewer discussion period was active and the authors did a great job clearing various concerns and questions and all reviewers agreed to support acceptance of the paper. The paper demonstrates a simple yet effective method for small data regime which would be interesting to the broad NeurIPS audience both for practitioners as well as researchers.
Below are multiple reviews of a paper. The paper proposes a method to regularize the training of time-series forecasting models. It extends the recently proposed flooding method which prevents the training loss from dropping to zero.This paper proposes an effective regularization method called WaveBound for time series forecasting, targeting on the overfitting problem of deep networks. WaveBound uses two networks throughout the training phase. The first network provides lower bounds of errors for the second network. Experimental results show that WaveBound improves the performance of several time-series forecasting models.WaveBound is a new regularization method to prevent unstable training and over-fitting for time series forecasting problems by encouraging a non-zero training loss. The error bound is automatically customized.This paper presents a regularization method for time series modeling aimed at preventing overfitting in deep learning methods. This method extends flooding regularization, which uses a constant target training risk, to use an exponential moving average of past models, yielding a level of training risk that is adaptive.	The reviewers highlight the novelty of the method, the clarity of writing, and the consistent performance improvements over baselines. Initial concerns by the reviewers related to missing related work, missing empirical evaluation within the more mature short-term forecasting experimental paradigm, and missing empirical comparisons (comparing to reversible instance norm, isolation of the effect of EMA) were addressed by the authors during the discussion period. Some concerns around the overall motivation behind the proposed approach remain, but are outweighed by the empirical effectiveness.
Below are multiple reviews of a paper. The proposed method has two stages, 1) generate synonym candidates from WordNet and then 2) use a binary classifier to filter the candidates. The method is simple and effective.The paper presents an interesting approach to taxonomy extension. It is based on identifying synonyms for component words of multi-word terms. The approach seems to rely very much on WordNet.The authors describe and evaluate two approaches to collecting alternative aliases (synonyms) for entities in a taxonomy. Mitigating vocabulary mismatch in search applications provides a good motivating use case.	The work provides an interesting and yet rather straightforward approach to synonym expansion that relies on a combination of user queries and existing background knowledge in terms of WordNet. The evaluation shows good results for an interesting domain in practice. It would be great if the crowd sourced data would be released. I also wonder if the paper actually covered enough of the related work in particular with respect to synonym expansion from information retrieval.   Overall, I think the task itself and the resource would be interesting to have at the conference although it's not a radical innovation, hence, I would recommend it for the poster session.
Below are multiple reviews of a paper. The provided code is well-documented thus enhancing the reproducibility. The presented approach seems suitable for the problem at hand and the experimental results are fair.The paper proposes a novel algorithm for an interesting research question. It is not clear if a regret bound for the minimax regret optimal policy is bounded and its value.Most RMAB methods assume that the underlying system dynamics are known, which is rarely the case in many real-world settings. Transition dynamics of states are often estimated with significant uncertainty, and cannot be point-identified. This paper proposes methods to address this challenge by learning a robust policy.	Meta Review: This paper applies reinforcement learning (RL) to learning a robust policy in restless bandits, which performs well in the worst case. This is a major departure from the traditional approaches to (restless) bandits, where the policy is designed manually to have low regret in theory. While the authors analyzed an idealized variant of their approach, the strengths are generality and being data-adaptive. None of the reviewers had major concerns. I also looked at the paper. My comment is that the authors should present their work better in the context of other attempts to learn bandit policies from data, such as  Algorithms for the multi-armed bandit problem: https://arxiv.org/pdf/1402.6028.pdf  Differentiable meta-learning of bandit policies: https://proceedings.neurips.cc/paper/2020/file/171ae1bbb81475eb96287dd78565b38b-Paper.pdf  Policy gradient optimization of Thompson sampling policies: https://arxiv.org/pdf/2006.16507.pdf  I support acceptance of this paper.
Below are multiple reviews of a paper. This paper proposes to formulate the unfairness as the smallest OT cost between the score function of the classifier and the closest fair score function over the same data. The author proposes to compute the OT cost as differentiable fairness regularizer.Optimal Transport to Fairness (OTF) is used to quantify the unfairness of a probabilistic classifier. OTF can be computed as a differentiable fairness regularizer for a class of linear fairness definitions. In experiments, OTF shows better fairness-prediction trade-off.This paper proposed to quantify the unfairness of a classifier in machine learning by the Optimal Transport (OT) theory. The empirical results on two datasets indicate that the proposed methods achieve a better AUC-fairness trade-off under the demographic disparity (DP) and equalized odds (EO) metrics.	Reviewers are fairly positive about this paper. This paper takes an optimal transport approach to projecting an unfair score function to a fairness constrained set by minimizing transport cost. This addresses the issue of making similar changes to individuals with similar features instead of just post processing score thresholds to match the necessary fairness criteria. This work also provides a nice regularization term reflecting the OT cost to be optimized during training. They handle fairness measures that are linear in a certain sense.   Main concerns that were brought was:  a) Computational complexity : Due to pairwise transport and cost matrices being involved - reviewers were worried about time complexity. Answer from authors is to do batch computation which is reasonable.  b) More experimental validation was suggested. Authors responded to adding one additional evaluation. However, it would be great if authors could add additional evaluations before camera ready as there is plenty of time.  c) There was question about using unbiased Sinkhorn divergence . Authors clarified that this would lead to a multi level optimization problem while their approach is simpler.  I believe the concerns were adequately addressed and not major.   In any case, I reiterate to the authors to consider adding another evaluation on additional datasets as suggested by one of the reviewers before camera ready.
Below are multiple reviews of a paper. The experiments considered in the paper are mostly low-dimensional datasets. It remains unclear whether the proposed approach could scale to high-dimensional data.The authors present a thorough examination of the properties of NCE for the very small models introduced in section 3.1. The paper is definitely welcome as a foundation for a more thorough analysis on the optimality of the hyper-parameters.This is a paper with a very clear goal which it tackles very convincingly and with clarity. I can see no clear weaknesses of the paper. No obvious feedback to give to authors.This work demonstrates both theoretically and empirically that the optimal noise distribution in NCE is somewhat different from the data distribution, in contrast to the folklore that the good noise distribution should be data distribution. The main theorems of this paper (Theorems 1 and 2) assume relatively general situations (i)-(iii) The pilot	Meta Review: The reviewers and myself agree that this is an interesting theoretical paper on characterizing the optimal (in the sense of asymptotic sample complexity) noise distribution for noise contrastive estimation. Though the results are mostly derived for simple data distributions (e.g. Gaussian), some of the results are unexpected, and along with empirical verification, suggest that they could potentially generate insights for more complicated real-life settings.
Below are multiple reviews of a paper. This paper addresses an interesting topic relevant for the workshop. It is also well written and mostly easy to follow. I had some initial difficulties understanding Definition 2 in the described contexts of online re-planning and plan execution. The exact setting should be described more concisely early in the paper.The paper introduces a search algorithm for situations where new goals appear during the execution of a plan. The algorithm (SRE) plans while executing the plan for the previous goals. It looks for a plan that achieves the current and the next goal simultaneously.	Dear Authors, thank you very much for your submission. We are happy to inform you that we have decided to accept it and we look forward to your talk in the workshop. Please, go over the feedback in the reviews and correct or update your papers in time for the camera ready date (May 24). Best regards HSDIP organizers
Below are multiple reviews of a paper. The paper proposes to address system benchmarking across several tasks as a ranking optimization problem. It proposes a solution essentially based on aggregating preference rankings using Borda count. This is validated on synthetic data and using a large amount of real benchmarking on multiple NLP tasks.This paper proposes a ranking method for comparing NLP systems that does not simply take the average of target scores. The authors propose to use a method called Kemeny consensus in which Kendall distance or correlation is used for choosing the best permutation as a ranking candidate.The authors argue that the naive method of averaging task scores can be biased if the scores have different ranges. They advocate ranking in order of summed per-task ranks instead. A variant "two-level" algorithm is more robust to adding or dropping tasks.	The paper proposes to address system benchmarking across several tasks as a ranking optimization problem and proposes a solution essentially based on aggregating preference rankings using Borda count. This is validated on synthetic data and using a large amount of real benchmarking on multiple NLP tasks, illustrating the benefits of the proposed method over simple averaging. Reviewers questions regarding how ties are resolved, taking task difficulty, and use-case were addressed convincingly by the authors. I hope they revise their manuscript so that it is easier to follow, the results section is packed with information, too many graphs to the point where finding information is difficult. I would strongly urge the authors to remove some analyses in the appendix. It would be good to also tell us how the various systems are being evaluated.
Below are multiple reviews of a paper. The proposed method has been evaluated on several benchmarks. The size of the stacked image input is related to the number of $k$. The authors claim that the proposed method do not change the general network architecture.The proposed method is very simple and shows performance improvements across the board in the experiments when combined with other mix-up based techniques. There is no theoretical explanation of why the proposed method helps to improve performance.The method is simple and easy to implement. It can be used with other existing augmentation methods. The authors validated the method on multiple datasets, showing performance gain. The effect of StackMix is nontrivial.	Meta Review: AC read the paper, reviews, and responses. AC appreciates the simple and effective StackMix method that surpasses all existing baselines.  Though the average rating is below the acceptance bar, AC still recommends acceptance due to the comprehensive experimental results that may shed light on future research in the community. However, AC suggests that the authors do follow the negative comments, especially from Reviewer Z7zb, to improve the quality of the paper for publication.
Below are multiple reviews of a paper. The authors conducted a competition and analyzed how approaches tend to cheat so as to obtain higher FID scores. They propose a new metric — Memorization-Informed Frechet Inception Distance (MiFID) — which takes into account sample memorization w.r.t. a reference set.This paper studied the memorization issue of generative modeling. It proposed a benchmark for a publicGenerative modeling competition. It observed how participants attempted to game the FID.The paper investigates memorization/overfitting in GANs and proposes a new metric (MiFID) to identify memorization in trained GAN models automatically. The concept of memorization seems to be a bit obscure in some parts of the paper.	The paper proposes a competition on generative models on a new dataset to study memorization in generative models and propose a  new metric Memorization-Informed Frechet Inception Distance (MiFID).   While this is an important topic, reviewers raised multiple issues and concerns regarding 1)  the metric definition (that it needs to be max and not min, this was acknowledged in the rebuttal but not updated in the paper) , 2)  how this competition is ran in terms of the definition of "cheating",  that the setup is not controlled and only constraining the time of training 3)  the notion of MiFID is depending on the sets of samples considered and the feature extractor used.   Some other reviewers raised concerns that the paper is only concerned by FID and not other metrics , and that it was only verified on GANs.  We hope the authors will address those concerns and submit the paper to an upcoming venue.
Below are multiple reviews of a paper. IA-MARL is a novel and effective method leveraging a generative adversarial approach to a specific MARL problem with regard to missing training data. The imputation approach appears convincing and effective and poses some intriguing discussion points. I would appreciate if the authors could include some of these discussion points in the paper, where they see fit.This paper proposes an imputation-assisted multi-agent reinforcement learning (IA-MARL) method. It uses a generative adversarial imputation network to impute the missing data, and train the MARL method on the imputed data. Strengths: Clear writing in the Introduction.This paper develops an imputation method for missing data in multi-agent settings. The main idea is to train a GAN based generator that imputes missing data. The method seems fairly incremental and it's unclear to me how broadly applicable it is.The submission presents experiments for multi-agent particle environments. The submission is poorly written, to say the least. The appendix has some information about what hyperparameters the submission used.	The paper tackles the problem of missing data in centralized training multi-agent RL approaches. The authors propose 1) using generative adversarial imputation networks for imputing missing data and 2) discarding training data where data from multiple consecutive timesteps is missing.  Reviewers agreed that the problem of missing data in multi-agent RL is interesting. At the same time, several reviewers shared two main concerns about the experimental evaluation: * The lack of comparisons to baselines other than MADDPG, especially decentralized critic approaches. * The lack of experiments on non-toy domains such as SMAC.  The author response did not sufficiently address these concerns leaving the reviewers in agreement that the paper should not be accepted without these additional experiments.
Below are multiple reviews of a paper. Convolutional Neural Networks are biased towards either texture or shape according to the dataset used for training. If so, can we develop an approach that can do shape- texture debiased learning?The paper tackles the problem of an existing bias in the classification networks. The more items in the dataset easier to recognize using shape features, the more shape-biased the model will be.The authors propose a method to mitigate the bias towards either texture or shape, in convolutional network training. The method follows the idea from Geirhos et al (2019), but use images randomly sampled from the same dataset. The expected outcome would be - shape biased model underperforms; texture biased model, improves texture recognitionThe paper is extremely simple. It builds on the idea of Geirhos et al. 2019 to use style transfer to augment IN training data by mixing shape and texture information. This alone seem to provide a clear boost on IN and different variants.	After the rebuttal stage, three of four reviewers recommend acceptance, and one gives a borderline score but argues they lean positive. Concerns seem well addressed; the method is simple yet effective.
Below are multiple reviews of a paper. This paper investigates the impact of different calibration strategy on the performance of a deep ensemble. It presents both theoretical and empirical proof to show that well-calibrated ensemble member does guarantee calibration in the final ensemble.The paper makes an analysis of calibration in ensembles of deep learning models. The paper supports that a given ensemble cannot be more confident than the average individual members for regions where the ensemble is well calibrated.Reviewer: "I think the paper is useful, but I'm keeping my score at a 6 (instead of raising to a 7) "AnonReviewer1: The theory is interesting but it does not give us a lot of insides (maybe it's very subjective). The dynamic temperature scaling is not proofed to outperform the basslines. The writing quality needs to be improved.	This paper studies ensemble calibration and the relationship between the calibration of individual ensemble member models with the calibration of the resulting ensemble prediction.  The main theoretical result is that individual ensemble members should not be individually calibrated in order to have a well-calibrated ensemble prediction.  While other recent work has found this to be the case in empirical results, this paper substantiates the empirical results through theoretical results.   Pros: * Theoretical study of ensemble calibration with meaningful insights  Cons: * Contributions limited to theoretical study of known observation and dynamic temperature scaling. * Dynamic temperature scaling is not shown to outperform baseline methods. * Limited experimental validation: CIFAR-10/CIFAR-100.  The authors engaged in a extensive discussion with reviewers and made changes to their paper, including adding standard deviation results over multiple runs and the SKCE calibration measure.  Overall this is solid work and could be accepted to the conference; however, reviewers agree that parts of the work are lacking, in particular: 1. limited experimental evaluation (one type of task, one/two datasets only), and 2. given known literature the benefit of the derived theoretical results to practioners is not clear.  The discussions have been unable to resolve this disagreement.
Below are multiple reviews of a paper. This paper incorporate the popular contrastive with unsupervised learning from video. Multiple frames from the same video is used as positive pairs and frames from different videos is viewed as negative pair. The author also proposed a simple and effective ways to collect class-balanced and diverse video frame dataset.The paper combines ideas of using discrimination loss for unsupervised learning of image features. The authors create a dataset based on video with positive pairs for noise contrastive estimation. The experiments showcase this type of learned representation outperform alternatives not based on videos on a variety of tasks.This paper proposes an idea to use NCE for videos where positive/negative training pairs are created by temporally sampling different frames in the video. I think there is some potential in the paper, but needs more to be convincing. Currently, I'm not convinced by the experiments.	This paper was a difficult decision. Overall it seems to be a quality paper, well written and with many experiments, in particular evaluating learned representations across various tasks and datasets. The authors were also quite courteous in their replies which is appreciated. I really like the point the paper makes about video as a natural augmentation and I find that novel amid the recent NCE surge, where most papers rely critically on augmentation. R4 was also very positive about the paper overall concept.  In terms of paper weaknesses two of the reviewers voted for rejection because the paper ignores existing work on contrastive learning from videos. The authors rebuttal is that they are the first evaluating on images, not on videos. All reviewers also point out limited technical novelty, which the authors acknowledge. Finally, R1 is not very confident about the experiments.  Overall, and after calibration, the appropriate recommendation seems to be rejection.
Below are multiple reviews of a paper. In this paper, the authors propose to solve the gradient conflict in training and dense activation in inference in multi-task learning using a co-designed mixture-of-expert model. Experiments on GPU and FPGA show the proposed co-design achieves better performance than existing methods.The paper presents a multi-task MoE and model-accelerator co-design. At the algorithm level, the method adopts a task-level mixture-of-expert approach that can effectively reduce training and inference cost. The proposed reordering reduces memory footprint at small overheads.This paper studies a novel setting of MTL: training with multiple tasks hoping them to boost each other, and inference with a single task each time. The setting is practically convincing as most MTL systems switch between tasks. The authors presented a model-accelerator co-design framework involving both algorithm and hardware innovations.The model consists of a mixture of vision transformer experts that are sparsely activated by a GELU activation function. The main innovation is that mixture of expert layers are computed expert-by-expert.	This paper presents a model-accelerator co-design framework to enable on-device Multi-task Learning (MTL). At the model level, customized mixture-of-expert (MOE) layers are introduced for MTL, which alleviate gradient conflict at training time and improve the efficiency at inference time via sparse activation. At the accelerator level, the paper proposes computation reordering which allows zero-overhead switching between tasks. The algorithm is verified the on popular multi-task datasets, and the accelerator is implemented on commercial FPGAs, demonstrating improved efficiency.  The paper is very well written, the details on the algorithm and hardware implementation are clearly explained. The author chose a particular setting of MTL, then design the model and tailor the parameters to enable efficient on-device MTL. The work is complete, covering from algorithm design to hardware implementation with sufficient innovations.   Reviewers have raised concerns such as 1). Evaluation on small datasets. During rebuttal period, the authors provide more experimental results from the large-scale Taskonomy dataset. 2). Overclaiming. For example, double buffering is a well-known technique for dataflow optimization. The technique itself is by no means novel. However, I think using it to solve a practical problem still has value.  Overall, it is a solid paper and is recommended for acceptance.
Below are multiple reviews of a paper. This paper presents a simple (and convincing) idea that neural networks can be employed to "memorize" the surface geometry of 3D objects. Such memorized networks -- dubbed neural implicits -- exhibit significantly lower memory requirements, while allowing for better surface approximation.This paper discusses implicit SDF representations encoded by neural networks. It is written in opposition to Park et al. 2019, which I found useless and tiring to read. The idea of encoding an implicit function in the weights of a network without latent code is not new at all.The paper proposes a weight-encoded neural implicit representation for 3D shapes. The approach outperforms latent encoded shape representations such as DeepSDF in terms of compression and accuracy.	The paper proposes how weight-encoded neural implicit can be strong 3D shape representations. A neural network is trained such that it overfits over a single shape, and the weights of such network is a great representation for the 3D shape. Results are shown on signed distance field (SDF) generation from meshes.  Strengths: - an interesting idea for generating compact representations of 3D shapes - Will further foster several conversations within the deep learning community  Weaknesses: - Very limited evaluation to support the authors  claims, particularly against other traditional learnable 3D representations
Below are multiple reviews of a paper. Proposed method is called OPEN for Orthogonal Propagation with Ego-Network modeling. The basic idea relies on dimension reduction through principal component analysis. Theoretical and empirical evidence suggests the effectiveness of the proposed method.This submission studies local refinement in GNNs via orthogonal propagation with ego-net modeling. The proposed methods are designed to address the problem of irrelevant propagation. Experimental results on multiple real-world datasets were provided.OPEN is a new GNN model to tackle the irrelevant propagations issues. By design, the propagation weights from different channels are orthogonal in OPEN, therefore it encourages diversity and reduces overfitting risk.	Reviewers recommended borderline accept, borderline reject, and accept. Reviewers found the article studies one of the main issues of GNNs and proposes a simple but effective solution method supported by extensive experimental evaluation. There were some reservations about the comparison with other methods and the theoretical analysis. While some of these items could be addressed during the discussion period, leading to updated more favorable ratings, some reservations about the theoretical part persisted. There were also persisting disagreements about the novelty and about the issues that are solved by the proposed method compared with previous methods. All together I found that the merits outweighed the shortcomings and hence am recommending accept. However, I strongly encourage the authors to carefully consider the reviewers comments when preparing the final manuscript, particularly that they work on the discussion and clarification of the novelty of the method, particularly the issues between over smoothing and overfitting and the corresponding presentation in the work, and the reservations on the theoretical part.
Below are multiple reviews of a paper. The authors adopt the prior that features that correspond to an object's appearance should preserve frequency histograms. They learn a library of convolutional filters using a contrastive learning framework. They provide many convincing baselines and comparisons to related work.The authors build upon prior work (FineGAN) in intra-domain disentanglement to extend to inter- domain transfer of separate attributes. Since no ground truth data exists for inter-domain transfer, they use contrastive losses to enforce similar statistics of low-level filter activations.The paper proposed a method to learn disentangled representation of shape and appearance for cross-domain (different object categories) data. The method uses contrastive learning combined with normalized temperature-scaled cross-entropy loss.The submission describes a method to disentangle shape and appearance of images across two domains. New images can be generated that have appearance and shape from either of these domains while still being visually convincing. The results are compared to some relevant baselines and show moderate improvements over those.	The paper swaps characteristics of an object in one image onto those of another object in another image--for example, adding fur to a car.  The authors give some examples where the task could be useful.  Further, they successfully argue  that this task is an illustration that the disentanglement task has been done well.  Two reviewers argued for acceptance, two for just-below-the-bar rejection.  The 2nd of those in favor of rejection engaged thoughtfully with the authors and raised the score by 1 after that engagement.  We have decided to accept the submission as a poster.
Below are multiple reviews of a paper. The main problem with the similarity function learning models is the pairwise component of the loss function which grows quadratically with the training set. The existing stochastic approximations which are agnostic to training set size have high variance and this in-turn results in poor convergence and generalisation. This paper presents a new stochThis paper proposes an efficient algorithm to learn neural embedding models with a dot-product structure over very large corpora. The main method is to reformulate the objective function in terms of generalized Gramiam matrices, and maintain estimates of those matrices in the training process.This paper proposes a method for estimating non-linear similarities between items using Gramian estimation. Two algorithms are proposed which allow for estimation in the stochastic / online setting. Experiments are presented which appear to show good performance on some standard benchmark tasks.	This paper presents methods to scale learning of embedding models estimated using neural networks. The main idea is to work with Gram matrices whose sizes depend on the length of the embedding. Building upon existing works like SAG algorithm, the paper proposes two new stochastic methods for learning using stochastic estimates of Gram matrices.   Reviewers find the paper interesting and useful, although have given many suggestions to improve the presentation and experiments. For this reason, I recommend to accept this paper.  A small note: SAG algorithm was originally proposed in 2013. The paper only cites the 2017 version. Please include the 2013 version as well.
Below are multiple reviews of a paper. Direct Kolen-Pollack learning (KP) is an alternative to Direct Feedback Alignment (DFA) KP uses weight decay on both the forward and backward matrices to encourage symmetry between the two. DKP shows an interesting improvement over DFA for CNNs but results and analysis are slightly insufficient.This work proposes an approach to update feedback weights in DFA using modification of kolen-pollack method, which helps in training deep CNN network. It is well known that DFA in its vanilla form suffer whenever tested with deep networks.DFA does not work well for deep networks and CNNs. This work proposed a possible improvement for this problem. My main concern is the novelty of this paper.	This paper investigates an improvement to the direct feedback alignment (DFA) algorithm where the "backward weights" are learned instead of being fixed random matrices. The proposed approach essentially applies the technique of DFA to Kolen-Pollack learning. While reviewers found the paper reasonably clear and thought the experiments were acceptable, there were significant concerns about the novelty of the approach and the fact that the proposed approach was a straightforward combination of existing ideas. Further, the paper could have done a better job situating (and applying) the proposed method to DFA variants that have been proposed since the original DFA paper came out.
Below are multiple reviews of a paper. This paper addresses the problem of learning generalizable context in RL. It suggests learning disentangled context representation of each confounding in the environment. The experiments are comprehensive and the results are impressive.This paper studies a contextual reinforcement learning (RL) setting where the environment dynamics are parameterized by independent factors, which the authors refer to as “confounders” In each episode, the underlying factors can vary. They present a method that learns to encode the RL agent’s current trajectory into a set of independent contextThis paper tackles the problem of generalization in MDPs where dynamics changes are assumed to be caused by multiple independent factors, denoted as context. The proposed framework (DOMINO) learns a context encoder that maps trajectories to a latent context via decomposed mutual information.This paper proposes a decomposed mutual information method to learn disentangled context information. The experimental experiments demonstrate that the proposed method can achieve better performance than the previous methods. The writing of this paper is pretty well, and the idea of it is easy to follow.	This paper proposes DOMINO, an optimization framework, for contextual meta reinforcement learning. The reviewers generally agree that the paper is well written, the idea is novel and interesting, the evaluation is comprehensive and the results are impressive. Reviewers also raised a few concerns in the initial reviews, such as the proof of Lemma 1 and Theorem 1, and the mathematical definitions. Throughout the discussion phase, most of these concerns were sufficiently addressed, and the review scores were increased accordingly. Overall, the quality of the revised paper has improved significantly during the rebuttal. Thus, I recommend accepting this paper. Please incorporate the remaining reviewers' suggestions in the future version of this paper.
Below are multiple reviews of a paper. This is largely an experimental paper, proposing and evaluating various modifications of variational recurrent models towards obtaining sequence data representations that are effective in downstream tasks. The highlighted contribution is a "stochastic generation" training procedure in which the training objective evaluates the reconstruction of output sequence elements from individual latent variables independently.The authors claim to propose a family of methods and generative models that are suited better for downstream tasks than previously proposed approaches. A "bad" variational posterior is used because it is unclear how to get vectorial features otherwise. An adhoc likelihood function is used.This paper proposes a new variational recurrent model for learning sequences. Instead of having latent variables that are dependent on the neighbors, this paper proposes to use independent latent variables with observations that are generated from multiple latent variables.	This paper heavily modifies standard time-series-VAE models to improve their representation learning abilities.  However, the resulting model seems like an ad-hoc combination of tricks that lose most of the nice properties of VAEs.  The resulting method does not appear to be useful enough to justify itself, and it's not clear that the same ends couldn't be pursued using simpler, more general, and computationally cheaper approaches.
Below are multiple reviews of a paper. In this work generative models using a GP as prior and a deep network as likelihood (GP-DGMs) are considered. In the VAE formalism for inference, the novelty of this paper is located in the encoder. Sparsity is obtained using inducing inputs and the missing observations are handled through the use of deep setsThis paper attempts to enhance the inference in multi-output GPs on previously unobserved data using amortised variational inference. This model is proposed to overcome the shortcomings in current GP-DGMs.The model proposed by the paper is a multi-task, multi-output GP, with likelihoods driven by a decoder network. The paper is contributes to the community and the work is correct, so *accept*.	The paper proposes a method for inference in models with GP priors and neural network likelihoods for multi-output modelling, dealing with the problem of scalability and missing data. The paper builds upon previous work on inducing variables for scalability on GP models and inference networks for amortization (reducing the number of parameters to estimate) and dealing with missing data.  There are several concerns about the paper in terms of generality/flexibility of the approach, as the proposed model shares the NN parameters across tasks and the results on the small datasets do not show improvements wrt baseline such as GPAR. The authors’ comments provide somewhat satisfactory replies to these issues. Nonetheless, the major drawback of this paper is its novelty as the ideas on the paper have been explored extensively in the GP literature. Although the authors do make a case for scalability when using inference networks, there are other previous works that perhaps the authors are unaware of, for example, https://arxiv.org/abs/1905.10969   and even more sophisticated inference algorithms than can serve as truly state-of-the-art competing approaches (for example based on stochastic gradient Hamiltonian Monte Carlo, https://arxiv.org/abs/1806.05490).
Below are multiple reviews of a paper. The ARMAC algorithm using the off-policy policy evaluation algorithm TreeBackup to estimate value function and use regret matching to get the next joint policy.The authors adopt the idea from gaming theory to reinforcement learning. They propose a new algorithm that uses the previous policy to update the current training without using importance sampling. Experiments show that the proposed algorithm cannot only work on the single-player setting. However, I have the following concerns about the algorithms.This paper considers the problem of counterfactual regret minimization and proposes an algorithm that does not use the importance sampling procedure. They propose a new algorithm that uses the previously used policies as a buffer and replays those policies to learn a new policy. The algorithm is also claimed to be highly scalable for games with large state-action pairs	This paper introduces a new algorithm to solve game, more or less similar (in the general idea, yet differences are interesting) than CFR. The concept is to sample from past policies to generate trajectories and update sequentially (via regret matching).  The three reviewers gave rather lukewarm reviews, with possible suggestions of improvements (that were more or less declined by the authors for those proposed by Rev3 and Rev4; the added material focuses more on the clarity of the text than on the content itself).  I have also read the paper, and find it quite difficult to assess. At the end, it is not clear to a reader whether ARMAC is the new state of the art, or just a "variant" of CFR that will be soon forgotten. The performances do not seem astonishing (at least against NSFP) and even though DREAM might not be satisfactory to the authors (EDIT POST DISCUSSION: actually, DREAM is a valid competitor and must be included in the comparative study), it would have been nice to provide some comparison. Maybe the issue is the writing of the paper that could and should be improved so that it is clearer what are the different building blocks of ARMAC (and their respective importance).  If ARMAC is the new state of the art, then I am sure the authors will be able to clearly illustrate it in a forthcoming revision (maybe with more experiments, as suggested by Rev2). Unfortunately, for the moment, I do not think this paper is mature enough for ICLR.
Below are multiple reviews of a paper. This paper proposes LatTe Flows, a novel autoregressive flow model with autoencoders to learn latent embeddings from time series. Authors claim that it can model cross-series dependencies across time while scaling to large dimensions with an end-to-end training process.The authors propose a novel approach that scales well for multivariate sequence forecasting tasks. They offer to use conditional normalizing flow to capture the sequence dynamics in the latent space and then use auto-regressive architecture to decode the signal in the original space.The proposed method leans some lower-dimensional representation of the frames pertaining to observed sequences. It then postulates an RNN-type of model in the leaned latent space to model temporal dynamics. The experimental results do not support publication of an methodologically boring paper.	This paper proposes a new autoregressive flow model with autoencoders to learn latent embeddings from time series. The authors conducted extensive comparative experiments, and the experimental results are very encouraging. However, the proposed method, as a combination of the encoder/decoder structure and autoregressive flows on the latent space, does not seem novel enough.
Below are multiple reviews of a paper. In this paper, the authors provide theory for memory capacity (at a given classification margin) for perceptrons with distribution-constrained weights. The amount of assumptions / simplifications required to arrive at the actual results dampens my enthusiasm (expanded below)The manuscript presents a generalization of traditional perceptron analysis, under constraints over the marginal distribution of weights. It shows that perceptron capacity is negatively affected, the more so as the target weight distribution deviated from the unit normal. The link to biology remains fuzzy throughout.The paper develops a theoretical framework for weight distribution-constrained perceptron learning using replica method. They compute capacity based on the proposed distribution and develop a modification to SGD to satisfy the weight distribution constraints.The authors compare the capacity of a perceptron with normally distributed weights. They show analytically that the difference in capacity is a function of the Wasserstein distance between the normal distribution and the specified distribution. The results are interesting and worthwhile from a theoretical perspective.	Reviewers appreciate the novel weight-distribution contrained algorithm, in spite of reservations about potential impact in comp neuro or ML remain.
Below are multiple reviews of a paper. The proposed approach is evaluated on the well-known SentEval benchmark. It generally does not outperform supervised approaches such as InferSent and MultiTask. It is competitive with existing state-of-the-art sentence representations such as QuickThoughts.The proposed approach is evaluated on SentEval giving encouraging results. It is similar in some sense to the self-supervised representation learning literature in computer vision.The paper presents an unsupervised sentence encoding method based on automatically generating inconsistent sentences. It would've been interesting to experiment with training multi-task layers on top of the sentence encoder and see how it would've performed. The paper is missing comparison and reference to recent works on universal language models.	The overall view of the reviewers is that the paper is not quite good enough as it stands. The reviewers also appreciates the contributions so taking the comments into account and resubmit elsewhere is encouraged.
Below are multiple reviews of a paper. The paper builds on a branch of recent works that consider and analyse Variational autoencoders (VAE) from the view point of data compression. Unfortunately, the paper is not well written. This begins with sloppy wording and imprecise notations.The current manuscript might not be self-contained. It relies heavily on the prior work RaDOGAGA (Kato et al., 2020) The main interpretation/discussions are proposed for the classical VAE with a (conditional) isometric Gaussian variational arm.This paper analyses the theoretical properties of the VAE. It shows that under some assumptions theVAE can be interpreted as an implicit isometric embedding of the data manifold. The authors show that with this analogy one can make inferences about the data distribution and the latent dimensions.The paper proposes a methodology to understand quantitively the VAE model, based on the Rate-distortion theory. The writing of the paper is rather confusing, says one reviewer.	This submission analyses the VAE objective from the perspective of non-linearly scaled isometric embeddings, with the aim of improving our information-theoretic understanding of the variational objective.   Reviewers are in consensus that this submission in its current form is very difficult to read, even after revisions by the authors. The metareviewer, who is highly familiar with information-theoretic and even information-geometric interpretations of VAEs, similarly struggled to understand this paper. Many concepts (e.g. KLT transforms) are not introduced in a self-contained manner, nor are related works like RaDOGAGA. Moreover the exposition introduces lots of notation (often somewhat implicitly) and requires more  high-level plain-English statements that signal the structure of the overall narrative to the reader. As a result, it is hard to understand the paper, even at the level of the contributions that are claimed by the authors. It appears that Section 3.4 should be read as culminating in a "correction" of the rate-distortion view of VAEs proposed by Alemi et al. Unfortunately the metareviewer is not able to understand from the writing what fault the authors find with the proposed interpretation, and how their view informs a better perspective.  It is difficult to provide the authors with concrete addressable suggestions at this stage of revision of their manuscript. The metareviewer's advice would be to attempt to focus on defining a narrative structure that clearly explains what insights this perspective of VAEs contributes, what misconception it corrects, and how it corrects it –– and then focus on streamlining notation in a manner that makes it possible to follow along with the exposition more easily.
Below are multiple reviews of a paper. This paper proposes a new model architecture for 3D problem which leverages the powerful backbones pretrained from the 2D task. The idea of using projection into 2D and coloring module is new. The experimental results demonstrate superior performance on public benchmarks including ModelNet40, ShapeNetPart datasets.In this paper, the authors introduce point-to-pixel prompting (P2P), a learning framework for leveraging pre-trained image transformers for 3D tasks. The method is mainly motivated by the data scarcity issue in 3D domains. P2P learns a geometry-preserving transformation from point cloud to 2D grid,The paper proposes point-to-pixel prompting to leverage 2D pre-trained models to help 3D point cloud recognition tasks. The main modules include a geometry-preserved projection and a geometrical coloring. The experiments on ModelNet40 and ScanObjectNN show that P2P achieves comparable performance on classification tasks with only aIn this paper, the authors propose to leverage the pretrained image model for point cloud downstream tasks. They introduce a Point-to-Pixel Prompting to transform a point cloud as the corresponding image. See Strengths And Weaknesses for more information.	The paper presents a method of prompt tuning to transfer 2D pre-trained weights to tackling 3D understanding problems. All reviewers are positive about the novelty of the method. With large 2D pretrained models, higher performances are still expected from xwSJ, which is also a reasonable comment. Other 3D understanding tasks, such as segmentation and detection of outdoor scenes, are strongly encouraged, as they are the true needs of the industry.
Below are multiple reviews of a paper. This paper addresses an issue of transformers that sometimes they fail to find solutions that are easily expressible by attention patterns. The authors propose two modifications, namely adding a copy gate functionality and a geometric attention module which facilitates focusing on local useful operations. The resulting method achieves near perfect accuracy on the considered benchmarks.This paper proposes two modifications to provide additional inductive bias to the attention mechanism in the transformer architecture. The first modification adds a copy mechanism to simulate a “no-op” at a given transformer layer. The second modification is an attention mechanism that is biased towards attending to local context. Both of these modifications are motivated as beingThe authors propose Transformer Control Flow (TCF), a set of improvements to the Universal Transformer (Dehghani et al, ICLR 2019). They show that, for three compositional problems, TCF allows trained models to generalize to longer sequences.	This work proposes a novel Transformer Control Flow model and achieves near-perfect accuracy on length generalization, simple arithmetic tasks, and computational depth generalization.  All reviewers give positive scores. AE agrees that this work is very interesting and has many potentials. It would be exciting if the author could extend this framework to more challenging tasks (e.g. visual reasoning [1. 2]).  Given the novelty of the proposed model, AC recommends accepting this paper!  [1]  CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning. ICCV 2017.  [2] PTR: A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning, NeurIPS 21
Below are multiple reviews of a paper. The paper considers the problem of multi-agent trajectory prediction. The idea of a structured generative loss for creating a richer diversity of predictions has a lot of potential to improve the trajectory prediction tasks. The paper's weak point is a much broader claim while it is only evaluated with Trajectron++. In Table 6, the proposedThe proposed method seems to be interesting, especially the adding of latent code z to generate trajectories and then classify them. It would be interesting to see how this method compare with "Multi-head attention for multi-modal joint vehicle motion forecasting" 2020 IEEE International Conference on Robotics and Automation.The paper is very hard to read. The contributions are not well-defined. The questionable nature of the proposed equations (4, 5) directly relates to my next point, that is, the lack of any useful improvement over SOTA.This paper presents an interesting technique to generate multimodal trajectory GAN and a carefully designed latent intent space. This latent intentSpace allows an operation termed as hallucination, which switches agent intents to enrich the latent spaces' coverage.	The paper presents a method for future trajectory generation. The main contribution is in proposing a technique for data augmentation in the latent space which encourages prediction of trajectories that are both plausible, but also different from the training set. The results clearly show superior performance on standard benchmarks. The evaluation is thorough and ablations show that the proposed innovation matters.   R2, R3, R4 recommend that the paper be accepted with scores 6, 8, and 6 respectively. R1 recommends the paper be rejected with a score of 5. The main concern of reviewers are:   R1: " In summary, the paper suffers from lack of a clear justification of the proposed contributions, unfair evaluations, and questionable significance of the results." The authors addressed this concern in their rebuttal.    R2: "Some other points remain still open such as the limited focus on Trajectron in evaluations." Since trajectron is a recent SOTA, I think this is not a big concern. Authors compare against other baseline methods too.   R4: Comparison to Mercat, Jean, et al., ICRA 2020 is missing. The authors mention that their code is unavailable and therefore cannot compare.    R4: "underlying reasons for the success of different components (classification of latent intent and hallucinative latent intent) are hard to explain". I agree with this and this is also my major concern which I detail below.   The paper proposes to find diverse trajectories by generating two latent vectors: z, z'. The first h time steps are generated by latent vector z and the remainder using z'. The generated trajectory is evaluated by a discriminator that ensures plausibility. The latent vectors are chosen to be discrete and a classifier is trained to recognize z from ground truth trajectories. To encourage diverse trajectories, authors use a loss that encourages mis-classification of the latent variable inferred from the generated trajectory. Since the generated trajectory cannot be classified well, it is assumed to be different from the training set.   This formulation is rather adhoc. If the trajectory is indeed different from the training distribution, then it will also fool the discriminator. If it doesnot, then it's not very different. The mis-classification, is akin to encouraging high entropy in the z space inferred from predicted trajectories. With this view, it is possible that there is no need to generate two latent vectors z, z', but simply generate one and use the entropy penalty. I would love to see this experiment and see the authors demystify their method. It would also lead to significant changes in writing. Even now, writing needs improvement. Due to the proposed method being a adhoc trick, that is not well justified, I would normally not recommend acceptance. However, the empirical results are strong, tilting the recommendation to acceptance.
Below are multiple reviews of a paper. The transfer/ interference perspective of lifelong learning is well motivated, and combining the meta-learning literature with the continual learning literature (applying reptile twice) wasn't explored before. However, I'm not entirely convinced with the technical contributions and the analysis provided to support the claims in the paper. Please find below my concerns and I'mThe paper is well structured and generally well written. The proposed framework for trading off catastrophic forgetting against positive transfer is enlightening and should be of interest to the community. It turns continual learning into multi-task learning.The paper considers a number of streaming learning settings with various forms of dataset shift/drift of interest for continual learning research. It proposes a novel regularization-based objective enabled by a replay memory managed using the well known reservoir sampling algorithm.	Pros: - novel method for continual learning - clear, well written - good results - no need for identified tasks - detailed rebuttal, new results in revision  Cons: - experiments could be on more realistic/challenging domains  The reviewers agree that the paper should be accepted.
Below are multiple reviews of a paper. This work studies the Minimum Enclosing Ball problem, where we are given a set P of n points in d-dimensional Euclidean space. The objective is to output a ball that contains all these points, such that the radius is minimized. This work considers differentially private algorithms (DP) and obtains an DP-fThis paper studies the Minimum Enclosing Ball problem (aka 1-Center) in the Differential Privacy Setting. In this problem, you have a set of data points X, and you need to find a point p such that if all the points X fit in some ball of radius (1+gamma)*r around p,A paper presents a differentially private algorithm for approximating the ball with the smallest radius that encloses all the input points in an arbitrary dimension. The classical approximation algorithm for this problem runs iteratively. Instead of picking the farthest point, this paper takes the mean of all the points that are currently not covered by a ball of optimalIn MEB, we are given $n$ points and the goal is to output a ball $B(\theta, r)$ of smallest possible radius $r$ that contains all points. Under DP, it is impossible to hope for a ball that covers all points, and we need to allow a certain number of points to	The paper improves the state-of-the-art for the minimum enclosing ball problem under differential privacy constraints. Moreover, the algorithm and its analysis are simple and intuitive.   The reviewers agreed that the paper is a concrete advance in the area, and the ideas may lead to a practical implementation. The authors carefully responded to all the issues raised by the reviewers, clearing the way to acceptance.
Below are multiple reviews of a paper. This paper presents numerous empirical facts about the distribution of the weights after training a neural network. The authors considered one FCNN, one CNN, and one ResNet, and computed several statistics on their weights. Despite the numerous and contradictory experiments, the empirical results are significant enough for helping other researchers.The work studies prior distributions for Bayesian CNNs. The work report that conventionally used priors e.g., Gaussian poorly fit empirical distributions of the trined weights. The empirical distributions appear to be heavy-tailed and correlated. Thus the paper proposes to use "heavy-tailed priors" for FCNNs.The paper provides an analysis of priors other than standard isotropic Gaussians for Bayesian neural network. The authors first empirically estimate the posterior distributions of the weights of a BNN and then use these distributions as a prior. They show that those priors allow better performance of BNNs.This paper proposed to use distributions different from isotropic gaussian for Bayesian neural network priors. For fully connected neural networks the heavy-tailed distributions such as laplacian and student-t are used. For convolutional neural networks multivariate gaussian with spatial correlations are employed. Empirical results show that these	This paper provides some empirical investigation of the choice of the prior distribution for the weights in Bayesian neural networks. It shows empirically that, when trained via SGD, weights in feedforward neural networks exhibit heavy-tails, while weights in convolutional neural networks are spatially correlated. From this observation they show that the use of such priors leads to some improved performances compared to the iid Gaussian prior in some experimental settings.  Reviewers have conflicting views on this paper, that have not been reconcilied after the author's response and the discussion. On the plus side, the paper is very well written, the experimental part is carefully conducted, and provides some insights on the choice of the prior in Bayesian neural networks, which could lead to further developments.  On the negative side, the claims made in the introduction are not fully supported by the experiments (the claims have been slightly amended in the revised version), and the take-home message is not so clear. In particular, Bayesian approaches with the proposed priors still underperform compared to SGD without tempering. The authors could also have considered a broader sets of experiments.  Overall, I think the contributions outweight the limitations of this paper, and I would recommend acceptance.
Below are multiple reviews of a paper. The paper proposes a method for exploration of 3D articulated environments. It alternates between collecting interaction data with RL while maximizing a combination of extrinsic and intrinsic rewards. The paper proposes training visually conditioned action maps, image conditioned manipulation trajectory priors, and success predictors.This paper is solving the problem of pushing and pulling objects (mostly things like cabinets) by learning visual action trajectories proposals via a curiosity-driven RL / Perception joint training. This approach is validated both in simulations but also in simulation and with real results.The paper extends work on static term action generation (Where2Act, ICCV21) for 3D articulated objects. The method itself is not very novel, more about extending the existing Where2Act. The overall quality of the paper, writing and experiment, is good.	The paper claims to present actionable visual representations for manipulating 3D articulated objects. Specifically, the approach learns to estimate the spatial affordance map as well as the trajectories and their scores. After checking the rebuttal from the authors, all reviewers agree that the paper adds value to the research area. In the end, it got three borderline accept ratings. The initial criticism included lacking (experimental) comparison to baselines, and the authors successfully corresponded to the request from the reviewer. One reviewer commented that the proposed approach is a combination of Where2Act and curiosity guidance for RL Policy for Interactive Trajectory Exploration, which we believe is a valid point. Still, the paper extends the previous Where2Act and successfully demonstrates its success on difficult tasks.  We recommend accepting the paper.
Below are multiple reviews of a paper. The paper introduces an approach regarding how a backdoored pre-trained model can behave maliciously in various downstream tasks without foreknowing task information. The paper presents Neuron-level Backdoor Attack (NeuBA), which can be used to restrict the output representations of trigger-embedded samples to arbitrary predefined values.This paper proposes a framework to inject backdoor into pre-trained models. Experiment results show that the proposed method successfully injects backdoors to NLP and CV tasks. I am not convinced that it makes significant contribution or overcomes unique challenges.Backdoor attacks to pre-trained models is an important security problem. The paper studied the attacks for both NLP and CV domains. The major challenge of the proposed attack is that it may only work for downstream dataset with a small number of classes.This paper shows that a backdoored pre-trained model can behave maliciously in various downstream tasks without foreknowing task information. Instead of building up connections between triggers and target labels, this paper explores to assign predefined output representations to triggers. To avoid all triggers cause the same target label, the authors carefully design pairs of triggers	This work proposed to insert backdoor into pre-trained models, such that down-streaming tasks can be attacked.   One of the main issue indicated by most reviewers is that some important and closely related works are missed and not compared, which also studied the backdoor attack to pre-trained models. The authors argued in the rebuttal that these missed works require some instances of down-streaming tasks, while the proposed method in this work doesn't. However, this difference could not be the reason to miss and not compare with them.  Besides, most reviewers also indicated the insufficient experiments, such as limited defense methods, and some experimental results are not well explained.   After reading the manuscript, reviews and discussions between reviewers and authors, I think this work is not ready for publication. The reviewers' comments are supposed to be helpful to improve this work.
Below are multiple reviews of a paper. This paper proposed a novel scene representations, called scene program. To extract the scene program, the authors proposed a hieratchical inference method. The resulting scene programs based on the proposed model outperforms several baseline models. The authors also showed the proposed scene program is suitable for image editing and visual analogy making.This paper investigates a descriptive representation of scenes using programs. Given an input image and an initial set of detections a sequence to sequence network is used to generate programs in a domain specific language (DSL) The authors consider a dataset where simple primitives are arranged in layouts in 3D scenes with varying material and color properties. They argueThis paper presents a system that infers programs describing 3D scenes. The system consists of three stages each of which is trained separately. The results on synthetic datasets are good.	This paper presents a dataset and method for training a model to infer, from a visual scene, the program that would generate/describe it. In doing so, it produces abstract disentangled representations of the scene which could be used by agents, models, and other ML methods to reason about the scene.  This is yet another paper where the reviewers disappointingly did not interact. The first round of reviews were mediocre-to-acceptable. The authors, I think, did a good job of responding to the concerns raised by the reviewers and edited their paper accordingly. Unfortunately, not one of the reviewers took the time to consider author responses.  In light of my reading of the responses and the revisions in the paper, I am leaning towards treating this as a paper where the review process has failed the authors, and recommending acceptance. The paper presents a novel method and dataset, and the experiments are reasonably convincing. The paper has flaws and the authors are advised to carefully take into account the concerns flagged by reviewers—many of which they have responded to—in producing their final manuscript.
Below are multiple reviews of a paper. This paper studies long time series forecasting by using segment correlation attention. For this, time series is segmented into periodical shorter sequences. attention is computed on each segment and final representation is formed by concatenating segments’ self-attention representations.The key idea is to replace the canonical self-attention with efficient segment correlation attention (SCAttention) mechanism. Experiment results on several datasets showed the effectiveness of the proposed method.This paper introduces a SCFORMER to address the problem that the complexity of the Transformer increases quadratically with the length of time series. The essential idea is to segment the input into small segments and calculate attention among the segments rather than each data point. To further improve the performance, the paper proposes a dual task, which useThe paper studies the long time series sequence prediction problem with Transformer. The main contribution is proposing a SCAttention mechanism to replace the original attention operation by dividing the whole sequence into equal-length segments and calculating attention among them.	The paper proposes a Transformer-based model called SCformer to perform long sequence time series forecasting by computing efficient segment correlation attention. The reviewers think the method lacks novelty and the experiments need a detailed ablation study.
Below are multiple reviews of a paper. The authors propose RAMBO to offline RL which imposes conservatism by adversarially modifying the transition dynamics of a learned model. The results in Table 1 also show the similarity in performance.This paper formulates the offline RL as an adversarial process between the agent and the environment. The environment is modeled as a neural network and trained with both MLE objective and conservative objective. Previous research [1] proved that this formulation enjoys a PAC performance guarantee.This paper proposes RAMBO, an offline model-based algorithm that formulates the optimization of models and policies as a two-player zero-sum game. RAMBO trains models with an extra objective that minimizes the value function to achieve conservative policy optimization.The authors tackle the generic Offline RL problem and propose a model-based approach to address it. They introduce a novel algorithm (RAMBO), consisting in adversarially training the model in order to minimize the trained policy performance estimate.	This paper introduces the idea of Robust Adversarial RL for offline model-based RL, which could have a high impact. It is well organized and the writing is very comprehensive; the authors manage to convey their idea in concise but informative language. The proposed RAMBO approach performs reasonably well in the presented experiments, although it was pointed out that the paper would benefit from more scenarios showing the necessity of RAMBO compared with the current baseline (COMBO). Questions and issues related to the theory that were raised during the reviewing process have been addressed in the rebuttal.
Below are multiple reviews of a paper. The paper makes an interesting observation that an intermediate checkpoint of the (teacher) model is just as good for the purposes of knowledge distillation. The paper provides ample evidence to support their observations. Their results also suggest that one could significantly reduce training cost of the teacher models.This paper observes that the intermediate models (checkpoints in the middle of the training procedure) can serve as better teachers than fully trained teacher models in knowledge distillation (KD) The Snapshot Ensemble, which ensembles several intermediate models and one full model, has better KD performance and low training cost than the full teacher ensembleThe authors propose a new model distillation method utilizing teacher's training checkpoints, showing performance gain over a handful of benchmarks. They connect their methods with information bottleneck theory and hypothesize that the performance gain partly comes from the fact that checkpoints save a lot of representation information about inputs.The paper deals with knowledge distillation, which is the training of smaller “student” models from larger “teacher” ones in an effort to reduce the model size while preserving as much performance as possible. The authors show that teachers are improved by constructing them from ‘intermediate’ models.	While this paper has 4 accept recommendations among the four reviewers, I have serious misgivings about the content of this paper. The main experimental insight, that a less trained teacher sometimes performs better, is already known and unsurprising. In fact it's the very point of KD that makes that result interesting --- why should it be better to aim for a noisy target than the true target? On any dataset, if we train the teacher for long enough, we will eventually recover the exact labels to arbitrary precision. In that sense, all KD is with an "intermediate" trained model, and the only question is (has always been) just how early to stop. The next issue with the paper is that the authors claim to "explain" theoretically why KD works from the perspective of information bottleneck theory, however what they offer falls short. The “theory” is more like a story, with significant gaps. Most significantly, there is no logic to carry the leaps from stories of how mutual information evolves to why knowledge distillation should work. Moreover what the authors call "mutual information" in their experiments is not actually mutual information and the surrogates they use seem odd choices that are not consistent. For I(F;Y) the authors look at the output of the teacher model but for I(X;F) the authors look at an intermediate layer of F, training a decoder to predict X from the last convolutional layer of F. Why should the information contained in this middle layer of the teacher model matter when the student only accesses the teacher's output? My ambivalence with this paper is two-fold: (i) that the experimental findings are the main contribution and they are by themselves not sufficient for publication and (ii) that the IB component of this paper is misrepresented as a theoretical explanation of the efficacy of KD but actually it falls short.   Unfortunately I’m discovering these concerns and expressing them after the discussion, hence my recommendation to accept the paper on the basis of the reviewer's initial recommendations. If the work is accepted, I expect the authors to edit it responsibly to remove all misleading claims that suggest that the paper provides a propert theoretical account for why KD works (they certainly have not), versus a speculative intuition, and to be much more careful to disambiguate the quantities that they track from actual mutual information.
Below are multiple reviews of a paper. The authors address the limitation of the ODE-RNN model that the trajectory is continuous everywhere except the observation points. They introduce a compensation term based on cubic splines that transforms the output trajectory into a continuous one. This approach is also applied to correct a hidden state trajectory.The paper proposes to use cubic spline interpolation to smooth out discontinuities outputs and state inferred by ODE-RNNs. While the approach is interesting, it is ill adapted to noisy data. The experiments are limited to data sets corresponding to applications with limited impact.This work addresses the discontinuity issues caused by jumps in hidden state/output at the arrival of new observations in a ODE-RNN. The paper focus on the task of learning from irregularly sampled data which is important in many domains. The key concern about the paper is the lack of rigorous experimentation to study the usefulness of theThis paper presented how cubic spline smoothing function was used to compensate the insufficiency in ODE-RNN for irregularly sampled sequences. Theoretical justification was provided.	This paper introduces a form of cubic smoothing for use with ODE-RNNs, to remove the jump when new observations occur.  I think this paper's motivation is based on a misunderstanding of what the hidden state of an RNN represents.  Specifically, an RNN hidden state is a belief state, not the estimated state of the system.  I think R2 is right that it's correct for a filter to jump when seeing new data.   It's not a matter of whether the phenomenon being modeled is slow-changing or not.  The filtering output is a belief state, which can change instantaneously even if the true state does not.  The important distinction to make is filtering (conditioning only on previous-in-time data) vs smoothing (conditioning on all data).  The smoothing posterior should generally be smooth if the true state changes slowly.  As R4 notes, all of the tasks are based on interpolation, which is not what the ODE-RNN is trying to do, and the proposed method would make the same predictions as a standard ODE-RNN.  Finally, as R4 notes, "The authors do not provide any experimentation on real-world irregularly sampled time series".
Below are multiple reviews of a paper. This paper proposes a text autoencoder with a bag-of-vectors embedding. To train such a model, the authors first encode the input sequence into a vector sequence of equal length. I recommend rejecting this paper because of its unclear method description, poor results, and insufficient evaluations.This paper extends previous work, Emb2Emb, by replacing the LSTM autoencoder with a Transformer autoenCoder. The authors propose some techniques to handle the difficulty of this replacement.The paper extends the unsupervised conditional text generation framework of Emb2Emb (Mai et al., 2020) from a single encoding to variable-length encodings. The new model is called a bag-of-vectors autoencoders (BoV-AE) The paper presents a reasonable multi- vector extension ofThis paper presents an autoencoding model which is trained for conditional text generation tasks in an unsupervised manner. Rather than using a fixed-sized bottleneck layer, the authors present a method for learning a variable-sized set of representations. This bag of vectors can then be transformed in order to generate a modified sequence of text based	The paper addresses unsupervised conditional text generation extending emb2emb (Mai et al, 2020) with bag-of-vectors antoencoders.  Reviewers shared several concerns about the clarity of this paper and empirical results.
Below are multiple reviews of a paper. The paper presents a zero-shot action recognition framework by learning an universal mapping from video to semantic space. The performance are very stronger when compared with other baselines. The results on UCF101 and HMDB-51, UCF Sports and J-HMDB validates the proposed method.The paper targets transductive zero-shot action recognition. To alleviate models biased to seen categories, the authors propose to re-position unseen action embedding through transduction. There are three steps in the proposed method: first, finding an optimal mapping from unseen actions to the mapped video in the shared hyperspherical space.This work tries to address the problem of zero-shot action recognition. Using the distribution of the unlabelled test set, the embeddings of unseen actions in the target domain are reweighted and repositioned along the geodesic. Empirically, the proposed method has been evaluated on benchmark datasets.This work introduces transductive universal transport for zero-shot action recognition, where no training examples for unseen classes are available. The approach needs access to the entire testing video set to obtain distribution information of testing videos.	This paper was reviewed by four experts in the field and received mixed scores (1 borderline accept, 3 borderline reject). The reviewers raised their concerns on lack of novelty, unconvincing experiment, and the presentation of this paper. AC feels that this work has great potential, but needs more work to better clarify the contribution and include additional ablated study. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere.
Below are multiple reviews of a paper. The experimental results are not convincing for me. Only two baselines are compared with the proposed method. The design of VCnet needs the numerical results to confirm its effectiveness.This paper is to develop a varying coefficient neural network to estimate average dose-response curve (ADRF) Although this paper has several interesting results, the paper is full of many typos and small errors.The paper is extremely well written. The theory, as far as I can tell, is sound. The experiment shows that the model outperforms existing benchmarks on the task it set out to do.	The paper designs a new way (in some sense a new perspective) on how neural networks can be used to model intervention variables when the goal is to estimate ADRF.  Basically, the idea is to emphasize the importance of the intervention variable by ensuring that it appears not just in every layer but also in every neural of a neural network.    Reviewers mostly agree that this is a good paper with varying degrees, although there are some criticisms on e.g., assuming away the confounders.  However, I believe the authors address the criticisms of R4 satisfactorily.   Overall I find the idea new and interesting and the experimental results strong, hence I happily recommend accepting the paper.  I do have a few quips myself and some comments that may help the authors to further improve the paper.  1. Re: the design that models each parameter as a spline.  This is equivalent to introducing additional parameters (coefficients for spline basis) and adding a fixed linear layer (spline basis themselves) to every layer of the neural networks. t is taken as an input in all layers thus it makes sure that the model prioritizes on learning the impact of t.   2. If you use a B-spline basis (that comes with kernels of bounded support), then the proposed method is very similar to stratifying the data according to different bins of t, and then fitting a separate model for each t. The only difference is that the different bins are now smooth kernels and they overlap somewhat. As a side note,  the authors should clearly write out how they are choosing the knots to specify the basis functions. Otherwise the paper will not be reproducible.   3. I am not sure how this method would compare to naive (non-deep) baselines. Maybe this was considered in a prior work? If not, then I tend to side with Reviewer 4 that the evaluations are mostly ablation studies and they are not really comparing to representative work in this domain. Given that there is a large body of work on this before deep learning takes over, it is important to somehow compare with the right baselines.
Below are multiple reviews of a paper. SAVi showed several key limitations, in particular its poor performance on complex, realistic (or real) datasets and a general inability to segment static objects. SAVi++ makes progress on both of these fronts by using an additional cue / reconstruction target: depth.The paper proposes a model to improve on top of the SAVI model. Key differences include: utilising image depth as a signal for supervision and adopting scaling techniques during training. The model obtains superior results on both a challenging synthetic dataset and also on real-world driving videos.SAVi++ is an object-centric video model which is trained to predict depth signals from a slot-based video representation. The paper claims that by using sparse depth signals obtained from LiDAR, SAVi++ is able to learn emergent object segmentation and tracking.The paper proposes an extension of a previous work SAVI which used optical flows as a training signal to further include depth maps obtained from RGB-D cameras / LiDAR. The main goal is to learn from videos which have depth-channels but no instance/semantic segmentation ground-truths.	Three out of four reviewers provided positive reviews and scores for this submission. They agreed that SAVI++ makes meaningful improvements over a previously proposed SAVI model. Importantly, while most past approaches evaluate on synthetic data, this submission evaluates the proposed model on a real world dataset. The proposed model clearly improves over the baseline and a clear ablation analysis shows where the improvements come from.   One reviewer had concerns about the evaluation using just one real world dataset. This was also brought up by other reviewers, who mentioned that the Waymo dataset has less diversity and fewer videos than others. While a more thorough evaluation would make this a stronger submission, the leap from synthetic evaluations to real world evaluations in this line of research is notable and sets the bar for future work. I also note, based on the discussion, that the employed dataset is not trivial and has several challenges for the model.   Another concern by the reviewer was about missing baselines. The authors did provide additional baselines in their response. While these baselines do not exactly match the ones requested by the reviewer, I think they provide good evidence that the proposed method is able to employ the depth signal effectively.   Overall, this paper makes solid progress on the problem, provides value to the readers and provides strong results on a real world dataset. Given these reasons, I recommend acceptance.
Below are multiple reviews of a paper. This paper proposes the backdoor defense even without a clean data set. After randomly shuffling the filters and comparing the changes in DNN output, the authors find there is an obvious difference between backdoored DNNs.This is the first time to try to detect such attacks without any clean data. Since we do not need clean data here, the proposed method can be used for many scenarios compared to previous methods.This paper casts a new "self-supervised" backdoor detection setting that was not explored by prior arts. There is no prior knowledge nor control of the training data quality; and no access to a comparable clean sample set.This paper proposes a backdoor detection method based on shuffling convolutional filters and assessing the resulting shift in deep representations. The abstract makes big claims (in bold) that may not be true. There are existing defense techniques that do not require clean data.	This work proposes a channel shuffling as a way to distinguish between backdoor and clean examples, based on the hypothesis that trigger features are sparsely encoded and activated in only a few channels. Reviewers all agreed that is a pretty intuitive, yet effective method and that it had solid evaluations after the rebuttal.  Reviewer oFCu had the concern that this paper is entirely empirical and has no supporting theory. I think this is ok given the precedence of papers in this field and also the framing of security and privacy is a more practically oriented one anyway.  The most critical reviewer (PjHg) pointed out that the benchmarks and related work contextualization were severely lacking. After the rebuttal period, these concerns were mostly alleviated.  Given the strength of the evaluations and the novelty of the idea, I believe this paper should be accepted.  That said, please address the following for the camera ready: Please improve the writing as this was brought up by several reviewers. There are a lot of grammatical errors. Please improve the discussion of the limitations section of this detection method as suggested by reviewer PjHg.
Below are multiple reviews of a paper. In this paper, the authors first formulate the optimization problem of GANs as an abstract minimax problem (Equation(1) The noise input is an important ingredient of GANNs. The authors should provide a clear explanation about this point.This work studies minimax optimization (a.k.a saddle-point problems) with nonsmooth regularizers. By leveraging the monotone operator theory, the authors propose to use the forward-backward-forward method.New method, FBFp, is introduced and studied. Preliminary numerical results obtained by training GANs are reported.The authors in this paper study the problem of min-max optimization for convex-concave functions. They prove novel convergence results for Forward-Backward-Forward (FBF) and Optimistic Gradient Descent Ascent (OGDA)	This paper provides a unified view of some known methods for monotone operator inclusion problems like Forward-Backward-Forward (FBF) and OGDA, and provides new convergence results for the stochastic version of a variant of FBF called FBFp. All reviewers initially recommended rejection. The rebuttal and the manuscript update addressed several concerns from the reviewers, though the general consensus after rebuttal was still that the paper lacked in significance for the ICLR community. The AC thinks that the paper could make an interesting overview paper in a more optimization / theoretically minded venue.
Below are multiple reviews of a paper. Pars destruens is a paper that criticizes current work in the area of data poisoning attacks. The first part criticizes the lack of standardized evaluations across different papers. The second part tries to overcome the limits described in the first part.This paper studies 4 different previously proposed (clean label and targeted) poisoning attacks. They show that these 4 attacks are not robust to changing parameters of learning algorithm or the experimental setting.The authors study a number of existing data poisoning attacks. They find that many of these attacks are quite brittle to changes in their original experimental evaluation. Then, they propose a unified benchmarks for evaluating these attacks.This paper discusses many issues in the data poisoning literature. They call into question the real world applicability of data poisoning attacks. They present a new benchmark which attempts to standardize the comparison.	This paper generated significant discussion and division amongst the reviewers. On the positive side, some reviewers enjoyed both contributions, feeling the further empirical investigation of existing attacks to be interesting, and the creation of a benchmark to be very useful. On the negative side, no new positive results were proposed, criticism of previous attacks were considered to be unjust, the focus was somewhat narrow, and a benchmark could plausibly be misleading and detrimental.  Given the highly competitive nature of ICLR and the many other excellent submissions, the committee was unable to accept the paper at this time. Below are some suggestions for future submissions.  The content of the paper is generally fine, as long as the caveats and the "tone" are appropriate: we would hope to not mislead potential readers. Here are some (strong) recommendations: - Previous works were proof of concept attacks, and the authors should be careful to not frame them as being "broken" -- they perhaps were not meant to be robust to these modifications. - The scope is somewhat narrow. There should be some explicitly statement and justification of the scope, and what in particular is *not* covered by the investigation. - Importantly, a single benchmark can't be a unique gold standard, for many reasons discussed by reviewers. Please state these caveats clearly and prominently in the paper and/or code release, as otherwise the presence of a benchmark could do more harm than good. In particular, Reviewer 4 brought up the following philosophical concern with a benchmark, which I believe is quite reasonable, and I reproduce verbatim. The authors should try to address this in the next version: "This kind of benchmark can push the research to a wrong direction. In my view, the point of attacks are to create an alarm for using machine learning in critical applications. Developing these benchmarks would push the competition in the direction of making existing attacks "better" (whatever "better" means in the benchmark) instead of focusing on designing defense techniques or showing the severity of attacks in other situations. This benchmark could also have a bad effect on future attacks (attacks that want to show a new threat, not the one that try to improve the performance of clean label targeted poisoning attacks on deep neural nets) to gain attention from community as they probably will not pass all the criteria of this benchmark."  As another comment (I believe mentioned by other reviewers), it would be nice if all the terms and settings were defined clearly and precisely. For a benchmarking paper, it is important that the reader can clearly understand the threat model, and what does and does not count as a valid attack.  Finally, many of the reviewers gave detailed comments and concerns. The authors should please note and discuss these concerns in future versions (or at least in a supplement or an arXiv version).
Below are multiple reviews of a paper. The authors explore the use of KL, 2-Wasserstein, and Frobenius norm in order to derive trust region projections in DRL. I find the study very relevant and useful but somewhat incomplete.In trust-region-based policy optimization methods such as TRPO and PPO, it is difficult to tune and lots of approximations are required. The authors try to solve this issue by introducing the closed-form derivation of trust regions for Gaussian policies with three different types of divergence (or distance) Based on the theoreticalThe paper proposes a way to impose trust region restrictions via projections when doing policy optimisation in Reinforcement Learning. The projections have a closed form and enforce a trust region for each state individually. The paper compares itself with the existing strong methods.	This paper proposes a differentiable trust region based on closed-form projects for deep reinforcement learning. The update is derived for three types of trust regions: KL divergence, Wasserstein L2 distance, and Frobenius norm, applied to PPO and PAPI, and shown to perform comparably to the original algorithms.  While empirically the proposed solutions does not bring clear benefits in terms of performance, as correctly acknowledged by the authors, it is rigorously derived and carefully described, bringing valuable insights and new tools to the deep RL toolbox. The authors improved the initial submission substantially based on the reviews during the discussion period, and the reviewers generally agree that the work is of sufficient quality that merits publication. To improve the paper and its impact, I would recommend applying the method to also off-policy algorithms for completeness. Overall, I recommend accepting this submission.
Below are multiple reviews of a paper. The reproducibility report sets out to verify these claims. The authors were unable to reproduce the results of the original paper to a high accuracy. They state that this is possibly a result of experimenting on an entirely different dataset.The authors have made a reasonable effort in reproducing the original work, "Differentiable Spatial Planning using Transformers" The authors implemented the algorithm from scratch due to lack of open-source code from the original authors.	A great reproducubility study. Even though there is some discrepancy in the results presented here with that of the original paper, the paper does a good job at explaining the reason behind such behaviour which is indeed a good contribution.
Below are multiple reviews of a paper. The paper is addressing the problem of a specific multi-task learning setup such that there are two tasks namely main task and auxiliary task. Auxiliary task is used for the sole purpose of helping the main one. The simple and sensible approach proposed in the paper is using cosine similarity between the gradients.Proposed cosine simiarity based soft gradient update scheme seems reasonable. Author(s) experiment the proposed method on three tasks, one supervised learning image classification task, two reinforcement learning tasks, and show improved results respectively.The paper proposes a method for using auxiliary tasks to support the optimization with respect to a main task. The method is demonstrated on image classification and a few reinforcement learning settings. The main merit of the proposed method is its conceptual simplicity.	This paper tackles the problem of using auxiliary losses to help regularize and aid the learning of a "goal" task. The approach proposes avoiding the learning of irrelevant or contradictory details from the auxiliary task at the expense of the "goal" tasks by observing cosine similarity between the auxiliary and main tasks and ignore those gradients which are too dissimilar.   To justify such a setup one must first show that such negative interference occurs in practice, warranting explicit attention. Then one must show that their algorithm effectively mitigates this interference and at the same time provides some useful signal in combination with the main learning objective.   During the review process there was a significant discussion as to whether the proposed approach sufficiently justified its need and usefulness as defined above. One major point of contention is whether to compare against the multi-task literature. The authors claim that prior multi-task learning literature is out of scope of this work since their goal is not to measure performance on all tasks used during learning. However, this claim does not invalidate the reviewer's request for comparison against multi-task learning work. In fact, the authors *should* verify that their method outperforms state-of-the-art multi-task learning methods. Not because they too are studying performance across all tasks, but because their method which knows to prioritize one task during training should certainly outperform the learning paradigms which have no special preference to one of the tasks.   A main issue with the current draft centers around the usefulness of the proposed algorithm. First, whether the gradient co-sine similarity is a necessary condition to avoid negative interference and 2) to show at least empirically that auxiliary losses do offer improved performance over optimizing the goal task alone. Based on the experiments now available the answers to these questions remains unclear and thus the paper is not yet recommended for publication.
Below are multiple reviews of a paper. The authors propose FOML, a new online learning algorithm based on MAML. It introduces two new features. Instead of resetting the inner loop weights back to the meta-weights after each task, the online weights are always kept and updated. The authors present a simple approach that is effective in a specific online continual learning scenarioProposed approach extends the previous online MAML (FTML), by removing the discrete 'resets' of task-specific parameters. To validate the proposed approach, authors conducted experiments on a synthetic continual image recognition benchmark (of 1,200 tasks) based on CIFAR100.The paper proposes an online learning approach that utilizes the meta-learning framework. The proposed method - FOML has two main components: a regularizer that does not allow the updated parameters of the model to deviate too far from the previously learned set and a meta update on the parameters using the online updates. The results suggest faster adaptationFOML is able to continually update online parameters with new datapoint, and meanwhile perform meta- gradient updates on a set of meta-parameters using a buffer of previous data. Authors compare the model to state-of-the-art like FTML on benchmarks such as Rainbow-MNIST and CIFAR100 datasets	The paper propose a Fully Online Meta-Learning (FOML) method which extend MAML for continual learning in a fully online learning  without requiring the knowledge of the task boundaries. Experiments show that FOML was able to learn new tasks faster than several existing online learning methods on Rainbow-MNIST, and CIFAR100 datasets.   There are a few major concerns from reviewers. One concern is about the lack of clarity on the problem statement: The authors cast the problem as meta-learning that must be done in a fully online setting, but it requires to store all the training data in a buffer storing all the training data seen so far, which contradicts to the principle of “online learning”. Another major weakness is the poorly written literature survey, which missed to cite a large body of related work in continual learning and online-meta-learning (such as Online Continual Learning, task-free continual learning, continual learning without task boundaries, etc). These should at least be discussed carefully if not fully compared in the empirical studies. Also experiments are quite weak in both settings, datasets and rather out-of-date baselines. Finally, there also lacks of theoretical justification or analysis.   Therefore, the paper is not recommended for acceptance in its current form. I hope authors found the review comments informative and can improve their paper by addressing these review comments carefully in future submissions.
Below are multiple reviews of a paper. The paper proposes Dynamic Hybrid Vision Transformer (DHVT) for visual recognition. The experiments are conducted on CIFAR-100, ClipArt, Sketch, Painting, and ImageNet. All of these datasets are for classification.The paper proposes a new architecture that modifies the FFN with a Dynamic Aggregation Feed Forward. It also proposes a "Head Token" so that each head of the MHA can attend to all others. This supposedly helps learning better features.This paper proposes a new Vision Transformer structure named DHVT targeting to improve the performance of ViTs on the image classification task with small datasets. DHVT is designed to improve spatial relevance among the patches with convolutional inductive bias.This paper focuses on generalizing vision transformers to the domain of small datasets through injecting spatial-wise and channel-wise inductive biases into model architecture design. By using additional convolution operations to gather the local feature, spatial relevance within patches is emphasized, and is forced to learn better relations even with limited data.	Authors introduce 3 modifications to ViT architecture to introduce additional inductive biases to improve performance in low-data scenarios: - SOPE: Sequential Overlapping Patch Embedding -- essentially convolutions before partitioning the image into patches. - DAFF: Dynamic Aggregation Feed Forward -- a DWCONV operation is applied to tokens after a FC layer increases the channel dimension. The new tokens are average pooled, input to additional FC layers, and then are used to scale the CLS token. - HI-MHSA: Head-Interacted Multi-Head Self-Attention -- this approach's name is confusing. This does not change the heads in MHSA. Rather a new mechanism is introduced prior to MHSA to introduce new tokens where each new token is derived from a different partition of the original channel dimensions.  AC recommends authors use a different name. For example, "Intra-Channel Modeling (ICM) MHSA" or something would be more clear.     Performance is evaluated on CIFAR-100, DomainNet subsets, and ImageNet 1K  Pros: - [R/AC] The topic is important to the community. - [R/AC] The paper is well written and clear.  - [R/AC] The authors present improved performance versus other recent SOTA hybrid model designs (during rebuttal phase, though missing from original work -- should be added to paper).   Cons: - [R/AC] The evaluation could be significantly improved. For example, more training experiments on undersampled version of more datasets, with comparisons to other SOTA methods.  - [R/AC] The design is complicated and the motivation isn't always clear.  - [R] Novelty of the components implemented is low.  - [R] Concerns over use of BN as opposed to LN. Authors have provided ablation experiments to demonstrate that BN improves performance of their model over LN. These ablations should be included in the manuscript. - [R/AC] Concerns over lack of comparison to other SOTA methods that mix convolutions with transformers, such as CvT. Authors have provided additional experiment tables that compare against CvT. These tables should be included in the manuscript in a consistent manner (showing number of parameters and FLOPS). - [R/AC] Authors do not include FLOPS in their experiment tables. Please ensure all tables report number of parameters and FLOPS for all models explored. There are python packages to help with computing this, such as "flopth".  - [AC] Some spelling and grammatical mistakes. Please spell check the manuscript.  Overall Recommendation: Reviews lean toward acceptance, but marginally so. Given that the authors have provided more comparisons against recent relevant SOTA methods, and that the reviewers (including expert in the field) lean toward accept, the AC opinion is that this manuscript can be published and provides some valuable knowledge to the community. There are ways in which the paper can still be improved before publication, such as inclusion of additional evaluation datasets.  AC Rating: Borderline Accept
Below are multiple reviews of a paper. The authors identify that adversarial examples lay on a flat minimum will be more likely to be transferred to other models. The authors then propose the reverse adversarial perturbation guided by an additional inner maximization optimization process. The proposed method is straightforward and effective.This paper focuses on generating transferable adversarial examples. Previous methods usually address the overfitting issues by borrowing the techniques from deep learning model training strategy. In contrast, this paper proposes a method specifically designed for generating adversarial example.The paper proposed to add reverse adversarial perturbation at each iteration in gradient-based attacks to compute more accurate gradient directions. The novelty of the method is not high.The authors claim that the adversarial examples should be in a flat local region for better transferability. To boost the transferability, they propose a simple yet effective method named Reverse Adversarial Perturbation (RAP) RAP adds an inner optimization to help the attack escape sharp local minima.	This paper studies the transferability of adversarial examples. In general, the reviewers found the paper is well motivated, and the proposed method is simple and effective. Most initial concerns were about missing comparisons and ablations.   All these concerns are well addressed in the rebuttal. As a result, all reviewers unanimously agree to accept this submission.
Below are multiple reviews of a paper. This paper proposes Bootstrapped Transformer, which uses bootstrapping to self-generate more offline data to improve sequence model training of Trajectory Transformer in offline RL setting. The authors study autogenerative generation and teacher forcing for trajectory generation. They demonstrate better performance comparing to other offline RL baselines in D4The proposed method is evaluated on a subset of the D4RL continuous control tasks. It is shown to outperform several baselines (including transformer-based and model-based ones as well as CQL and BC)This paper extends recent sequence-modeling approaches to RL with model-based data augmentation. The end result looks like a Dyna-inspired variant of the Trajectory Transformer. This paper considers a relatively straightforward combination of existing algorithms, but does so thoroughly.	## Summary Offline RL (RL) algorithms aim to learn policies without interacting with an environment purely from the state and actions covered in the offline datasets. However, in real-world datasets, the coverage can be insufficient to learn good policies. Thus it is an important research direction to improve the sample efficiency of those methods. This paper approaches offline RL from a sequence modeling perspective. The paper adopts a variant of trajectory transformers for data generation, and they investigate two of the main design decisions in those models: * Sampling methods (autoregressive vs. teacher-forcing based). * Reuse of model-generated data  The authors validate their idea on two D4RL tasks: * adroit * locomotion  ## Decision  Overall the paper is well-written and easy to understand. The results and experiments are thorough, and the paper goes for more depth in the experiments rather than breadth. The ideas in the paper are not novel, but the paper does not overclaim its contributions, and results are interesting. As a result, I think both NeurIPS and the broader offline RL communities would benefit from the findings of this paper. I am nominating this paper for acceptance.  The reviewers were very positive about this paper during the rebuttal and discussion paper. They all agreed that the paper is valuable and interesting contribution to the community. The main criticism of this paper that came up during the discussion period was that the idea is just a straightforward combination of the existing techniques. However, the idea presented in the paper is coherent, reasonable, and executed well.   The authors provided a very detailed rebuttal with clarifications to the points that reviewers raised. As a result of the rebuttal, some of the reviewers increased their scores. I would recommend that the authors incorporate some of those clarifications into the camera-ready paper version. Some of those are:  * In response to reviewer 9mfT’s question on the results with CQL on additional data generated by Boot is very interesting. I think the authors should include it in the camera-ready version of the paper.  * Additional experiments on other datasets from the D4RL gym environment as asked by reviewer 9mfT. * The experiments asked by the reviewer *hqzJ*.
Below are multiple reviews of a paper. This paper proposed to progressively use the prior from context model, reference model and hyperprior model instead of obtaining priors respectively and then combining them to obtain estimation results. The paper lacks the explanation and experiments to the rationality of the design of the progressive process.The paper presents a learning-based approach for image compression. It describes two novel extensions, one to take the global context into account and an improved version of the commonly used GDN layer. Their advantage has been shown in a thorough ablation study.This paper propose two methods for improve deep image compression performance. Proposal seems better Rate-Distortion results than Lee 2019 and Minnen 2018 (Figure 6 and 7).The authors introduce global reference into the entropy model for deep image compression. They also develop a reference algorithm to ensemble local context, global reference and hyperprior.	This paper received moderately good reviews, 3 positives (6, 6, 7) and 1 negative (5). The reviewers are generally positive about the main idea but identified several limitations; performance improvement is marginal compared to existing approaches, the proposed method incurs higher computational complexity, and the presentation is not clear enough. Some of these issues are addressed in the rebuttal, though. Overall, the merits of this work outweigh the drawbacks and I recommend accepting this paper.
Below are multiple reviews of a paper. This paper proposes a new domain adaptation SAUM method that learns a large margin classifier between different classes for cross-domain sentiment analysis. The key idea is to train a domain-agnostic embedding space based on learning a prototypical source distribution with GMM, which is then used to align domain distributions via SWD minimization.In this paper, the authors propose a new method to improve cross-domain sentiment analysis. They introduce large margins between classes in the source domain and it helps to reduce the possibility of misclassification on the target domain. The experimental results demonstrate the efficacy of their method.The paper proposes an unsupervised domain adaptation approach for sentiment analysis. The main idea is to align the cross-domain representation with Sliced Wasserstein Distance (SWD), and train the sentiment classifier on additional pseudo-labeled target domain data.The proposed SAUM2 is novel. As a contribution, the work introduced large margins between classes in a source domain. The result shows that the resultant model is domain-independent. It is unclear how the "domain shift" would cause performance degradation.	In this paper, the authors proposed a large-margin-based domain adaptation method for cross-domain sentiment analysis.  The idea of developing a large-margin-based method for domain adaptation is not new. Though the proposed method contains some new ideas,  the difference between the proposed method and the existing large-margin based methods needs to be discussed and studied empirically.  In addition, the experimental results are not convincing: some related baselines are missing and experiments need to be conducted on more datasets.   Though the authors did provide long responses to each reviewer, after a lot of discussions, the reviewers still find that their concerns are not well addressed.   Therefore, this paper is not ready to be published in ICLR based on its current shape.
Below are multiple reviews of a paper. This paper proposes a new method to segment pseudo-phoneme boundaries. The reward for the boundary predictor agent is the high-level CPC objetive. The learned representations show nice performance on phoneme prediction and boundary detection tasks.This paper proposed to achieve unsupervised acoustic unit discovery in speech using a specially designed variable-rate hierarchical CPC method. The paper is easy to follow. The proposed method is novel and does technically sound from the speech perspective.The proposed model achieves better frame-level phone accuracy, segment-levelPhone accuracy, and phone segmentation compared to several baselines. The paper is easy to follow, with all the design choices well motivated and clearly described.	In this paper the authors propose to use multiple levels of contrastive predictive coding (CPC) in self-supervised learning to discover acoustic units.  The lower level of CPC learning is a conventional one while the upper level of CPC is carried out based on non-uniform downsampling with boundary prediction. To facilitate the training, the authors introduce various loss functions for hierarchical CPCs, quantization, boundary predictor and average sampling rate regularization.  The authors show that the acoustic units discovered by this framework give better phone accuracies in both frame and segment levels compared to existing models.   The idea of variable-rate hierarchical CPC learning is interesting and experimental results are supportive.  The paper is well written and easy to follow.  Most of the raised concerns by the reviewers have been addressed in the rebuttal.  To further improve the paper,  the authors may want to show the effectiveness of this model to generate better acoustic representations in more downstream speech domain and tasks.
Below are multiple reviews of a paper. The paper introduces a new cost function for training Wasserstein Autoencoders. It combines reconstruction error with Sinkhorn distance on the latent space. Overall, it has potential, but the proposed method would probably require clearer evaluation.The Sinkhorn autoencoder minimizes the W-distance between aggregated posterior and the data prior. This looks new, but I did not look insight to the detailed derivations. One thing that I do not like is that Sink horn distance needs to be optimized before optimizing the autoenCoder distance.The paper builds upon the recent Wasserstein Auto-Encoders. The main innovation is the use of the Sinkhorn distance between the prior and the aggregate posterior. Theoretical results are a significant contribution, but not quite deep.The paper proposes a new representation of Wasserstein AutoEncoder and provides the formal analysis of learning autoencoders with optimal transport theory. The experimental results with different priors have demonstrated the effectiveness of the newly formulated model.	The reviewers appreciated the contribution of combining Wasserstein Autoencoders with the Sinkhorn algorithm.  Yet R4 as well as the author of the WAE paper (Ilya Tolstikhin) both expressed concerns about the empirical evaluation.  While R1-R3 were all somewhat positive in their recommendation after the rebuttal, they all have somewhat lower confidence reviews, as is also clear by their comments.  The AC decided to follow the recommendation of R4 as they were the most expert reviewer. The AC thus recommends to "revise and resubmit" the paper.
Below are multiple reviews of a paper. The paper presents a novel way of performing few-shot KB completion without having to rely on meta-train datasets constructed in an ad-hoc fashion. During inference, the proposed method checks if there is an evidence close enough to the proposed hypothesis using the Evidence Proposal module.The authors proposed to leverage sub-graph between the head entity and tail entity, which may be shared between support and query triplets. Through this way, they are able to better predict the target entity through the shared subgraph. To get a model that can be generalized to specific KG, they proposed to pretrain an encoderThe proposed approach relies on an intuition that entities linked by the same relation should have a similar-strctured subgraph. The framework is called connection subgraph reasoner.	This paper studies few-shot knowledge graph completion problem. It proposes learning a hypothesis proposal module that given different support evidence graphs, finds a common hypothesis that is supported by the evidence. The authors present 2 approaches for the hypothesis proposal and evidence proposal modules: an optimization-based training free method, and a fully trainable GCNN approach.   The reviewers agree that the proposed method is interesting and solid, the experiments are thorough, and the results provide valuable insights for future work. Reviewers' raised concerns and questions are properly addressed by the author's response.
Below are multiple reviews of a paper. The paper is a good contribution to spatio-temporal modeling in complex physics. However, the novelty of the paper is unclear. It is an extended version of Neural-ODEs but used a Bi-LSTM.This work proposes a sequence-to-sequence approach for learning the time evolution of PDEs. The method employs a bi-directional LSTM to predict solutions of a PDE-based formulation for a chosen number of time steps. The paper only compares to a simple form of PINNs, but not to a variety ofThis paper is about using deep neural nets to predict solutions of dynamical systems described by PDEs. The paper is overall well written, and the contribution is clearly stated. However, I do have several issues with the general principle.The paper proposes to use LSTM to learn partial differential equations. Experiments include Wave equation, Heat equation, Burgers' equation, and Navier-Stokes equation. They compare with PINN on Allen-Cahn and Burgers equation.	The paper introduces an approach for learning the dynamics of PDEs. It makes use of bi-directional LSTMs trained to regress future values from past observations, up to a given horizon. Experiments are performed on data generated from numerical solvers on two examples, inviscid Burgers and a Navier-Stokes system. While the topic is fine, the solution is nothing more than regression with sequence models and only shows that RNNs could learn to predict the data generated by these PDEs. The reviewers also highlight that the comparison with the baselines is not appropriate.
Below are multiple reviews of a paper. The paper addresses the counting-based VQA scenarios, as well as general object counting problems. They modified FiLM (Feature-wise Linear Modulation) formulation to form an alternative modulation for the task of counting, which they call MoVie.The paper presents MoVie (short for ‘modulated convolutional bottlenecks’): a new modulation block which reformulates the FiLM approach (Perez et al. 2018) The proposed approach showcases impressive results, establishing new sota both for open-ended and common object counting benchamrksThis work presents Modulated conVolutional bottlenecks (MoVie) to focus on visual counting. MoVie can be easily incorporated in any generic VQA on top of any convolutional feature map. Extensive ablation studies are presented with SOTA results.This paper proposes a method to count general objects for a query. Inspired by Perez et al. (2018), the authors design a convolutional neural network. The authors report the experimental results for object counting, visual question answering (VQA), and GQA.	The paper proposes a modification of the well-known FILM model for VQA which targets counting problems in particular, which have been a known weakness of existing models. The improvements have also been tested beyond counting. The experimental results are convincing, in particular a scientific competition has been won. The reviewers also appreciated convincing ablation studies.  The idea bas been perceived as interesting enough for publication, and in combination with the experimental results, this compensated several perceived weaknesses (limited novelty w.r.t. the modified FILM model; justifications of some design choices).  All reviewers agreed that this paper is of interest to the community and proposed acceptance. The AC concurs.
Below are multiple reviews of a paper. This paper provides theoretical guarantees on multi-step off-policy distributional RL algorithms. It derives a DRL algorithm, QR-DQN-Retrace based on QR- DQN which shows empirical improvements on Atari. There are some weaknesses of this paper. Although there are some theoretical contributions, the algorithm design is not novelThe authors study a multi-step off-policy learning approach to the distributional RL setting. The proposed methods generally outperform the compared methods in either the mean or median score.Theoretically, the paper provides the first theoretical guarantees on multi-step off-policy distributional RL algorithms. The design of the QR-based Retrace algorithm may not be novel enough. I would be happy to see a better version of this paper in the future.	The reviewers carefully analyzed this work and agreed that the topics investigated in this paper are important and relevant to the field. Although the reviewers generally expressed positive views on the proposed method, they also pointed out many possible limitations of this paper. On the one hand, one reviewer acknowledged that the authors provided the first theoretical guarantees on multi-step off-policy distributional RL algorithms via a novel algorithm. They argued, however, that the methodological novelty may not be too significant compared to the baseline QR-DQN, and that the experiments could be improved. After reading the authors' rebuttal, this reviewer—although still with an overall positive impression of the quality of this work—said that they do not believe the paper fully shows the particularity of applying the multi-step idea to DRL when compared to some value-based methods. They also believe that the empirical section of the paper was not strong enough. Another reviewer agreed that this is novel and significant work, as it introduces a non-trivial extension of one-step distributional RL to the multi-step off-policy setting. They argued that this paper provides a theoretical basis for the continued study of multi-step paradigms in off-policy reinforcement learning, which is important/significant. This reviewer, however, pointed out that the experimental results were not sufficiently convincing to support the claims that employing the multi-step distributional RL algorithm provides a significant empirical advantage. This reviewer carefully analyzed the authors' rebuttal and appreciated that they clarified the reviewer's original points of confusion. Overall, however, this reviewer agreed with others that the empirical results are not overly convincing. Furthermore, one of the reviewers argued that the notion of path-dependent distributional TD error is novel. They pointed out, as the main limitation of this paper, that investigating the multi-step distributional RL setting "may not be [particularly interesting since] some theoretical results on one-step distributional RL can be straightforward to extend into the multi-step version". They also argued that the unbiased QR-loss was not clearly motivated since the bias for RL may also be useful for exploration. After reading the authors' rebuttal, this particular reviewer updated their score since the authors provided more evidence to strengthen their theoretical and empirical claims. Overall, all reviewers were positively impressed with the quality of this work but brought up many points of contention regarding ways in which the paper could/should still be improved. They encourage the authors to update their work based on their constructive criticisms and, in particular, in a way that tackles the points of contention mentioned in the original reviews and their post-rebuttal comments.
Below are multiple reviews of a paper. This paper highlights the concern of unfair discrimination caused by imputation of missing feature values in graphs. They show that the theory supports their claims. Empirical evaluation on simulated stochastic block model (SBM) data also supports their cliams. However, on real data the results are not as expected, leading to future researchThis paper provides theoretical analysis on the estimation error of fairness, in the setting where missing data is present. While the theoretical results can be useful in understanding the behavior of fairness estimation under different settings, I am not sure if they will have much practical impact.The authors studied the effect of graph feature imputation on the fairness of models. The proposed method empirically showed improvement on synthetic datasets but not on real-world credit datasets.This paper discusses some of the problems related to fairness that can occur when a machine learning model is applied to graph data with missing values. Fairness is considered concerning two groups, a marginalized group ($Q$) and a dominant group ($R$). It seeks to derive theoretical results relating the Total Variation Distance between the conditional prediction distributionThe authors consider the problem of fairness when imputing features in a group setting where on average there is higher difference to ground truth among the marginal groups vs the dominant groups. Experiments are shown on both synthetic and real-world fairness-utility tasks.This paper studies the effect of mean aggregation feature imputation in graphs over marginalized and dominant groups. The paper proposes an algorithm to compensate for the discrimination across groups in each iteration. The algorithm can provably satisfy epsilon-fairness.	The work discusses some of the problems related to fairness that occur when a machine  learning model is applied to data with missing values in graphs. The authors propose a methodology to  compensate for the discrimination across groups.    All the reviewers and the AC agree that the paper overall idea of the paper is strong and very interesting. The paper is extremely well-written, easy to follow and contirbutions and limitation well described.   The main concern with the paper is its practicality as results on real-world datasets are not providing  any promising lift in terms of fairness. This is also acknowledged as a feature direciton by the authors in the rebuttal.  The AC believes that this is a promsing and impactful line of work and will ignite interesting discussions in the NeurIPS community.  As another reviewer pointed out, there is not much work connecting the imputation and fairness in the graph context. Acceptance is recommended.
Below are multiple reviews of a paper. This paper uses the pre-trained large model (CLIP) to transfer the language knowledge to the unseen labels. The experiments also show good results on several benchmarks in a zero-shot setting. However, the method is not novel and leads to many problems. The authors notice the issues but leave them to the readers.LSeg embeds text labels and image pixels into a common space, and assigns the closest label to each pixel. LSeg is flexible and can dynamically handle arbitrary label sets on the fly with varying length, content, and order.This paper is about semantic image segmentation, the template weights of each category is generated by language text. This method is similar to image classification of CLIP on ImageNet-1k. As a comparison, this paper can be treated as FCN v.s. VGG.	The paper presents an approach to semantic segmentation based on text embedding of class labels. This enables zero-shot semantic segmentation with class labels that were not seen during training. I appreciate the new ablation against a ResNet-101 backbone. I don't find the similarity with CLIP substantial, and I recommend that the paper is accepted.
Below are multiple reviews of a paper. This paper mainly studied how the negative samples can affect the model performance in supervised learning CIO works. The majority of negative samples are not important for the model learning, only a small subset of hard samples determine the model importance.This paper argues that in contrastive self-supervised learning, different negative instances have different importance. On ImageNet and MoCo2, the authors show that using the most difficult 5% negative instances can achieve similar performance compared with using all negative instances. The most difficult 0.1% of negative instances yield bad performance.The findings of this work are that for contrastive learning, most of the negatives deemed easily separable are unnecessary. The most important negatives are somewhere in the top 5% closest to the positive sample. Some of the exceedingly hard examples are detrimental.In this paper, the authors carried out a series of experiments to analyze the impact of negative samples in contrastive learning. Their main findings are, for negative samples, 1) Using the 5% hardest is enough for downstream tasks, 2) the easiest 95% of them were unnecessary and insufficient.	This paper empirically studies the impact of different types of negatives used in recent contrastive self-supervised learning methods. Results were initially shown on Mocov2, though after rebuttal simCLR was also added, and several interesting findings were found including that only hardest 5% of the negatives are necessary and sufficient. While the reviewers saw the benefit of rigorously studying this aspect of recent advances in self-supervised learning, a number of issues were raised including: 1) The limited scope of the conclusions, given that only two (after rebuttal) algorithms were used on one datasets, 2) Limited connections drawn to existing works on hard negative mining (which is very common across machine learning including metric learning and object detection), and 3) Limited discussion of some of the methodological issues such as use of measures that are intrinsically tied to the model's weights (hence being less reliable early in the training) and WordNet as a measure for semantic similarity. Though the authors provided lengthy rebuttals, the reviewers still felt some of these issues were not addressed. As a result, I recommend rejection in this cycle, and that the authors bolster some of these aspects for a submission to future venues.   I would like to emphasize that this type of work, which provides rigorous empirical investigation of various phenomena in machine learning, is indeed important and worth doing. Hence, the lack of a new method (e.g. to address the selection of negatives) was not the basis of the decision. While the paper clearly does a thorough job at investigating these issues for a limited scope (e.g. in terms of datasets), a larger contribution is expected for empirical papers such that 1) we can ensure the generality of the conclusions (across methods and datasets), 2) we have a conceptual framework for understanding the empirical results especially with respect to what is already known in adjacent areas (e.g. metric learning and object detection), and 3) we understand some of the methodological choices that were made and why they are sufficiently justified.
Below are multiple reviews of a paper. The proposed methodology for temporal super-resolution is an intriguing fusion of numerical methods and deep learning. The data section is well-detailed and code is provided, aiding reproducible research. Some details in the experiment section suggest the presence of overfitting.Application deep learning to solving partial differential equations is not new. Overall, I do not see stability and accuracy related analysis of the proposed approach, and I don't see the generalizability either.The main strength of this method is the effective integration of methods from Physics and Machine Learning. The main weakness I see is in the results. We can see only minor improvement over SRGAN-TM.	Meta Review: This paper on spatial and temporal super-resolution of turbulent flows. The novelty is acknowledged by Reviewer 1 & 2, while Reviewer 3 pointed out that the paper lacks theoretical analysis and formulation. Reviewer 1&2 also raise conern on the risk of overfiiting, and suggest a clear description of experiment settings and full comparison with more recent baselines. In all, the meta-reviewer considers the pros to outweigh the cons, and recommends acceptance. The authors need to incorporate the comments when preparing the final version
Below are multiple reviews of a paper. The research field of video TAP is under-studied. This paper introduces a companion benchmark it would benefit the community. The proposed baseline method presents the usability of the benchmark.The paper proposed TAP-Vid dataset, which is a benchmark for tracking any point in a video. Given a video clip and a set of query points, the goal is to predict trajectories over the whole video.TAP-Vid aims to expand keypoint tracking in video with a greater diversity of points and longer duration point tracks that account for occlusion. The contributed data is data recorded from a pre-existing robotic object-stacking simulator.This paper constructs a new dataset for arbitrary physical point tracking. The proposed task, i.e., tracking any points (TAP), can benefit the development of embodied agents.This paper formulates the problem of ‘tracking any point’ on video data. It aims to track points starting from any pixel in any frame, not using a variation of keypoints to limit point selection.This paper introduces a new benchmark dataset for the task of tracking any point (TAP), i.e., tracking an arbitrary 2D point defined at the first frame over the entire video. The dataset is composed of a mixture of real and synthetic data where for real data, human manually annotates the ground truth for a number of 2	TAP-Vid presents a benchmark that will be highly useful for tracking research for tracking arbitrary physical points on surfaces over long video clips. The reviews are all positive, with one reviewer raising ethical aspects in preparing the benchmark.  I find the rebuttal sufficient and adequate and hence recommend acceptance of the paper.
Below are multiple reviews of a paper. CyclesGym is a new benchmark environment for reinforcement learning (RL) applications to agriculture and farming. The benchmark allows for different crops to be produced over a span of multiple years. For the agronomist, this environment could provide a more realistic simulation of the real world.In this manuscript, Turchetta et al. propose a new environment for crop growth models (CGM) simulation. The simulator is a wrapper around the software Cycle, one of many CGM that can be used for simulation of crop growth and crop rotation.This paper introduces CyclesGym, an RL environment based on the multi-year, multi-crop crop grow model (CGM) Cycles for open field agriculture. The targeted problem of RL applications in crop management/agriculture is understudied and has great potential for societal impact. The experiments are interesting, which encompassThe proposed benchmark improves on previous RL environments for an important domain with widespread consequences. The provided experiments and evaluation allow the authors to identify the more pressing issues of RL algorithm design when applied to crop management.A key challenge all of these agronomic simulator-RL approaches have is that the simulators are not reliable. Until that is addressed, it's unclear that these simulators have any real value. The authors address that there is a sim-to-real gap that they are not addressing.	This proposal introduces CylesGym, the first Reinforcement Learning (RL) benchmark targeted at long horizon decision making in agriculture. Crucially, while prior work addresses single-year decision making, CylesGym captures the long term effects that one year's crop has on future generations.   The benchmark is clearly highly relevant and opens up a new frontier for RL researchers, making it a valuable contribution to the field. Furthermore, the benchmark does a good job of highlighting interesting opportunities for RL method development, such as costly information gathering, and evaluating current algorithms compared to baselines.   There was an active discussion between the reviewers and authors of the benchmark which resolved the majority of issues raised in the initial reviews. As a result there is broad support across the reviewers for the paper. A lingering concern is the sim-to-real gap which is mentioned at a number of places in the paper but could be emphasised more.   Lastly, the paper is well written and the evaluation sound. I believe this benchmark will be welcome by the community but I recommend that the authors address the concerns regarding the writing raised by  Reviewer MEYG, in particular regarding the utility for the agriculture community. In general I do not believe that issues which can be addressed in writing should be a reason to reject but those concerns should be addressed for the final version.
Below are multiple reviews of a paper. The writing is difficult to follow, unclear in several places, and has grammatical mistakes. The approach does seem somewhat incremental, though I would be open to changing my mind on author response. The paper shows experiments that validate that the method can learn meaningful representations in practice.In this paper the authors present a differentiable objective for slow feature analysis. I am not clear on the novelty of this formulation, as it appears to have been proposed in a similar form in previous works. Nevertheless, the approximate whitening layer and the way it is used is a smart approach for this problem.The manuscript proposes to use power iterations in an approximate "whitening layer" to optimize the slowness objective of SFA in a very general setting. A set of experiments illustrates that this way of doing nonlinear SFA is meaningful.	This paper proposes to unroll power iterations within a Slow-Feature-Analysis learning objective in order to obtain a fully differentiable slow feature learning system. Experiments on several datasets are reported.   This is a borderline submissions, with reviewers torn between acceptance and rejection. They were generally positive about the clarity and simplicity of the presentation, whereas they raised concerns about the relative lack of novelty (especially related to the recent SpIN model), as well as the current limitations of the approach on large-scale problems. Reviewers also found authors to be responsive and diligent during the rebuttal phase. The AC agrees with this assessment, and therefore recommends rejection at this time, encouraging the authors to resubmit to the next conference cycle after addressing the above points.
Below are multiple reviews of a paper. This paper proposes to use MCTS to enhance existing algorithms for Multi-Objective Optimization problems. The idea is simple, well-explained and the results are promising.The paper develops an enhancement to multiobjective solvers so to find better Pareto solutions. The idea is to learn a proxy of the distance of samples to the Pare to split the search space via a tree structure.This work proposes a novel learning-based method called LaMOO to partition the search space for the multi-objective optimization problem. With the learned partition, the computational budget can be allocated to the small promising regions (e.g., the region close to the Pareto frontier) rather than the whole search space. The proposedThis paper presents a learning space partitions-based multi-objective optimization framework. It uses Monte Carlo tree search and an innovatively proposed metric, i.e. dominance number. The metric of dominance number is reasonable and easy-to-follow.	Multi-objective learning is an increasingly important topic. This paper presents a method for better finding parts of the Pareto frontier through a new method to estimate the distance to the frontier and use this proxy to refine the state space partition.  The reviewers found this paper interesting and compelling and generally well written. The reviewers also thought the work could be further improved by better clarifying in the text where the proposed approach might fail, and what properties of the domain are needed, and also to better situate this paper within the related work, potentially including additional experimental comparisons. The authors provided detailed responses to the proposed questions and the authors are encouraged to ensure that these suggestions and discussions are well represented in the revised version.
Below are multiple reviews of a paper. The paper addresses the multi-armed bandit problem where post-action contexts are observed and may or may not be a d-separator. Many algorithms including the UCB algorithm achieve the optimal regret. Authors propose a new algorithm based on consecutive hypothesis tests.This paper proposes a novel algorithm for causal bandits that achieves ‘best of both worlds’ In the causal bandit setting, the player observes some other post-action contexts after they play some action, rather than observing all contexts before they play an action. Under this setting, they introduce the conditional benign property which is closely tied withThe authors study adaptivity in the setting of causal bandits. They consider a bandit setting where after an action a is taken, a post-action context Z_a is observed. They propose a new property, a conditionally benign bandit environment that subsumes Z being a d-separator. They develop an algorithm that isThis paper studies the problem of online learning in causal bandits. Existing methods assume that the correct causal graph is provided. The authors propose an algorithm that could achieve a sub-linear regret in the most general cases.	This paper exploits the causal structure in the multi-armed bandits setting and gives a set of novel and strong results, including (1) the conditional benign property -- a nice and simple generalization of prior assumptions; (2) an impossibility result for the previous algorithm C-UCB; and (3) a new algorithm gives sublinear regret in any cases and optimal regret when there actually is a d-separator.  The paper is well-organized and nicely written.  The reviewers are unanimously positive about this paper.
Below are multiple reviews of a paper. This work focused on the adversarial MDPs with delayed and bandit feedback. Compared with previous results, the author proposes novel algorithms and improves the regret bound of $(K+D)^{2/3}$ to $k+D$.This paper considers online learning in the adversarial MDP setting with unknown transitions, adversarially changing costs, and (unbounded) obliviously adversarial delayed bandit feedback. It proves the first near-optimal regret bounds which scale as $K$ the number of episodes and $D$ the sum of delays overThe paper studies online learning for adversarial MDP with delayed bandit feedback in the tabular cases. It proposes three algorithms to solve the problem. All these algorithms achieve better regrets than existing algorithms.	This paper has initially received mixed reviews, but the author response has successfully addressed the concerns of the less enthusiastic reviewers, thus we have eventually reached consensus that the paper is suitable for publication at NeurIPS 2022. That said, I encourage the authors to take all the reviewers' comments into account when preparing the final version, especially when it comes to improving the readability and self-containedness of the proofs in the appendix. As for the usage of the term "near-optimal" in the title, I concur with the reviewers who pointed out that this may not be the perfect choice of words. This is not to say that it is necessary to change the title of the paper, but perhaps a better choice of wording may give a better overall impression to future readers of the paper.
Below are multiple reviews of a paper. This paper tries to address the big model on the server-side in federated learning (FL) via knowledge distillation. Selective transfer knowledge happens on both server and clients sides. When the server predicts wrong on the public datasets, it transfers the knowledge from the correct, weighted clients.This work proposed a KD-based FL framework for training a larger server model securely. The proposed framework is a combination of FedGKT-like idea and further apply some KD strategies for selective transfer.The paper proposes an empirical technique to train large server models with selective knowledge fusion. The paper passes logits predicted on a public dataset accessible to both clients and server to share knowledge and uses a selection scheme to withstand poisoning attacks. Strengths: The authors tackle multiple challenges in federated learning.This paper aims to enable training of higher accuracy models by training a high-capacity model at the server and lower capacity models at the clients. Knowledge is shared via distillation on a weighted average of logits provided by the clients, rather than by averaging model parameters or model differences. The approach assumes the existence of a labeled public dataset.	This paper proposes a knowledge distillation strategy to enable the use of a large server-side model in federated learning while satisfying the computation constraints of resource-limited clients. The problem is relevant and well-motivated, and the paper presents compelling experimental results to support the proposed strategy. However, reviewers had the following major comments suggestions/: 1) The theoretical analysis section needs improvement in terms of the technical depth and rigor 2) Better explanation of how the proposed strategy compares with previous works/baselines 3) Considering the privacy and scalability properties of the proposed strategy.  The paper generated lots of constructive post-rebuttal discussions between the authors and the reviewers, and I believe the authors received several ideas to improve the work and appreciated the reviews. One of the reviewers increased their score. However, based on the current scores, I still recommend rejection. I do think the paper has promise, and with improvements, the revised version will make an excellent contribution.
Below are multiple reviews of a paper. The paper proposed a contextual knowledge distillation approach by leveraging two types of contextual knowledge: word relations and layer transforming relation. Recent advancement in this area emphasizes the promising effect of this area in language modeling.This paper presents a new knowledge distillation (KD) method for distilling BERT. This area is pretty active given that deploying BERT based models is of keen interest to many industrial applications. My biggest question in the paper is that this is bound to be expensive.This paper presents an interesting knowledge distillation method based on a newly defined contextual knowledge of transformer-based models. The proposed contextual knowledge models the pair-wise or triple-wise relations across BERT-based representations. Compared with existing BERT compression methods, this CKD has the advantage of being directly applied.The methods in this paper consider the pairwise or higher order (i.e. triplet) relations to constrain  the student embeddings. The methods shall provide more constrained information from the teacher network.	This paper proposes a new method to perform knowledge distillation (KD) for transformer compression, where two types of contextual knowledge, namely, word relations and layer-transforming relations, are considered for KD. Both pair-wise and triple-wise relations are modeled.   This paper receives two weak reject and two weak accept recommendations. On one hand, the reviewers appreciate that the authors have added more results into the paper to solve their concerns. On the other hand, several concerns still exist. (i) With regards to the compute-performance trade-off, the gains of the method does not seem too great. One reviewer feels that the authors tried to downplay the cost of their method too much. Though we care more about the inference time, the development time in practice should also not be underestimated. (ii) Compared with TinyBERT, the performance gain looks marginal on the GLUE benchmark (Table 1). (iii) It will make the paper more convincing if pre-training experiments can be performed.   Overall, after reading the paper, the AC thinks that the novelty of the proposed method is somewhat limited. The AC is also hesitant about whether modeling word relations and layer-transforming relations simultaneously are needed. The choices for ablation study are also not totally clear.   For example, in Figure 2, it is not clear why the authors choose SST-2 to plot the figure; in Table 5, it is unclear why SST-2, MRPC and QNLI are selected, but not others. When looking at Table 5, it is not totally convincing it is needed to model both WR and LTR, or it is needed to introduce both pair-wise and triple-wise relations. More careful ablation studies are needed. It also remains unclear what kind of word relations or layer-transforming relations are learned.   In summary, this is a borderline paper, and the rebuttal unfortunately did not fully address the reviewers' main concerns. On balance, the AC regrets that the paper cannot be recommended for acceptance at this time. The authors are encouraged to consider the reviewers' comments when revising the paper for submission elsewhere.
Below are multiple reviews of a paper. This paper addresses the problem of designing local robustness certification procedures for neural classifiers. The proposed technique is able to produce larger certifiable balls and improve upon the certified accuracy of randomized smoothing. The presentation and quality of writing in the paper needs significant improvement before the paper can be published.This paper proposes to exploit the certified robustness of samples in the neighbourhood of a given data. The authors leverage the intersection of the certified regions of multiple neighbourhoods. Compared to the previous state-of-the-art method, the experimental results validate the effectiveness of the proposed method.The paper presents three approaches for geometrically-informed certified robustness. The proposed approaches equipped with two optimization algorithms can outperform the baseline. Overall, it is a paper with a novel and effective idea but needs improvement in writing.The authors provide a method to enlarge the certification radii given by randomised smoothing based approaches. The approaches are evaluate on MNIST, CIFAR-10, Tiny-Imagenet - the networks are based on Resnet18. The ideas are interesting and the contributions are to the best of my knowledge novel.	The paper proposes a very simple idea that can improve one of the strongest robustness certificates. Most of the concerns were minor, and they were well addressed during the rebuttal phase. The reviewers were mostly happy with the current paper though shared a few remaining concerns, which could significantly improve the manuscript if properly addressed in the camera ready version. For instance, it will be great to see whether or not this idea can also improve the robustness certificates produced by different algorithms. The current performance gain still looks marginal, but it might be interesting if the same technique can bring in larger gains for different types of certificates.
Below are multiple reviews of a paper. This paper proposes a scheme for partially sharing CNN parameter across layers. Training CNNs reparameterized in this manner yields improvements along the accuracy-parameter tradeoff curve, compared to baseline models on image classification tasks.This paper proposes a novel method to decrease redundancy of parameters in a CNN through a joint subspace view. The authors use a low-rank decomposition of the convolutional kernel (A * D) into shared coefficients (A) and atoms (D) The authors propose a variety of proposal methods for their method termed Atom CoefficientThe experiments are conducted on four image benchmarks using several CNN backbones. Results show the effectiveness of the proposed ACDC on image classification and few-shot image classification tasks. The idea of coefficient sharing across different settings seem interesting, and a ok experimental results.This paper introduces a joint subspace view between the layers of convolutional neural network. Since the important features across the layers in deep CNN is maintained, the filters can be decomposed into shared coefficients and layer-specific coefficients. By using group convolution, they reduce the amount of parameters as well as maintain the performance.To reduce the parameters of the deep networks, this paper proposes a joint subspace view to convolutional filters across network layers. Experimental results verify the effectiveness of the proposed method.	The paper eventually got 5 "marginally above the threshold" after rebuttal. Such scores testify to that the paper is a borderline one. By reading the post-rebuttal comments, it is evident that most of the reviewers still deemed that the novelty is incremental. One of the reviewer (vUb9) raised the score simply to "encourage the authors to think more important problems", rather than acknowledging the merits of the paper. The AC also read through the paper and had the following opinions: 1. The paper is actually about DNN compression, based on the "new finding" that the weights across layers are low-rank. However, the authors would not write the paper in the way of DNN compression, but put more emphasis on the "new finding", which has no theoretical support at all (only some heuristic reasoning). The AC would deem that the "new finding" is only an assumption. 2. Actually the "new finding" is not new at all. For example,  [*] Zhong et al., ADA-Tucker: Compressing Deep Neural Networks via Adaptive Dimension Adjustment Tucker Decomposition, Neural Networks, 2019,   used a shared core tensor (which could be regarded as the common dictionary) across all layers for higher compression rates. More recent references that use tensors and consider shared information across layers for compression can be easily found as well.  So the AC thanked the authors for preparing the rebuttals carefully, but regretfully the paper is not good enough for ICLR.
Below are multiple reviews of a paper. The paper proposes a dataset and procedure for testing methods that reduce the training sample. The data sources are the well-known CIFAR and TinyImageNet datasets. The methods tested in the paper are state-of-the-art.The paper presents a benchmark for fairly comparing dataset condensation methods. The benchmark evaluates a condensation method’s performance with multiple data augmentation schemes and compression ratios, in addition to its performance in neural architecture search.This work aims to provide a comprehensive benchmark and library to study the true effectiveness of dataset condensation methods. The datasets (CIFAR10/100 and TinyImageNet) and architectures (MLP/ConvNets/ResNets) seem a little bit limited in scope for understanding transferability across architectures. If the goalThe paper proposes a benchmark for dataset condensation techniques. It aims to identify various factors to be analyzed when investigation dataset Condensation. These factors are then investigated empirically for the CIFAR and tinyImageNet datasets on the basis of four recently proposed condensation methods.This paper introduces a data condensation/distillation benchmark under different model architectures, compression ratios, and datasets. The evaluation also considers a neural architecture search scenario, and two data selection mechanisms. There are several parts that require further explanation, and some of the experimental setup choices are not justified.The authors propose a dataset condensation benchmark for images. They compare four methods: DC, DSA, DM, and TM. The paper addresses an important problem in ML.	There are quite a few problems raised by the reviewers worth paying attention to:   - Thoroughness of evaluations: Performance metrics are difficult to understand and insufficiently justified and described. There's also mention of non-performance related metrics like bias not being adequately considered. There's some debate over the appropriateness of the included baselines, and some skepticism about the justification for some experiments. Furthermore, Reviewer SxsG notes, "It would be great to see standard deviations/any measures of statistical deviations across randomly seeded experimental repetitions in any of the experimental result figures" and I agree. I also think authors could do a better job in the main text or supplement justifying the use of these specific baselines. However, in the revised version of the paper, many of these issues are addressed with the re-write of Section 3.  - Restricted scope: Many mention the limitation of focusing on images and a small handful of datasets. Reviewer aF85 notes, "The datasets (CIFAR10/100 and TinyImageNet) and architectures (MLP/ConvNets/ResNets) seem a little bit limited in scope for understanding transferability across architectures" and I'd agree, though I recognize that a goal of the tool is to allow for others to also contribute datasets, and send their models to be tested. Also, the authors are correct in noting that many of these issues are a byproduct of the fact that much of the data condensation work so far has been focused on image datasets.  - Usability: Reviewer Qbsw, Reviewer SxsG and especially Reviewer 5Lwd all mention issues with documentation, and not how difficult it is to follow the provided instructions in order to assess a model, add a new dataset, etc. However, the authors seem to have addressed many of the concerns, improving documentation significantly following this feedback.   Overall, it seems the authors paid attention to reviewer critiques and responded respectfully and meaningfully to the provided feedback. Given the importance of the topic and the current lack of testing infrastructure in this area, I recommend we accept this paper as a poster. I hope authors continue to take in feedback at the conference to continue to make further improvements to their benchmarking platform.
Below are multiple reviews of a paper. The biggest strength of this paper is the strong experimental results on their new initializations scheme on deep GNNs. I think that result alone could be the basis of a decent paper, if other major concerns are addressed.This paper relates GCN to PCA from the perspective of optimization. The authors propose Graph PCA that is a general form of GCN. The paper is well written and easy to follow.This paper attempts to establish the relationship between Graph PCA and Graph Convolutional Layer, so as to define a new Graph Neural Network based on graph PCA. The paper shows us that regularization of weights may be necessary for GNNs.This manuscript looks at the classic graph-regularized PCA (GPCA) and try to build the connection with GPCA and the state-of-the-art GCN, and finally proposes a new deep graph network GPCANet. The contributions presented in this manuscript are quite obvious to my knowledge, but not	The paper presents several related results. The initial main result consists in relating GPCA to GCN, showing that GPCA can be understood as a first order approximation of some specific instance of GCN where the W matrix is directly defined on data. This result is then exploited to define a supervised version of GPCA. As a follow-up the authors propose a novel GPCA-based network (GPCANet) and a GPCANet initialisation for GNNs. The paper is well written and easy to read. Empirical results are reported to verify the above mentioned connection between  GPCA and GCN, as well as the performances of  GPCANet  and the proposed initialisation for GNNs. Overall, while the mentioned connection was never explicitly reported in the literature, its existence is not surprising and thus its significance seems to be limited. Also the performances of GPCANet do not seem to be significant from a statistical point of view. The novel initialisation procedure for GNNs seems to be interesting and promising, although the used datasets may not make evident its full power. Authors rebuttal and discussion did not change the reviewers' initial assessment.
Below are multiple reviews of a paper. The paper propose a learning to rank surrogate approach as surrogate for the problem of counting and localization in dense senses. It is claimed that this labeling approach significantly reduces the labeling time and it sufficient to learn a dense map. In addition to the pairwise ranking loss, the paper use an adversarial training strategy to make the predictions look more likeThis paper proposed an object counting and localization method which uses pairwise image ranking information for training. A count-based ranking objective is proposed for model optimization. An adversarial density map generation strategy is introduced to regularize the features of the network.In this work, authors propose to learn to count objects in weakly supervised setting where only pairwise ranking information is used as supervision. The annotation cost is expected to be much lower than the widely-used dot annotation. An adversarial density map regularization method is proposed to enforce the properties of a density map.	Even though reviewers found some responses by the authors satisfactory, several concerns regarding the paper still remain. The authors are strongly encouraged to:  1) Explore how dataset size impacts accuracy. 2) Reason about annotation costs via empirical experiments. 3) Including benchmark datasets in experimental evaluations.
Below are multiple reviews of a paper. Adversarial Surprise is a new approach for unsupervised reinforcement learning in stochastic BMDPs. The algorithm uses a single agent with two policies, an Explorer and a Controller, which switch during an episode with opposite rewards: to maximize and minimize "surprise"Adversarial Surprise (AS) is a method for unsupervised training of RL agents based on the competition of two policies dubbed Explore and Control. AS explores more rooms within an episode in Minigrid, visits more x positions in VizDoom, and obtains higher zero-shot scores in 3/4 Atari games.Adversarial Surprise (AS) is a method for unsupervised reinforcement learning. AS employs a two-player, adversarial, sequential procedure in which an Explore player tries to maximize the approximate entropy of the observations. The method is then compared against other unsuper supervised RL baselines in visual domains.	The idea of having two policies with opposing strategies, one aiming to maximize a notion of surprise whereas the other tries to minimize it, is an interesting one. However, even after the author rebuttal, all reviewers have lingering concerns about the evaluation protocol. In addition, there are remaining questions about the bonuses used; there are concerns that these only work for very specific domains. For these reasons, I'm recommending rejection. I encourage the authors to carefully read the concerns of the reviewers about evaluation and consider using a different evaluation protocol for a future version of this work.
Below are multiple reviews of a paper. This paper improves the DreamerV2 model-based RL framework, by replacing the the discrete world model encoder with a MAE-like encoder. Experiments show that the proposed method achieves much better performance tha the original Dreamer V2.The paper presents a method for decoupling visual representation and latent dynamics learning for control. It does so by combining  recent approaches for visual representation learning (ViT) and latent Dynamics learning (Dreamer) for control such that they are decoupled.This paper presents Masked World Models (MVW), a model-based reinforcement learning framework for visual control. MVM uses a self-supervised Visual Transformer for representation learning, and it performs masking on convolutional features.The paper considers model-based RL with visual input. The key idea is to decouple visual representation learning and dynamics learning. The paper presents performance results on a variety of visual robotic tasks from Meta-world and RLBench.This paper successfully achieved visual representation learning for world models in visual model-based RL with good accuracy. The proposed method achieved higher success rates than conventional methods in variety of robot tasks.	This paper introduces an model-based RL approach that decouples visual representation learning and dynamics learning using a ViT. Results show that both this decoupling and the replacement encoder result in improved performance on a range of simulated benchmarking suites and tasks (RLBench, metaworld, dm_control). In the initial review process reviewers noted that the paper was  * Well written, interesting idea and a unique model design * Good performance demonstrated in simulation and well structured ablations  but expressed concerns about  * Some missing literature, and questions about the strength/ suitability of the baselines (eg. no comparison with other decoupled models, baseline tuning) * No experiments on real hardware * Potential limitations of the approach re versatility due to the inclusion of reward in the representation learning task, which learns task conditioned dynamics models  The authors rebuttal included some additional baselines, argued that there is evidence that similar models do transfer to real world settings, and added additional results to address concerns about overfitting to tasks by conditioning on reward (reward signal can be task agnostic or aid in representation learning). Reviewers were generally positive about this work post rebuttal, so I am recommending acceptance. Although there is a strong focus on real robot experiments at this years CoRL, I believe the extensive number of experiments on multiple benchmarks makes up for the missing real robot experiments to some extent.   I encourage the authors to include the additional experiments in the supplementary material included with the camera ready paper, along with additional clarifications and discussion points raised during the review process.
Below are multiple reviews of a paper. The proposed method is very similar or equal to the conditional VAE. The only difference comes from the way of involving the condition information during training. It is not intuitive how significant the improvement of 5% in PIS.The paper brings up a relatively new problem of learning a generative model for multiple domains. The domains, D1,...,Dn, may refer to person-specific preferred images. They focus on how to build generative models P(x|Di), which represents a set of images preferred by subject i.This paper does not deal with the conventional domain adaptation problem as many existing domain adaptation works do. It focuses on the adaptation task of data generation. The proposed framework assumes a prior, and models each domain as a posterior. Experimental studies are done to show the effectiveness of the proposed framework.	This paper proposes using conditional VAEs for multi-domain transfer and presents results on CelebA and SCUT. As mentioned by reviewers, the presentation and clarity of the work could be improved. It is quite difficult to determine the new/proposed aspects of the work from a first read through. Though we recognize and appreciate that the authors updated their manuscript to improve its clarity, another edit pass with particular focus on clarifying prior work on conditional VAEs and their proposed new application to domain transfer would be beneficial.   In addition, as DIS is the main metric for comparison to prior work and for evaluation of the final approach, the conclusions about the effectiveness of this method would be easier to see if a more detailed description of the metric and analysis of the results were provided.   Given the limited technical novelty and discussion amongst reviewers of the desire for more experimental evidence, this work is not quite ready for publication.
Below are multiple reviews of a paper. This work focuses on the problem of speeding up adversarial training in the $\ell_\inf$ threat model. The work shows a promising approach (as measured by outperforming Fast-AT-GA at $16/255$ in terms of standard accuracy while beating it in speed and in robust accuracy)The paper studies adversarial training as a bi-level optimization problem. The proposed method is evaluated on CIFAR10 and ImageNet against multiple baselines. Given that within the same computation budget as the baselines, the proposed method has lower variance and resolves catastrophic overfitting.The paper proposes a bi-level optimization problem for training models robust to norm constrained adversarial attacks that can be optimized via argmin/implicit differentiation. The new technique is then compared empirically to other existing approximations of the robust training problem and shown to provide improved or comparable results in terms of standard and robust accuracy.This paper aims to interpret the fast adversarial training methods from the perspective bi-level optimization. In general, I like this perspective due to the realizing of the implicit gradient term. However, in the current version of the paper, there exists several key points that requires careful justification to make it as a much stronger piece of work.	This paper investigates fast adversarial training methods as a bilevel optimization problem. The proposed algorithm compares well with the existing techniques in overall runtime (obtaining better clean-test accuracy, which is not the goal, and) matching the robust accuracy of existing adversarial training methods. The proposed framework, however, is more general and flexible and is theoretically grounded. The problem studied here is exciting and the approach the authors take is interesting.   The current version, unfortunately, has some serious shortcomings. The empirical comparisons are a bit lacking — in general, the wall clock time is not a very good measure, it depends heavily on the implementation and various optimizations therein. A more suitable comparison would be in terms of floating-point operations, or in terms of iteration complexity.   The paper reports other interesting findings such as how the proposed method avoids robust overfitting. However, there is little theoretical evidence or insight for how the proposed method avoids it.   The writing can be improved with more emphasis on the novelty and significance of the contributions — some of the statements regarding improvements over prior work are somewhat misleading given the incremental gains (e.g., see Table 1). I believe the comments from the reviewers have already helped improve the quality of the paper. I encourage the authors to further incorporate the feedback and work towards a stronger submission.
Below are multiple reviews of a paper. The paper proposes a new evaluation metric for generative adversarial networks and shows that it is better aligned with human judgment than FID. The metric is based on a domain-specific encoder to extract features of the image rather than ImageNet inception network.This paper proposes a variant of the popular FID score for evaluating GAN-type generative models. The paper makes two major complaints about the FID as it is currently used. The standard Inception network features trained on ImageNet might not be a good representation for whatever different dataset is being modeled.The authors study the task of sample-based quantitative evaluation applied to GANs. The ideas make sense on a conceptual level, albeit suffering from major practical concerns.	The paper proposes a novel sample based evaluation metric which extends the idea of FID by replacing the latent features of the inception network by those of a data-set specific (V)AE and the FID by the mean FID of the class-conditional distributions. Furthermore, the paper presents  interesting examples for which FID fails to match the human judgment while the new metric does not. All reviewers agree, that while these ideas are interesting, they are not convinced about the originality and significance of the contribution and believe that the work could be improved by a deeper analysis and experimental investigation.
Below are multiple reviews of a paper. CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of New York for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.A new framework graph-enhanced GoRL (G2RL) is proposed by leveraging the state-transition graph. G2RL produces under-explored goals (or goal states) by planning on the “one-episode ahead” graph.Paper presents a goal-oriented RL framework based on state-transition graph. Compared to prior work like SoRB, GoalGAN, HIRO, the proposed method G2RL demonstrates higher success in exploration on discrete and continuous control benchmarks.The authors describe a novel graph-augmented RL method for goal conditioned tasks. The results shown outperform a number of baseline methods. The method is well motivated and theoreticaly grounded.The paper proposes a goal generation procedure in order to improve goal-oriented reinforcement learning (GoRL) The idea is intuitive and could work in various settings, although the presentation itself is convoluted. The experimental results show modest improvements in terms of final performance.	This paper proposes a new approach to goal-oriented RL (GoRL) which constructs a state-transition graph from experience and uses this to guide exploration. Compared to prior approaches, this work innovates on (1) how subgoals are selected and (2) how relevant experience is sampled from the replay buffer. This approach outperforms a number of baseline methods across a fairly wide range of environments. The paper also includes extensive ablation and generalization studies.  The reviewers agreed the problem tackled by the paper was important, and were impressed by the empirical evaluation. Several reviewers (6obU and Sjwy) appreciated the theoretical grounding of the method as well, and generally found the approach to the problem compelling, with Reviewer 6obU writing that “defining the optimal goals to explore on the graph by looking one-step (or one-episode) ahead is a very interesting idea” and Reviewer EMRL noting a strength of the paper was a “goal generation method that explicitly considers only having access to a partial graph of the MDP”. The main concerns raised by the reviewers had to do with clarity and the simplicity of the experiments; however, the reviewers felt these were sufficiently addressed by the rebuttal. I agree the approach seems well-motivated and interesting and recommend acceptance as a poster.
Below are multiple reviews of a paper. This paper explores the prospect of theorem proving in natural mathematical language using large language models (LLMs) Two representative tasks are considered: generating the next step in a partial proof, and generating full proofs given only the statement of a theorem. A dataset for these tasks (based on the existing *NaturalProofs* benchmark) is contributed.NaturalProver is a machine learning-based proof solver that leverages large language models (e.g., GPT-3) for more than just natural language processing. The two-pronged approach of full proof and, perhaps more interestingly, next-step proof assistance, is compelling and has a reasonable amount of immediateThe authors use the NaturalProofs-Gen dataset to fine-tune GPT3 using two new loss functions: proof generation using in-context references and reference reconstruction. They evaluate the system on multiple metrics like usefulness and correctness of the proof steps.	The paper addresses an exciting problem statement--generating theorems directly in natural language--and shows how to adapt large language models to this task, both for autocompletion, proof reference generation, and wholecloth proof generation. While previous works have considered various auxiliary mathematical tasks posed in natural language, this work takes an important step by making progress toward doing proofs directly in natural language. This is a hard problem, and the authors support their work with experiments showcasing and analyzing different kinds of successes and failures. The reviews are unanimous in recommending acceptance.
Below are multiple reviews of a paper. Surgeon is a ANN/evolutionary algorithm hybrid optimization de- signed for neural architecture search. On SVHN and CIFAR-10, the network generated by the Surgeon is able to outperform the baseline in case of suboptimal topologies.This paper presents a neural network training framework based on a genetic algorithm called Surgeon. The idea consists of two modules. First, a series of network structure changes that aims to minimize the network input and output. Second, a heuristic for ranking and selecting the potentially good network modifications.The paper is a combination of genetic algorithm with recommendation rule. While these tools are organized in a reasonable manner, the overall idea seems rather simplistic and the contributions seem rather humble.This study aims to search for topology jointly with the network training. The topology is optimized by a heuristic search in structural modifications including adding/removing neurons/layers. Experiments on SVHN and CIFAR-10 are conducted to show the effectiveness.	This work proposes a framework to search for the topology of an artificial neural network jointly with the network training, via a genetic algorithm that can decide structural actions, such as addition or removal of neurons and layers. An extra heuristic based on Bayesian information criterion helps the optimization process decide on its decisions about the topology. They demonstrate improvements over baseline fully-connected networks on SVHN and (augmented) CIFAR-10.  Reviewers and myself agree that this is an interesting idea, and that the paper is easy to follow. While I may not agree that we need to achieve SOTA on these datasets, or see large scale ImageNet-type experiments for novel ideas, I agree with the reviewers, esp R1's point that the current experiments are not satisfactory to meet the bar for acceptance at ICLR.  CIFAR-10 and SVHN are well-established tasks, and showing baseline accuracy of 75%/48% on them respectively doesn't seem to do them justice, especially when most methods (even with low compute requirements) can get > 95% on both, for the past few years. For this work to be of interest to the broader community, it needs to be improved to incorporate at least respectable baselines on these small datasets, and perhaps be improved to work beyond fully connected networks.  At this stage, we need to see a revision of the method and see improvements before an acceptance decision can be made.
Below are multiple reviews of a paper. This paper proposed a 3D object segmentation method that can be trained in an unsupervised fashion. The core underlying assumption is the rigid motion dynamics and shape invariance between point cloud sequences. The paper has demonstrated promising results on multiple different datasets and scenarios.This paper studies the problem of unsupervised 3D object segmentation from a point cloud. The proposed approach learns the scene flow in a self-supervised manner which is used as supervision signal.The paper proposes a pipeline of 3D object segmentation from point clouds. The key idea is to add several regularization losses to enforce geometry consistency on object motion. The paper leverages self-supervised scene flow estimation models to obtain initial motion estimation from a pair of point clouds and a neural network.This paper introduced a self-supervised approach to do instance segmentation on point clouds. The key contribution is a set of auxiliary losses to ensure segmentation consistency under per-object rigid transformation and view-variance.	This is an interesting paper that proposes a novel unsupervised approach for object segmentation from point clouds, for rigid objects. The strong results demonstrated can be impactful both for 3d as well as potentially 2d vision. After rebuttal, all 4 expert reviewers are convinced that the paper should be accepted, so the decision to accept the paper was easy.
Below are multiple reviews of a paper. This paper proposes an approach for making Maximum A Posteriori (MAP) inference on the intensity function of a Poisson process. It is unclear why this work is needed. Do we really need Augmented Permanental Processes?This paper proposes an efficient Beyian algorithm to estimate the intensity function as a function of Covariates in a Reproducing Hilbert Kernel Space (RHKS) The purposed algorithm is based on an augmented permanent process and enjoys significant computational advantages.The paper proposes a new inference method for a variant of a Gaussian Cox process, which the authors call augmented permanental process (APP) The method is evaluated on a synthetic and three real-world datasets.This paper studies a fast Bayesian inference of point process intensity as a function of covariate. Using the path integral formulation of Gaussian processes, the maximum a posteriori estimate can be obtained by minimizing the action integral.This paper proposed an augmented permanental process whose intensity is modeled by a Gaussian process on covariate space. The proposed algorithm is based on path integration and Laplace approximation. The work does not have potential negative societal impact.	The paper looks a the Augmented Permanental point process as a model of (spatial) point phenomena.   One reviewer was unconvinced that the method was needed at all, which the authors refuted. There was a long exchange but I'm on the side of the authors here - the method is clearly distinct from a point process defined on the covariate space. I'm happy that the reviewer was able to make their point and that the discussion was enabled, and I applaud the authors for their patient responses. I'm disregarding that reviewer's score.   The reviewers suggest that an important and interesting contribution is the representer theorem for squared processes. I also appreciated the authors discussion on the approximation error on the integral operator. These should be highlighted in the manuscript.   There was the occasional confusion from the reviewers on notations: for example, the reviewers failed to spot the the performance of the method was presented in the paper using the $\tau$ column in the tables. Please, double check all the reviewer feedback for clarifications.   Overall, I think that there are a couple of interesting ideas in the paper that people working on Point Process data will be impacted by, and am recommending that this is just above the acceptance threshold.
Below are multiple reviews of a paper. In this paper, the authors developed a probabilistic programming framework for stein variational gradient descent and its variants using nonlinear kernels or matrix kernels. Simple experiments are included that the repository is effective and scalable for various problems.The paper shows how a particle-based nonparameteric Variational Inference methodology is integrated in a full-featured Probabilistic Programming Language, NumPyro. The authors describe a new variant of Stein VI which they call ELBO-within-Stein. This introduces a new line of research for Stein VI.EinStein VI is a lightweight composable library for Stein Variational Inference. The library is built on top of NumPyro and can take advantage of many of Num Pyro's capabilities. There is no strong evidence to support either the usability of the system (through elaborate examples) or its performance.This work is a description of a library for developing variational inference algorithms using the ELBO-within-Stein framework. Unfortunately the authors link directly to the code, and the code is not anonymous. This might be a desk-reject as this is not a double blind review.	All reviewers have carefully reviewed and discussed this paper. They are in consensus that this manuscript merits a strong revision. I encourage the authors to take these experts' thoughts into consideration in revising their manuscript.
Below are multiple reviews of a paper. The authors explore the similarity between neural networks that accrue information processing via depth and via recurrent iterations. They conclude that recurrent processing mimics depth in the experiments they have conducted and draw links to relevant work in computational and experimental neuroscience.In this work, the authors compare and contrast models wherein layer depth is replaced with equivalent number of recurrent time steps. They also analyze the linear classification accuracy at different depths of the stacked and recurrent CIFAR-10 feedforward model. The analyses on qualitatively visualizing the learned filters was exciting and insightful in how these models represent informationThis work examines what constitutes depth for deep networks by examining inference for networks with and without distinct parameters at each layer. The tasks studied are image classification, with standard datasets like ImageNet and CIFAR-10, and a custom task concerning images of 2D mazes. The experiments are restricted to relatively shallow nets (with depth ofThe paper shows that sharing the weights between inner layers of image classification networks has minimal effect on their performance. This questions the commonly accepted view that later layers of CNNs function as more and more specialised filters. It also suggests that instead of the number of weights, the amount of computation might be the main reason behind the good performance of	This paper show that in several different neural network  architectures, recurrent   networks that share parameters over iterations have comparable  performance and similar features to feed-forward networks of the same "effective depth".    Reviewers initially had some reservations about novelty and  generalizability to deeper SOTA networks.  These were successfully addressed by the authors and all reviewers feel the paper is above the bar due to the importance of the area, and that this paper brings together many important insights that, while many may have been known  before, had not previously been all brought together before.  The maze  task was also considered a useful task for the field.  I agree that the paper makes a worthwhile contribution and am in favor of  acceptance.
Below are multiple reviews of a paper. The paper is well-written and obtains very impressive results. The training and testing times could be reported. Some related methods on sparse connected self-attention/transformer should be cited and discussed.The proposed Deformable DETR can obtain multi-scale features without a huge cost. In this way, it can be optimized easily and detect objects precisely, especially small objects. This paper solves the main problems suffered by DETR.The main contribution is a new attention module called deformable attention module. Like deformable convolution, it adds a translation term into the expression of the transformer, allowing a sparse spatial sampling. Experiments shows that it increases the AP detection rate on MSCOCO.This paper aims to improve a very recent detection model -- DETR, which suffers from two issues: long training time and limited feature spatial resolution. The paper proposes (1) deformable attention (2) multi-scale processing ( inputs/attention) for DETR.	Accept. The paper proposes Deformable DETR that builds on DETR and solves the slow convergence and limited spatial resolution problem while getting impressive results. The authors should think about comparing with other linear attention mechanisms to show the applicability of the method.
Below are multiple reviews of a paper. This work proposes a methodology (called PACT) for extracting auxiliary task data for joint training alongside the tactic prediction objective. PACT significantly improves the theorem proving success rate on held-out suite of test theorems. The paper contributes LEANSTEP dataset and the Learning environment.The paper describes a transformer-based tactical prover for Lean and its training methods. The work is useful and the results are encouraging, however, there are also major issues.This paper proposes to train large Transformers for proving theorems on Lean by using the auxiliary training objective built with proof terms. The paper is well-written and the main approach is easy to understand. The main drawback of this paper is the lack of technique novelty in terms of matching learning.This paper addresses the general setup of using transformer models for interactive theorem proving (ITP) tasks. The ITP engine considered here is Lean. Results show that the additional datasets extracted in this way aid substantively when used for pretraining and cotraining.	This paper has potential impact in the theorem proving community, and demonstrated the possibility of using LMs for theorem proving in Lean, and is good enough to use "in the real world" through an interactive theorem proving tool.  The reviewers wish their data/models were public to address some concerns raised by the reviewers, but we think the community can benefit from this work.
Below are multiple reviews of a paper. Negative example sampling is an important differentiator on training and classifier performance. This paper proposed a method on negative class sampling by considering the degree of vertices. It provided both theoretical analysis and experiments on real world datasets to demonstrate the effectiveness on the proposed sampling approach.This paper investigates personalized ranking from implicit feedback. The idea is to minimize a loss over triplets (u,i, j) over users, a positively labeled instance and a negatively labeled instance to learn the embeddings for items and users. The authors propose a two-phase sampling approach dubbed as Vital Negative Sampler.This paper proposes to improve the negative sampling process for training pairwise ranking models in personalized recommender systems. The proposed VINS method is achieved through a bias sampler with reject probability, which cooperates with an item buffer to enable efficient sampling.This work formalizes the class-imbalance problem existing in the contrastive learning loss for recommendation task and gives a simple but effective solution. The proposed approach defines a conditional probability depending on both the given user and positive items.	The reviewers remained concerned about the overall novelty of the paper, finding the contributions somewhat incremental. The authors are encouraged to better substantiate design choices that they make, to improve the overall presentation, and to contrast with the works/line of research brought up by the reviewers.
Below are multiple reviews of a paper. The authors proposed a Modulated Variational auto-Encoders to perform musical timbre transfer. Timbre transfer is applying parts of the auditory properties of a musical instrument onto another. It replaces the usual adversarial translation criterion by a Maximum Mean Discrepancy (MMD) objective.The proposed method is designed to be many-to-many. It uses a single pair of encoders and decoders with additional conditioning inputs. The method is evaluated on a collection of individual note-level recordings from 12 instruments.This work proposes a hybrid VAE-based model (combined with an adversarial or maximum mean discrepancy (MMD) based loss) to perform timbre transfer on recordings of musical instruments. A single (conditioned) decoder is used for all instrument domains, which means a single model can be used to convert any source domain	This paper proposes a VAE-based model which is able to perform musical timbre transfer.   The reviewers generally find the approach well-motivated. The idea to perform many-to-many transfer within a single architecture is found to be promising. However, there have been some unaddressed concerns, as detailed below.   R3 has some methodological concerns  regarding negative transfer and asks for more extended experimental section.  R1 and R2 ask for more interpretable results and, ultimately, a more conclusive study. R2 specifically finds the results to be insufficient.  The authors have agreed with some of the reviewers' feedback but have left most of it unaddressed in a new revision. That could be because some of the recommendations require significant extra work.  Given the above, it seems that this paper needs more work before being accepted in ICLR.
Below are multiple reviews of a paper. The paper tackles anomaly detection of multiple classes without class labels. The experiments are conducted on MV-Tech and CIFAR10 datasets. The proposed method shows a notable performance gap over competing methods in a unified scenario.This paper aims to learn a unified framework for detecting multi-class anomalies. The experimental results on the MVTec-AD and CIFAR-10 datasets show that the proposed method can alleviate the “identical shortcut” phenomenon.The authors propose the learning of multi-class decision boundaries for the task of anomaly detection (AD) over multiple object classes. For this, they employ reconstruction-based scores obtained from a transformer network, modified with a couple of simple tricks. The experimental results are the strong point of this work, with outstanding performance on MVTec-	This paper is on a highly-important topic, and makes solid contributions. Anomaly detection for multi-class datasets without class information is an underexplored area. Reviewers have appreciated the strong experimental results (especially on the important MVtech benchmark), high quality paper writing, and explainability results besides accuracy, via a novel attention mechanism. On the flip side, there were concerns on lack of deep analyses of the constituents of the method and novelty (given that there are some recent papers with similar ideas). The scores were borderline and the authors have put significant effort to address the concerns of the reviewers. Especially extra ablation studies and comparisons with other relevant papers are quite helpful in regards to convincingness of the ideas. I support the acceptance of the paper given all. Please update your paper with the additional content you have provided in the responses below.
Below are multiple reviews of a paper. The paper proposed recovering and verification of causal graphs via sufficient hard interventions with unlimited data. Compared to existing approaches, their method could deal with general graph. The paper assume causal sufficiency, which is usually not true in reality.The authors study the problems of verification and search for identifying causal DAGs from minimal-cost interventions. Using the concept of covered edges, they provide a theoretical result characterizing verifying sets. For the problem of search, the paper provides a novel algorithm for search, with complexity bounded by a connection to the minimum cost verifying set.This paper considers the problem of recovering causal graphs from interventional data. The authors studied an interesting connection between the optimal number of interventions that are needed to verify whether the given directed causal graph is correct. They proposed lower bounds for both of the considered questions.	This paper's reviews as it stands are divergent. The scores are 7, 5 and 4. The paper has seen discussion between reviewers with negative opinion and the authors. One reviewer who engaged in discussion revised the score up by 1.  The most unfavorable reviewer's main issue was lack of empirical evaluations comparing the authors algorithms to close competitors [SMG 20, PSS 22]. - Authors have responded turning in a quick implementation with plots comparing performance of their algorithm with competitors. Authors attached it plots and a readme in the form of an anonymous Drive folder (I looked at it briefly).  It seems like their algorithm is very competitive with state of the art and infact in terms of runtime is faster than even random in some cases. Experiments seem reasonably comprehensive.  I would have ideally liked the authors to include the contents of the drive folder into the main paper and uploaded a revision (I am not sure if authors are aware that one can update the paper during the rebuttal).   I would consider this issue sort of taken care of. Empirical simulations do clearly show that the proposed algorithms are effective for random graphs of different size.  Other concerns (even after a long discussion with reviewers) are: How significant are the theoretical results in comparison to [SMG 20, PSS 22].  1) Does it follow from many theorems about covered edges [Chi 95] classically known and other theorems from these two recent references ?  Authors responded saying - they are the first to give an *exact* algorithm to perform adaptive interventions to verify if a given graph is indeed the true one exactly characterizing the instance optimal number of interventions. I agree with the authors that this is not known and relation to covered edges does not directly follow from existing classical results (as authors have explained and I did see the proofs in the supplement.) So results for exact instance optimal verification are certainly new and novel and previous works only provided bounds on the verification number.  2) How novel are the search results ?  - Here, it is true that for proving approximation guarantee they do rely on a slight modification of a lower bound, i.e. Lemma 21 in the paper as observed by one reviewer in the discussion. However, authors also point out that theirs is the first algorithm which has instance wise O(log n) approximation to the best adaptive rate for arbitrary graphs.   I believe this was an open problem. Previous works like [SMG+20] could not make a general argument due to their reliance on directed clique trees and some orientation properties of the directed clique trees. Current work takes a different approach using clique separators and authors very easily extend the results to interventions of bounded size (which was also not known in general).  3) Experiments were added in an anonymous drive folder (I would strongly suggest the authors to add a few to the main camera ready + put the rest in supplement and discuss in detail about runtime benefits etc. Currently the only discussion is in the readme file).    For all the three concerns, I feel authors have adequately addressed the concerns. This paper simplifies adaptive interventional design with many interesting observations and generalizations in addition to particularly novel contributions to the verification problem.   Hence, I am positive about this paper.  To the authors: Please do include the figures and discuss the experiments in the camera ready. Your anonymous folder contents must go into the paper (split between main paper and supplement) at the very least. Authors may think their theoretical contribution is the main point of the paper. However, experimentally seeing competitiveness to the baselines AND runtime benefits for various graph sizes is an important contribution. Unlike many other theory results, interventional complexity is unlike sample or computational complexity. Therefore, actual gains do matter (even multiplicative constants) and I do appreciate authors putting in the effort during rebuttal. It has definitely helped with one of the chief reviewer concerns.
Below are multiple reviews of a paper. N/A. n/a n/A n/e n/o n/i n/u n/y n/t n/b n/c n/d n/f n/g n/r n/l n/m n/p n/s n/w n/h n/nThe authors present a framework to ensure the systematic use of neurogenesis. Neurogenesis refers to the process of integrating new neurons in the neural network during the learning process. They decomposed the process into two stages – triggers and initializations.The paper addresses a framework for neural archtecture search (NAS), called neurogenesis. A (small) network can be extended on-the-fly (i.e. while learning) if so-called triggers deliver positive (non-zero) values. Experiments show that almost the same performance (of static largeThe paper aims to grow the neural architecture during training without having a predefined final size. The objective function is to choose the neural network with the minimum loss function value. The proposed approach is innovative, and the formulation of the problem is clear.The focus of this paper is on neuro-genesis -- the study of automatically expanding neural networks for hosting more knowledge during training. This paper can be seen as an extension of Lyle et al.'s 2021 work on understanding network capacity. When all eigenvalues are large, this is a signal that more neurons should be added intoThe paper is situated in the NAS literature, particularly in dynamically learned architectures. Authors try to answer the question of where, when and how to add neurons to layers to increase the capacity of the network midst training.	There is a lot of enthusiasm for this paper, but also one dissenting voice. The discussion was productive and the paper improved as a result. Reviewer 4ixA further suggests an experiment that would validate the results, and the authors should consider it. However, even without it, the paper makes a worthwhile contribution to the conference.
Below are multiple reviews of a paper. The authors present an approach to training collaborative swarms of agents. The training regime involves individual agents rolling out trajectories based on slight perturbations of an agent of focus. This is repeated for each agent, then these trajectories are used to batch update the joint policy with an average gradient.The algorithm pretty much is similar to the A2C algorithm (very minor differences) Overall, I don't see the contribution of the paper to be significant enough. In section 3.1, the notations are over-populated.This paper proposes a distributed policy gradient method for learning policies with large, collaborative, homogeneous swarms of agents. The method looks a lot like "Learning with Opponent Learning Awareness"	Pros: - interesting novel formulation of policy learning in homogeneous swarms - multi-stage learning process that trades off diversity and consistency (fig 1)  Cons: - implausible mechanisms like averaging weights of multiple networks - minor novelty - missing ablations of which aspect is crucial  - dubious baseline results - no rebuttal  One reviewer out of three would have accepted the paper, the other two have major concerns. Unfortunately the authors did not revise the paper or engage with the reviewers to clear up these points, so as it stand the paper should be rejected.
Below are multiple reviews of a paper. The paper proposes the Composable Perceptual Schemas recurrent architecture. It is decomposed into $n$ LSTMs, each of which the authors call a _schema module. The architecture aims for each module to specialize to represent a particular spatial configuration.This paper proposes Composable Perceptual Schemas (CPS), a modular state representation learning architecture for reinforcement learning. CPS combines modular RNNs as in RIMs with a dynamic feature attention mechanism. CPS is evaluated on three environments and compared to several baselines.The paper proposes a modular state representation learning architecture called Composable Perceptual Schemas to discover regularly recurring patterns. The proposed model is tested for generalization in the deepRL setting along various axes such as varying object types, object numbers, distractors, task solution lengths etc.	This paper develops a mechanism for learning modular state representations in RL that organize recurring patterns into composable schemas. The approach combines modular RNNs as in RIMs (Goyal et al., 2020) with a dynamic feature attention mechanism. There were a variety of concerns in the initial reviews that were addressed by the authors through a set of clarifications and improved empirical analysis, substantially improving the paper. However, there still remain some issues in clarity of presentation and inconsistent empirical results, especially in the form of clear take-aways from the empirical analysis and broader insights from the paper, as detailed in the individual reviews. The authors are encouraged to take these aspects into consideration in revising their manuscript.
Below are multiple reviews of a paper. This paper proposes a task-agnostic backdoor attack against the pre-trained NLP models. The attack goal is to implant the backdoor to the model so that it can transfer to any downstream tasks and inherit the backdoor.This paper proposes BadPre, a task-agnostic backdoor attack approach that injects backdoors into neural language models during the pre-training stage. The authors state that a backdoor attack should satisfy the following properties: effectiveness and generalization, functionality-preserving, and stealthiness.The paper proposes a task-agnostic backdoor injection paradigm BadPre for pretrained NLP models. An attacker first poisons the pretraining corpus by introducing unnatural static trigger tokens, and then pre-training the public model to inject the backdoor. This model can then be finetuned on any downstream task and data regularly and can be attackedThe authors propose a backdoor technique for NLP models that is agnostic to the downstream task or dataset when the poisoned model is used with transfer learning. Empirical evaluation on a variety of downstream tasks and datasets demonstrates the effectiveness of the proposed approach.	The paper presents a backdoor attack approach against pre-trained models that may affect different downstream languages tasks with the same trigger. The paper shows that the downstream models can inherit security holes from upstream pre-trained models.   The paper is on the borderline and disagreement remains after discussion and author responses. In general, the new setting introduced in the paper is interesting and well-motivated. However, the options split in how realistic the setting is (e.g., use of uncommon trigger), the evaluation of stealthiness, and the novelty of the idea. After checking the paper, I believe the ideas and insights are justifiable for an ICLR paper and they differ significantly enough from the prior work. I do agree with reviewers that they are some  limitations of the proposed techniques (mostly inherited from the prior work it based on). However, as backdoor attack in NLP is a relative new area, I would be more lenient on these weaknesses.   The reviewers also provide constructive suggestions on how to improve the evaluation and writing. I hope the authors can address all the comments in the next revision.
Below are multiple reviews of a paper. The paper proposes AT-GAN (Adversarial Transfer on Generative Adversarial Net) to train an adversarial generative model. The study aims to learn the distribution of adversarial examples so as to generate semantically meaningful adversaries. The paper is clearly written and some experiments are conducted.This paper proposed the adversarial transfer on generative adversarial net (AT-GAN) to train an adversarial generative model. Such a model was able to draw non-constrained adversarial examples. The goal of this work is obvious with experimental justification.The aim sounds good but the authors fail to clearly distinguish the idea with the exiting related methods theoretically or numerically. The authors try to argue that the proposed model does not require an input. But in my opinion, no input is a disadvantage. Since there is adversarial samples involved, the obtained GAN is expected to be related to	I thank the authors and reviewers for their discussions about this paper. The proposed AT-GAN is a GAN-based method to generate adversarial examples. Similar methods (e.g. Song et al) have been proposed to use GANs to generate adv. examples more efficiently. Authors show their method has some numerical benefits. However, more experiments are needed to further justify it. Also, creating "unrestrictive" adv. examples can cause a risk of generating samples where the true label is flipped. Authors need to clarify it. Given all, I think the paper needs a bit of more work to be accepted. I recommend authors to address the aforementioned concerns in the updated draft.     -AC
Below are multiple reviews of a paper. The paper is relatively clearly written and looks technically correct. Experimental results show some mild to no improvement over classical skip gram model. I believe that the proposed approach (or similar one) might be useful for practice of natural language processing.The paper proposes an algorithm that learns word embeddings in hyperbolic space. It adopts the Skip-Gram objective from Word2Vec on the hyperboloid model. The paper is well written, both the background geometry and the derived update method are clearly explained.This paper presents a technique for embedding words in hyperbolic space. The authors provide a new gradient based method for creating the embeddings. They find that in the low dimensions the approach outperforms standard Euclidean space methods while in higher dimensions this advantage disappears.	although the proposed method could be considered an interesting application to recently popular hypobolic space to word embeddings, it is unclear why this needs to be done so. experiments also do not support why or whether the application of hyperbolic space to word embedding is necessary.
Below are multiple reviews of a paper. The paper consists of several parts. The authors consider a problem of modeling distribution evolution given samples for different discrete time moments. The text of the paper is of low quality and clarity.The authors propose a geodesic auto encoder to map points on a manifold to latent space. The method seems to work well and results are convincing. The authors acknowledge training ODE may be challenging in some settings.The paper proposes a computationally efficient dynamic optimal transport framework to track samples overtime. Overall the paper is well written. Some elements are unclear however.The authors propose a new architecture, called Manifold Interpolating Optimal-Transport Flow (MIOFlow), to learn the dynamics of snapshot data like single-cell data. It consists of two major parts: An autoencoder that embeds the data into a latent space, conserving a geodesic distance	Even though several concerns have been raised by multiple reviewers, the reviewers largely agreed on the significance and novelty of the contributions. The authors provided quite detailed responses and given all the data, overall I believe the strengths of the paper outweigh its weaknesses. Hence I am recommending an acceptance.
Below are multiple reviews of a paper. The paper is well organized and provides some necessary analysis. There are sufficient experiments to support their method. The introduction of Fritz-John Conditions is nice.The authors claim that their proposed method aims at 'inducing the full Pareto manifold at train-time so users can pick any desired optimal trade-off point at run-time' This is not well illustrated in the experiment part of the paper. The use of Fritz-John Conditions is novel to my knowledge.The paper contains a clear mathematical analysis of why the method works, the memory complexity, and it contains extensive testing. I do not believe the paper has any weaknesses that aren't easily fixed but there are a few omissions that I think should be addressed. The motivation for why Pareto-front methods are necessary is not complete.	Meta Review: The reviewers reach a consensus on the acceptance. The authors are encouraged to take all the comments into consideration and further improve the paper in the camera ready.
Below are multiple reviews of a paper. This paper proposes a new knowledge distillation (KD) method for adversarial training. The key observation is very inspiring: The (adversarially pretrained) teacher model's accuracy on adversarial images generated by the student model gradually drops. This provides solid foundation for the main claim of the paper.In this paper, a new method called introspective adversarial distillation (IAD) is proposed for conventional adversarial training. Concretely, it targets the unreliable teacher case, where teacher is good at adversarial / natural data or none of it.This paper studies a specific distillation scenario, adversarial distillation, to improve the model robustness. The teacher model will become progressively unreliable along with training. The adversarial data are dynamically searched by the student model and might not be well identified by the teacher model.Adversarial training aims to provide reliable classifiers in the era of deep learning. In many ML-driven scenarios, users might not want to retrain their big deep networks using adversarial training. To address this issue, this paper proposes an Introspective Adversarial Distillation (IAD) to effectively utilize the knowledge from an	This paper proposes a new knowledge distillation (KD) method for adversarial training. The key observation is inspiring: soft-labels provided by the teacher gradually becomes less and less reliable during the adversarial training of student model. Based on that,  they propose to partially trust the soft labels provided by the teacher in adversarial distillation.   Reviewers unanimously agree that this paper has clear motivation, well-sorted logic, and neat writing. While some reviewers initially posed concerns on evaluation completeness and detail clarification, they were well addressed during the rebuttal. AC reads the paper/discussion thread and agrees this is a worthy work to get accepted.
Below are multiple reviews of a paper. Authors claimed that one of the contributions is a reformulation of the semantic segmentation problem as a sequence learning task. The authors applied the external memory module proposed by Graves et al. (2016) to the image segmentation task.The authors present a model for semantic segmentation. The proposed method casts the full image segmentation as a sequence of local segmentation predictions. The image is split in multiple patches and processed sequentially in some order.The paper proposes a system of semantic segmentation based on sequential processing of the image in a patch-wise manner with multiple "actors" This approach stands in contrast to the more usual approach of single-shot prediction for the whole image. Results are presented on segmentation of lung X-ray data and on MNIST digit completion.	The paper addresses the problem semantic segmentation using a sequential patch-based model. I agree with the reviewers that the contributions of the paper are not enough for a machine learning venue: (1) there has been prior work on using sequence models for segmentation and (2) the complexity of the proposed approach is not fully justified. The authors did not submit a rebuttal. I encourage the authors to take the feedback into account and improve the paper.
Below are multiple reviews of a paper. This paper addresses the problem of doing unsupervised learning of visual representations, including clustering these representations to infer the existence of new categories. The paper focuses on more "un-curated" settings in which the data comes from samples of an environment that a real agent is passing through.This work studies an online version of self-supervised representation learning. It uses Gaussian mixture  of constant isotropic variance as a prototype memory as well as a uniform distribution to handle new unknown classes. The overall distribution evolves using an online EM algorithm that supports adding and removing prototypes.This paper claims that in real world the data distribution is nonstationary, which is different from the current standard machine learning formulation. To solve this problem, the authors design an online unsupervised learning algorithm with Gaussian mixture model and EM algorithm.The authors propose a method for unsupervised learning of instance-based clustering which is more robust to data imbalance and non-iid distributions than existing approaches, such as SwAW. The method is mainly evaluated on RoamingRooms - a dataset with an agent moving through indoor environments with instance labels assigned to objects.	This paper tackles a small-batch online unsupervised learning problem, specifically proposing an online unsupervised prototypical network architecture that leverages an online mixture-based clustering algorithm and corresponding EM algorithm. Special features are added to deal specifically with the non-stationary distributions that are induced. Results are shown on more realistic streams of data, namely from the RoamingRooms dataset, and compared to existing self-supervised learning algorithms including ones based on clustering principles e.g. SWaV.   Overall, the reviewers were positive about the problem setting and method, but had some concerns about hyper-parameters (hYzM, cvrN, LjvY) and motivation for the specific setting where the method excels compared to other methods not designed for such a setting (hYzM, cvrN), i.e. small-batch setting, where it is not clear where the line should be drawn in terms of batch size and memory requirements with respect to performance differences between the proposed approach and existing self-supervised methods. Importantly, all reviewers had significant confusions about all aspects of the work ranging from low-level details of the proposed method to the empirical setting and evaluation (including for competing methods). After a long discussion, the authors provided a large amount of details about their work, which the reviewers and AC highly appreciate. However, in the end incorporating all of the feedback requires a major revision of the entire paper. Even the reviewers that were more on the positive side (cvrN and LjvY) mentioned it would be extremely beneficial for this paper to be significantly revised and go through another review. Since so many aspects were confusing, it is not clear to the AC that the underlying method, technical contributions, and other aspects of the works had a sufficient chance to be evaluated fairly, given that much of the review period was spent on clearing up such confusion.   In summary, while the paper is definitely promising and tackles an important area for the community, it requires a major revision and should go through the review process when it is more clearly presented. As a result, I recommend rejection at this point, since it is not ready for publication in its current form.
Below are multiple reviews of a paper. This paper presents an approach to combine OOD detection and classifier. The proposed "OOD-aware" training can be effective to improve the robustness of the classifiers. The draft lacks clarity in many aspects.This paper aims to detect out-of-distribution data in an adversarially robust manner. It uses a certified (binary) classifier to model in-and-out distribution and jointly model predictive distribution. The authors show that the proposed method is empirically strong under various detection scenarios.The proposed method, ProoD, merges a binary classifier and a multi-class classifier in a clever way to produce an OOD detector robust to adversarial perturbation. The binary classifiers are trained to discriminate inliers and outliers, while the multi- classifier is trained to predict class labels underIn this paper, the authors propose ProoD which merges a certified binary classifier with a classifier for the in-distribution task in a principled fashion into a joint classifier. The paper is well-written and easy to understand. The idea of training a discriminator independently via interval bound propagation (IBP) toThe proposed method is based on adding a binary classifier responsible for being certifiably robust to adversarial manipulation on the out-of-distribution data. Almost no classification accuracy drop is observed. The solution adds a hyperparameter called the bias shift.	This paper aims for detecting not only clean OOD data, but also their adversarially manipulated ones. The authors propose a method for this goal, with no/marginal loss in clean test accuracy (say, Acc) and clean OOD detection accuracy (say, AUC), while existing methods for targeting the same goal suffers from low Acc and AUC. 3 reviewers are positive and 2 reviewers are negative. Reviewers and AC think that the proposed idea of merging a certified binary classifier for in-versus out-distribution with a classifier for the in-distribution task is interesting. However, AC thinks that experimental results are arguable as pointed out by reviewers. For example, in CIFAR-10, the proposed method outperforms the baseline (GOOD) with respect to Acc and AUC, but often significantly underperforms it with respect to GAUC (guaranteed AUC) or AAUC (adversarial AUC). Then, the question is which metric is more important? It is arguable to say whether Acc is more important than GAUC or AAUC. But, at least, AC thinks that AUC and AAUC (or GAUC) are equally important as adversarially manipulated OOD data is nothing but another OOD data made from the original clean OOD data. Hence, the superiority of the proposed method over the baseline is arguable in the experiments, and AC tends to suggest rejection.   ps ... AC is also a bit skeptical on the motivation of this paper. What is the value of obtaining "guaranteed AUC"? It is not the "real/true" worst case OOD performance, as it varies with respect to the tested clean OOD data. Namely, it is the worst case OOD performance just in a certain "subset" of OOD data, i.e., adversarially manipulated OOD data made from a certain clean OOD data. Hence, AC is curious about what is the value of establishing such a "partial" lower bound (rather than "true" lower bound considering all possible OOD data). AC thinks that the problem setup studied in this paper (and some previous papers) looks interesting/reasonable at the first glance, but feels somewhat artificial after a deeper look.
Below are multiple reviews of a paper. The authors propose to utilize the part-level feature representation for the cross-domain generalization problem in point cloud applications. The proposed method achieves state-of-the-art performance on DG benchmarks.The authors present a new method for generalizing point cloud classification. They argue that the local geometric features are more generalizable than the whole shape. The proposed method achieves state-of-the-art performance on the 3DDG benchmark.The presented method detects ‘global’ features (PointNet or DGCNN) locally on sampled points. Then learn relations between those local representations as part-level aggregation. The performance is further improved by contrastive learning.	The paper works on domain generalization of 3D point cloud classification, and proposes a part-based domain generalization network for the purpose, whose key idea is to build a common feature space of part template and align the part-level features wherein. Three reviewers appreciate the contributions, including the clear motivation, the implicit domain alignment by part-template features, and the proposed part feature aggregation module. They also suggest to improve the paper by clearer definitions of parts, better organization of contrastive learning in the paper, a more complete citation of closely related works, etc.   After discussions between the authors and reviewers, consensus is reached on accepting the paper.  Congratulations!
Below are multiple reviews of a paper. This paper presents a method for identifying user's epistemic knowledge of a model without requiring a priori specification. This approach is in the realm of 'model reconciliation', but aims at providing a more practical approach.The paper is original and mostly clear (some suggestions below) The connection to active sensing and POMDPs is specially interesting and appreciated.	Thanks very much for submitting your paper!  Summary: This paper proposes an end-to-end adaptive explanation generation system that learns the different types of users that the agent could interact with and adjust its explanations accordingly.  Strengths:  - Clear motivation and interesting perspective - Broad evaluation with both quantitative evaluation and user study  Limitations: - Costly approach - i.e., requires gathering a lot of data from the existing users - Missing link with real-world applications  We hope that you find the reviewers' comments to be informative, please take them into account when revising your papers. We look forward to your presentation!
Below are multiple reviews of a paper. The paper provides theoretical results that favor MLE estimators, in terms of the excess square loss risk, compared to empirical risk estimators under mild assumption. The results seem to hold in low-dimensional cases where (n -- samples> d- covariates). The practical utility of the paper would be stronger if it could be applied inThis paper compares two inferential methods for regression models, the maximum likelihood estimation and the estimation based on loss functions. A quantity is proposed to measure the correctness of an estimator of a regression model. This result is applied to two models based on the Poisson distribution and Pareto distribution.This paper promotes the maximum likelihood estimation over target metric optimization. The main theoretical results is a finite sample error bound. Specific examples and numerical results are provide to further illustrate the investigation.	This paper has been independently assessed by three expert reviewers. The results place it at the borderline of acceptance decision: while one of the reviewers gave it a straight accept evaluation, two others assessed it as marginally rejectable, even after discussion with the authors. All of the reviewers agreed that the theoretical results provided should help promote the use of MLE estimators over perhaps more prevalently used in current practice TMO, and that is the main contribution of this work. The reviewers were concerned with the clarity of the presentation and with a confusing notation used. Some of these issues have been addressed in the authors' responses. All things considered, I conclude that this work can be of some interest to the ICLR audience, and as such it can be assessed as marginally acceptable for this conference: "accept if needed". I will recommend it as such for consideration by the Senior Area Chair and the Program Committee.
Below are multiple reviews of a paper. Authors argue that using average (independent) greedy matching of pixel embedding (based on 4-6 layer cnn hypercolumns) is a better metric for one-shot learning. Their argument is backed by outperforming their baseline and getting competitive results on few shot learning tasks. Their method is much more computationally heavy than theThe authors propose a deep learning method based on image alignment to perform one-shot classification and open-set recognition. The proposed model is an extension of Matching Networks [Vinyals et al., 2016] where a different image embedding is adopted.The paper proposed a new way of learning point-wise alignment of two images. Based on this idea, one-shot classification and open-set recognition can be further improved.In this work, the authors tackle the problem of few-shot learning and open-set classification using a new type of NNs which they call alignment-based matching networks or ABM-Nets for short. They main idea is to benefit from binary maps between the query image and the support set to guide the similarity measure.	The reviewers are polarized on this paper and the overall feeling is that it is not quite ready for publication. There is also an interesting interpretability aspect that, while given as a motivation for the approach, is never really explored beyond showing some figures of alignments. One of the main concerns of the method’s effectiveness in practice is the computational cost. There is also concern from one of the reviewers that the formulation could result in creating sparse matching maps where only a few pixels get matched. The authors provide some justification for why this wouldn’t happen, and this should be put in a future draft. Even better would be to show statistics to demonstrate empirically that this doesn’t happen.  There were a number of clarifications that were brought up during the discussion, and the authors should go over this carefully and update the draft to resolve these issues. There is also a typo in the title that should be fixed.
Below are multiple reviews of a paper. This work builds on a sum(top k) identity to derive a pathwise differentiable sampler of 'unimodal row stochastic' matrices. The Plackett-Luce family has a tractable density and is (as developed here) efficient to sample.The paper considers how to sort a number of items without explicitly necessarily learning their actual meanings or values. After responses: I now understand the paper, and I believe it is a good contribution.In many machine learning applications, sorting is an important step such as ranking. The sorting operator is not differentiable with respect to its inputs. The main idea of the paper is to introduce a continuous relaxation of the sorting operator in order to construct an end-to-end gradient-based optimization.	This paper proposes a general-purpose continuous relaxation of the output of the sorting operator. This enables end-to-end training to enable more efficient stochastic optimization over the combinatorially large space of permutations.  In the submitted versions, two of the reviewers had difficulty in understanding the writing. After the rebuttal and the revised version, one of the reviewers is satisfied. I personally went through the paper and found that it could be tricky to read certain parts of the paper. For example, I am personally very familiar with the Placket-Luce model but the writing in Section 2.1 does not do a good job in explaining the model (particularly Eq 1 is not very easy to read, same with Eq. 3 for the key identity used in the paper).   I encourage authors to improve writing and make it a bit more intuitive to read.  Overall, this is a good paper and I recommend to accept it.
Below are multiple reviews of a paper. The method proposed is well motivated. It looks simple but effective. The experiment scale is small. The author directly proposes the method of regularizing the second term of the dual form.The paper is well written and clearly explains the existing MI estimators. The improvements on CIFAR100 look good and demonstrate the necessity to solve this instability issue.The method is well-motivated, and the experiments are well designed to understand the reason for drifting and exploding in the MI estimation. Extensive experiments prove that the proposed regularization term decreases variance.	Meta Review: This paper studies the instability of neural network-driven mutual information estimators. It identifies two reasons for instability including the non-convergence of neural networks and the saturating neural network outputs. Then a practical regularization is proposed to mitigate the instability issues. Both theoretical and experimental studies are conducted to demonstrate the effectiveness of the regularizer.  All the reviewers agree that the proposed method is novel, simple, and effective. The theoretical analysis is insightful and the empirical results are good. Nevertheless, there are some concerns on the small scale of datasets. Given that the novelty and technical contribution of this paper outweighs the concerns, I recommend acceptance of this paper. But I highly suggest the authors add results of larger scale experiments (for example Imagenet) in the final version.
Below are multiple reviews of a paper. This work proposes a new CNN architecture: ConvMixer, which integrates some techniques/techniques used in the recently proposed visual transformer model/mlp model. The main claim of this work:  "the patch representation may be the most critical component" has not been sufficiently well validated.ConvMixer is a new design for the image classification task named ConvMixer. It brings the idea from CNN to Visual Transformer. Unlike previous ConvNets, Transformer-based models, and MLP-based model, it simply applies depth-wise and point-wise convolutions.The paper presents a very simple architecture which consist of patching the input image and then applying a combination of depth-wise and point-wise convolutions. In their main experiment, they train the architecture using only the ImageNet-1k dataset.	This paper observes that a fully-convolutional model in the style of recent MLP-Mixer and ViT variants can have surprisingly good initial performance. As this paper attracts certain amount of attentions, three expert reviewers have provided very detailed and serious comments, and two actively engaged with author discussions. AC also carefully read the paper as well as all discussion threads.  AC agrees the authors should not be penalized by not achieving the best performance, nor not comparing with very recent work. The main legitimate critiques, however, focus on three aspects: (1) over-claimed contribution; (2) experiment solidness/competitiveness; and (3) writing completeness/clarity.  First, this paper established an interesting ablation experiment that a very simple model, that uses only standard convolutions to achieve the mixing steps, can roughly "do the work". However, AC disagrees this is a very "surprisingly new" result, on top of MLP-mixer: given convolutions are increasingly re-injected into ViTs to gain the vision inductive bias, their similar role in MLP-mixer should be expected too. Moreover, as in general agreement by reviewers, the paper title might have over-claimed - the authors cannot directly prove this concept "patch is the most critical component" yet. The authors later also agreed and changed some confusing wording, which is a good move (but also, making their contribution now even less obvious).   Second, this method does not achieve noteworthy competitive results compared to others, in order to justify its merit (simplicity alone is good to have, but insufficient to justify a strong work). Importantly, it has been pointed out by two reviewers that the model throughput is much worse than the competitors. AC also noticed that the comparison was not very rigorous, e.g., comparing ConvMixer patch size 7 with DeiT-B 16 patch size 16 doesn't help draw much fair informative conclusion. The cifar-10 results alone did not provide strong support and were later de-emphaszied by authors too.   Third, while NOT being the main reason of rejection, AC personally suggests the authors to responsibly enrich their main text, and to remove the  “A note on paper length” paragraph. The authors intentionally kept the paper length unusually short. Reviewers generally dislike this idea. Being an innovative writer is good, but very relevant details and discussions were left in the supplemental as a result. Especially, AC agrees the whole section A and part of section B of the supplemental should have been in the main paper at very least.  In summary, the authors strive to tell an interesting story, but it is not yet a well settled story. The experiments are not solid enough to support their bold claims. The authors are suggested to improve their work further by taking into account reviewer comments.
Below are multiple reviews of a paper. This paper introduces new techniques in training NeRF-based GANs. It addresses the patch-based trianing issue, which blocked privious works to directly generate nerfs that renders into high quality resolution images.The paper proposes a non-upsampler-based 3D-aware generator. The author improves patch-based discriminators in two ways. They adopt location and scale to modulate the discriminator. They modify the patch sampling strategy based on an annealed beta distribution.Existing works adopt nerf to render 3D radiance fields into 2D images with a large memory cost. This paper proposes two important techniques to train 3D generative models from 2D supervision.The authors propose a framework to generate 3D images from latent code. They came up with a patch based strategy similar to GRAF to improve the performance. The idea is to condition the discriminator with a hypernetwork.	The reviewers found the method simple and effective and considered it a contribution of interest to the community. Claims are well supported by experiments and design choices have been validated. The paper is well written. Furthermore, the authors provided highly detailed responses to all questions by reviewers, which creates confidence that reviewers' remarks will be addressed in the final paper.
Below are multiple reviews of a paper. The authors group common data augmentation into two groups: simple and complex. They propose to use separate batch normalization layers for the two types of data augmentations. They show improvements in the clean and robust accuracy on multiple datasets.This paper tackles the problem of Lp-norm robustness for classification. The authors propose an optimised training strategy with: 1) increasing perturbation radius throughout training and 2) using JS divergence. The paper is very clear and well-written.This paper combines many previous robust training techniques together: adversarial training, Auto Augmentation, Split batch normalization, smoothness regularization (JSD loss) The method achieves good empirical performance. The technical novelty is limited.The paper proposes an augmentation strategy for adversarial training by combining simple and complex augmentations to improve the effectiveness of the augmentation. It introduces ACAT that gradually increases adversarial epsilon with 2 adversarial defence steps to allow the method to work efficiently.	The reviewers found the paper well written and were satisfied with the experimental setting, which shows clear improvements. The authors made a thorough rebuttal and carefully answered the reviewer's questions and I recommend for acceptance as I believe this will be useful to the community.   I recommend the authors to carefully go over the reviewers’ comments and incorporate them into the final manuscript, along with the additional experiments from the rebuttal.
Below are multiple reviews of a paper. The paper proposes a NAS algorithm for vision transformers. Experiments on classification and segmentation show its effectiveness. Though there are still some minor flaws in the paper, I think it is a good one.The paper investigates applying a SOTA NAS method (from AlphaNet) to a Sota ViT search-space (from LeViT) and notices disappointing results. Following an investigation, conflicting gradients are identified as the root cause, alleviated via three components: gradient projection, learnable scaling factors, and heavily reduced augmentationsThe motivation of this work is clear, but the explanation of poor performance ( gradient conflict issue) is somewhat  not convincible. The architecture in the search space consists of MBConv and transformer, it is better to compare with the existing works that also combine the CNN and transformers.The proposed NASViT achieves promising performance in classification and segmentation with low computational cost. The motivation of this paper is not very convincing, need to provide more evidence to prove. For more details, pls see the weaknesses.This paper aims at applying one-shot Neural Architecture Search (NAS) to Vision Transformers (ViTs) The authors claim that directly using existing CNN based NAS method to ViTs will lead to a gradient conflict issue. In order to tackle this issue, the authors propose three techniques, including a gradient projection, a switchable layer scaling,	This paper tackles a very timely problem.  Scores of 5,6,6,8 put it in the borderline region, but in the private discussion the more negative reviewer noted that they would also be OK with the paper being accepted. I therefore recommend acceptance.  Going through the paper I missed any mention of available source code. I strongly recommend that the authors make code available; this would greatly increase the paper's impact.
Below are multiple reviews of a paper. This work benchmarks recent automated weak supervision methods on seven datasets spanning multiple modalities. The relationship between pretrained models and AutoWS is only just beginning to be explored. The results indicate that foundation models unsurprisingly may not be helpful on out-of-distribution data.Automated Weak Supervision (AutoWS) methods aim to bring a step further WS methods. They provide automated approaches to create Labeling Functions (LF) which are then used to build labeled datasets for training supervised models.This paper proposed a benchmarking framework for AutoWS --- AutoWS-Bench-101 on a diverse field of tasks. They provided the baseline experimental results of different AutoWS methods on seven datasets. The authors are suggested to add more datasets in each domain.The paper proposes a benchmark for automated weak supervision that designslabeling functions. The authors describe the problem and data and present empirical results.This paper introduces a novel benchmark, AutoWS-Bench-101 for evaluating different AutoWS methods. It aims to generate weak supervision sources directly from the feature space. The codebase and datasets have been publicly released.The paper introduced a benchmark for evaluation of automated weak-labeling methods called AutoWS-Bench-101. Compared to a prior benchmark on the same (WRENCH), the current benchmark is significantly smaller. Not all methods used were analyzed further. Paper has problems with clarity (see below).	All reviewers except one recommend acceptance. The reviewer recommending rejecting the paper (score 5) raises valid concerns, e.g., the lack of semi-supervised baselines and the comparison to a prior benchmark for weak supervision (WRENCH). The authors addressed some of the concerns (e.g., by adding a semi-supervised learning baseline). Regarding the comparison to WRENCH: It is true that WRENCH is similar, but the exact problem benchmarked by WRENCH and AutoWS-Bench-101 is different: in the former, the labeling functions are assumed to be given, in the latter, the labeling functions are learned. I find this difference sufficient for a separate benchmark.  Overall I recommend accepting the paper. I strongly encourage the authors to take all the reviewer comments into account, especially the comparison to baselines form semi-supervised learning. As I understand, automatic weak supervision fits the same abstract problem statement as semi-supervised learning. Hence a comprehensive comparison to semi-supervised learning is essential.
Below are multiple reviews of a paper. The paper is mathematically detailed and correct. The novelty lies in learning a state-independent prior. This could lead to positive and interesting results empirically for exploration.Empirical Deep RL performance is notoriously difficult to test. This work introduces SoftQ with a learned, state-independent prior. They find that this results in small gains across most Atari games.The authors take the control-as-inference viewpoint and learn a state-independent prior (which is typically held fixed) They claim that this leads to better exploration when actions have different importance. They then propose a practical algorithm, MIRL and compare their algorithm against DQN and Soft Q-learning (SQL) on 19	The paper proposes a new RL algorithm (MIRL) in the control-as-inference framework that learns a state-independent action prior.  A connection is provided to mutual information regularization.  Compared to entropic regularization, this approach is expected to work better when actions have significantly different importance.    The algorithm is shown to beat baselines in 11 out of 19 Atari games.  The paper is well written.  The derivation is novel, and the resulting algorithm is interesting and has good empirical results.  A few concerns were raised in initial reviews, including certain questions about experiments and potential negative impacts of the use of nonuniform action priors in MIRL.  The author responses and the new version were quite helpful, and all reviewers agree the paper is an interesting contribution.  In a revised version, the authors are encouraged to   (1) include a discussion of when MIRL might fail, and   (2) improve the related work section to compare the proposed method to other entropy regularized RL (sometimes under a different name in the literature), for example the following recent works and the references therein:     https://arxiv.org/abs/1705.07798     http://proceedings.mlr.press/v70/asadi17a.html     http://papers.nips.cc/paper/6870-bridging-the-gap-between-value-and-policy-based-reinforcement-learning     http://proceedings.mlr.press/v80/dai18c.html
Below are multiple reviews of a paper. This is a nice method - extending the self-supervision framework of Momentum Contrast to operate in the challenging scenario of unsupervised domain adaptation framework is clever and very interesting. The results are impressive and the qualitative evaluation (t-SNE) nicely illustrates that the objectives stipulated in the loss function indeed learn similar features across domainsThe proposed method seems reasonable, though the cross-domain loss should be explained more clearly. For the validation on WSIs, only results of three examples are presented. Why not present the summarized results for the whole dataset?The sparsely-labeled UDA setting is important in medical image analysis domains. The proposed method achieves good performance on the public datasets. The technical novelty is limited.The main advantage is the combination of both approaches: self-supervised learning and unsupervised domain adaptation. The novelty lies in proposing an entropy-based approach that progressively learns domain invariant features.	The authors were able to resolve some of the reviewers' initial concerns. The paper can be of interest to the community and presents promising results.
Below are multiple reviews of a paper. This paper aims to minimize the dynamic regret (instead of the static regret in previous work) for the problem of online label shift (OLS) This paper constructs a new unbiased risk estimator that utilizes the unlabeled data and then proposes online ensemble algorithms to deal with the non-stationarity nature.This work studies the problem of online adapting to label shift. It features a very strong theoretical analysis and excellent experimental evaluation. The presentation is great, and the Appendix even includes a brief intro to OCO!This paper addresses the problem that the label distribution in testing data is different from training data. The authors propose to include the testing data in the training process in the goal to reduce error.	This paper considers online learning under a label shift scenario: an initial model is trained  on labeled data from the first distribution, and then the learner receives unlabeled data from shifting target distributions in rounds. The assumption here is that the underlying label-conditional densities (d(x|y)) do not change, only the "weighting" of the various labels changes between the rounds. This submission introduces the notion of dynamic regret for this setting where the learner is round-wise compared to the best predictor for the round-specific task. The submission provides an algorithm and bounds on this dynamic regret (that, naturally, involves a term measuring the amount of label-weighting-shift) as well as empirical evaluations of the proposed algorithm (both on synthetic and real datasets).  Overall this appears as a well-rounded submission on a problem setup that is clearly relevant to the NeurIPS community.  Since data is provided in batches per learning round, it would be appropriate to also compare to life-long learning setups, algorithms and guarantees, rather than just to online learning. It seems that the studied framework is more commonly referred to as life-long learning, but this connection and the corresponding literature is entirely ignored in this submission. This should be fixed/clarified before publication.
Below are multiple reviews of a paper. The topic of post-processing/regularizing the predicted segmentation is important. The proposed regularization method is a simple 2D UNet. A 3D graphcut or 3D CRF post- processing baseline is needed.The proposed solution of using 2D networks to reconstruct patch-wise results from 3D networks is interesting. The authors do not address the network size increase of adopting a full 2D UNet as a reconstructor of the 3D output.The paper illustrations are helpful, the tables nicely formatted, and the text is reasonably structured and readable. The authors base their work on false assumptions on the relevance and cause of the problems they observe. The data behind tables 2 and 3 could have better been summarized with boxplots.The paper lacks proper references to existing work specifically to the problem of patch-wise reconstruction. Re-using the probability map is heavily inspired by Auto-context (Mohseni Salehi et al., IEEE TMI, 2017), please reference appropriately.	The reviewers have provided very detailed, argumented and constructive criticism of the paper.  Although they acknowledge some interest to the paper, they all agree on the fact that this paper had major flaws to be adressed (missing baselines, lack of clarity, code availability).   The authors did not provide a rebuttal.  I follow the reviewer’s rating and recommend rejection of this paper.
Below are multiple reviews of a paper. This paper considers a very interesting setting:  the expert data in the imitation learning is confounded by the context, and the distribution of context may vary between expert data and online data. The setting considered in this paper is interesting and practical. The authors give a theoretical analysis about the limitation of imitation learning in such a setting.The authors considered the problem of imitation and reinforcement learning in the setting of contextual MDP with latent confounders. They defined an ambiguity set, i.e., the set of all deterministic policies that match the marginalized stationary distributions of a given policy. In imitation learning, in the case of no covariate shift, no policy inThe paper studies how to incoporate expert data with covariate shift. They also propose a hybrid RL-imitation algorithm that utilizes the expert data without allowing it to bias the final solution. The paper provides limited theoretical results for pure imitation based on state-action marginals.This paper focuses on imitation learning with confounded expert data (with no contextual information) Theoretical results (upper and lower bounds) are obtained, supported by numerical experiments and real data applications. Results in this paper cover settings that one may encounter in practice.	The authors consider the problem of using expert data with unobserved confounders for both imitation and reinforcement learning settings. They showed how latent confounders  negatively affect the learning process and proposed a sampling algorithm that mitigates the  impact and delivers good empirical results.  I agree with the reviewers, this is a borderline paper but with a preference to accept.  The most salient concern was the lack of clear contribution. While the algorithm is interesting  with good experimental results that attract interest, it lacks actual theoretical backbone.   That being said, the authors put in solid effort and addressed concerns sufficiently in the rebuttal stage. Thus I would prefer to see it accepted. The proposed research direction should be explored in the future.
Below are multiple reviews of a paper. The paper is well-written and its good experimental results are strengthened by theoretical complexity estimation. The text of the paper, though well-structured and concise, requires some polishing.The authors propose Transformer-QL to capture the contextual information in multiple temporal scales. The results show significant improvement in the perplexity score over Trans transformer-XL and Compressive Transformer.Transformer-QL is a transformer-based model that aims to capture long distance dependencies in the input. The presentation can be improved, all the definitions are hard to follow. Further, the performance improvements are nice, though not impressive.Using multi-scale hierarchical and compressive techniques, this paper examines a way to increase the context length of transformers. The results demonstrated in the experiments show an improvement over previous models.	This paper introduces Transformer-QL, a new variant of transformer networks that can process long sequences more efficiently. This is an important research problem, which has been widely studied recently. Unfortunately, this paper does not compare to such previous works (eg. see "Efficient transformers: A survey"), the only considered baselines being Transformer-XL and Compressive transformer. Moreover, the reviewers found the experimental section to be lacking, as the results are weak compared to existing work, and important ablation studies are missing. The authors did not provide a rebuttal. For these reasons, I recommend to reject the paper.
Below are multiple reviews of a paper. This paper gives a theoretical study of the tail behavior of the SGD in a quadratic optimization problem. It explores its relationship with the curvature, step size and batch size. The paper provides comprehensive experiments to support their result.The main theme of this work is to study conditions under which SGD iterations result in random variables with heavy-tail random distributions. The experiments verify the correctness of the theoretical results, but they are also of limited value.This paper studies the relations between the heavy tail phenomenon of SGD and the ‘flatness’ of the local minimum found by SGD. They show that depending on the curvature, the step size, and the batch size, the iterates can converge to a heavy-tailed random variable.This paper studies the heavy-tail phenomenon in SGD. The paper is technically sound and develops rigorous proof. The problem studied in the paper is very idealized.	This work seeks to describe the heavy-tail phenomenon observed for deep networks learned with SGD. The work presents proof of a relationship between curvature, step size, batch size, and a heavy-tail weight distribution. The proofs assume a quadratic optimization problem and the authors speculate that the results may also be relevant for non-convex deep learning settings. On the positive side the reviewers agreed that this work is one of the first, if not the first, to try to theoretically describe a poorly understood phenomenon in deep learning. On the less positive side, the reviewers believe that the proofs developed in this paper are for an idealized setting that is too different from the settings under which deep models are trained. As such, even though the authors provide some (somewhat mixed) experimental results to support the claim of relevance to deep learning, the reviewers were not convinced. Given that the stated goal of the work is to attempt to explain this phenomenon in deep models, the majority view is that this work, while promising, needs further development to convincingly claim some relevance to the original phenomenon being studied.
Below are multiple reviews of a paper. This paper is very well-written and motivated. The idea to unify invariances of the loss function by using symmetries and derive corresponding conservation laws in the gradient flow is very elegant. The proposed analysis is not fully predictive (depends on the norm of the gradients that depend on the empirical data)This paper studies the dynamics of the parameters while training a neural network via SGD. It tries to provide a physical meaning behind the dynamics. There is a lot of room for improvement (see below) and I don't recommend the paper for publication in this form.This paper analyzes the learning dynamics of DNNs from the perspective of symmetry of some parameters. The results are very interesting, which I like a lot. I have some confusions about some results, which make me not able to give the paper a pass at this time. I will consider revising the score if the authors canThe current work makes accurate predictions on DNNs trained in a real-world setting. They do so with a refreshing toolbox, that of symmetries. While being a clever trick, it can be viewed as an inherent limitation of the approach.	The paper offers a more systematic treatment of various symmetry-related results in the current literature. Concretely, the invariance properties exhibited by loss functions associated with neural networks give rise to various dynamical invariants of gradient flows. The authors address these dynamical invariants in a unified manner and study them wrt different variants of gradient flows aimed at reflecting different algorithmic aspects of real training processes.   The simplicity and the generality of dynamical invariants are both the strength and the weakness of the approach. On one hand, they provide a simple way of obtaining non-trivial generalities for the dynamics of learning processes. On the other hand, they abstracts away the very structure of neural networks from which they derive, and hence only allow relatively generic statements. Perhaps the approach should be positioned more as a conceptual method for studying invariant loss functions.   Overall, although the technical contributions in the paper are rather incremental, the conceptual contribution of using dynamical invariants to unify and somewhat simplify existing analyses in a clear and clean symmetry-based approach is appreciated by the reviews and warrant a recommendation for borderline acceptance.
Below are multiple reviews of a paper. This work proposes DDXPlus, a symptom-disease dataset of synthetic patient records. Each patient's disease and evidences (i.e. symptoms and antecedents) are sythetically generated based on a proprietary KB and a commercial synthesizer. Differential diagnosis for each patient is generated by feeding all evidencesThe authors propose a large-scale synthetic dataset of differential diagnosis, ranking a list of plausible diseases that a patient might suffer. The potential usage of the dataset is to assist doctors in telemedicine service.This work presents a new, large-scale synthetic dataset that can be used to evaluate differential diagnosis symptoms. By extracting diagnosis rules from medical literature, the authors automatically label a massive set of synthetic patients. Using these data, they compare two existing automatic diagnosis systems on their dataset. They find that incorporating differential diagnosis into the train improves their performanceThis paper introduces a large-scale synthetic dataset focusing on cough, sore throat, and breathing problems for automatic medical diagnosis. The experiments of two extended methods demonstrated that the collected dataset is useful for studying automatic diagnosis systems.The authors introduce a new dataset of synthetically generated data on patients for Automatic Symptom Detection (ASD) / Automatic Diagnosis (AD)This paper presents a large-scale synthetic automatic diagnosis dataset, including 1.3 million patient data. It highlights the importance of differential diagnosis during automatic symptom detection. The main weakness of this dataset derives from a series of very strong assumptions.	This paper proposes a symptom-disease dataset of synthetic patient records containing demographic information, disease, symptoms, antecedents and differential diagnosis. The disease, evidences, and differential diagnoses are synthetically generated which makes the dataset easy to share. Several reviewers pointed out important concerns in the methods used to synthesize the data which may raise ethical problems if it is assumed that performance on this dataset is indicative of performance on real patients. Nevertheless, I believe that this dataset can be of value to the community as it can help the community develop better ways to connect differential diagnosis to the AD/ASD task (while we wait for a dataset with real differential diagnoses). I urge the authors to clearly caution readers about the datasets limitations!
Below are multiple reviews of a paper. This paper aims to address object detection from LiDAR point clouds. The key idea is to train a densify network that can densify 3D features in a sparse point cloud. This densified network can be plugged into different object detection networks and enhance their performance. This is a well written paper. Good execution and good experiments.This paper proposes a knowledge-distillation approach to learning densified 3D features for outdoor 3D object detection. The final model is evaluated on the Waymo 3D Detection and Domain adaptation dataset where the method considerably outperforms multiple popular baselines.The paper proposes a method to boost the performance of object detectors in 3D LiDAR scans by learning an auxiliary task to densify them. It is fairly detector-agnostic and can thus be applied to different base SOTA detectors such as CentrePoint [1] or SECOND [15]. It improves their performance by 2–This paper presents a new framework to efficiently boost 3D detection performance by learning to densify point clouds in latent space. experiments on Waymo Open Dataset show promising results. The process of learning the feature representation of the point cloud in the dense point cloud space is actually an upsampling.	This paper proposes to utilize point cloud completion tools to densify sparse point clouds which could subsequently improve the performance of point cloud detection methods. After rebuttal, reviewers agree on the novelty of the method and its effectiveness on the Waymo open dataset. AC recommends this paper for acceptance following the unanimous opinion.
Below are multiple reviews of a paper. The paper proposes a frequency-based SGD method, where the learning rate is inversely proportional to the token frequency. Theoretical results show the proposed methods outperform SGD in skewed distributions. The empirical results are also very interesting.This paper proposes a counter-based learning-rate scheduler for SGD. This algorithm is designed based on the long tail distribution in recommendations and languages. The proposed algorithm enjoys a theoretic guarantee unlike other adaptive learning rate methods.This paper proposes a frequency-aware learning algorithm for embedding learning in recommender systems. The proposed method is very simple and easy to implement with provable benefits. In my opinion, the paper can be improved a lot by re-framing the pitch and enriching the experiments.This paper proposes two optimization algorithms for recommendation where the token distributions are highly imbalanced. The proposed algorithms are easy to understand and implement, and the theoretical analysis for the bounds are provided.	The paper provides a new learning technique for problems that require learning embeddings. In particular, the authors analyze a technique that takes into account the frequency of items in an embedding layer to modify the learning rate for each embedding. The paper provides a theoretical analysis of this approached and contrasts it to that of SGD. It also provides experiments validating this approach empirically.  The reviewers agree that the paper provides a simple yet effective method, based on realistic assumptions (non-uniform frequencies). In addition, the paper seems to be well written and easy to follow. One issue raised in the reviews was about the focus of the paper, and the fact that the experiments are limited to recommendation systems even though the method is claimed to be generic for any model requiring embeddings. During the rebuttal the authors provided experiments for an NLP task that show favorable results to the new technique in another regime. Given the overall positive feedback and this new evidence validating the proposed method, I recommend accepting the paper.
Below are multiple reviews of a paper. This paper proposes a method for exploration in reinforcement learning by using the uncertainty over the value function as an intrinsic reward. The noise in this stochastic environment, however, is very low. I think it will improve the paper a lot if the authors add such environments to their analysis and discuss such problems.This paper proposes to use an intrinsic reward based on uncertainties calculated from temporal difference errors. The paper in its current form is not yet ready for publication for two main reasons. There are significant gaps in motivating and detailing the TDU technique.The authors introduce the use of value function variance as auxiliary reward promoting exploration during training. The variance is estimated using the bootstrap DQN approach. This new form of auxiliary reward is rather attractive as it automatically scales down during training as the model becomes more certain.The paper proposes a novel heuristic approach to estimate the uncertainty of the value function of an agent. This heuristic can be applied not only to tabular RL, but also when using function approximation. The paper is well written and clearly structured.	The submitted paper contains interesting theoretical insights into common approaches for exploration and proposes a new way for deriving intrinsic rewards for exploration which is evaluated in several benchmark environments. While all reviewers appreciate these aspects, there are concerns about whether the paper is ready for publication. In particular, the authors’ response did not clarify all open questions and concerns (although the authors already improved the paper a lot by updating the submitted paper according to recommendations/questions of the reviewers). After discussions and author feedback, 3 knowledgable reviewers suggest (weak) rejection of the paper and 1 reviewer suggested acceptance of the paper. Considering this, I recommend to reject the paper but I would like to encourage the authors to consider the comments of the reviewers to revise their paper accordingly, as I expect the paper to then turn into a strong and impactful one.
Below are multiple reviews of a paper. Paper proposes a scheme to accelerate popular sparse recovery methods that rely on hard thresholding. The key idea is that if the measurement matrix is normalized, then the k-sparse thresholding of the gradient update can be viewed as solving a k-nearest neighbor problem.The paper is very well-written, readable, with the ideas and derivations clearly explained. My biggest concern is that the technical contribution is too modest. Theorem 1 serves more as a decorative technical result.The paper proposes a greedy-like algorithm for sparse recovery that uses nearest neighbors algorithms. It assumes that the norms of the columns of the matrix A are one to be able to change the project-and-sort step into a nearest neighbors search.	The main idea of this paper is to use nearest neighbor search to to accelerate iterative thresholding based sparse recovery algorithms. All reviewers were  underwhelmed by somewhat straightforward combination of  existing results in sparse recovery and nearest-neighbor search.  While the proposed method seems effective in practice, the paper has the feel of not being a fully publishable unit yet. Several technical questions were asked but no author feedback was provided to potentially lift this paper up.
Below are multiple reviews of a paper. The authors observed that L2 distance between pre- and post-training embedding of a token varies significantly based on the token’s frequency. Based on that they devised strategies (black and white box) to perturb the sub-token.The paper proposes a gradient-free method to craft adversarial examples for Code2Seq model. The paper is well written and easy to understand. However evaluation should be improved. STRATA is based on the interesting observation that token frequencies and their $L_2$ norms are strongly correlated. The paper covers what one would expect when proposing a new attack, including performance evaluation, study of transferability and adversarial training results.This paper proposes STRATA, a simple adversarial attack against the code2seq model. The key idea is to replace local variable names in the input code with other randomly chosen sub-tokens. They observe that such tokens often appear frequently in the training set.	The paper gives a gradient-free method for generating adversarial examples for the code2seq model of source code.  While the reviewers found the high-level objectives interesting, the experimental evaluation leaves quite a bit to be desired. (Please see the reviews for more details.) As a result, the paper cannot be accepted in the current form. We urge the authors to improve the paper along the lines that the reviews suggest and resubmit to a different venue.
Below are multiple reviews of a paper. Data-IQ is a framework compatible with any machine learning (classification) models. It categorizes data samples into Easy, Ambiguous, Hard groups based on the aleatoric uncertainty of the data samples. The paper demonstrated the utility of Data-IQ in guiding feature acquisition.The authors make a strong case that population level metrics for model performance may not be representative of model performance on subgroups. The authors apply their proposed technique on multiple real world healthcare datasets. Overall I like this paper, even though there are a few weaknesses.The authors present an approach that given a model can identify 3 general sub-groups in the dataset that differentiates the model performance across the dataset. They conducted experiments and demonstrated various aspects of the proposed method. Overall, their proposed method aims at informing reliable model usage.The paper proposes a framework to identify examples in the datasets that a classifier tends to distinguish correctly, wrongly, and randomly. The paper decomposes the accuracy of a given example into a summation of epistemic uncertainty and aleatoric uncertainty.The authors proposed a framework of data characterisation and data sculpting during model training based on the outcome and feature characteristics of the subgroups within a dataset. They provide a tool, Data-IQ, to help the researcher understand data better.	This easy-to-follow paper has been thoroughly evaluated by five competent reviewers. Four of them rated the work as acceptable (two full and two weak accepts), while one recommended a rejection. In my opinion, the reviewer with the negative assessment has not raised fundamental issues that would disqualify this paper from being considered for NeurIPS. The authors provided extensive clarifications to all the reviewers, including the one with a negative opinion. That reviewer did not engage in discussion with the authors. I recommend accepting this paper without reservations
Below are multiple reviews of a paper. This paper proposes a deep GNN network for graph classification problems. It turns the graph down-sampling problem into a column sampling problem. The approach is applied to several benchmark datasets and achieves good results.The main purpose is the classification of graphs. The proposed approach consists of four parts. Each of the part is poorly explained and/or a method that has already been used before.The authors argue that graph neural networks based on the message passing frameworks are not able to infer the topological structure of graphs. They propose to use the node embedding features from DeepWalk as (additional) input for the graph convolution. A graph pooling operator is proposed, which clusters node pairs in a greedy fashion based on	The extension of convnets to non-Euclidean data is a major theme of research in computer vision and signal processing.  This paper is concerned with Graph structured datasets. The main idea seems to be interesting: to improve graph neural nets by first embedding the graph in a Euclidean space reducing it to a point cloud, and then exploiting the induced topological structure implicit in the point cloud.   However, all reviewers found this paper hard to read and improperly motivated due to poor writing quality. The experimental results are somewhat promising but not completely convincing, and the proposed framework lacks a solid theoretical footing. Hence, the AC cannot recommend acceptance at ICLR-2019.
Below are multiple reviews of a paper. The authors deal with the problem of revising previous recorded data and its effect on timeseries predictions. They showcase how revisions in past data, quantified as the backfill error, can introduce a considerable error in predictions. Towards that, they propose a novel deep learning approach, the Back2Future, that refines the model predictions usingThe authors consider the effects of backfill dynamics--the correction of historical data--on time series prediction. A key finding is that real-time forecasts tend to overestimate their accuracy when compared to the stable accuracy after errors are corrected. The authors then propose a Back2Future (B2F) pipeline that can be used to refineThe paper proposes a real-time forecasting model for situations where the predictive features and the response variable are both subject to recording delays. The technical part of the paper is very well written and the intuition behind various modeling decisions is explained in a clear and simple way.	This paper introduces Back2Future, a deep learning approach for refining predictions when  backfill dynamics are present.    All reviewers agree on that the authors successfully motivate their work and  introduce a topic of great interest, i.e. that of dealing with the effect of revising previously recorded data and its effect  timeseries predictions. The reviewers also underline the strong and thorough experimental section. Among the reviews is also underlined the potential impact of the work for the research domain.   Many thanks to the authors for replying to the minor concerns raised.  I concur with the reviews and find this submission very interesting, convincing and thus  recommend for accept.   Thank you for submitting the paper to ICLR.
Below are multiple reviews of a paper. Authors propose knowledge distillation from graph Transformer (GT) to SMILES Transformer toward learning a molecular representation. They say ST-KD achieves strong performance, similar to graph-based models, on molecular property prediction tasks with a fast inference time.The SMILES-Transformer's performance can be largely boosted by simple augmentation trick, e,g using random-smiles as augmentation when training the model. The authors provide an interesting knowledge distillation framework to learn molecule embedding.High-throughput molecular representation for large chemical databases is one of the kernel requirements for many downstream applications, such as drug discovery and virtual screening. This paper provides a SMILES-based molecular representation learning model, named ST-KD. It uses deep graph models to extract molecular feature from raw SMilES data without SMILThe paper targets speeding up the inference process (specifically, SMILES-to-graph preprocessing) in virtual screening. It proposes to use graph-based transformer as teacher network to conduct knowledge distillation (ST-KD) I am uncertain about the efficiency claim in this paper.	The paper  builds  fast and high-quality SMILES-based molecular embeddings  by distilling  state-of-the-art graph-based models teachers. This has the advantage of speeding inference time w.rt to graph based methods.   The reviews were split regarding the motivation of the work, in the sense of why not train directly on SMILES instead of distilling graph based methods that are in some tasks behind SMILES transformer. Authors provided clarifications in the rebuttal showing that on Knowledge distillation of graph models  surpasses  SMILES only model training.   I think given the experimental nature of the paper the main motivation of the paper should be better clarified and supported with more experimentation and downstream tasks.
Below are multiple reviews of a paper. This paper studies the geometry of adversarial examples under the assumption that dataset encountered in practice exhibit lower dimensional structure. Under the proposed framework, the authors analyze several interesting phenomena and give theoretical results.This paper gives a theoretical analysis of adversarial examples. The biggest weakness of the paper is that theoretical analysis is done on a very synthetic dataset. The authors do not give a bound on the probability that the sampling conditions for the robust nearest neighbor classifier will be satisfied.This paper tried to analyze the high-dimensional geometry of adversarial examples from a geometric framework. The authors analyzed the most robust boundary of norm 2 and norm infinity in different dimensions through a simple example. They concluded that the single decision boundary cannot be robust in different norms.	The paper gives a theoretical analysis highlighting the role of codimension on the pervasiveness of adversarial examples. The paper demonstrates that a single decision boundary cannot be robust in different norms. They further proved that it is insufficient to learn robust decision boundaries by training against adversarial examples drawn from balls around the training set.   The main concern with the paper is that most of the theoretical results might have a very restrictive scope and the writing is difficult to follow.   The authors expressed concerns about a review not being very constructive. In a nutshell, the review in question points out that the theory might be too restrictive, that the experimental section is not very strong, that there are other works on related topics, and that the writing of the paper could be improved. While I understand the disappointing of the authors, the main points here appear to be consistent with the other reviews, which also mention that the theoretical results in this paper are not very general, that the writing is a bit complicated or heavy in mathematics, and not easy to follow, or that it is not clear if the bounds can be useful or easily applied in other work.   One reviewer rates the paper marginally above the acceptance threshold, while two other reviewers rate the paper below the acceptance threshold.
Below are multiple reviews of a paper. The paper analyzes contrastive learning by bounding the supervised loss with contrastive loss. The bounds are tighter than those proposed by previous works. The insights from the analyses seem not directly applicable to practical setting.The paper studies the learning bounds of popular representation learning. Not only the improved tighter upper bound is provided, the lower bound is also studied. The paper is well written with many great figures to explain ideas.This work establishes a downstream classification loss bound for contrastive learning. Existing works cannot explain the experimental fact that larger negative samples improve the classification performance. The authors should discuss the novelty of the proof techniques compared with existing one.This work proposes a new theoretical upper-bound for contrastive unsupervised learning loss and its downstream supervised loss. Compared to previously published upper-bounds, the newly proposed one is lower and decreases when the number of negative samples increases. The authors use experiments on multiple datasets to verify the theoretic results.This paper provides some new theoretical insights on how contrastive representation help to improve downstream classification performance. The author(s) have made many clarifications and improvements to the paper per reviewers' requests. I am happy to bump up my score by 1 to reflect the changes & promises made.	The paper presents an analysis of the benefit of unsupervised contrastive learning for downstream classification tasks using the cross-entropy loss. Building on prior work, the authors show that the contrastive loss can be bounded in terms of the cross=entropy term and an “intercept” term which depends logarithmically on the number of negative samples per positive sample (for contrastive learning) rather than polynomially as in the prior work.   There are several differences between the setting here and that of the prior work by Arora et al. (2019). First, the work here focuses only on cross-entropy loss and leverages the similarity of the loss structure between the contrastive loss and the cross-entropy loss. Second, the assumptions here are different, e.g., boundedness of the representation. Finally, the assumption that latent classes are the same as the label classes (which is not the case in the prior work) is significantly restrictive.   The writing is poor and the presentation is not clear. Despite the title and various references to learning bounds in the abstract and the main text, there are no learning bounds in the paper. The main result is to bound the contrastive loss in terms of the cross-entropy loss under the assumption that the latent classes and the label classes coincide. Authors state that getting generalization bounds is routine and, therefore, they chose not to give them — I do not see how generalization bounds follow in a straightforward manner here, and even if they do, it is important to write them for completeness.   The main contribution here is that the bounds depend logarithmically in K — the number of negative samples per positive sample — compared to sqrt{K} in the previous work. The previous bound however holds for Lipschitz losses as well, for e.g., hinge loss. So the question remains whether this improvement is only for the cross-entropy loss. Regardless, K is typically small in practical applications. Even the experiments in the paper (Figure 7) suggest that the performance degrades for larger K even on simple tasks. So, the improvement is really somewhat insignificant.    The reviewers were generally positive and appreciated the paper. However, in the light of comments above (of which I am quite certain), unfortunately, I am unable to accept the paper at this point. I believe the comments above (and from the other reviewers) will help improve the overall quality of the paper. I encourage the authors to incorporate the feedback and work towards a stronger submission.
Below are multiple reviews of a paper. QWR algorithm estimates the Q-function using parameterized Q-network. AWR estimates the V-function. I think the paper is not novel enough to guarantee acceptance. Many existing off-policy papers make assumption on sampling policy.This paper proposes a variant of AWR with an added Q-function. Experimental evaluation of QWR focuses on online sample efficiency and offline performance. The algorithm presented here is largely the same as that in two recent papers.This paper focuses on offline policy learning with a limited dataset. Experiment results show that the QWR algorithm has better performance than the AWR algorithm with limited data.This paper presents a Q-value weighted regression on top of the advantage weighted regression (AWR) to improve the sample efficiency for offline RL settings. The experimental results are not convincing. The state-determines-action assumption is problematic.	This paper proposed Q-value-weighted regression approach for improving the sample efficiency of DRL. It is related to recent papers on advantage-weighted regression methods for RL. The approach is interesting, intuitive, and bears merits. Developing a simple yet sample-efficient algorithm using weighted regression would be a critical contribution to the field. The work has the potential to make an impact, if it has all the necessary ingredients of a strong paper.  However, reviewers raised a few issues that have to be addressed before the paper can be accepted. As some reviewers pointed out, there seem to be unaddressed major issues from previous submissions. Novelty appears limited, especially because the proposed approach is very similar to recent works (e.g., AWR). The experiment section lacks comparison to recent similar algorithms, and the available comparisons appear to be not strong enough to justify merits of the proposed algorithm. Theorem 1 requires an unrealistic state-determines-action assumption for the replay buffer. Although the authors made an effort to justify this assumption, it remains very problematic and rules out most randomized/exploration algorithms.
Below are multiple reviews of a paper. The paper develops a decentralized algorithm for solving variational inequalities with a certain structure motivated by machine learning applications. The key innovation is the utilization of compression for communicating loss functions and their aggregates between a set of devices and a centralized server node. The paper provides theoretical convergence guarantees that account for the quantization errors.The paper studies the communication needed in order for a group of distributed players to collectively solve a variational inequality problem. The paper provides two algorithms MASHA1, MASHA2 to do this that solve both the deterministic and stochastic cases. They also provide experimental results on applying their techniques to Bilinear saddle point problem andThis paper proposes compression methods for solving variational inequalities. Theoretical analysis is provided to show that the proposed method can converge. For practical problems such as GAN or adversarial training, the objective of min-max optimization is nonconvex-nonconcave.The paper has some interesting aspects for example large-scale adversarial training of transformers. Given the issues regarding theoretical results, connection with related work, and clarify and presentation of the paper, I recommend rejection.	In this paper, the authors consider two algorithms for solving (strongly) monotone variational inequalities with compressed communication guarantees, MASHA1 and MASHA2. MASHA1 is a variant of a recent algorithm proposed by Alacaoglu and Malitsky, while MASHA2 is a variant of MASHA1 that relies on contractive compressors (by contrast, MASHA1 only involves unbiased compressors). The authors then show that - MASHA1 converges at a linear rate (in terms of distance to a solution squared), and at a $1/k$ rate when taking its ergodic averge (in terms of the standard VI gap function). - MASHA2 converges at a linear rate (in terms of distance to a solution squared).  Even though the paper's premise is interesting, the reviewers raised several concerns which were only partially addressed by the authors' rebuttal. One such concern is that the improvement over existing methods is a multiplicative factor of the order of $\mathcal{O}(\sqrt{1/q + 1/M})$ in terms of communication complexity (number of transmitted bits) for the RandK compressor, which was not deemed sufficiently substantive in a VI setting (relative to e.g., wall-clock time, which is not discussed).  After the discussion with the reviewers during the rebuttal phase, the paper was not championed and it was decided to make a borderline "reject" recommendation. At the same time, I would strongly urge the authors to resubmit a properly revised version of their paper at the next opportunity (describing in more detail the innovations from the template method of Alacaoglu and Malitsky, as well as including a more comprehensive cost-benefit discussion of the stated improvements for the RandK/TopK compressors).
Below are multiple reviews of a paper. This paper proposes a Quantization neural network to spiking neural network (QNN2SNN) conversion method. The authors first analyze the conversion error between ANN and SNN. Then they construct the ann with quantized activation to eliminate the error.The paper first analyzed the various sources of ANN-SNN conversion errors namely clipping error, quantization error and unevenness error. It then proposed quantization clip-floor-shift activation function to replace the ReLU activation function in source ANNs to train them. This resulted in ANN-sNN conversion at ultra low latency (forThis research proposes an ANN-SNN conversion method based on quantization clip-floor-shift activation. The achieved experimental results are notable, but some key points need to be addressed.This paper proposes a quantization clip-bottom-shift activation function to replace the ReLU activation function in ANNs. The authors also prove that the expected error of ANN-SNN conversion can be reduced to 0 by using this method. This work archives state-of-the-art accuracy with fewer time-steps.	The authors present an improved method to convert ANNs to spiking neural networks (SNNs). First, a network with quantized activations is constructed, then it is converted. They analyze the conversion errors theoretically. In addition to previously considered errors [Li et al. 2021] they also consider an error they call "unevenness error" and propose a way to compensate for that. They test the method on data sets such as CIFAR-100 and show good improvements over previous methods with respect to classification accuracy and inference time. The reviewers agree that the manuscript presents interesting and valuable work with a significant novel contribution.The manuscript is well written.  Weak points according to the first reviews were: - Lack of ImageNet conversion experiments. - Analysis of energy consumption was missing. - More related work needs to be compared. The revision addressed all these points, This was acknowledged by the reviewers with increased ratings. All reviewers propose acceptance.
Below are multiple reviews of a paper. The paper builds upon the recently proposed S4 architecture, which was shown to be effective at modeling long-range dependencies. The paper is clear and well-written, and the background described in Section 2 is sufficient for new readers to understand the paper.The paper extends prior work on efficient state space models by simplifying the state transition matrix to be diagonal. The paper introduces 2 parameterizations of DSSMs that are based on this insight and show strong empirical performance on the long-range arena.The paper builds on structured state space (S4) models and shows that one can achieve similar or slightly better performance with just diagonal state matrices. This is interesting because then the model becomes conceptually simpler and easy to implement. I like the paper and recommend acceptance.	This paper proposes a simpler alternative to S4 that achieves comparable performance. The method makes sense and the experiments are thorough. All reviewers agreed this is a good paper. I recommend acceptance.
Below are multiple reviews of a paper. Conservative unsupervised data sharing (CUDS) is a new offline multi-task RL algorithm. CUDS shares task-agnostic transitions via simply relabeling their rewards as a constant. Surprisingly, CUDS achieves competitive results compared to CDS.This paper proposed a method for multi-task offline reinforcement learning setting where it can assign shared and annotate the reward. The proposed CUDS and UDS methods share similarities with one existing study (Yu et al. 2021a)This work targets useful data sharing between multi-tasks in an offline reinforcement learning setting. Motivated by the same transition kernel $P$ for each task, data sharing from other tasks is considered to be beneficial for finding an optimal policy. Under some assumptions, the proposed data sharing methods (CUDS, UDS) will be beneficial	Although sharing data between tasks benefits multitask RL, this requires that rewards be relabeled across tasks. This paper shows that, for binary rewards, directly reusing data from other tasks with constant reward relabels is effective, and the paper develops a method around this idea that is highly effective.  The reviewers found that the idea and execution were impressive, that the paper was well written, and that the empirical analysis was convincing.   In response to concerns in the preliminary reviews about certain shortcomings in the empirical analysis and some lack of theoretical analysis, the authors provided substantial revisions to the paper. Due to some lack of reviewer response to the discussion, this meta-reviewer examined whether those revisions were sufficient to address the reviewers' concerns. The authors did a good job in providing the requested improvements and the analysis is stronger, but remaining similarities to existing methods (CDS) means that this paper still remains borderline. These same concerns were also shared by reviewers that continued to engage in discussion with the authors. To remedy this, the authors are encouraged to better and more substantially address differences with prior work in the writing and motivation throughout the entire paper. In addition, although space is a concern, it would be beneficial to integrate the high-level takeaways from the new analyses in the appendices into the main paper.
Below are multiple reviews of a paper. The paper proposes to speed up inference of Deep Equilibrium Models by replacing the classic fixed-point solvers (Broyden or Anderson Acceleration) by a learned extension of AA. Their approach operates on a pre-trained DEQ, and trains a small neural network to propose an initialization and update scheme based on ground truth fixed pointsThe authors introduce a neural network approach for solving the fixed point equations arising in deep equilibrium models. The approach is intuitive and empirical. Although no theory is given, the authors demonstrate the strength of their proposed solver in large scale experimental evaluations. The new solver is fast to train and has a small parameter count.The paper presents a method called neural deep equilibrium solver to increase the efficiency in the inference stage for implicit deep models by initializing the equilibrium states using neural network. The method offers significant speedup (2x) in forward steps over the current solvers for fixed point calcuation at inference.	The authors introduce a neural network approach for solving the fixed point equations arising in deep equilibrium models. This consists of a tiny network that provides an initial guess for the fixed point, as well as a small network that computes coefficients inside an algorithm inspired by Anderson iteration.  Overall, there is consensus among the reviewers that the paper is well written and is a strong empirical study.  I recommend acceptance as a poster.  Additional remarks:  - The authors argue the DEQs / implicit deep learning models allow a decoupling between representational capacity and inference-time efficiency. Yet, in the "Regularizing Implicit Models" paragraph, they write "Implicit models are known to be slow during training and inference. To address this, recent works have developed certain regularization methods that encourage these models to be more stable and thus easier to solve.", which seems like a contradiction to me. So while in theory I agree with this decoupling, in practice, it seems not completely true.  - Section 3 should include some discussion on conditions on f_theta for the existence of a fixed point.  - Since the initialization and HyperAnderson networks are trained using unrolling, there is some memory overhead compared to vanilla DEQs, that are differentiated purely using implicit differentiation. It would be great to clarify the amount of extra memory needed by these networks. It is necessary to justify that the initialization and HyperAnderson networks are smaller than usual neural networks.
Below are multiple reviews of a paper. The paper establishes equivalence of state evolution for approximate message passing (AMP), convex min-max Gaussian theorem (CGMT), and Leaving-one-out (LOO) for three different problems. The paper has some grammatical and typographical errors. It needs a quick revision to correct for such errors.This paper provides derivations of equivalences between what they refer to as "state evolution" (SE) equations derived from different perspectives. They focus on M-estimators for high-dimensional linear regression. The only strength for me is the a-priori good intention of the paper. As a specialist of the field I wasThis paper considers the state evolution equations obtained via different methods (AMP, LOO and CGMT), and it shows that their fixed points are the same for some high-dimensional inference problems. While the paper focuses on a very interesting subject, unfortunately it does not seem to offer much insight into why the different state evolutions lead to theThis paper compares the so-called "State Evolution" equations from 3 different derivations for the MSE of high dimensional M-estimators in the proportional asymptotic regime. There are currently 3 well-known frameworks for analysis in this regime: Approximate Message Passing (AMP), Convex Gaussian Min-	Three out of the four reviews rated this paper well below the acceptance threshold. Although the review scores show a relatively large spread, I think that the review contents are more or less coherent across the four reviewers. The equivalence of the state equations (SEs; a set of equations that macroscopically characterizes optimal solutions of certain high-dimensional regression problems) derived from three different approaches (AMP, CGMT, and LOO) is well expected to hold, as the optimal solutions should be independent of how their macroscopic characterization in the form of an SE is derived, and this paper concretely showed such equivalence to hold for three problems. More concretely, Theorem 1 states the equivalence of the SEs for M-estimator derived from the three approaches, Theorem 2 states the equivalence of the SEs for LASSO derived from AMP and CGMT, and Theorem 4 states the equivalence of the SEs for logistic regression derived from LOO and CGMT. The main concern raised by all the reviewers is that this paper does not provide novel and significant insights as to why and how the equivalence arises. Some reviewers also pointed out that this paper lacks citation to the relevant statistical-mechanics literature, as well as that this paper contains so many typos, grammatical errors, and inappropriate typesetting styles. The authors responses were not instrumental in persuading the reviewers with negative evaluation. On the basis of these I would not be able to recommend acceptance of this paper for presentation at ICLR 2021.
Below are multiple reviews of a paper. The paper targets at developing a more expressive pooling layer for GNNs. Theoretical analysis shows that the CP layer can achieve permutation-invariance. The proposed method shows improved performance across tasks and datasets.The paper proposes a novel aggregation (pooling) layer for GNNs, called CP layer. The main idea consists of leveraging multilinear tensor decomposition to model high-order polynomial interaction between the components of node embeddings.This paper proposes a novel Tensorized Graph Neural Network (tGNN) based on symmetric CP decomposition. It can model high-order non-linear interactions among nodes. Experiments on several benchmark graph datasets demonstrate that the proposed method achieves more effective and expressive results.This paper proposes to consider non-linear high-order multiplicative interactions among nodes with symmetric tensor decomposition. The authors verify their model on node and graph classification benchmark datasets, on which the proposed method named tGNN outperforms existing baselines on most datasets.	The reviewers initially disagree on whether this paper has sufficiently advanced the research topic of graph pooling and have concerns on missing the comparison with Wang and Ji (2020), which have also introduced higher-order pooling for graph neural networks (GNNs). After extensive discussions with the authors, the reviewers have reached a consensus towards acceptance: While the performance improvement is marginal, and in some cases, not statistically significant, the proposed tensor decomposition-based pooling algorithm is new and provides a theoretically-sound valuable addition to advanced neighborhood aggregation methods for GNNs.
Below are multiple reviews of a paper. The authors present a method to jointly learn a shape and UV parameterization of a creased document observed from multiple views. They use an SDF based implicit shape representation in combination with a recent neural volumetric renderer IDR. The authors show that they can get better results both quantitatively and qualitatively when compared to one ofA paper proposes a neural rendering technique to learn how to estimate an implicit surface and its UV-parameterization from a set of 2D images. The proposed approach is applied to the problem of document unwarping. The paper shows that learning the texture mapping enables the contents of the unwarped document to be edited in the textureThis paper presents document unwrapping based on optimization of neural networks. Four MLPs are defined to model the implicit surface of the target. The target example is approximated by training the MLPs using differentiable rendering.The paper presents a multi-view method for undistorting documents. The method makes use of an existing method (IDR) for reconstructing distorted documents in 3-D, with an additional bijective neural network to parameterize distorted surfaces by rectangles.	This paper proposes an architecture for learned surface parameterization, with application to image unwarping, which can be coupled with differentiable rendering, multi-view data, and other modern objective terms.  The shape of the document is parameterized using an SDF technique, coupled with neural rendering and objective terms inspired by classical geometry processing.  This machinery is quite "heavy," leading to slow training times.  As pointed out by reviewer QH85, there were some experimental discrepancies---rightfully acknowledged by the authors---which make comparisons to DewarpNet less favorable for the new method, at least from a quantitative perspective.  Visual inspection makes the comparison more favorable, although it would be preferable for the quantitative quality metrics and qualitative examples to align.    Runtime measurements here are also not favorable and severely limit applicability of this technique in real-world scenarios, as pointed out by reviewers hfPz and QH85.  While the mistaken quantitative results are forgivable, the AC agrees that the scope of this work is quite narrow; it is not clear where this architecture would be applied relative to the motivating application.
Below are multiple reviews of a paper. This paper proposes a machine learning framework, named Markov neural operator (MNO), to learn the Markov operator of dissipative chaotic systems. Different from the conventional neural networks, they use Sobolev norms in operator learning and add dissipativity losses to ensure dissipativity. They experimentally show that the MNO can accurately approximate theThis article discusses robust estimation of chaotic dynamical systems using Markov neural operators. The major innovation in the present work is the addition of a ‘dissipativity loss’ that enforces attracting behavior within a shell around the data.This paper proposes a machine learning framework (MNO) by using neural networks or Fourier neural operators to learn the underlying Markov operator of dissipative chaotic systems. MNO has lower loss and outperforms the other neural network models, including U-Net, LSTM-CNN, and GRU.The authors show that adding a dissipative term in the loss and training it with sobolev loss would improve the stability of the autoregressive data-driven models. The major weakness of this work is that 2 of the 3 systems considered are not realistic enough to show issues with instability.	This paper proposes a neural network-based approach to estimate the Markov operator of dissipative chaotic systems. It introduces a novel combination of Sobolev and dissipativity losses. While the reviewers had initial concerns about clarity, assumption and application condition, and the choice of learning Markov operator versus modelling continuous dynamics, the author-reviewer discussion addressed most concerns, and all reviewers agree this work exceeds the bar for publication.  I would encourage the authors to take into consideration the remaining concerns from the reviewers, incorporate key conclusions of the discussions and the limitation of the work in their final version.
Below are multiple reviews of a paper. The paper compiles a dataset from various sources into one unified format for use in downstream research. This dataset can be used for pre-training (since it is not labelled for any specific purpose) and can provide useful insights into various social issues and data-related insights.The paper presents a dataset of open-source English-language legal and administrative data. It covers court opinions, contracts, administrative rules, and legislative records. Unfortunately, it contains mainly US/Canada legal domain.Privacy and toxic content is a problem for training material in large language models. The paper investigates the issue by curating and using a large open source legal dataset. The data has already been filtered through legal and administrative processes.The paper studies responsible data filtering practice for AI researchers. The released corpus is comprehensive and will be useful for studying legal AI. The accompanying PoL-BERT language models do not seem to be trained optimally and their usefulness may be limited.	The reviews are generally positive (though somewhat short), and a large pre-training corpus for legal text will likely be useful for NLP research. One reviewer gave a reject score (5) with the following two weaknesses:  A) The dataset comes from a wide spectrum of law-related data sources, which may differ substantially and hence limit the usefulness of the dataset.  B) Privacy   I am not too worried about Point A because large language models seem to be able to learn from diverse data sources.  Regarding Point B, the separate ethics review mentions the privacy concerns as well but finds that the submission sufficiently discusses this concern and sees no serious ethical issues.  Hence overall I recommend accepting the paper.
Below are multiple reviews of a paper. The paper proposes a simple method (SALR) to encourage the SGD to converge to flatter minima for better generalization. The basic idea is that it increases the learning rate when the sharpness is high, vice versa.SALR is a new optimization algorithm which adapts the learning rate to avoid sharp local minimas. This is achieved by computing/approximating the sharpness at different iterations. The theoretical proof provided is for simple convex problems.The paper proposes a method called SALR, which adeptly updates the learning rate based on the local sharpness of the loss function to escape the sharp local minimum. By doing this, the author shows that their method can enhance the generalization and converge speed during the training procedure.This work proposes an algorithm that aims at finding a flat minimizer. Theorem 5 does not differentiate between flat and sharp local minima. The algorithm is easy to implement and seems to work well in practice.	This paper proposes a method to update the learning rate dynamically by increasing it in areas with higher sharpness and decreasing it otherwise. This would the hopefully leads to escaping sharp valleys and better generalization. Authors further provide some related theoretical results and several experiments to show effectiveness of their models.  All reviewers find the proposed method well-motivated, novel and interesting. The paper is well-written and easy to follow. However, both theoretical results and empirical evaluations could be improved significantly:  1- The theoretical results as is provides little to no insight about the algorithm and unfortunately, authors do not discuss the insights from the theoretical results adequately in the paper. See for eg. R1's comments about this.  2- Given that the theoretical results are not strong, the thoroughness in empirical evaluation is important and unfortunately the current empirical results is not convincing. In particular, there are two main areas to improve:  a) Based on the Appendix D, the choice of hyper-parameters seem to be made in an arbitrary way and all models are forced to use the same hyper-parameters. This way, the choice of hyper-parameters could potentially favor one method over the other. A more principled approach is to tune hyper-parameters separately for each method.  b) It looks like the choice of #epochs has been made in an arbitrary way. For all experiments, it would be much more informative to have a figure similar to the left panel of Fig. 4 but with much more #epochs so that reader can clearly see if the benefit of SALR would disappear with longer training or not.  c) Based on the current results, SALR's performance  is on par with that of Entropy-SGD on CIFAR-100 and WP and there is a very small gap between them on CIFAR-10 and PTB. I highly recommend adding ImageNet results to make the empirical section stronger. The other option is to compare against other methods in fine-tuning tasks. That is, take a checkpoint of a trained model on ImageNet and compare SALR with other methods on several fine-tuning tasks.  Given the above issues, my final recommendation is to reject the paper. I want to thank authors for engaging with reviewers during the discussion period and adding several empirical results to the revision. I hope authors would address the above issues as well and resubmit their work.
Below are multiple reviews of a paper. The submission claims that other works that investigation compositionality in representation learning do not actually test compositional generalization. Here are some examples of prior works that correctly hold out novel combinations (of underlying components) for test time. The evaluation tasks are extremely simple (overlayed MNIST digits and conjoined word token)This paper studies "compositionality" and in particular the way in which it "transfers" on test data. They run simple baselines on three experiments (overlapped MNIST, colored MNIST and concatenated month names) and find that the baselines do not learn compositional representation. They proposed the useThe paper introduces a “transferability of compositionality” problem and proposes an approach to alleviate it. The problem may arise when one trains neural models to produce “compositional” representations of the input. The proposed solution at inference time is to project object representations to the manifold of individual object representations.Compositional generalisation in neural networks is a relevant and hot topic. This paper aims to contribute on this topic and proposes some interesting datasets. I am not convinced that the authors have properly understood the questions that are asked in this domain.	This work considers an apparent problem with current approaches to compositional generalisation (CG) in neural networks. The problem seems to be roughly: 1. prior work in CG aims to extract 'compositional representations' from the training distribution 2. work on CG, the training set and the test set are drawn from different distributions therefore 3. we don't know whether these models can also extract compositional representations from the test distribution  All four expert reviewers were, to differing degrees, confused by this problem framing, largely because they consider the premise (1) to be false.   I am also aware of a large body of recent work on CG in neural networks (see those papers listed by R2) and, as far as i know, none of it involves extracting 'compositional representations' from the training set. Rather, it involves learning something (from the training set) that enables strong performance on a test set that differs from the training set in a way that is informed by ideas of compositionaity.   As far as I know, there are very few  studies that try to identify compositionality by considering the internal representations of neural networks, so it feels incorrect to claim this is standard practice. Any work that goes down this route ought to have a very thorough treatement of the various thorny philosophical and theoretical treatments of compositionality in the literature. As pointed out by R4, the work in its current form does not do this.   In summary, this work attempts to solve a problem that none of the four expert reviewers consider to be in need of a solution.
Below are multiple reviews of a paper. This short paper presents a preliminary approach to explaining planning modeling decisions. This is in contrast to the prevalent approaches of explaining the agent's actions in the context of a given domain. As such, this approach aims to explain how modeling decisions affect the plan.This work considers how to explain model abstraction decisions to a human. The authors define different abstraction step types that either affect the optimality of a plan, or removes plans from the possible plans in a model.	The paper presents some ideas on explaining how the modeling decisions, such as abstractions, underlying a planning problem may affect its generated plans. Although in a preliminary stage, it is an interesting direction and would be a good addition to the workshop.   Nevertheless, we suggest the authors revise the paper with the reviewers’ comments. Particularly, there seems to be a confusion with the term “model reconciliation” and some of the assumptions about the human’s model (see reviewer’s 2 comment). It will benefit the paper greatly if these were addressed and ironed out.  We are looking forward to your presentation.
Below are multiple reviews of a paper. This paper advocates for the use of group theory to characterize geometric features of grid worlds. It claims these geometric features reflect information about obstructions that can ultimately be used to check for collisions. The paper's poor organization is one of its major issues.This paper considers gridworlds, 2D grids where cells are occupied by objects that can either move around the grid themselves or be moved by other objects. Authors find that agents separated by either a knight or 2-step bishop move could collide, and interpret this as saying that agents only need to know what other agents are doing 4 stepsThe paper studies the geometry of the state space specific to 2-dimensional grid-world environments. The methods provide a way of identifying unsafe states in discrete environments. Although the study of geometric structures of state complexes is interesting, it is hard to see the computational benefits.	This paper analyses grid worlds, more precisely multiple objects moving in grid worlds, using the mathematical idea of state complexes.  The state complex represents all possible configurations as a single space, from which domain properties can be ascertained by group-theoretic, combinatorial, or geometric analysis.  In particular, the paper develops a theory around "Gromov's Link Condition" to analyze conditions under which collisions can be prevented in such domains.  The reviewers had a mixed initial response to this paper.  On the positive side, the reviewers appreciated the theoretical development (txoD) and novelty (2SSW).  On the negative side, the reviewers struggled to see the significance or relevance of the work to learning or AI (2SSW, 5vs3).  The reviewers understood the work as a mechanism for collision checking (2SSW), a means to support learning (5vs3), and a computational mechanism for analyzing gridworld dynamics (txoD).  The author response clarified several aspects of the reviews that were misunderstood.  The author response did not sway the reviewers.  Primarily, the concern is that the paper failed to communicate the relevance of the mathematical analysis of gridworlds to an AI audience.  The sole positive reviewer ultimately concurred with the arguments made by the negative reviewers.    Two reviewers indicate to reject, and one indicates a weak accept.  Based on the failure of the paper to clearly communicate the relevance of its ideas to any reviewer, the paper is rejected.  One suggestion for a future revision would be to present these ideas in the general setting of an MDP (instead of a specific domain of a gridworld).  The local combinatorial analysis on a generic MDP could potentially be more useful to the MDP community when considering planning for AI safety or problems of mechanism design.  The evidence needed to validate the ideas for those communities might again be different from the evidence provided in this paper.  As a separate comment, the analysis of the transition dynamics of actions may have related work stemming from predictive state representations.  In the paper's current form, the reviewers were unable to see a clear contribution.
Below are multiple reviews of a paper. The paper makes some progress regarding a formal analysis that supports these different paradigms. The main weakness is that the assumptions are a bit stronger than desired. Overall, I like the general formulation and have thought about it more than most papers I review.The paper is well structured and generally readable. Many ideas are expressed clearly, but some important concepts are not. English and notation are a bit contrived in places.The theoretical analysis is sound. The motivation is strong. The experiment could be more adequate. More details and explanations are needed.The manuscript is written in clear and concise prose. Most related work is covered. The hypothesis, assumptions, and claims are formally stated. A lot of work is needed in the experiments section.	Meta Review: This paper receives generally positive ratings. After rebuttal, all reviewers recommend acceptance. One reviewer has concerns that authors should also include domain generalization settings and baselines. AC agrees with this but also understands that it is impossible for one paper to incorporate every piece of OOD such as: Cross-domain/Domain Transfer/Domain Adaptation/Domain Generalization/Few-shot/Zero-Shot/Open-set, etc. As well as the most recent WILDS benchmarks and DomainBed settings, So, AC suggests the authors position this paper topic more clearly in the introduction and experiments. AC recommends acceptance.
Below are multiple reviews of a paper. This paper proposes an algorithm for computing an approximation of the posterior and marginal likelihood by analysing the sequence of programs. Experiments demonstrate the feasibility of the meta-algorithm for learning inference algorithms.The paper presents an algorithm for composing inference algorithms. The language is simple without recursion or loops. The networks are trained using HMC or importance sampling samples from many programs in a similar space.Aims to learn general inference algorithms applicable to any probabilistic program. Aims to associate a neural network with every grammar rule of a Probabilistic programming language.The paper proposes a new restrictive class of probabilistic programs with fixed number of random variables and without loops. The authors then propose an inference technique that learns the parameters of a neural network for sampling from the programs posterior distribution. This technique is shown to perform well during inference.	The paper presents a meta-algorithm for learning a posterior-inference algorithm for restricted probabilistic programs. While the reviews agree that this is a very interesting research direction, they also reveal that there are several questions still open. One reviewer points out that there learning to infer should take both the time for learning+inference and the generalization to other programs into account, i.e., what happens if the program is too different from the training set? Is benefit than vanishing? Moreover, as pointed out by another review, recursion as well as while loops are not yet supported. Also, the relation to IC needs some further clarification. These issues show that the paper is not yet ready for publication at ICLR. However we would like to encourage the authors to improve the work and submit it to one of the next AI venues.
Below are multiple reviews of a paper. This paper introduces generative neuro-symbolic modelling, advertised as a probabilistic programming framework in which the distributions are modelled by neural networks. This is a very exciting idea, and well past its time. However, the work discussed here is limited to modelling the drawn characters in the Omniglot dataset.This paper presents a generative neuro-symbolic model for learning the task-general representations. The model is inspired by the BPL approach, with less manually-defined prior or rules but more learning-based ingredients.A new approach to mimicking human concept learning has been proposed. The method is called GNS (Generative Neuro-Symbolic) It is an advance over methods based on pre-defined subroutines. The weakest part of the approach is the image model.The paper is well written and the model itself is described in detail. The experimental results on four Omniglot tasks are strong and quite thorough. The GNS model does seem to outperform the BPL model and other baselines. The representation used by GNS seems too low-level to adequately capture a character concept.	This paper was reviewed by four experts in the field. Based on the reviewers' feedback, the decision is to recommend the paper for acceptance to ICLR 2021. The reviewers did raise some valuable concerns that should be addressed in the final camera-ready version of the paper. The authors are encouraged to make the necessary changes and include the missing references.
Below are multiple reviews of a paper. The paper introduces an approach that, given a set of "basis" policies, constructs a high-level policy from the basis policies that is able to perform well in a variety of distinct (but related) tasks. It provides two examples of such policies (SMP and GPI) and formalizes the problem of computing a SThe authors propose to solve a family of related tasks with shared features and rewards that are linear in the features and equivalent up to scaling factor. The theoretical results are also validated experimentally, on a grid world example and control problems from Deepmind.The submission suffers from several serious weaknesses. Although the reward-set setting is quite general, it includes very unnatural cases that make the problem artificially too complex, in my opinion. The formalization is messy and sometimes unnecessarily confusing.Theory developed in the paper relies on reward functions that can be represented as linear combinations of the features of the MDP. In many problems, there is no linear reward function that would allow an agent to achieve the desired behavior, so these techniques would not be helpful.	All reviewers are positive or very positive about this work. The authors successfully addressed all questions. I believe this paper should be accepted.
Below are multiple reviews of a paper. This paper proposes a suite of long sequence processing tasks to benchmark efficient transformer variants in terms of their accuracy/speed tradeoff. The benchmark tasks are constructed following six desiderta: generality, simplicity, challenging, long inputs, probing diverse aspects, and accessibility.This paper proposes benchmark tasks for the new crop of efficient Transformer models. My main reservations concern the somewhat artificial nature of the tasks and the generalizability of the results. BigBird seems to work the best out of the box.This paper proposes a new benchmarks for the host of recently-proposed transformer variants. It’s not entirely clear to me that LRA is best-positioned as a benchmark, rather than an analysis tool. I’d like to see this toolkit shift toward being more customizable for individual user questions and values.The paper presents LongRangeArena (LRA), a new benchmark for evaluating models such as Transformers on tasks that require long-range processing. Overall, this paper makes an important contribution and despite some limitations should be accepted to ICLR.	The paper attempts at providing a general benchmark for evaluating/analysis of long range transformer models, consisting of a 6 evaluation tasks. The main goal of the paper is to remove conflating factors such as pretraining from model performance and keeping the benchmark accessible. All reviewers agreed that these are important positive aspects of the paper and the presented analysis/results are useful.    While reviewers generally feel positive about the work, there are some critical concerns on how useful this benchmark is in practice, how generalizable are the results, and whether the benchmark is good at what is intended for. For example, the vanilla Transformer model performs very well on all the proposed tasks, making me question on what we can actually learn about long range dependencies through this benchmark. In addition, most tasks are synthetic and all models fail on 1 of the 6 proposed tasks.   Therefore, I think LRA should be viewed more as a tool for analysis, or as authors nicely put in their response, it should be viewed as a means to "encourage hypothesis driven research instead of hillclimbing or SOTA chasing.".  During discussion period with reviewers, while acknowledging the above-mentioned issues, this strength was highlighted as a valuable contribution. Therefore, given the general positive sentiment about the work, I'd recommend accept.
Below are multiple reviews of a paper. This is the first work to systematically investigate the shift in the performance of commercial ML APIs. The proposed algorithm asymptotically approaches the optimal allocation decay rate of 1/N. The experiments could be improved by comparison to baselines other than random sampling. API shifts are common in several deployed machine learning models. This work proposes an efficient way to measure shifts in the confusion matrices of ML models using limited number of API calls.Authors track the changes through confusion matrix differences. They propose an efficient algorithm they call MASA to evaluate the changes in results with reduced number of queries. Their algorithm achieves better estimates given the same budget than uniform sampling.A method to estimate the confusion matrix of a black-box classifier, using as few samples as possible. Algorithm is uncomplicated to implement, and provides clear improvement over naive sampling methods.	The paper studies real world ML APIs' performance shifts due to API updates/retraining and proposes a framework to efficiently estimate those shifts.  The problem is very important and the presented approach definitely novel. My concern is about limited novelty of the theoretical analysis and weak experimental evaluation (just two dates, limited number of systems tested, small number of ablations). As of now the paper looks like an interesting but unfinished proposal. Looking forward to the discussion between the authors and the reviewers to address the concerns.  In the rebuttal, the authors have addressed reviewers' comments, in particular by adding additional experiments that strengthen the paper. All the reviewers recommend the paper to be accepted. It is suggested that in the camera-ready version the authors will add additional details regarding the experiments, as some of the reviewers mentioned.
Below are multiple reviews of a paper. This paper proposes a novel method on weak-shot semantic segmentation, in which fully-supervised model, MaskFormer, with dual similarity transfer was employed. The experimental results showed the effectiveness of the proposed method.This paper focuses on the weak-shot semantic segmentation problem. It proposes a dual similarity transfer network based on MaskFormer. The experiments show that the proposed method can successfully improve the segmentation accuracy.This paper proposes a dual similarity transfer framework based on MaskFormer for the Weak-shot Semantic Segmentation task. Experiments are performed on the COCO-Stuff and ADE20K datasets.	Two reviewers give a weak accept rating while the other one gives a borderline reject rating. Considering the low confidence of the negative comment and the contrary comments in paper writing (confident "easy to follow" vs. unconfident "hard to understand"), the AC would lean to accept this paper.
Below are multiple reviews of a paper. The paper studies the empirical properties of the Kronecker Factorization based approximation to the Hessian of the loss. Overall, the paper is not clearly written. It really needs to improve on the notation and needs to explain the ideas more clearly.Reviewer: The analysis of the spectrum of the Hessian of the loss function gives us significant insight. Three separate researchers at my institution have written papers on this general topic in the last few years.The authors study the layer-wise Hessian of several well-known vision networks on several vision classification datasets. They trace the surprising top eigenspace overlap to the structure of the data and show that it weakens with the application of batch norm. They also show that this overlap can tighten PAC-Bayes bounds.The paper studies the structure of the Hessian matrix of loss functions by approximating Hessians using Kronecker factorizations. The authors provide a tighter bound on classification error.	This paper studies different properties of the top eigenspace of the Hessian of a deep neural network and their overlap. It raised quite a lot of discussion, which finally went in not very constructive way. The reviewers generally agree that the paper has potential, but the actual contribution is limited.  Pros:  - The idea that top eigenspaces between different models have high overlap is interesting - The explanation that these structures can be explained by Kronecker-product approximation of the Hessian.  Cons:  - The connection to PAC-Bayes is unclear and seems artificial. - Many of the related work is missing - The models and datasets are too simple, and general conclusions can not be made on such kind of models. Much more testing is needed to verify the claims, including state-of-the art architectures and datasets.
Below are multiple reviews of a paper. This paper proposes the acceleration implementations of the greedy-type algorithms for DPP MAP inference. The authors mention the limitation that the method does not improve the worst-case time complexity. The proposed method can only fasten empirical runtimes.This paper presents new greedy algorithms for maximum a posteriori (MAP) inference for determinantal point processes (DPPs) MAP inference seeks to find the subset with the highest probability under the DPP. The first major algorithm combines the ideas of “lazy” and “fast” greedy MAP inference algorithms from priorThis paper studies a fast algorithm for greedy MAP inference of Determinantal Point Processes (DPPs) The authors first apply a lazy evaluation trick (widely used in submodular maximization) to the Cholesky-factorization-based greedy DPP MAP algorithm (FastGreedy) Experimental results on both synthetic andThis paper considers the problem of efficiently computing an approximation to the maximum a posteriori inference (MAP) of a discrete determinantal point process (DPP) Two cases are discussed: cardinality-constrained and unconstrained DPP MAP inference.	Although the reviewers gave a wide range of ratings to this paper, they all agreed that it is well-written and presents two novel, sound algorithms that perform well in practice. The main concern was that the algorithms merely combine existing techniques, which is true. However, given that the resulting algorithms are elegant, well-motivated, and highly performant, and that achieving the combinations is not trivial, I believe this paper makes a significant contribution to an active field of research and deserves acceptance.  The authors should take the reviewers' comments into account as they prepare their final revision. In particular, I would encourage them to more explicitly describe their reasons for presenting two different algorithms (cardinality constrained/unconstrained). Currently, it feels like the two parts of the paper are somewhat disconnected.
Below are multiple reviews of a paper. CAML is a gradient-based meta-learning method closely related to MAML. It divides model parameters into disjoint sets of task-specific parameters adapted to each task and task-independent parameters. The adapted parameters are then re-interpreted as an embedding. Experiments demonstrate that this approach performs on par withThe paper talks about Meta-Learning where some of the parameters of the models adapt to the new task. The authors propose a more general approach and show how CAML works for supervised learning and reinforcement learning paradigms.The method is inspired by previous method, MAML. Their idea is separating the parameters in to two groups of context and shared parameters. The context parameters are learned through back-propagation of inner-loop and represents embedding for individual task. Shared-parameters are shared between all tasks, and are learned in the outerCAML seems an interesting meta-learning algorithm. I like the idea that the context parameters are used to modulate the whole network during the inner loop.	This paper proposes a meta-learning algorithm that performs gradient-based adaptation (similar to MAML) on a lower dimensional embedding. The paper is generally well-written, and the reviewers generally agree that it has nice conceptual properties. The method also draws similarities to LEO. The main weakness of the paper is with regard to the strength of the experimental results. In a future version of the paper, we encourage the authors to improve the paper by introducing more complex domains or adding experiments that explicitly take advantage of the accessibility of the task embedding. Without such experiments that are more convincing, I do not think the paper meets the bar for acceptance at ICLR.
Below are multiple reviews of a paper. This paper studies the generalization of algorithms when the weights converge in distribution. Traditional generalization analysis assume that a given algorithm converges to a fixed point. This paper gives a sufficient condition for an algorithm that satisfies the SAS.The standard notion o stability assumes learning algorithms to be convergent to a fixed point w.r.t. the weights. But, in practice, the weights of deep neural networks do not satisfy such a condition and they often oscillate indefinitely. Motivated by this fact, the authors propose a notion of statistical algorithmic stability (SThe paper lays the theoretical groundwork for studying the behavior (generalization, dynamics) of stochastic learning algorithms. Strengths: It correctly points out limitations of prior (deterministic) approaches to analyzing learning dynamics.This paper extends the notion of algorithmic stability to algorithms that do not converge in the traditional sense of reaching a fixed point in weight space. The authors validate their theory on VGG-16 and ResNet-18 models.	The authors new notation for the statistical algorithmic stability. It will be useful for studying algorithmic stability, and will open up new discussion in the field. Overall, the review team provide positive feedback and I would recommend accepting this work.
Below are multiple reviews of a paper. This paper proposes a method to incorporate 3D information into molecular representation learning, Uni-Mol. The method outperforms SOTA in most of the tested tasks and demonstrates its ability in few-shot learning settings.The paper proposes a pretraining / self-supervised learning method for 3D molecular representation learning. The backbone is Transformer based. The pretraining is adding noise to atom coordinates.This work provides representation learning for 3D molecules. It provides two good pretrained models for small molecules and protein pockets. The models can be finetuned for various downstream tasks.The authors proposed the same SE(3)-equivariant transformer variant, called Uni-Mol, for both molecular pretraining and protein pocket pretraining. They devise an invariant spatial positional encoding for the transformer variant. According to different downstream tasks, the two models are used independently or jointly.	This paper proposes a new framework for molecular representation learning (MRL) using both 2D and 3D molecular data. This framework is general and applied to various problems (e.g., protein-ligand binding pose prediction and molecular conformation prediction). I believe this paper is potentially quite impactful and able to reshape how research is conducted for MRL research.   However, the contribution of this paper is unclear in its current form.  - The proposed methodology is not very novel and uses a combination of existing methods.  - While the main contribution of this paper is to propose a new framework for MRL, the experiments focus on evaluating a single algorithm (i.e., SE(3)-equivariant model + 3 self-supervised tasks) compared to existing algorithms under different frameworks. In other words, the experiments do not deliver new information since (1) existing works demonstrated how combining 2D & 3D data improves downstream task performance and (2) pretraining is useful for the considered downstream tasks.  Overall, I recommend rejection for this paper. However, I believe this paper can be a very strong submission for the next conference if the authors clearly demonstrate their contribution. For example, I think the proposed idea would be pleasantly presented as an important "benchmark" paper, rather than a framework with superior performance.
Below are multiple reviews of a paper. The proposed formulation extends the classifier-guidance solution for latent autoencoder semantic codes z. Instead of explicitly training classifiers p(z | x_t), they propose to directly fit to the posterior mean gap of the pretrained, unsupervised, and frozen DPM. Results demonstrate higher quality reconstruction than DiffThis paper presents a method of learning representations out-of pretrained unconditional diffusion models. Different from DiffusionAE which learns the encoder and condition DPM together, this paper proposes to keep a pretrained diffusion models unchanged, and learn the gradient of classifier guidance.The paper presents a new learning framework for diffusion probabilistic models. The proposed framework aims to learn a robust representation feature through a pre-trained diffusion models.The authors propose an unsupervised method for data representation and reconstruction. They use a pre-trained unconditional diffusion probabilistic model (DMP) to avoid the long training time of such models. The method incorporates a gradient estimator, that learns the posterior mean shift.	This paper presents a new unsupervised learning method by making full use of pre-trained diffusion probabilistic models. Extensive experiments show that the proposed method can obtain an improvement in performance and learning time. Four reviewers voted for accepting the paper after the rebuttal and the discussion. All concerns raised by the reviewers have been well addressed by the authors. The AC agrees with the reviewers and recommends accepting the paper. Also, AC urges the authors to improve their paper by taking into account all the suggestions from reviewers.
Below are multiple reviews of a paper. This paper proposes an approach for lifelong learning for a set of parametrically varying tasks, by maintaining a joint world model across all tasks encountered. In the absence of task-specific data, the prior of the task- specific models is set to the world model posterior. The paper includes theoretical analysis that shows that this leads to increased sampleThis paper proposes that to more effectively handle life-long reinforcement learning settings, one can use model-based techniques with model uncertainty measured globally across tasks and locally within tasks. By tracking model uncertainty and using planning over stochastic models, the method can better tackle both forward transfer (better performance on future tasks after experiencing previous tasks) andThe authors tackle the problem of lifelong learning in RL. They propose to use hierarchical Bayesian modeling to achieve transfer between tasks over the course of learning. Both forward and backward task transfer is implemented to boost performance.	Unanimous accept from 3 experienced reviewers with good confidences  Important topic (lifelong RL), clearly explained, well-formulated with a variational and hierarchical Bayesian model, evaluated on a range of relevant experiments in discrete and continuous settings in MuJoCo, and also MetaWorld MT10 & MT50 domains in response to reliever osbM and thFd questions, adapted to the lifelong setting of rolling out tasks sequentially, to include like opening a boxes/closing drawers/opening windows.
Below are multiple reviews of a paper. This paper proposes power-law dynamic of SGD which considers state-dependent noise. Power-law distributed derived from this dynamic explains the heavy-tailed distribution of parameters trained by SGD.In general I have a tendency to accept this paper. Even though there are crucial assumptions that are made, it can be considered as a first step towards a more rigorous and general argument.The paper studies the effect of SGD noise near a local minimum of the loss. It uses a novel Taylor expansion to estimate the distribution of gradient noise in the neighborhood of that minimum. The results seem interesting, and it is understandable that certain assumptions must be used.This paper proposes to use power-law dynamics to approximate the state-dependent gradient noise in SGD. It also analyses its escaping efficiency compared with previous dynamics.	The average review rating is 5.5 which means it’s somewhat borderline. One of the reviewers planned to increase the score but apparently didn’t do so formally. A subset of the main pros and cons the reviewers pointed out are:   Pros:  “Some empirical support is provided for the theory.” “ It is particularly interesting that the authors show that the second order effect of the SGD noise in the Hessian induces a power law distribution over the iterates.”  Cons:  “The escaping efficiency of the power-law dynamic is only analyzed in low-dimension case. ...” The author responded that Theorem 7 proves the multi-dimensional case. But the AC noted that it’s very likely that escaping time is exponential in dimension (because kappa needs to be larger than d as the author noted and the det() might also be exponential in d. The author did say in the revision that the dimension should be considered as the effective dimension of the hessian, but the AC couldn’t find a formal argument about it.) “The assumptions made are somewhat strong and may not hold in some cases...”  The reviewers also had a few clarity questions which the author addressed in revisions with re-organized writing. The AC weighed the pros and cons and found that the unclarity and potential exponential escaping time in the multi-dimensional case outweigh the pros.
Below are multiple reviews of a paper. In this paper, the authors consider the global convergence and stability of stochastic gradient descent in a fairly general non-convex setting. One weakness is that some of the assumptions is less intuitive, and needs more explanations, discussions and justifications.Under weaker conditions, the iterates of SGD will either converge to a stationary point of the objective function or diverge. I found the manuscript to be clearly written and technically sound. Although it has some weakness, I think it still worth a publication.In this paper, the authors study the behavior of SGD under very general assumptions. The main results include global convergence and stability. The paper is clearly written and the results seem to be interesting. Here are some comments/suggestions.	The paper considers the global convergence and stability of SGD for non-convex setting. The main contribution of the work seems to be to remove uniform bounded assumption on the noise, and to relax the global Holder assumption typically made. Their discussions in Appendix A provide an example for which the uniform bounded assumption on the noise commonly assumed in the literature fails.  The authors establish that SGD’s iterates will either globally converge to a stationary point or diverge  and hence tehir result exclude limit cycle or oscillation. Under a more restrictive assumption on the joint behavior of the non-convexity and noise model they also show that the objective function cannot diverge, even if the iterates diverge.  The reviewers are on the fence with this paper. While they agree that the paper is interesting, they only give it a score of weak accept (subsequent to rebuttal as well). One of the qualms is that while the authors claim the result helps show success of SGD in more natural non-convex problems, they don’t provide realistic examples supporting their claim. Further, while the extension to holder smoothness assumption while is indeed interesting, unless practical significance is shown via examples, the result is not that exciting.  From my point of view and reading, while the reviews are not extensive, i do not disagree with reviewers sentiment. Technically the paper is strong but there is a unanimous lack of strong excitement for the paper amongst reviewers. While there is this lack of more enthusiasm, given the number of strong submissions this year, I am tending towards a reject.
Below are multiple reviews of a paper. This work proposes a line search method LABPAL for first order methods to train neural networks with SGD. The idea is to leverage the two empirical observations that the full-batch loss along lines in the SGD update direction is shaped parabolically and the optimal step size changes rather slowly.The authors propose a parabolic line search for SGD to automatically adjust the learning rate during training. The authors emphasize that their method is not motivated by theory, but on an empirical evaluation of ResNet-20 on CIFAR-10.This paper uses empirical observations of Mutschler & Zell to come up with a line search algorithm called LABPAL. The experiments only include image classification workloads, so whether this algorithm generalizes to other tasks (e.g. NLP tasks) is an open question.In this paper, the authors propose an algorithm for the automatic selection of the step size for SGD and apply this algorithm for DNN training. Full batch loss along the negative direction of the normalized batch gradient could be localy approximated with a parabola with high precision. So optimal step size could be also approximated as distance	This work proposes a method for automatic adaptation of the learning rate via a estimating quadratic approximation of the full batch during training. The method motivated by two observed properties of the loss landscape, first the full batch loss along the gradient direction is well approximated by a quadratic polynomial, and second the optimal full batch step size does not change quickly during training. Two primary criticisms raised by reviewers is the weak experimental evidence provided to validate the method and similarities with other approaches for adapting the learning rate. Ultimately reviewers remain unconvinced by the rebuttal and maintained their scores. The AC further stresses the difficulty of properly (and fairly) comparing optimization methods in deep learning. As is consistently shown in the literature, optimizer performance is typically dominated by hyperparameter tuning, this is particularly problematic when submissions tune their own baselines as authors naturally are incentivized to tweak their own methods until the method looks favorable relative to others. Comparing directly against prior published results tuned by other researchers would help alleviate reviewer concerns regarding hyperparameter tuning.
Below are multiple reviews of a paper. The manuscript proposes a 2-stage transfer learning strategy for the classification of epithelial ovarian cancer subtypes. The approach takes 1024×1024 patches from the whole slide image and downsample the patches to 256×256. The network is then embedded into a Stage-2 network with downsampled 512×512 as initial input. Results showWell described approach for 2-stage deep learning that trains on low and high detail images of the WSI. Reasonably well motivated problem, even if the clinical relevance isn't mentioned.The paper proposed a multi-resolution approach that is using two DL models and shared weights. The proposed approach is interesting. The authors achieved decent results with the Kappa score equal to 0.8.This paper is well written, the methods are appropriate, sufficient detail is provided to enable replication, and the results are presented clearly. This paper could be improved by expanding on the motivation for this work, including information about how ground truth labels were obtained.	All reviewers agree that the paper is strong enough for acceptance. They highlight the interesting methodological developments, the well though-out experiments, and the easy-to-follow description. The results look promising as well.
Below are multiple reviews of a paper. This paper introduces a new VAE model (JMVAE) for multi-modal data. The evaluation is fairly qualitative and it's difficult to understand what we achieving from using JMVAE. One weakness with this work is all the examples are fairly toy problems.The paper proposes a multi-modal VAE with a variational bound derived from chain rule. It is an interesting and important research direction. The experiments are very toyish.This paper proposes an objective, M^2VAE, for multi-modal VAEs, which is supposed to learn a more meaningful latent space representation. The qualitative figures throughout the paper are hard to interpret. If the clarity and quality of the writing could be improved then perhaps the contributions may become more evident.	This paper suggests a problem with the standard ELBO for the multi-modal case, and proposes a new objective to address this problem.  However, I (and some of the reviewers) disagree with the motivation.  First of all, there's no reason one can't train a separate encoder for every combination of modalities available, at least when there are only 2 or 3.  Failing that, one could simple optimize per-example approximate posteriors without using an encoder.  Second, once you stop optimizing the ELBO, you've lost the motivating principle for training VAEs, and must justify your new objective empirically.  Almost all of the results are (in my opinion) ambiguous plots of latent encodings.  Finally, a point made throughout the paper and discussions was that different modalities should give the same encodings, which is plainly false.  One of the reviewers made this point: "The fact that z_a != z_b != z_{a,b} should be expected if a and b provide different information. I don't see the problem with this.", which you dismiss.  Additionally, the encoder's job is to approximate the true posterior.  The true posteriors will in general be different for different modalities.  I would recommend focusing on ways to train the original ELBO in the presence of different modalities, instead of modifying it based on these intuitions.
Below are multiple reviews of a paper. The paper shows that the hyper parameters used to train a model and the corresponding utility can leak information about training (through experimenting with outliers) The proposed method seems solid and the experimental results look promising.This paper provides privacy guarantees for hyperparameter search procedures within the framework of Renyi Differential Privacy. Their results improve and extend the work of Liu and Talwar (STOC 2019)The paper provides an considerable improvement to the DP analysis of hyperparameter tuning of DP algorithms (such as DP-SGD) The analysis is carried out using Rényi differential privacy (RDP), and the DP bounds are RDP bounds that contain the RDP parameters of the underlying mechanisms.The authors provide an algorithm for private hyperparameter tuning. It consists of running a learning algorithm that satisfies Rényi differential privacy (RDP) for a *random* number of times. The authors propose a way to measure the utility of the algorithms by looking at the expected quantile of the output.	This paper tackles a problem at the intersection of AutoML and trustworthiness that has not been studied much before, and provides a first solution, leaving much space for a lot of interesting future research. All reviewers agree that this is a strong paper and clearly recommend acceptance. I recommend acceptance as an oral since the paper opens the door for a lot of interesting follow-ups.
Below are multiple reviews of a paper. The paper proposes an interesting idea where they seek to distinguish between activation channels that are crucial for preserving information flow and approximating the rest with low degree polynomials. While it is a neat modification, I think it is very incremental in its novelty and the performance is not very large either.The main contribution of this paper is a new heuristic for identifying "less useful" activation channels. The authors then propose using simple approximations for activation functions for these channels without compromising network accuracy. The main novelty in the approximation used by the authors is flexibility in the degree of the polynomial approximation.The algorithm also considers various degrees for approximation (0, 2, and 3) Experiments show that this reduces the latency by up to two thirds while maintaining a similar accuracy.This paper proposed a new method called SAFENet. It is able to support a secure, accurate and fast neural network inference service. The best result presented in Table 2, is 3x faster than previous.	The authors did a nice job of responding to the concerns of reviewers during the discussion phase which increased reviewer scores. Because of this I will vote to accept.   The authors should carefully edit the paper for typos, grammatical errors, and style errors. Some examples: - Abstract: Make this one paragraph without a line break - End of 1st paragraph in Intro: "So there is an urge" -> "So there is an urgent" - Start of 3rd paragraph in Intro: "State-of-the-art cryptographic" -> "The state-of-the-art cryptographic" - Last paragraph of 2.1: "To solve above" -> "To solve the above" - End of 2.3: "Compared to the light-weight InstaHide and TextHide, MPC and HE are of advantages in the security guarantees so far." -> "Compared to the light-weight methods InstaHide and TextHide, MPC and HE provide much stronger security guarantees."  I also urge the authors to please double check the reviewer comments when preparing a newer version to ensure all concerns are taken into account.
Below are multiple reviews of a paper. This paper discusses the addition of a regularizer to a standard sparse coding/dictionary learning algorithm. I do not think this work should be accepted to the conference for the following reasons: The authors show no benefit of this scheme except perhaps faster convergence.This paper develops and tests an adaptive homeostatic algorithm for unsupervised visual feature learning. The authors also develop a computationally cheaperversion they call HAP (Homeostasis on Activation Probability) The literature review is quite extensive.The paper is quite well written and contains an extensive literature reviewdemonstrating a good understanding of previous literature in both ML/DL and biological vision. The system learns in an unsupervised way faster.	This paper shows how to obtain more homogeneous activation of atoms in a dictionary. As reviewers point out, the paper is well written and indeed shows that the propose scheme results in a more uniform activation. However, the value of this contribution rests on making a case that uniformity is indeed a desirable outcome per se. As two reviewers explain, this crucial point is left unaddressed, which makes the paper too weak for ICLR.
Below are multiple reviews of a paper. This paper addresses adversarial detection through the absolute-value difference between the two logit vector values of a DNN binary classifier. It uses the Background Check calibration techniques recently proposed by Perello-Nieto et al.The manuscript has a number of shortcomings which in my opinion makes it a strong rejection. The authors should test their approach on Carlini & Wagner's attack which allows for explicit control of logit differences. The two-class classifier setting is very limited.Intuition that multiple sources of uncertainty are relevant to adversarial examples is interesting. The naming convention for the perturbation sizes reads a bit imprecise and is perhaps more confusing than it is informative. No adaptive adversaries are considered. Attack parameters could be better justified.	The reviewers and AC note the potential weaknesses of the paper in various aspects, and decided that the authors need more works to publish.
Below are multiple reviews of a paper. In this paper, the authors propose to use mixture models of policies and present good experimental results. The approach is quite sound, and the experimental results looks solid. However, there are some concerns that make this paper cannot be fully appreciated.The paper focuses on the policy architecture of deep reinforcement learning algorithms. The results indicate that in some tasks, the PMOE policy outperforms the naive policy baseline. Despite these advantages, I cannot recommend acceptance of this paper due to the lack of novelty and significant performance improvement.The paper proposes an end-to-end method to train probabilistic mixture-of-experts policies in RL agents. They show that the approach can be applied in the context of popular on-policy and off-policy algorithms.The paper studies the problem of differentiating through the policy return when the policy is a Gaussian mixture model. The main contribution of the paper is a heuristic approach for computing this gradient. The experiments show that the algorithms with GMMs behave roughly the same as with a single Gaussian save for one (SAC) or two (	The paper studies mixture of expert policies for reinforcement learning agents, focusing on the problem of policy gradient estimation. The paper proposes a new way to compute the gradient, apply it to two reinforcement learning algorithms, PPO and SAC, and demonstrate it in continuous MuJoCo environments, showing results that are comparable to or slightly exceeds unimodal policies. The main issue raised by multiple reviewers is novelty. Mixture of expert models have been widely studied in the context of reinforcement learning, and while the paper proposes a new method for the gradient computation, a more suitable format, as pointed out by Reviewer 2, could be to ground the paper around the proposed gradient estimator, and compare, both analytically and empirically, it to existing alternatives. Therefore, I recommend rejecting this submission.
Below are multiple reviews of a paper. The authors address a challenging and important problem of group feature selection. The uniqueness of their work is that they learn the grouping without any predefined knowledge. Overall the paper is well written, and I enjoyed reading it.The paper is written well, it is very clear and is easy to follow. The incentives which are discussed in the introduction section for solving group feature selection problem are not convincing enough. The experimental part where only 3 datasets (Syn1-Syn4 could be labeled as a single dataset) are used to evaluate the proposed method is not convincingThis paper attempted to detect groups of predictive features without the need for predefined groups. The research review of traditional/standard feature selection methods is not sufficient. Maybe the proposed method should be validated on genomics-related data.This paper proposed a composite feature selection, which aims to find groups of features with combined effects for prediction. Experimental results on synthetic datasets, semi synthetic datasets and MNIST dataset demonstrated the effectiveness of the proposed method.	### Summary of paper This work addresses the problem of grouped feature selection in the supervised learning setting. A new method based on ensemble of features is proposed as well as a new metric to evaluate the results on synthetic, semi-synthetic and real data.   ### Rebuttal Authors were engaged and addressed all the reviewers' concerns and questions.  While reviewers did not engage in the rebuttal discussion nor post-rebuttal discussion, they significantly raised their scores, bringing the average score from 4.75 to 5.75, indicating that their main concerns were addressed.  ### Acceptance There are no major concerns that remain to be addressed and the paper is ready to be published. I hence recommend acceptance of the paper.
Below are multiple reviews of a paper. This paper proposes a new methodology for training models in the presence of label noise. The method is a combination of standard SimCLR and a Mixup-style augmentation. The paper also presents significant improvement of artificially noisy versions of CIFAR-10 and CIFar-100.The paper proposes noise-robust contrastive learning to combat label noise, out-of-distribution input and input corruption simultaneously. It embeds images into low-dimensional representations by training an autoencoder, and regularizes the geometric structure of the representations. The effectiveness of the proposed method has been evaluated on multiple simulated andThe authors of the paper propose to use the contrastive loss, the mixup prototypical loss, and a reconstruction loss to regularize the learned representation. Extensive experiments were conducted to demonstrate the effectiveness of the method. A major complaint I have regarding this submission is the lack of novelty.The authors have conducted a range of experiments to validate the performance of the proposed method. The potential hyperparameter space is relative black-box to understand where is the bottleneck of learning with noisy labels in this method.	This paper proposes a framework to train a discriminative model robust against (i) label noise, (ii) out-of-distribution input, and (iii) input corruption. To tackle these problems, a complex model is proposed that combines several existing models including InfoNCE-style contrastive learning, prototypical contrastive loss, Mixup, and reconstruction loss. Noisy training labels are cleaned using a temporally consistent label smoothing mechanism, combined with a curriculum learning algorithm.   Originally, the reviewers raised concerns regarding the limited ablation experiments and the lack of studies on real-world noisy labels. The additional experiments in the revised version addressed some of these concerns. Thus, the reviewers increased their rating slightly.  However, the reviewers in the discussion phase agree that the proposed method has a limited novelty, is complex, and involves many moving parts that require a careful design and hyperparameter tuning, and they do not recommend accepting the submission. I agree with the reviewers and recommend rejection.
Below are multiple reviews of a paper. This paper extends prior results, namely that VAEs are able to learn the principal components. The novelty is the extension to a new distribution: multinomial logistic-normal distribution. While prior results were derived analytically, this paper provides (only) empirical evidence for the claim.The paper offers a novel solution to the seemingly persistent problem of performing efficient inference of a non-congugate latent variable model for count data. The authors claim that existing solutions are not scalable. The paper is clearly written with a few minor typos.This paper is well written, presenting a great interdisciplinary work on covariance estimation. It relies on recent techniques such as connection between VAE and PPCA, ILR transformation. Such setting has direct application potential in many bioinformatics problems.The authors use the probabilistic PCA framework, extending it to multinomial-distributed data. They show that similar work on PPCA are limited to Gaussian data. Analysis on real-world biomedical data sets are promising.	Authors extend the probabilistic PCA framework to multinomial-distributed data. Scalable estimation of principal components in the model is achieved using a multinomial variational autoencoder in combination with an isometric log-ratio (ILR) transform. The reviewers did not agree on the degree of novelty of the paper to PC estimation. The presentation of the paper can be improved. The reviewers criticise that large changes have been made to the paper during the rebuttal phase. Overall, the paper is borderline and due to the mentioned large changes I recommend a rejection (and re-review at a different venue).
Below are multiple reviews of a paper. A method is proposed, which learns to reason on physical interactions of different objects (solids like cuboids, tetrahedrons etc.) The method involves a planning phase, were different objects are dropped on the scene in the right order, targeting bottom objects first and top objects later.The paper presents a platform for predicting images of objects interacting with each other under the effect of gravitational forces. The proposed platform is also used for planning object placements by sampling a large number of object shapes, orientations and colors. The paper needs to be made much clearer and more precise, and the experimental evaluation should be improved.The paper presents a method that learns to reproduce 'block towers' from a given image. A perception model, a physics engine model, and a rendering engine are first trained together on pairs of images. It outperforms a related pipeline that lacks a scene representation based on objects.	1. Describe the strengths of the paper.  As pointed out by the reviewers and based on your expert opinion.  - The problem is interesting and challenging - The proposed approach is novel and performs well.  2. Describe the weaknesses of the paper. As pointed out by the reviewers and based on your expert opinion. Be sure to indicate which weaknesses are seen as salient for the decision (i.e., potential critical flaws), as opposed to weaknesses that the authors can likely fix in a revision.  - The clarity could be improved  3. Discuss any major points of contention. As raised by the authors or reviewers in the discussion, and how these might have influenced the decision. If the authors provide a rebuttal to a potential reviewer concern, it’s a good idea to acknowledge this and note whether it influenced the final decision or not. This makes sure that author responses are addressed adequately.  Many concerns were clarified during the discussion period. One major concern had been the experimental evaluation. In particular, some reviewers felt that experiments on real images (rather than in simulation) was needed. To strengthen this aspect, the authors added new qualitative and quantitative results on a real-world experiment with a robot arm, under 10 different scenarios, showing good performance on this challenging task. Still, one reviewer was left unconvinced that the experimental evaluation was sufficient.  4. If consensus was reached, say so. Otherwise, explain what the source of reviewer disagreement was and why the decision on the paper aligns with one set of reviewers or another.  Consensus was not reached. The final decision is aligned with the positive reviews as the AC believes that the evaluation was adequate.
Below are multiple reviews of a paper. The paper is structured and written well, with clear articulation of technical details. The experiments and reported results are comprehensive, and clearly showcase the efficacy of the proposed solution. It is unclear as to the assumed structural constraints.The paper proposes a novel approach to generate adversarial examples based on structured sparsity principles. The main downside of the paper is that the proposed idea essentially consists in replacing the standard \ell_p norm penalty/constraints with a group-\ell_ p one.The paper is clearly written and results are convincing. But what I am not sure I understand is what is the purpose of this research. I think the mechanisms of adversarial perturbations remain as unclear as they were before this paper.	This paper contributes a novel approach to evaluating the robustness of DNN based on structured sparsity to exploit the underlying structure of the image and introduces a method to solve it. The proposed approach is well evaluated and the authors answered the main concerns of the reviewers.
Below are multiple reviews of a paper. This paper presents the analysis of 13 zero-cost proxies on 28 tasks, and releases the pre-computed scores of them. The authors also studied a way to combine all zero cost proxies to allow better NAS performance.NAS-Bench-Suite-Zero evaluates 13 zero-cost proxies for architecture performance prediction across 28 tasks. It creates by far the largest dataset enabling orders-of-magnitude faster experiments on ZC proxies.Recent prior work introduced zero-cost proxies (ZC proxies) as a means to predict architecture performance to significantly speed up neural architecture search algorithms. This work introduces a novel benchmark dataset "NAS-Bench-Suite-Zero" to study 13 ZC proxies across 28 tasks.This paper aims to answer the important questions about the performance, generalization, and bias of ZC proxies and their combinations. The search space used in this benchmark is far from the modern search space, such as ResNet and MobileNet. This limits the significance of this work and makes observations in it less guiding to the real-worldThis work replicates some of the typical Zero NAS on multiple NAS benchmarks. It is more appropriate to appear in a new NAS method rather than a new benchmark.This paper creates a NAS benchmark NAS-Bench-Suite-Zero including 13 zero-cost(ZC) proxies, 28 tasks and 1.5 million ZC proxy scores in total. The dataset can be used to speed up ZCproxy-based NAS experiments.	This paper presents a systematic review of zero-cost proxies for neural architecture search. By design, these proxies are cheap and easy-to-evaluate but results reported in the literature have been mixed. In this light, a benchmark seems relevant and important for further progress in this area. The reviewers uniformly appreciated the extent of tasks and proxies considered. Moreover, the reviewers also appreciated efforts made to explore the complementary strengths of these proxies. There were some concerns related to the search space and metrics used, but those were addressed by the authors during the rebuttal period. Finally, the availability of open-sourced and well-documented code is a plus that was appreciated by everybody.
Below are multiple reviews of a paper. The authors present a distributed protocol for the column subset selection problem. The main contribution consists of a protocol that requires $O(sdk)$ communication. The polynomial running time guarantee makes the practicality of the proposed algorithm marginal.Proposed distributed algorithm guarantee an $\tilde O(k^{1/p-1/2} )$-approximation to the best subset of columns. It is observed that proposed method performs better than SVD on both synthetic dataset and some real world dataset.The paper considers the column subset selection (CSS) problem, which has received considerable attention in numerical linear algebra. Despite the attention this problem has received previously, it seems like this is a new setting that has not been considered before. The paper primarily provides theoretical results, but also does some experiments.	Clarity: Well written paper with a clear contribution statement; related work is up-to-date; concise algorithm description and corresponding theoretical guarantees. However, the presentation could be still improved.  Significance: The polynomial running time guarantee makes the practicality of the proposed algorithm marginal. Experimental results do not back up strongly the significance of the algorithm.  Main pros: - Solid theoretical work on the distributed CSSP problem.  Main cons: - The reviewers point out the significance of the experimental results, beyond the theoretical contribution. For the ICLR audience, real, large-scale experiments, that really dictate that the proposed solutions is (if not the only) one of the few solutions to follow, are necessary. The reviewers highlight that the theoretical results need to be applied to really large-scale scenarios (e.g., the problems considered in the paper can definitely be handled by a single computer, and no distributed implementation is required).  - Τhe polynomial time complexity of the method makes the proposed protocol hard to be useful in real applications. - How does the distributed protocol compares with a centralized one? This is not fully addressed in the rebuttal.
Below are multiple reviews of a paper. The paper proposes a mixture model formulation of NMT. The assumptions behind the proposed approach are not justifiable. Some of the claims are simply not appropriate.The authors aim to increase diversity in machine translation using a multinomial latent variable that captures uncertainty in the target sentence. The proposed approach (hard-MoE) is well motivated and the experimental results are relatively promising. The authors did a good job analyzing and justifying their approach against the soft version of their model.This paper studies the diverse text generation problem, specifically on machine translation problem. The authors use a simple method, which just using a single multinomial latent variable. They use parallel greedy decoding to generate the diverse translations. experiments on three WMT datasets show the approach make a trade-off between diversity and quality.This paper proposes a sequence to sequence model augmented with a multinomial latent variable. This variable can be used to generate multiple candidate translations during decoding. This approach is simpler than previous work using continuous latent variables or modifying beam search.	+ a simple method + producing diverse translation is an important problem   - technical contribution is limited / work is incremental - R1 finds writing not precise and claims not supported,  also discussion of related work is considered weak by R3 - claims of modeling uncertainty are not well supported   There is no consensus among reviewers.  R4 provides detailed arguments why (at the very least) certain aspects of presentations are misleading (e.g., claiming that a uniform prior promotes diversity). R1 is also negative, his main concerns are limited contribution and he also questions the task (from their perspective  producing diverse translation is not a valid task; I would disagree with this).  R2 likes the paper and believes it is interesting, simple to use and the paper should be accepted. R3 is more lukewarm.
Below are multiple reviews of a paper. This paper looks at the secure release of network data with deep generative models. The paper develops two models, DPGVAE and DPGGan, which can be viewed as a combination of DP-SGD and graph generation techniques.The techniques involve recent advances in graph generation networks and DP deep learning. The network structure is based on recently proposed Graph VAE and VAEGAN. DPSGD is used during the training process to ensure the privacy guarantee.This paper proposes a method, Differentially Private Graph Generative Nets (DPGGAN), to release graph in way the preserves utility while preserving privacy. This method trains a deep graph generation model in a differentially private manner. While the paper claims to offer robust privacy guarantees towards various graph attacks, such guarantees are not explicitly spelled out.This work consider the problem of link privacy when releasing models that are trained on graph data. It achieves this by making a generative graph model based on a VAE differentially private. Differential privacy is obtained by adding noise to gradients during training (DPSGD approach)	This paper studies synthetic data generation for graphs under the constraint of edge differential privacy. There were a number of concerns/topics of discussions, which we consider separately: 1. Theoretical contributions. There are not that many theoretical contributions in this paper. I think this is OK, if the other components are compelling enough. On the theory, the authors mention that accounting for the constants is important in the analysis of DPSGD. On the contrary, I would say that these constants are not very important: if one requires specific constants, numerical procedures can determine values, otherwise for the sake of theory, no one generally needs these constant factors.  2. Empirical/experimental contributions. This was the primary axis for evaluation for this paper. None of the authors were especially compelled by the results. The methods are essentially combinations of known tools from the literature, and it is not clear why these are the right ones to solve this problem in particular. If the results were very exciting, that might be sufficient to warrant acceptance, but it is still not clear how significant the cost of privacy is in this setting. The experiments are not thorough enough to give serious insight here. It is a significant oversight to not provide results on DPGGAN without the privacy constraint, as this is the best performing model with privacy. The omission of something as important as this (and lack of inclusion in the response, with only a promise to include later) is indication that the experiments are not sufficiently mature to warrant publication at this time. The decision of rejection is primarily based on concerns related to the empirical and experimental contributions.  3. Privacy versus link reconstruction. Reviewer 4 had concerns about the notion of privacy, claiming that it does not correspond to the probability of a link being irrecoverable. This is differential privacy "working as intended", which is not intended to make each link be irrecoverable: it is simply to make sure the answer would be similar whether or not the edge were actually present, so it may be possible to predict the presence of an edge even if we are differentially private with respect to it (e.g., the presence of many other short paths between two nodes are likely to imply presence of an edge). Some discussion of this apparent contradiction might be warranted, as this might mislead reader who are specifically trying to prevent edge recovery. It might also be worthwhile to have discussion of node DP in the final paper. The authors comment "we focus on edge privacy because it is essential for the protection of object interactions unique for network data compared with other types of data" -- the stronger notion of node differential privacy might also be applicable here. It would indeed be interesting to know whether it can preserve the relevant statistics (some of which seem more "global" and thus preservable via node DP).
Below are multiple reviews of a paper. In this paper the authors propose a new approach to train deep energy-based models (EBMs) EBMs are typically trained via contrastive divergence which requires MCMC sampling in a high-dimensional space and from a mutli-modal distribution. This results in a biased estimation of MLE. To address this problem, the authorsThis paper studies the learning of a special class of EBMs, which is a correction or an exponential tilting of a flow-based model. The authors raise good questions, which are validated by empirical evaluations. The idea of learning EBMs by NCE has also appeared in Wang&Ou (2018)This paper proposes a product of EBM and FLOW and samples in latent space to improve mixing. Such a model can be learned using both MLE or NCE. The paper is clear and easy to understanding, but there are some questions to be addressed.The authors propose to learn energy-based models with a flow-based model as "backbone" This is to utilize Neural Transport and ultimately make the Markov Chains mix well in data space. This is an important problem. Do the authors feel that mixing is more important than good synthesis?	The authors set up a simple combination of an energy based model and a flow based model that corrects the flow based model with an energy based term. The merits of this relative only an energy based model is improved sampling to compute the gradient. The advantage over a only flow based model is that the kinds of transforms that can be used are less limited.
Below are multiple reviews of a paper. The paper performs a theoretical analysis on one kind of noisy label learning method. The paper also presents an empirical analysis. The empirical analysis could be improved (see below)This paper studies how self-supervised pre-training impacts the resistance of the neural network to noisy labels. While the theoretical claims look solid, the important, more general settings outside of symmetric synthetic noise are missing. I vote to reject the paper in its current form.The authors illustrate theoretically why learning good representation can help learning with noisy labels. The authors motivate a regularizer between the SL and SSL. The paper is marginally below the acceptance threshold.This paper studies the usefulness of self-supervised features when encountering data with noisy labels. It presents an array of ideas on this topic, including the question of fine-tuning pre-trained representations.	This paper presents an analysis of the robustness of self-supervised learning (SSL) features to noisy labels in downstream supervised learning, and provides empirical verification of the results (mostly in the symmetric noise setup); a SSL regularization scheme is also analyzed (section 4). While the paper contains plausible insights, the reviews share similar concerns that the analysis is mainly based on the noise being symmetric, and that the SSL features already have good class separation and Gaussian clusters, which are strong assumptions. Given that the assumptions are not theoretically verified, and that there is not sufficient empirical results in heavy non-symmetric noise scenario on large benchmark datasets, the reviewers think the paper does not provide practical guidance for noise label learning in its current form.
Below are multiple reviews of a paper. The authors propose a new explanation type called subgoal-based explanations in the setting of sub-optimal and non-robust Intelligent Decision Support Systems. The aim of the explanation type is to serve as a training benefit for users to determine when to trust that a recommended action is optimal.The paper suggests explaining planning decisions by indicating the sub-goal that the action aims to satisfy. An interesting avenue for future work would be to explore sub-goals at different granularity levels.	The paper proposes a novel approach for generating explanations for sub-optimal IDS systems.   Both reviewers agree that that the methods described are technically sound and the paper is in a fairly mature stage. It would be a valuable addition to the workshop. As you move forward, we suggest you take into account the reviewers’ comments, especially those of reviewer 1 as they highlight some interesting points.  Thank you for submitting to the workshop. We are looking forward to your presentation.
Below are multiple reviews of a paper. This paper applies the idea of distributional robustness for crafting adversarial examples. The methodology in the paper extends that of (Sinha et. al. 2017) by introducing learnable parameters. A soft-ball based projected gradient descent is used instead of a hard one.This paper aims to establish a formal relation between Wasserstein distributionally robust optimization (W-DRO) and a number of Adversarial Training (AT)-like defenses against adversarial attacks. The relation between point-wise adversaries which are commonly used in AT-like methods is already known to the community.This paper proposes a unified framework for adversarial training from the perspective of Wasserstein distributional robustness. Empirical results demonstrate that the proposed method is more effective than previous methods. The paper is overall well-written and interesting to read.The paper proposes a new approach for improving adversarial training (AT) in deep neural networks (DNN) It extends previous work on Wasserstein distributional robustness (WDR) and suggests a unified WDR framework to encompass previous approaches and to improve AT. The theoretical results show that previous approaches can indeed be formulated in theWasserstein cost function can cover those of commonly used AT methods as special cases. A family of algorithms are developed to generalize AT methods with better generalization. Extensive experiments show the improvement of the proposed robustness AT algorithms over those commonly used ones.	The paper extends the previously established connection between adversarial training (AT) and Wasserstein distributional robustness (WDR) to other adversarial defense methods such as PGD-AT, TRADES and MART, and connects them to WDR. While this connection itself is not surprising given earlier works connecting AT and WDR, the paper makes contributions in establishing it formally and proposing algorithmic variations (eg, softball projection) that show clear empirical gains on standard benchmarks of MNIST/CIFAR10/CIFAR100 over point-wise adversarial defense methods.
Below are multiple reviews of a paper. This paper explores extreme parameter compression for pre-trained language model, especially BERT. It introduces and compares several tensor decomposition methods and proposes to leverage Tucker decomposition as the final solution. The motivation is clear and the methods are technically sound. Though there exist some weaknesses, I think the paper is of good quality.This paper proposes to use tensor decomposition to jointly compress the model weights in all attention and FFN layers of a Transformer model. It reaches similar performance as the original BERT model while marking the model much smaller.This paper proposes to use tensor decomposition to compress the multi-head attention (MHA) and FFN layers in transformer architecture. The results of compression are strong. Possibility of 50x compression, albeit at 1.5-2% accuracy loss opens a lot of possibilities for on device deployment.This paper proposes an approach to compressing the Transformer family of pretrained language models via tensor decomposition. The approach, when combined with distillation, outperforms existing methods for compressing BERT models on the popular GLUE benchmark.	This paper reviews a number of parameter decomposition methods for BERT style contextual embedding models. The authors argue for the application of Tucker decomposition to the attention and feedforward layers of such models. Evaluation is performed for a range of models on the GLUE benchmark. Further ablation studies indicate that the distillation procedure employed is crucial for obtaining competitive results and the raw decomposition approaches are ineffective at directly approximating the original pre-trained model.  Strengths: The reviewers generally agree that the methods explored and results presented in this paper are interesting and could be of use to those deploying large embedding models. The authors review a range of possible decomposition methods and use this to motivate their approach. The resulting levels compression are high while maintaining good performance, while the ablation study clearly shows the contribution of the various steps of the training pipeline.  Weaknesses: The main weakness identified by the reviewers is the incremental nature of this work in comparison to previous works applying various decomposition and compression techniques to neural networks. They also highlight that many of the techniques discussed early in the paper are not compared in the evaluation. The authors have effectively responded to this issue by providing further comparisons and justification for their modelling choices (e.g. not compressing the embedding layers).   Overall, despite the incremental nature of this work, I believe that there are enough though provoking ideas and results presented to warrant publication. Interestingly, as the authors emphasise in their response, the ablation study highlights that this work is not really about approximating the original models weights, as all of the work appears to be being done by the distillation procedure in concert with the choice weight decomposition. In general I wonder whether this paper would be better presented as exploring a structured distillation procedure rather than weight compression.
Below are multiple reviews of a paper. The initiative is novel and interesting. The proposed model is rather ad-hoc for two reasons. The mysterious design of (3.1) makes no physical sense to me, or at least other designs used in previous cost-sensitive neural network models.A cost-sensitive robust optimization formulation is then proposed for deep adversarial learning. Experimental results on two benchmark datasets (MNIST, CIFAR-10) are reported to show superiority of the proposed method to overall robustness method.Review score incremented following discussion below. Strengths: Well written and clear paper. Weaknesses: Cost matrices choices feel a bit arbitrary in experiments. CIFAR experiments still use very small norm-balls.	This paper studies the notion of certified cost-sensitive robustness against adversarial examples, by building from the recent [Wong & Koller'18]. Its main contribution is to adapt the robust classification objective to a 'cost-sensitive' objective, that weights labelling errors according to their potential damage.  This paper received mixed reviews, with a clear champion and two skeptical reviewers. On the one hand, they all highlighted the clarity of the presentation and the relevance of the topic as strengths; on the other hand, they noted the relatively little novelty of the paper relative [W & K'18]. Reviewers also acknowledged the diligence of authors during the response phase. The AC mostly agrees with these assessments, and taking them all into consideration, he/she concludes that the potential practical benefits of cost-sensitive certified robustness outweight the limited scientific novelty. Therefore, he recommends acceptance as a poster.
Below are multiple reviews of a paper. NeurWIN uses a neural network architecture to learn the Whittle indices. The learning behavior of NeurWIN is very good in all tested cases. The paper is a bit sloppy and not very precise.The paper proves a simple but important result which essentially states the following: It is possible to construct an RL environment for a one arm restless bandit system, such that any neural network which achieves a certain discounted net reward has to approximate the whittle index of that arm.The paper "NeurWIN: Neural Whittle Index Network for Restless Bandits via Deep RL" proposes a new RL approach for estimating the Whittle index in restless bandit problems. The approach is elegant and looks useful from the results.This paper proposes the use of Deep Learning, namely a multi-layer perceptron, for approximating the Whittle index in restless bandits. There are a lot of issues in the presentation of the proposed algorithm, NeurWin.	This paper approximates the Whittle index in restless bandits using a neural network. Finding the Whittle index is a difficult problem and all reviewers agreed on this. Nevertheless, the scores of this paper are split between 2x 4 and 2x 7, essentially along the line of whether this paper is too preliminary to be accepted. Therefore, I read the paper and propose a rejection.  The reason is that the paper lacks rigor, which was brought up by the two reviewers who suggested rejections. For instance, in the last line of Algorithm 1, it is not clear what kind of a gradient is computed. The reason is that \bar{G}_b is not a proper baseline, as it depends on the future actions of the bandit policy in any given round. I suggest that the authors look at recent papers on meta-learning of bandit policies by policy gradients,  https://papers.nips.cc/paper/2020/hash/171ae1bbb81475eb96287dd78565b38b-Abstract.html  https://arxiv.org/abs/2006.16507  This is the level of rigor that I would expect from this paper, to make sure that the gradients are correct.
Below are multiple reviews of a paper. The paper does not attempt to convert all possible sounds, but it tries to convert a single speaker's monaural speech signal to binaural audio where the speaker is moving. I think this inherent assumption is important since the method will probably not work for multiple overlapping audio sources.This paper proposes to impose monotonicity and causality to the learned warping function, which incorporates the physics of sound propagation. The proposed end2end model significantly outperforms previous SOTA in terms of objective measures and subject tests.This paper presents a neural network-based model to generate binaural audio given a single-channel audio and positions of source/listener & their angles. Technical details and model architecture are available in the body of the paper.	+ Interesting method for binaural synthesis from moving mono-audio + Nice insight into why l2 isn't the best loss for binaural reconstructions.  + Interesting architectural choice with nice results. + Nicely motivated and clearly presented idea -- especially after addressing the reviewers comments.  I agree with the idea of a title change. While I think its implied that the source is probably single source, making it explicit would make it clearer for those not working in a closely related topic. Hence, "Neural Synthesis of Binaural Speech from Mono Audio" as suggested in the review process sounds quite reasonable.
Below are multiple reviews of a paper. One iteration of Optimistic-AMSGrad is more expensive than one iteration of AMSGrad since it requires to compute m_{t+1}. The authors should explain to what extend this computation is significantly cheaper that a backprop.The authors borrow the idea of "optimism" from the online learning literature and apply it to two frequently used methods for neural network training. The manuscript ends with a comparison of the optimistic methods against their plain counterparts on a set of test problems.The paper proposes new online optimization algorithms by adding the idea of optimistic updates to the already popular components of adaptive preconditioning and momentum. Such optimistic schemes attempt to guess the yet-unseen gradients before each update, which can lead to better regret guarantees when the guesses are accurate.This paper combines recent results in online learning and convex optimization, specifically adaptivity, momentum, and optimism. The authors add an optimistic gradient prediction step into the AMSGrad algorithm proposed by Reddi et al, 2018. The paper is relatively well-written, and the algorithm is also presented clearly.	The reviewers expressed some interest in this paper, but overall were lukewarm about its contributions. R4 raises a fundamental issue with the presentation of the analysis (see the D_infty assumption). The AC thus goes for a "revise and resubmit".
Below are multiple reviews of a paper. The authors build a generator that builds on top of the latent space of a “well-trained auto-encoder” The method consists of a novel combination between an existing generative model and an existing kernel transfer operator. The authors compare their model to several state-of-the-art generative models and show some resultsThe method appears to work, which in itself is very interesting as this means one should be able to construct generative models (a la VAEs) starting only from a simple autoencoder. The results aren't that impressive compared to the baselines compared, but surprisingly they don't compare to any flow-based algorithms, suchThe paper proposes a different kind of generative model that is composed of autoencoder in the bottom, and a standard distribution p(z), and a conditional kernel mean embedding. The distribution of the latent codes p(l) is modeled by the kernel sum rule that corresponds to the marginalization.This paper proposes a method for a deep generative model. It uses a trained autoencoder in conjunction with kernel conditional embeddings. The authors validate their model experimentally on CelebA and a brain imaging dataset.	All four reviewers were against accepting the paper. A major point shared by everyone was lack of clarity: this included its overall writing, its discussion toward prior work, and imprecise math to explain the ideas. The paper did improve quite a bit over its revisions. Whether this clarified all of the reviewers' understanding of the paper remains unclear. The work may ultimately need another cycle of reviews to assess its quality.  Another shared point are a number of recommended ablations in the experiments, as well as going through more comprehensively in the set of studied datasets (R3), effect of AE choices (R2), and alternatives to the geodesic (R1, R2).
Below are multiple reviews of a paper. The authors describe a method where a deep learning framework can be quantised. This is done by considering the two state form of a Bloch sphere/qubit and mapping binary neural network. onto the quantum object. I have a few concerns/ nitpicking issues I would like the authors to address.The paper proposes a new algorithm "quantum amplitude amplification" for training and model selection in binary neural networks. The paper observes quadratic speedups with respect to a brute force search.This paper proposes a novel idea of outputting a quantum state that represents a complete cost landscape of all parameters for a given binary neural network. And then the landscape state is utilized to training the neural network by using the standard quantum amplitude amplification method. Although this idea is interesting, I trend to reject this submission as I think its presentation is	This paper studies the problem of training binary neural networks using quantum amplitude amplification method. Reviewers agree that the problem considered is novel and interesting. However the consensus is that there are only few experiments in the current paper and the paper needs more experiments on different datasets with comparisons to proper baselines. Reviewers opined that the paper was not so easy to follow initially,  though later revisions may have somewhat alleviated this problem.
Below are multiple reviews of a paper. This submission contributes an approach to handle missing values in Neural networks. It replaces inside the architecture the missing values by placeholders which cancel the role of the feature in the architecture. The approach is benchmarked empirically, but does not appear to outperform mean imputation.Missing values are replaced by a data-specific numerical representation that is learned at the same time as the rest of the network. The handling of the missing values is located in the neurons of the first layer and each missing value is "replaced" by a neuron-specific neutralizer.In this paper, the authors propose a method titled PROMISSING. This provides a new approach to handling missing data. The approach is interesting, and the experiments and data analyses are a good start at understanding the method.The paper provides a novel method of handling missing values in neural network architectures. The author(s) tested the method on simulated data as well as real data on a group of classification and regression tasks.The paper tackles the problem of missing data by proposing the replacement of the input to the k-th hidden neuron in the first hidden layer from the j-th input as in eq 2. The paper does not do a good job of correctly reviewing the literature on missing data.	The paper presents a simple and intuitive method to prune the missing value in the learning and inference steps of the neural networks, leading to similar prediction performance as other methods to impute missing value. It has some really useful insights, but could benefit from one more round of revision for a strong publication:  1. improving the writing so that its sets up the right expectations on the contributions of the paper;  2. providing discussions on its connections (and differences) with zero-imputation and missing-indicator methods;  3. thoroughly investigating the experiment results to illustrate the advantages of the proposed method.    The recommendation of reject is made based on the technical aspect of the paper. ----------------------------- During the rebuttal phase, the authors misused the interactive and transparent (for the better or worse) openreview system by writing inappropriate comments with personal accusations to the reviewers who write negative reviews. We would like to extend the apologies to the reviewers for this unpleasant experience and thank the reviewers for their engagement and work, as well as their fair assessment of the paper.
Below are multiple reviews of a paper. The paper proposes a variant of BNN with stochasticity added to the activation layer (auNN) It's proposed to solve the underestimation of uncertainty for instances located in-between two clusters of training points. It indicates that auNN is better than DGP by requiring less inducing points and better suited for deep architectures.This work is heavily built on the DGP work with help from the reparameterization trick. It would also have been stronger if more baselines are included to make a more convincing case.The authors capture uncertainty in deep networks by employing stochastic activation functions but deterministic network weights. They place a Gaussian process (GP) prior over activation functions and propose a customized GP kernel.This paper is well-motivated, clear-to-read, novel, and interesting. The mathematical reasoning is sound and the Figures are of excellent quality. While the work compares extensively against deep GPs, a broader set of comparisons would improve the paper.	This paper presents  a new approach to model uncertainty in DNNs, based on deterministic weights and simple stochastic non-linearities, where the stochasticity is encoded via a GP prior with a triangular kernel inspired by ReLu. The empirical results are promising. The comments were properly addressed. Overall, a good paper.
Below are multiple reviews of a paper. The authors propose Code Editing that control bitrate of neural image compression with semi-amortized inference. The new part of method has not seem to be clearly explained. It would be great if you could clarify what is new when compared to these previous studies.The paper investigates obtaining flexible-rate neural image compression methods by adapting representations during encoding. They obtain a new representation y' by adapting the quantization width as well as the latent values themselves.This paper proposes a method called "Code Editing" for rate control, which is an optimization of the latents at encode time. This has commonly been used in the past to boost rate distortion performance, but not as a continuous rate control mechanism. The empirical results of naive code editing only being successful in a narrow rate range.	Thanks for your submission to NeurIPS.  The reviewers are all in agreement that the paper is ready for publication.  They in particular appreciated your rebuttals and changes to the paper, and increased their scores as a result.  The proposed method is novel, interesting, and performs well.
Below are multiple reviews of a paper. The paper studies the problem of learning symmetry from sequential data with a certain stationarity property. It is shown that doing so can tease out the disentangled structure by simultaneous block-diagonalization. Experiments on Sequential MNIST, 3D Shapes, and SmallNORB show the efficacy of the proposed method.This paper proposes to discover structural properties of the data by solving a sequential prediction tasks. The idea is that solving the prediction tasks produces equivariant models, which by guarantees from representation theory, means that the learned representations are simultaneously block-diagonalized.The authors of this paper investigate the time series models with certain stationary properties. By applying these operators to the initial time step, they show that they could predict the future sequence for a few number of time steps.	While there was a certain lack of enthusiasm in the scores of the reviewers, the author's answers cleared the concerns of the reviewers participating in the discussion and overall the recommendation leans towards acceptance. This paper is, in the reviewers' opinions, sound and adds to the literature on unsupervised learning of symmetry. The formulation (of learning symmetry by only modelling linear transitions) is nicely simple. Experiments and evaluations generally were considered of adequate quality.
Below are multiple reviews of a paper. The paper proposes a A-Cycle approach to learn a latent representation for human-robot video correspondence. The proposed methods in the paper achieves comparable performance to the state-of-the-art method.The authors introduce an approach for meta-imitation learning that aims to traslate human videos to robot demonstrations from a single video demonstration. The correspondence between human and robot is learned end-to-end exploiting a generative architectures.This paper studies the problem of meta imitation learning of robot control policies from only video demonstrations of humans performing the tasks. The goal is to make data collection simpler by not requiring robot demonstrations which can be expensive to acquire.This paper studies the meta-imitation learning from human videos problem. It aims to learn a new task by watching a few demonstrations of a human performing the task. The approach proposed in this paper translates human videos into the robot domain with a CycleGAN.	This is an interesting paper working on the difficult problem of learning from video demonstration. The authors provided convincing experimental solutions for visual representation, domain adaptation, and imitation. It would be a nice ICLR paper.
Below are multiple reviews of a paper. This paper shows that a sentence selection / evidence scoring model for QA trained on SQuAD helps forQA datasets where such explicit per-evidence annotation is not available. The paper is mostly well-written, and suggested models are sensible.The proposed base open-domain QA method (+DISTANT) itself improves a lot, which I think is the major contribution of the paper. The proposed semantic labeler training strategies only improve significantly on TriviaQA. The improvement on Quasar-T and SearchQA is relatively marginal.This paper aims for open-domain question answering with distant supervision. First, the authors proposed an aggregation-based openQA model with sentence discriminator and sentence reader. Second, they use a semantic labeler to handle distant supervision problem by utilizing other span supervision tasks. They run experiments on 3 open- domain QA datasets and achieve	This paper presents a model for question answering, where the idea is to have a collaborative model that aligns queries and sentences on a small supervised dataset and also uses semi-supervised information from a weakly supervised corpus to answer open domain questions resulting in short answer spans.  The main criticism of the paper is regarding its novelty, and reviewers cite the similarities with prior work such as Chen et al. and Min et al.  There is relative consensus between the reviewers that further work using the semi-supervised outlook with stronger results could strengthen the paper further.
Below are multiple reviews of a paper. This paper develops a method for neural network pruning using simulated annealing. In the proposed method, the mask matrix indicating the pruning location is optimized by simulated annaling. The method is evaluated on pruning tasks of fully connected neural networks in image classification.Simulation annealing (SA) algorithm to prune neural network by randomly dropping and adding links according to SA's acceptance-rejection criteria. Experiment results shows the algorithm is useful in reducing number of weights while maintain model accuracy.This paper explores the application of simulated annealing to network pruning. Two variations of the algorithm are proposed, one where the target percentage of connections is removed in one-shot, the other where the process is gradual.This paper presents a novel simulated annealing method for pruning neural networks. Both one-shot pruning and gradual pruning strategies are discussed in this study. Experiments are conducted based on a simple neural network structure with only two hidden layers.	This paper presents the use of Simulated Annealing (SA) for pruning and optimizing the architecture of a neural network. After reviewing the paper and taking into consideration of the reviewing process, here are my comments: - The contribution of the paper and the novelty is limited and not well presented - The related work is very sparse. It requires a major improvement. - The main concern is about the simplistic experiments and the lack of comparison between the results of the proposal and the SOTA methods. - Conclusions are not well supported by the results. From the above, the paper does not fulfill the standards of the ICLR.
Below are multiple reviews of a paper. The paper presents a backdoor benchmarking framework. It includes several basic and current attacks and defenses. The work is an excellent contribution toward trustworthy machine learning.The paper presents a benchmark and software system to evaluate poison attacks and defenses. The proposed code base is well-documented and comprehensive. The main weakness of this paper is the existence of many prior works on backdoor frameworks, specifically TrojanZoo.This paper proposes a comprehensive backdoor benchmark of backdoor learning. It consists of 8 state-of-the-art backdoor attacks and 9 backdoor defenses. Overall, this paper offers a very easy-to-use backdoor benchmark.This paper provides a Benchmark on Computer Vision Backdoor Learning. It contains 8 attack methods, 9 defense methods with 4 datasets, as well as the detailed results.The paper tackles a relatively new and important subfield of research, attacking/defending backdoor attacks in deep neural networks. The main contribution of the paper is a codebase that implements the latest attack, defense, and evaluation methods related to backdoor attacks.	This is a valuable benchmark on backdoors. Most reviewers argue for acceptance, some strongly so (with scores 7,7,8,9), while only one reviewer gave a rejecting score. That reviewer mostly questioned the relationship to TrojanZoo, and the authors discussed this comprehensively now. That reviewer, RPfC, also was inactive during the rebuttal and decision process, and thus I do not weigh their (apparently answered) concerns highly. I thus recommend acceptance.
Below are multiple reviews of a paper. This paper proposes a FX (fixed point) framework to calculate the reduced bit numbers, which can (I) use float numbers with the reduced bits to represent each NN layer's weight values. Criteria 1 generalizes the idea from Sakr et al. 2017, to force the contributions of weight and activation almost at the same orderThis papers introduces a quantization scheme for the back-propagation algorithm to reduce the bit size in the target neural networks. While the paper introduces one way to bring the quantization inside the training procedure, the paper is poorly written.The proposed framework can quantize the neural network obtaining a minimal or close-to-minimal error for a pre-specified precision level. Experimental results on CIFAR have shown that the proposed quantization framework had reduced the representational cost, computational cost, and the communication.	The paper investigates a detailed analysis of reduced precision training for a feedforward network, that accounts for both the forward and backward passes in detail.  It is shown that precision can be greatly reduced throughout the network computations while largely preserving training quality.  The analysis is thorough and carefully executed.  The technical presentation, including the motivation for some of the specific choices should be made clearer.  Also, the requirement that the network first be trained to convergence at full 32 bit precision is a significant limitation of the proposed approach (a weakness that is shared with other work in this area).  It would be highly desirable to find ways to bypass or at least mitigate this requirement, which would provide a real breakthrough rather than merely a solid improvement over competing work.  The reviewer disagreement revolves primarily around the clarity of the main technical exposition: there appears to be consensus that the paper is sound and provides a serious contribution to this area.  Although the persistent reviewer disagreement left this paper rated at the borderline, I am recommending acceptance, with the understanding that the authors will not disregard the dissenting review and strive to further improve the clarity of the presentation.
Below are multiple reviews of a paper. The paper presents a new way of molecular optimization that is based on chemical fragments. The authors employ VQ-VAE to encode a fragment library in a coherent latent space. They argue that this method produces more diverse rationales than a Gaussian VAE.This paper proposes a new reinforcement learning method for molecular optimization. They train VQ-VAE to learn the vocabulary of molecular fragments. The optimizer consisted of general reinforcement learning and MPNN.This paper proposes to perform molecular optimization by sequential translation. A reinforcement learning policy is employed to increase the diversity of the generated molecules. Combing variational auto-encoders and RL policy for fragment-based molecular optimization gives a good practical performance.The present paper aims to discover novel molecules with desirable properties. One of the main contributions is to compose a molecule fragment-by-fragment, where each fragment is drawn not from a fixed fragment dictionary but from a NN-based pre-trained fragment generator. The proposed method is evaluated by ligand generation tasks.	Reviewers agree that the paper is well-motivated and the proposed method is somewhat interesting and well-experimented. However, reviewers feel that the paper relies on many existing methods and does not appear to be novel enough.
Below are multiple reviews of a paper. The motivation behind Equation 3 is not clear at all. It seems that the choice of different configurations is mini-batch dependent and not task dependent. The algorithm works in practice and outperform multiple suggested baselines.The paper proposes a method for selective weight sharing per layer during continual learning. The authors adopt a layerwise transfer configuration vector which decides activated layer-sharing at specific tasks.This paper studies the problem of lifelong learning of a sequence of tasks by selectively transferring knowledge of some layers across tasks. The proposed approach, LASEM, uses EM to dynamically adjust transfer configuration between tasks.The paper is really well executed. Easy to follow, enough of background and motivation is provided. The algorithm for the most part is clear and intuitive. My main complaint is that it is somewhat thin on the experiments.	The reviewers enjoyed reading about an interesting take on lifelong learning, encapsulating an EM methodology for selecting a transfer configuration and then optimizing the parameters. R3 made valid concerns regarding comparison with previous, recent work. R2 also would prefer to see more thorough experiments (ideally in settings where multiple tasks exist, as also commented by R4). During the rebuttal phase the authors made a good effort to run additional experiments which cover the related work aspect better. These experiments and the overall paper were discussed extensively among reviewers after the rebuttal phase.  In the discussions, the reviewers agreed that an interesting idea can be publishable even if it does not achieve SOTA results in all scenarios, as long as it brings new perspectives and shows at least comparable results. However, in the particular case of this paper, there exist remaining concerns regarding the usefulness and applicability of the method. Specifically, the paper could benefit from a more convincing demonstration about how the method can scale (e.g. R3 and R4’s comments), especially since training time and model capacity are important factors to consider for practical continual learning scenarios. Furthermore, it is not clear how the proposed method can be used in combination with other machine learning tools within a continual learning application, for example by leveraging modern deep architectures or by complementing existing adaptive knowledge approaches (as discussed by R3).   Although the opinions of the reviewers are not fully aligned, this borderline paper seemed to lack an enthusiastic endorsement by a reviewer to compensate for the concerns discussed above and the relatively weak experimental results. Therefore I recommend rejection.
Below are multiple reviews of a paper. The paper studies why and when averaging the weights of a model improve out-of-domain generalization by way of a new a bias-variance-covariance-locality decomposition. They show how diversity is needed and thus propose Diverse Weight Averaging (DiWA)In this paper, the authors proposed a simple method to improve the out-of-domain generalization. Some theoretical analysis is also given for explaining weight averaging. Experiments on the DomainBed benchmark show the performance of the proposed method.DiWA is simple and effective, and the experiments show that it can be combined with previous advances. To my knowledge, this work has no potential negative societal impact other than what was already present in the existing literature.The authors propose an approach to mitigating the generalization problem in computer vision. Their proposed method of averaging diverse sets of weights leads to improved results on the DomainBed benchmark suite of datasets.	The reviewers unanimously recommend accepting the paper - congratulations!  My only concern is in the related work: The submission mentions  > The recent “Model soups” by Wortsman et al. [28] developed a WA algorithm similar to Algorithm 1. However the task, the theoretical analysis and most importantly the goals of these two works are different.  This is not an accurate characterization because Wortsman et al. [28] were also interested in out-of-distribution generalization - their paper mentions "robustness" and "distribution shift" several times and contains results on multiple OOD test sets. The results in this submission and in Wortsman et al. [28] reinforce each other since the two papers evaluate on different OOD benchmarks and find that weight averaging helps in both. I encourage the authors to clarify this in their related work section so that the reader can correctly put the results in context.
Below are multiple reviews of a paper. In this paper, the authors propose a new benchmark for reinforcement learning based on a popular game — Minecraft. It includes thousands of tasks with unified observation and action spaces, and a large knowledge base.MineDojo includes an extended API for Minecraft, multiple datasets, and a demonstration of one successful path to leverage these components. It provides multiple significant contributions towards the goal of training an agent which can solve a general set of goals in an open-world environment.This work introduces a multi-task open-ended environment in Minecraft accompanied by a large-scale knowledge base to facilitate building generalizable agents. The task suite goes beyond previous Minecraft benchmarks both for its massive number of tasks and for the language-conditioned creative tasks that are more complex than programmatic tasks.This work introduces a new Minecraft benchmark for developing general-purpose agents. The benchmark suite includes more than 2000 tasks with unified observation and action spaces. Tasks can be categorized into kinds, programmatic tasks that have well-defined rewards and creative tasks that are more open-ended.This work provides an excellent open-world platform for embodied AI agents to learn continually in solving multi-tasks. This work helps to address a significant problem in existing research in embodied AI research. The work aims to build a generalist embodied agent.The benchmark is a selection of around 3100 tasks in the Minecraft simulator, each of which is described a natural-language prompt. The work propose using the video-text data to learn a CLIP-style model that learns to match open-vocabulary natural text descriptions to 16-frame video segments.	This paper proposes a new RL benchmark called MineDojo, which consists of thousands of diverse tasks on Minecraft game. The main challenge in designing such a benchmark is to define a good reward function to specify the desired task. This is very tricky since Minecraft is open-ended environment and there are various tasks, where human can't easily define the reward. To address this issue, the authors propose a very interesting idea: utilizing multi-modal (text-video) encoder as a reward. Specifically, the authors pre-trained the multi-modal encoder using contrastive learning (similar to CLIP) using multimodal data collected from the Internet and utilized the similarity between agent's behavior (video) and text as a reward function. Throughout human evaluation, the authors showed that their reward function can induce desired behavior (described by text). Since the authors open-sourced simulator, pre-trained reward model and agents, Minedojo can be a good starting point for making a progress on developing open-ended, multi-task RL agents.  Overall, all reviewers agreed that this is very solid submission and authors also handled concerns from reviewers during discussion period. I recommend acceptance.
Below are multiple reviews of a paper. This work presents a novel theoretical development to tackle the problem of estimating normalising flows (NF) for data with support on complex manifolds. Motivated by the fact that NF are diffeomorphic  transformations from a simple space, ideally Euclidean. The idea consists in inflating the data manifold with suitable noise (normal noise)The paper tackles the problem of recovering a probability distribution, which is supported in a low-dimensional manifold. When the dimension of that manifold is full, the problem can be solved by the Normalizing Flow method.This paper proposes a method for estimating the probability deinsity distribution on a low-dimensional manifold embedded in a high-dimensional space. The problem is that the universality of Normalizing Flow (NF) is limited. The proposal of this study is to make NF applicable by inflating low- dimensional manifolds with Gaussian noise.In this paper, the authors address main limitations of Normalizing Flows (NFs) method. Since NFs requires the support of density function to cover the whole Euclidean space, they propose to add noise (inflate) to apply NF.	The paper provides an interesting set of theoretical ideas to improve the estimation of normalizing flows on datasets that fail to be fully dimensional. Although the method is appealing, I believe the paper falls a bit short of acceptance at the conference. Too many practical issues are left out, as discussed by reviewers, and the method seems promising but not fully connected to the rest of the literature on estimating low-dimensional distributions living in high dimensional spaces. We encourage the authors to use the feedback contained in this round of reviews to improve their work.
Below are multiple reviews of a paper. This paper proposes star temporal classification (STC), an extension of CTC. It is designed when only partial labeled supervision is available. The paper has several strengths and weaknesses.Star Temporal Classification (STC) is an approach to train sequential models where there is an expectation that some labels are missing. The key machinery to accomplish this is composition with a WFST constructed, and appropriately weighted.The paper proposes Star Temporal Classification (STC) to solve the problem of missing labels for weakly supervised sequence labeling tasks (such as ASR, HWR) STC uses a special star token to allow alignments which include all possible tokens whenever a token could be missing.	This paper is right on the border. I'm going to mark this as accept as the only reviewer marking reject is due to limited evaluation, but i believe the evaluation is ok (as do the other two reviewers). The idea is interesting and novel, and the paper is well written.
Below are multiple reviews of a paper. This paper explores different metrics to measure the ‘selectivity’ of single neurons for a class in deep neural networks. Using AlexNet as the model under study, the paper shows strengths and weaknesses of several recent methods in the literature. The paper conducts a psychophysics experiment to see if human subjects can reliably label images generated throughThis paper analyzes the selectivity of individual units in CNNs. The authors analyze existing techniques such as precision selectivity, class-conditional mean activity selection and localist sensitivity. The results of this paper are surprising compared to existing work.This is a paper with scattered potentially interesting ideas. But the execution is limited and the writing poor with critical details lacking. A major limitation of the paper is that it is not clear what contribution it makes.	The paper examined the folk-knowledge that there are highly selective units in popular CNN architectures, and performed a detailed analysis of recent measures of unit selectivity, as well as introducing a novel one. The finding that units are not extremely selective in CNNs was intriguing to some (not all) reviewers. Further, they show recent measures of selectivity dramatically over-estimate selectivity.  There was not tight agreement amongst the reviewers on the paper's rating, but it trended towards rejection. Weaknesses highlighted by reviewers include lack of visual clarity in their demonstrations, the use of a several-generations-old CNN architecture, as well as a lack of enthusiasm for the findings.
Below are multiple reviews of a paper. Jin et al, 20’ consider RLSVI-type algorithms on a bilinear exponential family MDP. The work is well explained and it flows easily.This paper studies episodic reinforcement learning where the reward and transition probability functions belong to parametric bilinear exponential families. A randomized least square value iteration algorithm is proposed to perform tractable exploration and planning. The paper is well-written and easy to follow.This paper studies model-based reinforcement learning for episodic Markov decision processes whose rewards and transitions are parametrized by bilinear exponential families. To balance the exploration-exploitation trade-off, the author suggested a randomized algorithm that injects a calibrated Gaussian noise in the parameter of rewards. The proposed algorithm achieves	The paper presents a tractable algorithm for bilinear exponential MDP with regret bound that improves from the best known result and achieves \sqft{d^3 HK} regret. The result appears to be correct with strong technical analysis. Reviewers and ACs appreciate merits of the analysis for this specific problem class.  However, both the reviewer team and the AC found that the authors miss to discuss several important and closely related works, such as Zanette et al, '19; Yang and Wang, '19 and a line of works on kernel RL and model-based RL with Eluder dimension analysis. In particular, Table 1 only compares the new result with several recent results on specific MDP models published after 2021, which is far from comprehensive. During the rebuttal, the authors acknowledged that they were not aware of these related works. However,  they didn’t revise the submission to include the missing discussions pointed by the reviewer.   It remains unclear how the submission’s analysis relates to the aforementioned results that were not discussed in the paper. The authors provided some high-level discussion after rebuttal, but they would need a lot more technical details to be convincing. For example, regret analysis using Eluder dimension for general function class is often a go-to benchmark for non-linear models. The proposed model appears to be a generalized linear model, which is a standard special case of the Eluder dimension analysis. Then one would expect such analysis to lead to a O(d poly(H)\sqrt{T}) regret, (with \sqrt{d} coming from Eluder dimension and \sqrt{d} coming from metric dimension), better than result of this paper.  Note that this is just a conjecture, and rigorously working out this analysis would likely need extra work (nontrivial, as the authors pointed out). However, it is still not appropriate to overlook the possibility of using a more general analysis and just focus on a specific parametric model. A careful and honest discussion is necessary.  Beyond using Eluder dimension, there are actually a handful of RL theory papers on general function approximation and general model classes. We strongly recommend the authors to redo their paper survey and properly place their contribution in the context of state-of-art RL theory. We have reviewed a very competitive batch of RL papers this year. This submission has strengths but falls on the borderline. After consulting with the senior AC member who is also expert in RL theory, we regretful commend the authors further revise the paper and submit to the next venue.
Below are multiple reviews of a paper. The authors investigates how to reduce the cost of EEG caps. Reducing the number of electrodes only leads to a small drop in performance.This paper examines gaze signals within EEG. This work is a cool blend of state-of-the-art computer science deep learning techniques with neuroscience. The authors show that eye movements can be reconstituted with a small number of electrodes and specific frequency bands.Eye tracking using EEG has been long studied by HCI researchers. Authors have limited computational contribution. New additions are in EEG analysis and electrode placement.	This work studies the use of EEG-based gaze estimation. Reviewers indicated the promising experimental findings of being able to capture eye movements with a smaller number of electrodes in the EEG cap, and have also provided additional feedback for improvements (see Reviewer dm5p list of comments). An immediate suggestion for improvement would be to incorporate related work from the HCI literature, as pointed out by Reviewer nhaM. Overall, the paper has received positive feedback that suggests acceptance.
Below are multiple reviews of a paper. This paper proposes an MLP-free NeRF representation that supports both compression and composability. The authors use a hybrid feature volume decomposition that mixes the more expensive CP decomposition and the more compact TP decomposition. The mixing ratio controls model size vs. quality.This paper presents a compressible NeRF model which also supports the composition of different NeRFs to form a new scene. The proposed method uses a mixture of CANDECOMP/PARAFAC (CP) and Triple Plane (TP) decomposition. The rank components of different scenes are concatenated together to achieve theThis paper proposes a rank-residual learning strategy to obtain a radiance field representation that supports compressibility and compositionality with an acceptable diminishment of rendering quality. The submission is well-written and easy to follow.This paper aims to compress neural field representations. To this end, the authors first propose a hybrid tensor decomposition and learn the decomposition via differentiable rendering. To encourage the primary information be learned in lowewr ranks, they introduce a novel training strategy.	This paper presents a new NeRF method based on tensor decomposition. The method supports both compression and composability, while achieving similar results compared to standard NeRF models. The method does not use a neural network. Several reviewers found the paper easy to follow, the method novel & sound, and the comparisons comprehensive. Two reviewers mentioned the similarity between the proposed work and TensoRF. The rebuttal addressed most concerns and highlighted the differences between the two works. As TensoRF is a concurrent ECCV submission, the existence of TensoRF should not be used against the proposed work. The AC agreed with most of the reviewers and recommended accepting the paper.
Below are multiple reviews of a paper. A contention resolution scheme (CRS) is a method to round a fractional solution for a (packing) problem to a random integral one. An OCRS is said to be $c$-selectable if, roughly, $P(z_i=1) for each $i$The paper presents some results regarding online contention resolution schemes. The main result, to my taste, is the result for selecting a single item. This can be implemented as a greedy OCRS.An Online Contention Resolution Scheme (OCRS) is a rounding technique designed for online optimization problems especially in Bayesian optimization. The paper focuses on Greedy online contention resolution schemes and provides an optimal greedy OCRS for the single-item setting.The paper studies the problem of designing greedy online content resolution schemes (OCRSs) The authors provide an OCRS that provides a $\frac{1}{e}$-selectable greedy strategy for single-item settings.	Executive summary:  The paper considers the design of greedy online contention resolution schemes (OCRS) for the single-item setting and certain matroids (partition matroids, transversal matroids). The main result is that there is a 1/e-selectable greedy OCRS (which improves over the best known bound of 1/4 for greedy OCRS), and that this is best possible.  Discussion and recommendation:  This is a nice little result. Not tremendously difficult, but fundamental. A plus is that the question is resolved tightly. All but one reviewer felt positively about the paper. A major concern raised in the reviews was that it's unclear why we care about greedy OCRS. In the rebuttal, the authors emphasized that greedy OCRS yield guarantees against an almighty adversary and that they recently found application in a delegation variant of the Pandora's Box problem (Bechtel, Dughmi, and Patel [EC'22]).  (Weak) accept.  ---  Additional comments:  I always thought of OCRS as one of the two main techniques that have emerged for proving prophet inequalities and guarantees for posted-price mechanisms; the other being the "balanced prices" framework. I would encourage to extend the discussion in the related work accordingly, and cite the most relevant works on the "balanced prices" framework. Or, at least, cite the most relevant papers in that direction (see list below).  Citations to add:  Kleinberg and Weinberg. Matroid Prophet Inequalities. STOC'12.  Feldman, Gravin, Lucier. Combinatorial Auctions via Posted Prices. SODA'15.  D\"utting, Feldman, Kesselheim, Lucier. Prophet Inequalities made Easy: Stochastic Optimization by Pricing Non-Stochastic Inputs. FOCS'17.  D\"utting, Kesselheim, Lucier. An O(log log m) Prophet Inequality for Subadditive Combinatorial Auctions. FOCS'20.
Below are multiple reviews of a paper. This paper proposed a new data augmentation framework for low-resourse (and zero resource) cross-lingual task adaptation by combining several methods. The writing style is a bit redundant and confusing.The authors present an unsupervised data augmentation framework for cross-lingual NLP. Their method, called XLA, combines self-learning with co-learning and filtering. The method is quite elaborate requiring three epochs, with different training sets at each step.This paper improves 1-to-1 cross-lingual NLP by proposing a new data augmentation method. The proposed method is novel in crafting augmentation texts using masked language model of BERT.The paper argues that generating new samples for data augmentation using the vicinity distribution of the source and target samples is better than back-translation. However, similar problems would occur with vicinity distributions based augmentation since even changing a single word may result in changing the meaning of the sentence.	The paper clearly has merits, presenting a reasonable approach to zero-shot cross-lingual learning with good results, but with limited novelty, perhaps. I am sympathetic to the departure from XTREME on NER, agreeing with the authors that using CoNLL data is more interesting than WikiANN.   The post-rebuttal discussion centered on novelty and baselining - and specifically, whether other approaches to unsupervised data augmentation exist that should be used to baseline the proposed work. The authors argued that most of the approaches mentioned by the reviewers were in some way supervised. I personally think the confusion is a result of the paper being somewhat poorly framed:  Reviewer 2, for example, suggests a bunch of baselines. Some of these require gold labels for supervised fine-tuning to condition the MLM, but this seems like a trivial difference, which is orthogonal to using the augmentation strategies as baselines? Also, other papers have been presented that do not require gold labels, e.g. https://www.aclweb.org/anthology/D18-1100.pdf  Also, on the discussion of Täckström et al. (2012): Older approaches relying on distributional clusters *are* in fact data augmentation methods. Training on augmented data with words replaced is, in the limit, equivalent to training with clusters, when replacement words are sampled from clusters. Others have in the past proposed to use FSAs or clusters induced from static embeddings.  What the authors suggest is a form of co-training procedure, so similarly, semi-supervised algorithms - e.g., tri-training - could have been used as baselines.    In sum, I think the sentiment shared across the reviewers is that the results are largely unsurprising, and could likely be obtained in different ways, including jointly training with a target language modeling objective, tri-training, etc. Finally, I agree with Reviewer 2 that a “detailed comparison and discussion of the trade-off” between the different approaches to data augmentation, even beyond what’s apples-to-apples, would benefit the paper. Maybe there's other advantages to the proposed approach over other baselines (effectiveness, robustness)?
Below are multiple reviews of a paper. This paper extends the existing work on robust adversarial RL by training multiple adversarial agents from a population. Solid experimental results are presented to show that the proposed method improves the single adversary setting and domain randomization.This paper proposes an algorithm to improve the robustness of reinforcement learning. The algorithm combines ideas from domain randomization and adversarial training. During learning, it trains an ensemble of adversary to attack the learner.The authors present a scheme that can be used to train agents to be robust against a population of adversarial policies. Motivated by the observation that agents trained against a single policy may overfit to that policy and hence will lack robustness to new/unseen policies.This paper proposes to improve robustness in reinforcement learning via a population of diverse adversaries. Previous works mainly focus on the use a single adversary to mitigate the problem that the trained policy could be highly exploitable by the adversary.	The paper studies reinforcement learning in the presence of (adversarial) perturbations in the underlying system dynamics. The main (novel) observation is that  agents trained against a single policy may overfit  to that policy and hence will lack robustness to new/unseen policies. The paper proposes a population-based augmentation to the Robust RL formulation in which a population of adversaries are randomly initialized and samples from during training. The authors seek to show that their method generalizes well to unseen policies at test time.  Most reviewers agree that the paper provides a range of solid experimental results (with in-distribution and out-of-distribution tasks) showing robustness and generalization of their methods on several robotics benchmarks while avoiding a ubiquitous domain randomization failure mode. However, all the reviewers (and myself) agree that some of the conceptual claims of the paper may not be precise. For example, some of the reviewers disagree with the authors on finding the (mixed) Nash equilibria. Such general claims are hard to validate (may not even be true) and need theoretical justification. Hence, it is not conceptually clear why using multiple adversaries would not suffer from the same limitations as in the single adversary case.  Also, in the discussion phase, the reviewers agreed that the results/claims of the paper (i.e. overfitting to a single adversary and the need for multiple adversaries) are very interesting, but at the same time need to be confirmed by more extensive experiments.    Indeed, if the above are addressed, the paper would make a strong contribution to the area of RL.
Below are multiple reviews of a paper. The paper introduces Variational Stochastic Differential Networks to filter and smooth sporadically observed time series. The authors adopt a Bayesian perceptive on the smoothing problem for time series living a latent space and irregularly observed.This paper introduces a latent variable model for high dimensional stochastic time-series. The work is reasonably clearly presented and the experiments are multiple data sets are a nice addition. The authors use two inference procedures for the model, one the standard VAE and the other importance weighted IWAE.The authors claim that using SDE instead of ODE for the latent states has higher flexibility to capture more complex dynamics. The proposed VSDN model has the capability to capture the latent state stochasticity not via the initial states but rather via SDE.In this paper the author/s study/ies the fundamental problem of learning continuous-time stochastic dynamics. The paper assumes that high dimensional data are generated from a system where latent states are observed. In such a settings, it is generally impossible to derive a continuous- time Stochastic process which precisely describes the many behaviors of	This paper sits right at the borderline: the reviewers agree that it is interesting and addresses a relevant problem. On the negative side, the presentation could be improved (including some incorrect claims), and the experiments could be strengthened (both in terms of baselines and datasets used). Ultimately, the paper will probably require another round of reviews before it is ready for publication.
Below are multiple reviews of a paper. This paper proposes NeurOLight, a variant of neural operators that is suitable to emulate optical devices efficiently. The paper has many merits: the introduced ad-hoc techniques are convincing for the targeted domain. My main concern is that the target domain seems to be a niche problem for NeurIPS audiences.This paper proposes a neural operator that jointly models multiple parameters of EM simulation. Given input light wavelength, permittivity, and domain/material properties, the goal here is to establish a parametric mapping from the inputs to the output EM field via a neural network.This paper proposed a physics-agnostic light field prediction framework, called NeurOLight. It consists of a joint PDE encoder and an efficient cross-shaped neural operator backbone. A superposition-based mixup technique is developed to dynamically boost the data efficiency and generalization during the training.	The authors propose a domain-specific extension of neural operators that is appropriate for photonics applications. This is an interesting application of neural operators which demonstrates the usefulness of building in physical priors. Some reviewers expressed concern about the topic being too far outside the usual focus of NeurIPS, but there is also an upside to introducing novel application areas to the NeurIPS community. All reviewers agreed the work was of high quality and worth accepting, so I recommend acceptance.
Below are multiple reviews of a paper. This paper proposed a regularized policy learning algorithm for offline reinforcement learning. The implicit policy is trained by a GAN-like framework, and the regularization loss constrains the distance between learned policy and behavior policy. Experiments and ablation study on the D4RL dataset validate the proposed framework and designs.The paper proposes offline RL algorithms which consist of several key components. The paper provides a theoretical analysis to show the equivalence between regularizing policy and regularizing state-action visitation. It also provides an empirical study on several deep RL environments.In any given state s, the potential action value function in the action space may have multiple local maxima. Therefore, only one point can be used to evaluate whether the current policy is close to the behavior policy in any specific state. This direct matching state-action joint access alleviates the problem of uncontrollable extrapolation errors.	The authors propose to use implicit policies (similar to a conditional GAN) with a GAN-inspired regularizer. Theoretically, they show an equivalence between policy-matching and state-action-visitation matching. Finally, they evaluate their approach on D4RL and showed improved performance as well as ablations.  Reviewers did not find the theoretical contribution to be significant.  While the exact form may be novel, the general result has been shown in previous work and they only use the general result as a loose motivation for their approach. All reviewers acknowledge their empirical improvements as the primary strength of the paper. While a central component of their story is joint state-action regularization, Reviewer Ht1b identified that their proposed approach does not appear to directly regularize the joint state-action distribution, but rather behaves more similarly to existing policy constraint methods. I agree with Reviewer Ht1b and after much back-and-forth discussion (both Reviewer Ht1b and myself) with the authors, I have not been persuaded otherwise.  The paper has a lot of potential - strong empirical results, but the justification and explanation of the method needs to be rewritten in light of the policy constraint regularization or a stronger argument needs to be put forth in support of joint state-action regularization. I don't think this diminishes the results though, but without this substantial revision, I cannot accept the paper at this time.
Below are multiple reviews of a paper. The paper has a number of strengths, which lead me to support its acceptance. The writing is very clear, easy to follow, concise and accurate. The results are interesting, useful, and (to my knowledge) completely original.The paper derives PAC-Bayes generalization bounds taking as complexity term integral probability metrics, in particular Total Variation and Wasserstein distance. The paper is generally well presented and the proofs are clear and easy to follow.The paper presents new generalizations bounds that aesthetically look like a mix between uniform convergence and PAC-Bayesian bounds. One desirable feature of these bounds is that they allow for degenerate posteriors. The fact that uniform convergence is required in most bounds is not ideal.Authors open the classical PAC-Bayesian framework to new type of divergences. They introduce the general notion of Integral Probability Metric (IPM) Authors provide new concrete results for two classical divergence: the TV distance and the Wasserstein distance.	PAC-Bayes bounds provides a control of the risk of aggregation of predictors. In these bounds, the Kullback-Leibler divergence between the aggregation distribution and a prior appears in the upper bound on the risk. In this paper, the authors prove variants where the KL is replaced by an IPM (Integral Probability Metrics), including the total variation distance and Wasserstein. The important point is that these bounds are close to "uniform" (Vapnik-type) bounds in some unfavorable settings, but also can improve on them is more favorable scenarios.  The reviewers agreed that the results are novel and that the paper is technically sound. These bounds really extend the framework of PAC-Bayes bounds (for example, they are not necessarily vacuous when the posterior is not absolutely continuous with respect to the prior), and the fact that they recover uniform bounds in the worst case is also nice. All the reviewers recommended to accept the paper, and I agree with them.  The reviewers pointed out a few missing references, I will ask the authors to include them in the paper as promised during the discussion. I will add the following references that were not mentioned by the reviewers, and thus leave the authors decide to include them or not: - Alquier and Guedj (2018) actually provided PAC-Bayes bounds based on f-divergences, that were then improved by Ohnishi and Honorio (2021) (especially the dependence with respect to the confidence level). - there were a few attempts to replace the KL by the Wasserstein distance. The benefit were not as clear as in the present paper, but the authors might want to comment on the paper https://hal.archives-ouvertes.fr/hal-03262687/ or Lopez & Jog (2018) on MI bounds...
Below are multiple reviews of a paper. The paper is well written. Structure learning is an important problem though very hard. The controllability of explainability is a great plus to the proposed model. The notion and the proof of relational stability are interesting.The paper is very clearly written and organized. The idea of demanding more explainable predicates in the model is interesting. The empirical evaluation is compelling and conducted on realistic datasets. The paper does not have significant weaknesses in my opinion.This paper presents a novel idea to handle symbolic data. It is definitely a step forward in the realm of Explainable AI. The proposed algorithm is easily implementable, provided the authors augment the current work.The paper proposes a structure learning algorithm for PSL that is fast and takes into account the goal of explainability. The presentation has a few problems, with some imprecisions and unclear points. The reproducibility is excellent, with the code available upon acceptance.	Meta Review: The paper introduces a new algorithm for structure learning of probabilistic soft logic (PSL) from data, providing an explanation framework for its predictions. There is a consensus that some of the ideas provided in the paper are novel and will be of interest among the researchers in the field of explainable AI (XAI). The main strenghts are its novelty and originalty, contributing to both structure learning and explainability, and the main weakness are some issues in presenting the results that could addressed by the authors when preparing the camera-ready version.
Below are multiple reviews of a paper. Author studies VAEs under the assumption that the decoding distribution p(x|z) and approximate posterior distribution q(z|x) are in the exponential family. Theorem 1 is an interesting addition to the literature on analyzing VAEs, and is novel to the best of my knowledge. The empirical novelty, on the other hand,This paper proposes theoretical and empirical results on why VAEs tend to fail when the encoder distribution is not flexible enough. The paper observes that only general linear models satisfy ‘consistency’ or even approximate consistency. The experiments are an insightful addition to the theoretical analysis.This paper presents an analysis of the approximation error of VAE models when the encoder and decoder are from exponential families. The paper shows that with some limits on the densities to exclude deterministic solutions the VAE solution remains close to the consistent solution which matches the posterior perfectly.The paper studies the VAE approximation error, when the encoder and decoder distributions are from conditional exponential families (EFs) It is interesting that this is an *undirected* model, while VAEs are usually thought of a directed z->x latent variable model.	Wide agreement from the reviewers.  Interesting theorems.  Empirical work illustrates the theory. Claim and insight: failure of VAEs is caused by the inherent limitations of ELBO learning with inflexible encoder distribution. Good discussion pointed out related work and insights from the experiments.
Below are multiple reviews of a paper. This paper introduces a novel cross-device federated dataset, FLAIR. The dataset consists in 429k images from 51k individual Flickr users. The task consists in classification, with 2 levels of granularity for the classes.This paper proposes a new benchmark for large-scale cross-device federated multi-class image classification problem. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users.This paper builds a large-scale multi-label image classiﬁcation dataset FLAIR. FLAIR includes 429,078 images from 51,414 users, with 17 coarse-grained labels and 1,628 ﬁne- grained labels. FL AIR considers several important non-IID challenges in federThe paper presents FLAIR, a large-scale image dataset for federated learning. The images in the dataset are gathered and filtered in such a fashion that no faces are present to avoid any personally identifiable information. The dataset is collected from real Flickr profiles, which guarantees realistic user splits.The authors provide a large-scale classification dataset for cross-device Federated Learning with two tracks; fine-grained classification 1628 classes and coarse classification with 17 classes. The authors do not provide the NeurIPS checklist in the main article nor in the supplementary. I would advocate for not rejecting the article based on this.	The authors provide a benchmark for federated learning.   The commonly mentioned strengths: - there is a big need in the community for this type of work - easily accessible code - various levels of complexity with different granularity  Regarding the weaknesses, I see no showstoppers - some feedback about the experiments done on the datasets -> this point comes back consistently among all reviewers, in terms of the amount, settings and reproducibility.. The authors are adviced to address this in future work, to keep momentum for the use of the community on this dataset  - there was some discussion about tensorflow and pytorch, but based on the discussion both seem supported - some settings / image types could be better supported  None of these weaknesses seem serious, and quite frankly, we can not expect one dataset to cover all possible settings. Since the reviewers are in agreement about the quality of this work, I recommend them for an oral presentation.
Below are multiple reviews of a paper. The paper tries to argue that the Bellman error cannot be trusted as a good metric or objective for off-policy evaluation. Theoretical analysis gives a few example on the relation between the true value error, which could be arbitrary especially under finite sample cases.This paper studies the Bellman equation commonly used in reinforcement learning (RL) algorithms. The findings may be useful for a more complete understanding of when and why RL algorithms break down, especially in offline RL.This paper examines the role of Bellman error as an objective function in offline reinforcement learning. The paper provides both theoretical analysis, and empirical experiments. The main takeaways are: (i) zero Bellmanerror implies zero value error, but (ii) low Bellman Error doesn’t imply low value error.This paper studies the relation between the Bellman equation and the accuracy of the value functions. This paper shows that Bellman error is not a good measure for comparing value functions and thus is an ineffective objective function for off-policy evaluation.	This paper studies whether the Bellman error is a good metric to reflect the quality of value function estimation, focusing on finite-sample off-policy data sets. Both theoretical analyses and empirical experiments have been provided, showing that the Bellman error is often not the right metric to consider. However, while I appreciate the authors' theoretical attempts, the current theoretical contributions are not deep/significant enough. As the reviewers mentioned, the failure of the direct use of BRM is not surprising given the insufficiency of data (namely, no algorithm can make predictions on completely unseen regions unless further modeling structure is present). The authors might want to further strengthen their theory along this important direction.
Below are multiple reviews of a paper. The proposed approach is experimented on both simulated and in-vivo ICH test sets. The proposed method is not completely supervised and addresses the generalization drawback of supervised learning. The effect of concatenating the input field with the FINE reconstructed susceptibility is not reflected in the ablative study.This paper is well-written. The proposed method nicely introduced, and the evaluation seems solid. The reconstructions are convincing. The major weakness is that the method is not reproducible.The paper is well-written with strong motivation. Problems from the prior work (FINE) are clearly stated, and it is easy to follow how these problems were solved through the newly proposed method, HOBIT. The thing that concerns me the most is the motivation for using both iterative reconstruction and network parameter update.	strong paper with many positive remarks, especially after rebuttal. In addition the authors released their code. Recommendation for accept as oral.
Below are multiple reviews of a paper. This paper proposes a world model that can decompose controlled and uncontrolled factors in the environment. In experiments the authors show that the proposed method outperforms other world models in a modified version of DMC and the CARLA driving environment. The proposed method is able to perform action conditioned video prediction in the BAIR robot push and RobotNet datasetsIso-dream uses a variant of RSSM as a world model. It explicitly represents controllable and non-controllable aspects of the world state. Because these factors are modeled independently, it allows its policy to condition on samples of future non-controlled state rollouts from the model.This paper expands on the Dreamer framework to explicitly model controllable vs. non-controllable dynamics. The approach is novel, well-motivated, and well supported by evidence. It is highly relevant to a number of robotics applications.	This paper studies the problem of building world models that can decouple controllable and uncontrollable factors in the environment. The paper received reviews that generally tended towards acceptance. However, the reviewers had difficulty understanding some details and had concerns that the setup might not be the same across environments. The authors provided a rebuttal that addressed most of the reviewers' concerns. The paper was discussed and all the reviewers updated their reviews in the post-rebuttal phase. Reviewers generally agree that the paper should be accepted. AC agrees with the reviewers and suggests acceptance. However, the authors are urged to look at reviewers' feedback and incorporate their comments into the camera-ready.
Below are multiple reviews of a paper. The authors introduced a new, large-scale, open-domain dataset for on-screen audio-visual separation. The videos span 2500 hours, 55 of which are verified by human labelers. The flow of the model architecture section can be improved. The authors did not provide any high-level context.This paper proposed an unsupervised method for open-domain, audio-visual separation system. The authors suggest to separately process the audio and video, and next align them with a spatiotemporal attention module.This paper describes a system for separating "on-screen" sounds in an audio-visual task. It is trained to do this using mixture invariant training to separate synthetic mixtures of mixtures. The predictions are evaluated in terms of how well they can estimate the true on-screen sound.The proposed method is a combination of existing approaches, which shows mere novelty. The experiment results show reasonable performance on separating mixture from mixtures. Although the novelty is mild, I think this work shows a promising research direction.	This paper presents a new, large-scale, open-domain dataset for on-screen audio-visual separation, and provides an initial solution to this task. As the setting is quite specialized, the authors proposed a neural architecture based on spatial-temporal attentions (while using existing learning objective for audio separation). The reviewers were initially concerned that, while reasonably motivated, the architecture seemed some arbitrary. The authors then provided extensive ablation studies to evaluate the significance of each component with existing datasets, and these efforts are appreciated by reviewers. The authors may consider re-organizing the paper and moving some ablation studies to the main text. On the other hand, the reviewers believe that the dataset will be very useful for the community due to its diversity in content and label quality.
Below are multiple reviews of a paper. The paper compares Learning from Dynamics (LfD) and Learning from Intuition (LFI) in the context of physical reasoning. It concludes that the state-of-the-art LfI method is at least as good as LfD while being much simpler.The paper tries to understand the utility of learning dynamics in solving physical reasoning tasks. The main problem that makes the claims presented in the paper weak is the use of a single benchmark to test hypotheses. The authors do a good job with discussing the limitations of the paper.The paper systematically studies the impact of different learning mechanisms on physical reasoning problems through four controlled experiments. The results suggest that reasoning based on a static scene without dynamics predictions can perform as good as that based on an approximate dynamic model subject to errors.The paper examines two types of approaches for physical reasoning, namely learning from intuition (LfI) and learning from dynamics (LFD) LfI directly predicts the outcome without trying to learn or predict the trajectory of the process. The paper shows that existing state-of-the-art LfD methods are only as	This paper investigates a simple and important question: does learning to predict physical dynamics help an agent perform better physical reasoning? While most prior work automatically treats this as a given, the paper provides interesting findings that intuition-based learning is better than dynamics-based learning, especially when the dynamics model is approximate. All the reviewers appreciated the clear writing and thorough experiments performed. I believe this will be an insightful and impactful paper.
Below are multiple reviews of a paper. The paper describes an interesting tweak of the standard GAN model. The results are good and their tweak seems to help in most of the cases. The paper is not very well written and is not of publication quality.The paper proposes a ‘relativistic discriminator’ which has the property that the probability of real data being real decreases as the probabilities of fake data being true increase. The experiments show that the relativistic discriminate helps in some settings.In this work, the authors consider a variation of GAN by consider simultaneously decrease the probability that real data is real for the generator. The resulting GANs are relatively more stable and generate higher quality data samples than their non-relativistic counterparts. The English of the paper has to be significantly improved.	All authors agree that the relativistic discriminator is an interesting idea, and a useful proposal to improve the stability and sample quality of GANs. In earlier drafts there were some clarity issues and missing details, but those have been fixed to the satisfaction of the reviewers. Both R1 and R3 expressed a desire for a more theoretical justification of why the relativistic discriminator should work better, but the empirical results are strong enough that this can be left for future work.
Below are multiple reviews of a paper. Proposed method creates a *fixed* random mask to zero out lower layer activations during training and test. Extensive experiments show that the proposed method without adversarial training is competitive with a state-of-the-art defense method under blackbox attacks.The authors propose a simple method for increasing the robustness of convolutional neural networks against adversarial examples. The method is simple but seems to achieve surprisingly good results. It consist in randomly remove neurons from the network architecture.The authors propose to randomly drop a few parameters at the beginning and fix the resulting architecture for train and test. The claim is that the resulting network is robust to adversarial attacks. Most of the arguments seems to be handwavy.	This paper presents a new technique for modifying neural network structure, and suggest that this structure provides improved robustness to black-box attacks, as compared to standard architectures. The paper is very thorough in its experimentation, and the method is simple and quite easy to understand. It also raises some important questions about adversarial examples.   However, there are serious concerns regarding the evaluation methodology. In particular, the authors claim "black-box robustness" but do not test against any query-based attacks, which are known to perform better against gradient masking-based adversarial defenses. Furthermore, it is not clear why one would expect adversarial examples to transfer between models representing two completely different functions (i.e. from a standard model to a random mask model). So, the gray-box evaluation is much more informative and, unfortunately, random-mask seems to provide little to no robustness in this setting.  Given how fundamental sound and convincing evaluation is for proposed defense methods, the submission is not ready for publication yet. In particular, the authors are urged to (a) evaluate on stronger black-box attacks, and (b) compare to a baseline that is known to be non-robust, (e.g. JPEG encoding or SAP), to verify that these results are actually due to black-box robustness and not simply obfuscation.
Below are multiple reviews of a paper. This paper studies whether a model can generate its language instruction to solve long and complex sequential tasks. Ground-truth (natural) language instruction is only provided during a pretraining phase. The contributions of the authors are the following: The extension of the grid-world Minecraft-like environment with a natural language dataset.This paper studies the problem of generating natural language instructions to guide a policy to generalize to new environments. A natural language generation (NLG) LSTM network and an initial policy network is trained from labeled data collected from human workers. During testing, the instruction is not given but sampled from the NLG module.This paper proposes to use natural language to aid reinforcement learning by generating instructions for sub-goals that allow the agent to complete tasks with delayed rewards. The authors first design a multi-task crafting environment and collect step-by-step human demonstrations along with sub-goal instructions using crowdsourced workers. The proposed method then involves a modelA system that exploits both natural-language instructions, and demonstrations, to learn how to perform multi-subtask tasks in a Minecraft-like environment.	Although some reviewers still had concerns about the novelty of the proposed method, most of the other concerns have been addressed in a satisfying manner according to reviewers. They globally have a positive opinion about the paper after revision.
Below are multiple reviews of a paper. The paper appears not to be written in a professional way. There are some inconsistencies both in the fonts and on the overall presentation style. At a minimum, I believe that the paper writing would need to be improved for the paper to be accepted.This paper revisits two commonly used approaches in online adaptive LQR control: Reward-Biased Maximum Likelihood Estimate (RBMLE) and Upper Confidence Bound (UCB) The authors show that these two methods can be reconciled, and thereby propose an Augmented RBMLE-UCB algorithm. TheoretThis paper proposes RBMLE and ARBMLE algorithms for LQR with unknown dynamics. Numerical results show promising improvements over the existing methods. The paper is very well written.The paper addresses the control of a fixed stochastic linear system of known order but unknown parameters with the objective of minimizing a finite horizon quadratic cost. The solution to this problem when the parameters are known (and under certain assumptions) is a well known result. This allows the authors to show that RBMLE is a penaltyThis paper develops a Reward-Biased Maximum Likelihood Estimate-Upper Confidence Bound (RBMLE-UCB) policy for controlling a stochastic linear system with quadratic costs. This problem is sometimes called the adaptive LQ control problem. The authors prove that this policy achieves the best-known square-	Reward-Biased Maximum Likelihood Estimate (RBMLE) is an approach to balance exploration-exploitation that is based on biasing models with smaller cost functions. The paper considers an augmented version of it (ARBMLE) that confines the search of the model to the confidence set used by an Upper Confidence Bound (UCB)-like algorithm. The paper considers the Linear Quadratic Regulation (LQR) with unknown dynamics, provides a regret bound of ARBMLE, which is comparable to that of UCB-based approach. The paper empirically shows that both ARBMLE and RBMLE outperform many other methods, particularly UCB-based ones.  We have both strong support in favour of acceptance of this paper and some less enthusiastic negative reviews. After reading the paper, the reviews, and the discussions, I am inclined to accept the paper. The main reason is that the paper considers a relatively less-known approach to exploration-exploitation problem, provides reasonable analysis (even though the tools might be standard), and shows promising empirical results. However, my recommendation should not be considered as dismissing the concerns of reviewers. I believe many of them are valid. I merely put less weight on them in my evaluation compared to the negative reviewers.  Let me emphasize a few points brought by reviewers and my own reading of this work. I hope the authors consider them in the revision of their paper.  - The writing quality varies a lot. The first two sections are written clearly and have some nice insights and intuitions, but then the writing quality deteriorates. For example, Section 3.2 becomes confusing (we have E_t, E_1, E_2 with different meanings), and Section 5 becomes a series of lemmas without much insight. Sections 6 and 7 are of better quality again.  - The series the sequence of lemmas in Section 5 is not very insightful. The authors have added a paragraph at the beginning of that section, but I believe that is not enough. My suggestion is that authors either provide better intuition behind each of these lemma, or move them to an appendix.  - Be clear about the dependence of the regret bound on the dimension of the system.  - Assumption 3 requires more discussion.  - The issue of tractability of solving the required optimization problem should be discussed explicitly.  - Given that [31] (Mete et al., "Reward biased maximum likelihood estimation for reinforcement learning", 2021) solves an arguably more general problem (RL instead of LQR), a detailed comparison is needed. What are the differences in insight, proof techniques, etc.?
Below are multiple reviews of a paper. This paper proposes to incorporate the proprioceptive and visual information together for quadrupedal locomotion. The use of visual information can allow the robots to be less conservative and plan their actions for a longer time horizon. The paper will be much stronger by including some more concrete comparisons with the current state-of-the-art learning approachesThe authors proposed to use transformer architecture to solve visual locomotion + navigation tasks. The proposed approach is compared with a few end-to-end trained baselines including HRL and has demonstrated advantages. The main weakness of the paper: Not enough baselines to compare with.This work proposes a novel architecture for quadrupedal locomotion that fuses proprioceptive and visual information with a transformer-based model. The method is extensively evaluated in simulation and on a sim to real transfer tasks. Overall, the paper is well written and the provided evaluation is conducted fairly and well.This paper proposes an approach to legged locomotion which leverages a Transformer-based model and is trained via end-to-end reinforcement learning. It provides extensive experimental evaluation of the approach in terms of performance and safety metrics, both in simulation and using real-world experiments.	The paper addresses vision-based and proprioception-based policies for learning quadrupedal locomotion, using simulation and real-robot experiments with the A1 robot dog. The reviewers agree on the significance of the algorithmic, simulation, and real-world results. Given that there are also real-robot evaluations, and an interesting sim-to-real transfer, the paper appears to be an important acceptance to ICLR.
Below are multiple reviews of a paper. The paper provides detailed analysis of different uncertainty quantifications in Model-based offline RL, from both statistical and empirical perspectives. I think the research is well-motivated and interesting, while I have some concerns about the experiments.The authors present an empirical study of several uncertainty quantification heuristics applied to model learning in offline model-based reinforcement learning. They present these results showing that the optimal choice of penalty and penalty weight can vary significantly.The paper provides an evaluation of many of the design choices and hyperparameter decisions made in offline model-based reinforcement learning methods. They compare the “optimized” version of MOPO with hyperparameters tuned using Bayesian optimization, and find that it leads to statistically significant performance improvements.This paper conducts empirical analysis to compare different design choices of the uncertainty estimation in practice. The main contribution of this paper is to systematically compare several uncertainty estimate methods. I recommend rejecting this paper because the technical contribution is not strong enough.This paper reviews the different penalties that have been designed in the literature. The impact and importance of associated hyperparameters such as the planning horizon and the number of models in the ensemble are also evaluated. The author show that the selection of the best penalty and best hyperparameter lead to stronger performance.	This paper empirically studies various design choices in offline model-based RL algorithms, with a focus on MOPO (Model-based Offline Policy Optimization). Among the key design choices is the uncertainty measure used in MOPO that provides an (approximate) lower bound on the performance, the horizon rollout length, and the number of model used in ensemble.  The reviewers are positive about the paper, found the experiments thorough, and the results filling a gap in the current literature. They have raised several issues in their reviews, many of which are addressed in the rebuttal and the revised paper. I would like to recommend acceptance of the paper. Also since the results of this work might be of interest to many researchers working on model-based RL, I also recommend a spotlight presentation for this work.  I have some additional comments:  (1) The paper studies the correlation of uncertainty measures with the next-state MSE, with the aim of showing which one has a higher correlation. The underlying assumption is that the next-state MSE is the gold standard that we should aim for.  If we go back to the MOPO paper, we see that to define an uncertainty-penalized reward, we need an upper bound on the absolute value of G(s, a), which is the difference between the expected value of the value function at the next-state according to the true model and the estimated model.  If we assume that the value function belongs to the Lipschitz function class w.r.t. a metric d, this upper bound is proportional to the 1-Wasserstein distance between the true next-state distributions and the model's distribution. If the dynamics is deterministic, 1-Wasserstein distance becomes the $d( T(s, a), \hat{T}(s,a) )$. If the distance d is the Euclidean distance, this becomes the squared error.  Therefore, the squared error makes sense for deterministic dynamics, and it only provides an upper bound of $|G(s, a)|$. If the environment is not deterministic, the squared error may not be a reasonable gold standard anymore to compare the correlation of various uncertainty measures with.  The paper introduces a generic MDP framework, but does not mention anything about its focus on MBRL for deterministic environments until the last sentence of its conclusion. Please clarify this in your camera ready paper.  (2) The experiments are conducted using 3 or 4 seeds. Although this is the common practice in the deep RL community, it is too small. Standard deviations in Tables 1, 2, ... are computed with 3 seeds, which would be cringeworthy to statisticians and empirical scientists. I encourage the authors to increase the number of independent random experiments to make their results more powerful.
Below are multiple reviews of a paper. This paper builds the connection between various steerable CNN structures based on group representation theory and filter transformations. Using the discrete rotation and reflection group as an example, the paper establishes ways to construct steerable convolutional filters that transform features in trivial, regular and irreducible representations.This paper studies the connection between steerable CNN and filter transformation. The theoretical connection doesn't seem to provide a significant advantage nor solve the problems in existing methods. The experiment doesn't provide much information and only shows that the proposed implementation works on simple datasets.The paper outlines the construction of filters in a group equivariant convolutional network. The authors achieve this by taking linear combinations of (harmonic) basis filters. They then show explicitly how one can build filters between particular representations of each group.Steerable CNNs for 2D/3D rotation+reflection+translation groups have generally been implemented as a filter transform/expansion step followed by a standard convolution. The precise way in which a basis filter is to be rotated and flipped to obtain the steerable filter basis for the 2D case had not been worked	This paper introduces an approach based on filter transform for designing networks equivariant to different transformation groups. Especially, the authors rely on the haramonic analysis view of steerable CNNs given in Weiler & Cesa (2019) to design an equivariant filter bank by computing simple transforms over base filters.   The reviewers finds the paper technically solid but difficult to read and with a limited contribution.  The AC carefully reads the paper and discussions. Although the connection between steerable CNNs and filter transform are interesting, the AC considers that the main contributions of the paper should be consolidated, especially the positioning with respect to Weiler & Cesa (2019). \ Therefore, the AC recommends rejection.
Below are multiple reviews of a paper. The paper empirically studies the Double Descent phenomenon by using a cool construction that squares the dataset size by concatenation. The main empirical finding is that this construction mitigates double descent.The paper shows that the phenomenon of double descent can be mitigated via augmenting the input. The idea of investigating double descent from manipulating samples is novel and interesting. However, the paper is quite poorly-written.There has been a recent surge of research interest in explaining the double descent phenomenon. This paper proposes to mitigate double descent by artificially augmenting the dataset. The paper does not provide any rigorous theoretical analysis.Concatenated inputs construction does not impact the double descent curves in linear regression but can largely alleviate those in the case of (deep) neural nets. The idea of (artificial) data augmentation looks interesting. There is visually no theoretical contribution and the empirical contribution is also somewhat limited.	This paper proposed an augmentation construction to mitigate the double descent. For any pairs of data points, the constructed input is simply concatenation of two inputs and the constructed label is the average of their corresponding labels. The authors further empirically show that this would mitigate double descent.  Reviewers unanimously like the main idea of the paper but they have other major concerns about this work. The main concern is that we already know double descent is not a practical issue since it can be mitigated by early stopping or proper regularization (Nakkiran 20'). Therefore, the main benefit from this paper could come from a better understanding of double descent using the observations from this construction. However, the paper does not provide us with insightful theoretical or empirical findings beyond the main observation. There are a couple of other concerns as well about discussions around #samples and the fact that the proposed construction is not i.i.d. and also lack of proper discussion about the relationship between the proposed construction and regularization techniques.  Unfortunately, authors did not responded to reviewers concerns. Nonetheless, I encourage authors to read reviewers' specific feedbacks, incorporate them and resubmit their work.  Given the above concerns, I recommend rejecting the paper.
Below are multiple reviews of a paper. This paper proposes an implicit neural representation called Hybrid Sign and Distance Field (HSDF) It employs a neural network to regress unsigned and signed distance fields separately. It then fuses the two fields by taking the distance from the unsigned distance field and the sign of the signed distance.This submission proposes to regress sign and distance separately, and extend sign to oriented open (ie. non watertight) meshes. Authors demonstrate it can represent both open and close surfaces, and propose a way to mesh it.A paper proposes a hybrid distance field approach to represent 3D object surfaces. The main idea behind it is to utilize the advantage of the unsigned distance function. The experiments conducted in ShapeNet demonstrate the HSDF achieves good performance.	The reviewers agree that the paper's idea to include both sign and distance fields is a valuable contribution to 3D computer vision research.  Reviewers ask sensible clarifying questions (e.g. orienting the training data, sign network continuity) and the rebuttal's answers are illuminating and to the point.  A short notice on terminoloy: I agree that "adversarial" should not be used here as it has a special meaning for the wider NeurIPS audience.  Regarding other wording suggestions, I add no extra vote for or against.
Below are multiple reviews of a paper. This paper refines the the truncation error analysis for discretizing the ODE to obtain accelerated optimization method. Built upon the analysis, the authors propose a new method which is claimed to be more stable and converges faster.This paper proposes an accelerated method that has a high-order truncation error. This implies that the iterates of the proposed method converge to the trajectory of the differential equation faster than those of Nesterov's method. A matrix completion problem experiment is further included.The paper studies the well-known Nesterov's accelerated gradient method. It shows the rate of convergence to the solution of an ordinary differential equation. The method is combined with the proximal operator into a new algorithm. This algorithm is then applied to the matrix completion problem.In this paper the authors study a version of accelerated gradient method. The authors propose a different discretization of the ODE by Su et.al. The truncation order of this scheme is of a higher order, thus the proposed algorithm is more stable.	The paper studies a high-order discretization of the ODE corresponding to Nesterov's accelerated method, as introduced by Su-Boyd-Candes. The main claim of the paper is that the more complex discretization scheme leads to a method that is more stable and faster. However, the theoretical claims do not seem sufficiently supported, and the experimental results are insufficient to judge the usefulness of the proposed approach. Thus, the reviews could not recommend acceptance, and I concur. The authors are advised to revise the paper to provide more theoretical and experimental evidence for usefulness/competitiveness of the proposed approach, and resubmit to a different venue.
Below are multiple reviews of a paper. This paper constructs methods named CurvatureEG+ (and Adaptive EG+ and CEG+), built upon a recently proposed EG+ [Diakonikolas et al., 2021], a variant of EG, that works under the weak MVI condition. Most importantly, the CurvaturesEG+ works for a range (This paper focuses on variants of ExtraGradient (EG) by considering different options for the two step-sizes of the method: one for the extrapolation step and the second for the iterate update. It builds on the analysis of (Diakonikolas et al. 2021) by allowing a larger range of values forThis paper proposed CEG+ and CurvatureEG+ which extend extragradient method to a proximal variant (regarding the operator $A$) The authors also studied the lower bound in the simpler case when $A\equiv 0$, showing a difference compared to EG+ in (Diaonikolas etThis paper studies the constrained/regularized nonconvex-nonconcave minimax optimization and its generalization called weak MVI problem. Theorems and experiments convincingly demonstrate that there are inclusion problems where the original extragradient algorithm diverges while the proposed algorithm with adaptive stepsizes converges.	The paper considers the saddle point problem of finding non-convex/non-concave minimax solutions. Building onEG+ of Diakonikolas et al., 2021 that works under weak MVI conditions, the work presents a new algorithm CurvatureEG+ that works for a larger range of weak MVI condition compared to previous work and also works for the constrained and composite cases. The authors show cases where this algorithm converges while the previous algorithms can be shown to reach limit cycles. Overall, this theoretical work seems strong. Most reviewers seem to agree that the contribution is good enough for publication. Compared to EG+ the additional contribution is to expand the range of weak MVI condition. While this seems like a slight improvement, looking beyond just the final convergence rate, the paper has some nice insights that provides a unifying view that captures past algorithms (like EG+ as special case). I recommend acceptance.
Below are multiple reviews of a paper. This paper studies the generalization performance of Markov chain stochastic gradient methods for both minimization problems and minimax optimization problems. The analysis is performed by using the method of algorithmic stability in learning theory. The paper is generally well-written and well-structured.The paper studies generalization ability and excess risk of a one-sample SGD with averaged iterates where selection of samples happens according to the Markovian process rather than i.i.d. The stability analysis essentially follows the on Hardt et al. for SGD.The authors propose the first generalization performance of MC-SGD and MC- SGDA with Markov sampling. The rate is the same as the i.i.d sampling scheme. The technical tools used are fairly standard and elementary.	The paper authors a new generalization analysis of SGD with MC sampling by using algorithmic stability. The reviewers agreed that the technical contribution is novel and interesting. Though initially two reviewers were concerned about the potential applications for SGD with MC sampling, the authors have updated their paper pointing out several applications that fits the type of MC sampling assumed in their proof.
Below are multiple reviews of a paper. In the paper, the authors propose to minimize the discrepancy between pairs of (conditional) neural axioms to align the embedding spaces of different KGs. This method is justified by the authors' study of all kinds of OWL2 properties.This paper proposes an entity alignment framework to further refine the results of conventional embedding-based alignment approach. The proposed framework is shown to be effective in improving the performance of baseline models.The presentation and organization of this paper is very difficult to follow. The claimed challenges, that have not been solved well by previous works, are not convincing enough. It's an interesting work but not ready.The paper proposes NeoEA, an approach that further constrains KG embedding with ontology knowledge. The paper shows significant improvements when combining the newly designed loss with state-of-the-art baselines.	The authors study the problem of augmenting embedding-based entity alignment in knowledge graphs (KG) through the use of joint alignment with deduced neural ontologies (more specifically, alignment of the KG 'neural' axioms). Motivated by the observation that the representation between two potentially aligned entities must be bound by a minimal margin, which can be problematic when there are many potential alignments, they propose aligning neural axioms by Wasserstein distance-based loss between learned entity embeddings conditioned on the relation embeddings. Experiments are conducted on OpenEA against multiple strong baselines -- showing that adding the ontology alignment to these baselines improves the results.  == Pros == + The addition of aligning (conditional) ontologies is ostensibly novel. + For KGs with sufficient entity/relation overlap, the proposed NeoEA method is applicable.  + NeoEA has been shown empirically to improve many SoTA methods.  == Cons ==  - While the theoretical justification is a welcome motivation, the reviewers did not find the theoretical arguments significant nor convincing. - Overall, the narrative needs work to make the paper more self-contained and approachable for a broader range of readers. The reviewers (and myself) found many concepts and statements somewhat confusing and needing clearly context and contrast with existing works.  Evaluating along the requested dimensions: - Quality: Conceptually, the core idea is interesting, well-motivated, original, and ostensibly effective. Empirically, NeoEA is shown able to improve upon several strong baseline (underlying) methods.  I believe that all of the reviewers find the work is interesting and promising. However, there were continuing concerns the strength/value of the described theory; it isn't clear if stronger theory isn't possible or if this just hasn't been fleshed out.  - Clarity: Most of the reviewers (and myself) found the paper difficult to follow as a self-contained work in terms of concepts, clear definitions (e.g., \mathcal T isn't defined early on) and the actual applicability of the theory. The figures help, but even these need some work. A related work section (or more structured presentation of related work) might be clarifying along with running examples and a more unifying math presentation that captures existing and proposed work. After thinking about this more, it is actually a relative simple (in a good way) and clever idea. However, it took several readings and readings of related work to get there. Additionally, the fact that all of the reviewers were concerned about different limitations is concerning wrt clarity. Appendix B helps a bit and I believe can also be put into the main paper. - Originality: As best as the reviewers and I can tell, we haven't seen this method applied to entity alignment despite this being a relatively mature subfield. - Significance: The consensus seems to be that the approach could be a notable contribution to an important area. However, it also appears that most of the reviewers don't feel the paper is ready for publication at a top-tier venue yet.  As stated throughout this meta-review, there are several aspects to like about this work including the originality of the idea, strong motivation, and good empirical results. However, we all agreed that the paper isn't quite ready in its current form -- thus, I presently recommend reject for this submission.
Below are multiple reviews of a paper. The paper proposes to use Riemannian stochastic gradient algorithm for low-rank tensor train learning in deep networks. The novelty of the paper is rather limited, both in terms of the convergence analysis and exploiting the low- Rank structure in tensor trains.In this paper, the authors proposed a new method to update the weights in RNN by SGD on Riemannian manifold. The updated weights in each iteration are contracted with a low-rank structure, such that the number of the parameters of TT can be automatically decreased during training.This paper proposes an algorithm for optimizing neural networks parametrized by Tensor Train (TT) decomposition based on the Riemannian optimization and rank adaptation. The paper needs to be improved in several aspects before being useful to the community. In particular, I found the several mathematical errors regarding basic definitions and algorithms (see below	This paper proposes using a tensor train low rank decomposition for compressing neural network parameters.  However the paper falls short on multiple fronts 1)lack of comparison with existing methods 2) no baseline experiments. Further there are concerns about correctness of the math in deriving the algorithms, convergence and computational complexity of the proposed method.  I strongly suggest taking the reviews into account before submitting the paper it again.
Below are multiple reviews of a paper. This paper proposed a method to trace the strong adversarial attacks (specifically PGD). PGD attack is likely to leave a trace and trigger the local linearity of the network. They then introduced the ARC to capture the SAE, resulting in a detector that can identify the informed attacks and uninformed attacks.This paper proposes a new and interesting method to detect PGD-like adversarial perturbations. The proposed method is very interesting and novel. The authors propose to use the Sequel Attack Effect to continue the attack with BIM.This paper proposes a detection defense against adversarial examples generated by untargeted PGD-like attacks. The defense relies on the assumption that such examples trigger distinguishable patterns of linearity along a local trace defined by the BIM attack. The linearity pattern is characterized by the ARC feature, a vector reduced from the jacThe authors propose a new detection method to detect PGD-like attacks. The detection method is based on the analysis of local linearity between benign samples and adversarial samples. The authors also introduce ARC and SAE to measure the locallinearity.	This paper observes that "PGD-like" attack algorithms have characteristics that allow one to detect an input has been attacked. While I agree that it is interesting PGD-like attacks have detectable properties, I agree with the reviewers that designing attck-specific defenses has limited utility. The authors already show that FGSM and similar attacks are not detected with this approach, and this makes me worry that adaptive attacks will also not be easy to detect. And so while making an observation about how PGD works is interesting, it is not yet sufficient and will likely not form the basis of a strong defense.
Below are multiple reviews of a paper. The authors have proposed a tailored network that extracts information from binary spikes with ST representation based on the differential of spike firing time and spatial information aggregation. An extensive literature review has been performed to support the research objectives.Spike2Flow is a deep neural network that maps spikes from a spiking camera to optic flow estimates. The method encodes spikes with a differential of spike firing time (DSFT) transform.The authors present an algorithm for optical flow from spiking camera data. Given that spike cameras have high temporal resolution, optical flow is a good application for these cameras. Source code will be released upon publication.This paper proposes a method, Spike2Flow, to estimate optical flow from videos recorded by spiking cameras. Strengths: The empirical performance seems good. Weaknesses: The presentation is quite unclear.	This work is focused on the estimation of optical flow from a neuromorphic camera that produces Poisson spiking at each pixel with a rate governed by overall intensity. The authors use local space-time aggregation of spike-time differentials to identify features that are then corresponded via a convGRU decoder.   The reviewers found the application interesting, and noted the good performance of the method. There were however a number of concerns about innovation and novelty of the method. Specifically the aggregating spikes to operate on point process data is a standard approach and the assessment of the spiking source of the data was not analyzed. Regardless of the similarity to past methods, overall the reviewers felt that the strengths of the paper, specifically the combination of methods brought together to solve a unique problem, outweighed the weaknesses. Thus I recommend that this work be accepted.
Below are multiple reviews of a paper. This paper tries to identify a condition that makes quantum-based kernel methods superior to standard ones. Although the question raised by this paper is interesting, I am not convinced enough by the proposed answer to warrant acceptance. There are many writing flaws**.This article studies the superiority of quantum kernel methods over classical kernel methods. Several numerical simulations were conducted to support the theoretical findings. The introduction of the article is well-written and reflects a good knowledge of the literature. The presentation of the theoretical results is poor and informal.This paper studies quantum kernel methods for classification problems. It compares the differences between quantum kernel functions and classical kernel functions. Some empirical experiments are done on the datasets from Qiskit and Kaggle.The paper investigates the circumstances under which quantum kernel methods will be superior to classical kernel methods. Validation of the proposed criteria is carried out on a range of toy and real datasets. Overall a well-written paper.	There was consensus that though  the paper introduces an interesting question, but not enough exploration has been made. The reviews point out several mathematical in-accuracies, and points out  several issues including that the delta criterion needs to be examined.
Below are multiple reviews of a paper. This paper names and addresses the stability/efficiency dilemma in large language model training. Large batch sizes and learning rates enable more efficient and faster distributed training. But they also increase the prevalence of instabilities which tend to hurt performance. This problem appears to get worse for larger models.This paper proposed a simple and effective method, "sequence length warmup" (SLW), to improve the training stability and efficiency, in GPT model pre-training. For GPT-3 (125M parameters), when limited to 10% of data available, 8X larger batch size and 40x larger learning rate, SLIn this work, the authors address the difficulty of training large language models with a novel strategy: sequence length warmup. The authors note that transformer training requires limited batch size and learning rate, and that methods which allow both to be increased can improve training efficiency. Their proposal is to use a training strategy which uses short sequence length examples toThis work introduces the Sequence Length Warmup (SLW) method. It is a simple but demonstrably effective technique for improving training stability of GPT models.	# Summary of the Paper  This paper makes two contributions as far as I can tell: 1. The paper attempts to characterize training instability in large language models. 2. The paper presents Sequence Length Warmup (SLW), a technique that the authors claim to reduce training instability and that empirically makes training LLMs much more efficient.  # Metareview  The paper isn't perfect, but it's an obvious accept. Even in the most pessimistic assessment of the paper, the SLW technique is a clear win for efficient training regardless of how harshly you judge the analysis of training instability.  The biggest weaknesses of the paper are (1) all of the methodological and scientific questions around trying to grapple with the phenomena around training stability and (2) claims of a connection between SLW and training instability.  On the topic of instability in large model training (1), there has been plenty of griping on Twitter but very little scientific analysis of the phenomenon. This paper's analysis will hardly be the last word on that topic, but it's a reasonable first attempt at something that other researchers will doubtlessly build on and hone over the coming years. I share Reviewer c8jb's concerns that correlation with gradient norms is insufficient to make claims about training stability or SLW and that more rigorous definitions of training stability are necessary. However, even if, in the very worst-case scenario, this paper is one of the first attempts at characterizing a vexing phenomenon and inspires future researchers to tear apart the modes of analysis and findings in this paper to improve upon them, this paper will have been a worthwhile contribution to the scholarly literature.  On the topic of claims of a connection between SLW and training instability (with the concerns most poignantly expressed by Reviewer S5Qt), this is really a byproduct of the scientific analysis of training instability. This connection (or lack thereof) will become clearer as time goes on and the science improves, and I simply ask that the authors acknowledge the uncertainty here.  **If the above scenarios are the very worst possible outcome for this paper, it's still a major contribution to both science and practice. I therefore advocate for accepting this paper, and the reviewers seem to agree with that assessment (both the good and the bad). I urge the authors to prepare the camera-ready version of the paper by carefully incorporating the feedback of the reviewers and, in particular, Reviewer c8jb, who had some very thoughtful comments about ways to clarify the scientific aspects of the paper. To satisfy the reviewers and future readers, I highly recommend openly and frequently acknowledging the vast uncertainty we have about the scientific aspects of this paper as we strive to make sense of this strange training instability phenomenon.**  The reviewers were enthusiastic and engaged, and the discussion was lively, which suggests to me that this is an exciting paper that deserves to be featured to the community via publication at NeurIPS.  There were some other common comments that I urge the authors to address in order to produce the best and most influential possible version of this paper: * "The reason why instabilities lead to worse performance when they do not cause divergence was not discussed much.", "The reason why using longer sequences creates instability was not discussed much." The authors discussed this a bit during the discussion period, but it's worth emphasizing these as open questions so that other researchers know it's important to follow up on. * It's worth being crystal clear about truncation vs. just focusing on shorter sequences. It's an important experimental detail that may seem surprising or counterintuitive if it's not clearly laid out.
Below are multiple reviews of a paper. The cross approximation of tensor train decomposition is an analog of CUR decomposition for a higher-order tensor. The authors derive an error bound in terms of the Frobenius norm where the observation noise is taken into account.This paper considers the problem of tensor train decomposition. It provides theoretical guarantees of cross approximation in terms of the Frobenius norm for both exact and noisy measurements.Tensor train (TT) application is a feasible approach to generalize tensor information. Experimental analysis revealed that the error of the decomposition is stable with the increase of tensor order.This paper provides the error analysis for the entire tensor, given clean or noisy measurements. The authors have done a good job walking readers through the motivation, definitions, and theoretical results. The technical contribution is self-evident.	The reviewers agree that the theoretical result shown in the paper improves upon prior art and that the experiments are compelling.  All comments and concerns of the reviewers have been well addressed by the authors.
Below are multiple reviews of a paper. The paper proposes a novel RNN architecture (CorNN) to tackle the infamous problem of vanishing and exploding gradients in RNNs. The novel CorNN architecture is based on time-discretized forced coupled damped nonlinear oscillators. For the gradient norm of CorNN analytical lower and upper bounds are calculated implying that CorThe paper introduces a novel recurrent neural network architecture which approximately preserves the norm of the gradient irrespective of the number of unroll steps. The motivation for the use of non-linear oscillators is well-written but perhaps should be de-emphasized.This paper proposes a new continuous-time formulation for modeling recurrent units. The particular form of the recurrent unit is motivated by a system of coupled oscillators. The analysis is mathematically sound. Code is provided!This paper provides a new idea to address the exploding and vanishing gradient problem, which hinders the development of deeper neural networks tremendously. In my opinion, this coRNN model is meaningful for practical application, especially for the extension of more complicated neural networks.	A novel second order nonlinear oscillator RNN architecture is proposed, analyzed, and evaluated in this paper. The results are solid and impactful. Authors and expert reviewers showed exemplary interactions with each other, improving the manuscript in significant ways. All four reviewers overwhelmingly recommended accept. I recommend that this paper be selected as an oral presentation.
Below are multiple reviews of a paper. This paper tackles a symbolic regression (SR) SR is a task to explain observed data using mathematical expressions. The authors state that there are five individual methods and the proposed method combines them. The experimental results on SRBench, a benchmark for SR, demonstrate that the proposedmethod performs better than the existing methods.This paper provides a holistic review of symbolic regression approaches, and picked 5 most popular ones for algorithm amalgamation. The new symbolic regression algorithm is claimed to maximize the benefits of each and cover each other’s weaknesses. Based on my limited assessment, this work stays free of possible negative societal impact.This work proposes a new symbolic regression method that unifies 5 existing symbolic regression methods. It also discusses contribution of each component to the unified framework through comprehensive ablation studies. The reviewer found that the study may be beneficial for the community while there are some things to be addressed.	The paper presents a novel deep symbolic regression approach that is a hybridization of existing methods, showing state-of-the-art performance on the SRBench. Let me stress that being a hybrid is no reason to reject a paper as creating hybrids can be a very creative contribution. And for me this is the case here. the hybrid is not just a "mixture" but actually a very creative rewiring of components of the underlying approaches. This is also supported by the ablation study. Moreover, several of the  issued raised were clarified well in the rebuttal.  BTW, the authors may also want to cite other approaches for equation discovery, see e.g.  Jure Brence, Ljupco Todorovski, Saso Dzeroski: Probabilistic grammars for equation discovery.  Knowl. Based Syst. 224: 107077 (2021)  Will Bridewell, Pat Langley, Ljupco Todorovski, Saso Dzeroski: Inductive process modeling. Mach. Learn. 71(1): 1-32 (2008)  But this only for making the paper more self-complete.
Below are multiple reviews of a paper. The paper focuses on neural networks with ReLU activations. For these networks, the paper proposes bounds on the number of neurons needed to represent continuous piecewise linear functions.In this paper the authors provide bounds for approximating a continuous piecewise linear function by a ReLU function. The paper is very well written and motivated and provides a rigorous proof for improving bounds.The authors study the representation of continuous piecewise linear (CPWL) functions using neural networks with ReLU activations. They showed that, for Any CPWL function with q pieces or k linear components, it can be represented by a ReLU network.	Three reviewers agree that this work meets the bar for acceptance, rating it weak accept, weak accept, and accept. The work provides bounds for approximating continuous piecewise linear functions by ReLU networks and an algorithm. Reviewers praised the novelty and significance, and were positive about clarifications offered during the discussion period, particularly about the time complexity of the algorithm. Hence I am recommending accept. I encourage the authors to still work on the items of the discussion and the promised additions such as the open source implementation of their algorithm for the final version of the manuscript.
Below are multiple reviews of a paper. The manuscript considers the use leave-one-out error to analyse the generalization ability of one-versus-all multi-class classification models. As examples of such models, the authors review certain variations of neural networks. The mathematics is clear and convenient to read but the overall story is somewhat confusing due to the connections to neural networksThis paper investigates leave-one-out (LOO) error as a generalization measure for wide, deep neural networks using the correspondence to the NTK. The study of LOO error in deep learning is quite underexplored and could be a promising direction.The paper proposes to approach the generalization prediction problem in the domain of big neural networks using the classical notion of leave-one-out (LOO) error. The proposed approach to avoid computational burden based on the closed form calculation of LOO error/accuracy makes sense when connected to the view of neural networks as NTK.	This paper proposes to use LOO to characterize the generalization error of neural networks via the connection between NN and kernel learning. The reviewers find the new results interesting. The meta reviewer agrees and thus recommend acceptance.
Below are multiple reviews of a paper. This article is concerned with convergence guarantees of online stochastic gradient descent for a rather generic class of three layers neural networks. The main results state that in a proper limit of infinite width + vanishing learning rate, the dynamics of online SGD is proven to be tracked thanks a mean-field description.The paper provides global convergence guarantees for an unregularized feedforward three-layer NN. This is the first time global convergence is established for neural networks of more than two layers in the mean-field regime.This paper studies the behavior of a 3-layer fully connected network when the width of the network is large. The authors define a mean field regime and prove that the network's behavior under stochastic gradient descent converges to this regime for any finite time horizon.This paper studies some theoretical properties of three-layer neural networks (NNs) under the mean-field (MF) regime. The authors proposed neuronal embedding in order to study large-width neural networks. The global convergence of the MF limit is used to establish the optimization efficiency of the neural network.	This paper provides a global convergence guarantee for feedforward three-layer networks trained with SGD in the MF regime. By introducing the novel concept of neuronal embedding of a random initialization procedure, SGD trajectories of large-width networks  are shown to be well approximated by the MF limit, a continuous-time infinite-width limit (Theorem 3). Furthermore, under some additional assumptions the MF limit is shown to converge to the global optimum when the loss is convex (Theorem 8, case 1) and for a generic loss when $y=y(x)$ is a deterministic function of input $x$ (Theorem 8, case 2). The global convergence guarantee presented in this paper is based on less restrictive assumptions compared with existing studies. All the reviewers rated this paper quite positively, with less confidence however, seemingly because of mathematical thickness of the proofs. Although the reviewers did not manage to check every detail of the proofs, they agreed that the reasoning seems mathematically sound as far as they can tell. The authors response adequately addressed minor concerns raised by the reviewers. I am thus glad to recommend acceptance of this paper.  Pros: - Introduces the idea of a neuronal embedding, which allows establishing relation between SGD on large-width three-layer networks and its MF limit in a quantitative way with a less restrictive setting. - Provides a global convergence guarantee under the iid initialization, in the sense that if the MF limit converges it attains the global optimum. - Shows that the global convergence guarantee does not require convexity of the loss when a deterministic function is to be learned.  In particular, the uniform approximation property, rather than the convexity of the loss, plays a crucial role in proving the  global convergence guarantee (it allows translation of the vanishing gradient in expectation at convergence into the almost-sure vanishing gradient), which is a quite original contribution of this paper.
Below are multiple reviews of a paper. This work analyzes the effect of gradient descent training on the compositionality of the learned model. Experiments are conducted on three simple benchmarks to demonstrate that when gradient descent trained model would use redundant information and not generalize compositionally.This paper addresses the effects of gradient descent methods onto compositionality and compositional generalization of models. The authors claim that the optimization process imposes the models to deviate compositionality, which is defined with conditional variables of input and predicted output.The paper investigates what neural networks learn when trained with gradient descent. In a set of synthetic experiments it is shown that indeed GD learns to use all information in the input. This results in poor generalization ood when only a subset of it was relevant.This paper studies if gradient descent will affect compositionality generalization. It attempts to prove the results by information theory and demonstrated several experimental results. Unfortunately, I think the proof has mistakes, and the conclusion doesn't hold.	Dear Authors,  Thank you very much for submitting this very interesting paper.  This work analyzes the effect of gradient descent training on the compositionality of the learned model. Their main argument is that GD tries to use the redundant information in the data and, as a result, it doesn't generalize well. The paper then tries to show that theoretically and empirically with some simple experiments.  There is a general consensus among all the reviewers that this paper is not suitable for publication at ICLR. The authors do not entirely address most of the concerns raised by the reviewers during the rebuttal.   If the authors improve the clarity of the paper, making some of the propositions and theories more concrete and grounded in experiments as well, I would recommend them to resubmit this paper to a different venue since the premise of the paper is important and interesting.  Some of the reasons:  - The paper claims that the gradient descent can not ignore the redundant information without providing sufficient empirical results. Though the part that is not clear to me whether if it is a credit assignment or an optimization problem. I agree with R1 that it is not clear what type of new insights from the proofs.  - As R1 mentions, this paper's claim seems too strong and not supported by experiments.  - R2 finds part of the paper unclear and thinks that some of the paper's propositions and theories are either trivial or wrong. The rebuttal doesn't seem to be doing a good job in terms of addressing those concerns.  - R4 also is confused with the paper thinks that some of the theories are incorrect.
Below are multiple reviews of a paper. The paper proposes a generalization of the invariant risk minimization objective to the continual learning setting. The weaknesses of the paper are the scalability of the approach and the lack of theoretical guarantees for the ad hoc ADMM scheme.This paper extends the idea of invariant risk minimization (IRM) to the setting of continual learning in which environments are observed sequentially rather than concurrently. The resulting bilevel problem can be efficiently addressed using the alternating direction method of multipliers.In this work, the authors consider the problem of continual learning with distribution shifts. The authors propose a Bayesian extension of the IRM framework that allows sequential updates as the environments arrive. Several experiments were carried out on colored MNIST and its variants to show how the proposed scheme is better than existing continual learning methods and existing IRM frameworksIn its current form, I cannot recommend this paper for acceptance. The proposed solution is arguably not learning at all. The authors need to look at their experiment results in more detail and do some sanity checks.	The authors address the problem of learning environment-invariant representations in the case where environments are observed sequentially. This is done by using a variational Bayesian and bilevel framework.  The paper is borderline, with two reviewers (R2 and R3) favoring slightly acceptance and two reviewrs (R4 and R1) favoring rejection.  R4 points out that the current experiments do not do a good job of reflecting a continual learning setup and that simple modifications on existing IRM based methods could outperform the method proposed by the authors. The authors are encouraged to take into account the reviewer's suggestions to improve the paper.  R1 argued initially that the proposed solution is not learning at all since it has errors very close to random guessing. While the authors have improved their method in the revision, the results are still close to random guessing, which questions the practical usefulness of the proposed approach. Also, in the revision, the authors managed to obtain better results when their method is combined with Environment Inference for Invariant Learning (EIIL), but these results are secondary and not the main part of the paper.  The authors should improve the work taking into account the reviewrs' comments.
Below are multiple reviews of a paper. The authors have explored the capability of box embeddings to model hierarchical data. They have demonstrated that it provides superior performance compared to alternative methods, requiring less of the transitive closure.Box embedding can be applied to graphs that are not tree-like. The author set up experiments using the IsA relation (Hypernymy) and HasPART relation (Meronymy) in WordNet. The results show the effectiveness of box embedding.Box Embeddings represent an object as a rectangle in an n-dimensional space. This makes it possible to represent asymmetric relations (compared with symmetric cosine similarity in regular embeddings) The paper is elaborating on prior work on Box Embedding.	Reviewers unanimously appreciated this paper. Please do take into account their feedback to improve the paper. From our perspective, the paper is not written in a scholarly fashion: there is so much work on hierarchical models, learning embeddings of trees, and why not give credit to these people? Please expand your related work discussion and give proper context.
Below are multiple reviews of a paper. The paper is motivated by the gap in our understanding of the importance of curriculum learning in biological models vs machine learning models. The main issue I think is that the emprical experiments are too simple and far away from the state of the art ML techniques.The paper explores the mechanism of curriculum learning, specifically when will, or will not, the curriculum setting work. It investigates two kinds of demos, online learning dynamics, and batch learning, as well as proposes an elastic penalty regularization. The paper also validates the observation on CIFAR10, which further illustrates the investigation.This work introduces an analytical framework that eases the study of the effect of data curricula in teach-student networks. The benefits of the analytical solution are states as a) "free of finite size effects and stochastic fluctuation", and b) "their evaluation is very fast"	In this paper, authors provide an analytical theory of curriculum learning for an online teacher-student setting where a subset of features are relevant and are used by the teacher while a student might get distracted and use irrelevant features. In such a setting, the difficulty of examples can be captured by the variance in the irrelevant features. The insights from this analysis help explain existing empirical observations reported in prior work for effectiveness of curriculum learning as opposed to random-ordering and anti-curriculum learning in compute-limited regime. Further interesting connections to the literature on cognitive science are discussed in the paper.  Given the lack of theoretical basis for curriculum learning, reviewers are in agreement that this paper is in-time and impactful for the ML community and they all recommended accepting the paper. However, during the discussion period it became clear that this recommendation was based on the promise of authors to revise the paper which never happened during the rebuttal period.  My final recommendation is to accept the paper based on the authors' promise that the final version will include all changes promised by authors in their response to reviewers. Although there is no formal conditional acceptance mechanism, the authors should view this as a conditional acceptance based on taking their word that they will revise accordingly (see the list of changes below). I will check the camera-ready version and call-out anything less than that.  **List of changes promised by authors (quoted from their response)**  **Authors' response to reviewer Cgtb:**  1- "Unfortunately, implicit curricula cannot be directly studied within our framework, since we always assume the hardness information is completely disclosed. Considering a pseudo-labeling step before the actual learning stage would likely make the (already involved) computation unfeasible. Empirically this procedure has been investigated in [e.g. https://arxiv.org/abs/1812.05159, https://arxiv.org/abs/2012.03107] and, limiting our interest in the generalization aspect, this heuristic does not seem to induce a sizeable improvement. We will include this discussion in the revision." 2- "We mean an algorithm that explicitly depends on the curriculum, for instance by changing its objective function when example difficulty changes. That is, a curriculum aware algorithm would adapt the learning process in order to account for different levels of difficulties in the data. A simple way of implementing this is to modify the training loss, as proposed in this paper. Other approaches may involve adapting the optimization algorithm as proposed in https://proceedings.mlr.press/v139/ruiz-garcia21a.html, or possibly modifying the architecture https://www.sciencedirect.com/science/article/pii/0010027793900584. A key message emerging from our work is that standard algorithms do not dramatically benefit from curriculum, and we believe curriculum-aware algorithms may be the way forward. We will include a clear definition and discussion in the revision."  **Authors' response to reviewer S1ip:**  1- "The first point raised by the reviewer is the object of current investigations (see answer below). We will add more details on the CIFAR experiments in the revised version."  2- "We agree that this appears counter-intuitive. We also have hoped for greater intuition on this point, but we do not have a simple explanation for this phenomenon. This result is what appears from solving the equations and it was checked in the numerical simulations. A possible intuition could be that, in some settings, the large amount of noise contained in the hard data will always be too disruptive for effective learning. Thus, leaving the “clean” data for last could allow the model to better exploit the easy data. We will add this possibility to the revision. Even without a clear intuition, our contribution here is to show, in an identical setting and without finite size effects, that both anticurriculum and curriculum can indeed outperform the baseline."  **Authors' response to reviewer S1ip:**  1- "Overall, the analytical solution is between 2 and 6 orders of magnitude faster. We will add this approximate speed-up factor and discussion to the supplement (or if space allows, the revision)."  2- "The large input limit means that the input size N and the dataset size M go to infinity with finite ratio \alpha=M/N. This is an important point that must have gotten lost during the iterations, thank you for catching this. We will reintroduce it in the revised version."  3- "Figure 1 is based on notations and definitions introduced in section 3 and is not easily understood at the point it is presented. Reply: We will replace the image with explicit notation."  4- "Line 143: "starting from a large initialisation", I assume it means the random initialization scale of the student or teacher network. It is not entirely clear. Please include more details about this initialization. Does it use a normal random distribution? Reply: Yes, we use a normal distribution with a fixed variance. When we refer to large/small initialization we mean large/small initial variance. We will clarify this in the revised version."  5- "Figure 1: "The curriculum boundary lies at α = 1/2". What is the curriculum boundary? It is never defined. The abstract talks about "curriculum boundary consolidation", but it is not further elaborated. Reply: We mean the switching point between the two levels of difficulty. We will clarify this."  6- "Half-way through the paper section numbers stop being used. What I assume are sections 5 and 6 do not have numbers. And I am not sure if the subsections of Section 4 belong there. Reply: We will add 5 and 6 to the last two sections."  7- "Figure 3c "Accuracy hard samples." is not an accurate title. It is accuracy of all samples, easy and hard. It's just that anti-curriculum performs best, which is influenced by hard samples. Reply: We will replace it with just accuracy."  8- "The figure captions are inconsistent in the uses of (a), (b), (left, center, right), and (top, bottom). For example Figure 3 says (a), (b) and then "the right panel". Reply: We will use only the a,b,c notation."  9- "As stated in the paper, the answer does depend on the setup and in principle we would expect different behaviours for non-convex models. In particular, the presence of different basins of attraction towards different minima would suggest that initializing close to a good one would produce a performance improvement. However, note that empirical results in the ML field are not showing clear signals in this direction. A possible explanation is that relying on memory effects in the learning dynamics would require one to hit a sweet spot in the learning rate value and in the number of training epochs, and this seems hard to be achieved consistently. For this reason, we speculate that explicitly enforcing this memory by altering the loss with the curriculum information could be useful even in these settings. We will further emphasize that this statement about memorylessness applies only to our setting."  10- "We thank the reviewer for pointing out several elements that were missing in this version: we will make sure to include them in the revised version of this paper."
Below are multiple reviews of a paper. The authors challenge the CNNs robustness to label noise. When the label noise is class dependent, more realistic scenario than class independent noise. This work confirms the commonly admitted fact that CNNs learn features that are visually meaningful. There is no significant novelty in the paper.This paper attempted to analyse the performance of CNN models when data is mislabelled in different manners. It carried out several good experiments as a good start, but several points are not comprehensively studied and analysed.In learning with noisy labels, there are two basic models. Most research focuses on class-conditional noise (CCN) model. Recent research explore a bit on instance-dependent noise (IDN) models. This paper demonstrates that CNNs are more robust to class-relevant label noise.	The paper analyzes the performance of CNN models when data is mislabelled in different manners.  The reviewers and AC note the critical limitation of novelty of this paper to meet the high standard of ICLR.  AC thinks the proposed method has potential and is interesting, but decided that the authors need more works to publish.
Below are multiple reviews of a paper. The task is a challenging one and the authors propose a hierarchical optimizer similar to Wichrowska et. al. I wish the authors invested more thought into the architecture of the optimizer beyond assimilating features of previous work. The sub optimal performance on imagenet is concerning.This paper attempts to address the fundamental barriers of learned optimization. Authors identify three barriers: computational requirements, number of training tasks and lack of inductive bias. A “large-scale” evaluation and comparison of learned optimizers is then carried out using many multi-core CPUs.The goal of a learned optimizer is to replace a human-designed optimizer with a machine-designed one. The goal is to increase the efficiency of a machine by increasing the number of tasks that can be done.	The paper aims to address several challenges in learning neural network-based optimization algorithms by increasing the #unrolled steps, increasing the #training tasks, and exploring new parameterizations for the learning optimizer. The authors demonstrated the effectiveness of applying persisted Evolution Stratergies and backdrop through over 10,000 inner-loop steps can improve the performance of the learned optimizer. Empirical experiments showcased incorporating LSTM to the previous state-of-the-art improve their training performance.   There are a lot of interesting ideas in the paper. However, packaging them together and only glance over each idea briefly unfortunately dilutes the contribution and the novelty of the work. There are still some major concerns echoed among the reviewer:  1) The proposed hierarchical optimizer seems interesting. It is one of the major contributions of the paper. But, its architecture was only briefly mentioned in Sec 3.3. Its motivation, implementation and the corresponding engineering choices remain unclear by just reading the main text. Some of the details were discussed in the appendix but it would be of great interest if authors could give some intuition on which subset of the tasks the proposed architecture gives the most improvement / failure among the 6000 tasks.  2) Training the optimizer on a diverse set of tasks is crucial for the learned optimizer to generalize. One of the paper's contributions is to further expand the task dataset from the prior work Metz et al., (2020). The authors have conducted very thorough experiments on this new dataset, which is amazing. I would argue there are even enough results for another standalone paper. However, there is surprisingly little detail on how the newly proposed dataset differs from the prior TaskSet dataset. What are the new optimization problems? How are they different from the family of tasks in TaskSet? A TSNE plot of the tasks similar to Figure 1 from Metz et al. (2020) could provide more intuition for the reader and highlight the contribution.   Overall, if the authors could provide more insight into their experiments and the proposed methods, it would help the readers greatly to see the novelty and the contribution of the paper. The current version of the paper will need additional development and non-trivial modifications to be broadly appreciated by the community.
Below are multiple reviews of a paper. Adversarial attacks are semantically constrained as opposed to being constrained by an artificial norm ball. The emphasis given to the result that adversarial training improves clean performance isn't fully justified, as unrealistic images were controlled for by limiting the number of iterations.This paper proposes a mechanism to generate adversarial examples by applying latent variables level manipulation. It is proposed for general classification tasks such as object classification, object detection and semantic segmentation. The experimental results show not only qualitatively confusing human vision but also quantitatively improve the performance on testing clean images.The paper presents a new method for generating unrestricted adversarial examples. Based on Style-GAN, this work separates stylistic and noise modifications. The method is evaluated with three tasks, classification, semantic segmentation and object detection.The paper proposes a method of generating adversarial samples to enhance classification performance. The new classifier is then trained by adding these samples to the existing training dataset. The method achieved good performance because the distributions of the samples generated in this way is closer to the distribution of the real images.	The paper received two borderline accept recommendations and one accept recommendation from three reviewers with low confidence and a reject recommendation from an expert reviewer.   Although all reviewers found that the paper addresses an important and challenging problem of semantically constraining adversarial attacks as opposed to constraining them artificially by an artificial norm ball. However, during the discussion phase it has been pointed out that there were some important weaknesses indicating that the paper may need one more evaluation round.  The meta reviewer recommends rejection based on the following observations.   In terms of evaluation, while it is understandable the authors were unable to compare to Gowal et al. due to the lack of publicly available implementation, showing Song et al.'s adversarials hurt performance and and are farther than the image manifold has been found puzzling, as this was done by Song et al. only to keep human prediction the same while changing model prediction. Furthermore, the paper did not contain a user study similar to Song et al. for a fair comparison Finally, the discussion revealed that the comparison to "norm-bounded adversarial inputs" may not have clarified whether this experiment faithfully demonstrates an advantage for the contribution as the norm could be contained to a point where accuracy is not reduced, and the discussion on the certified defense being "broken" was inconclusive.
Below are multiple reviews of a paper. This paper focuses on the discontinuities (aka. holes) in the latent space of VAE. The author proposes a heuristic-based BFS algorithm for highly efﬁcient latent space searching. Comprehensive experiments on the language generation task show how the latent holes harm the performance of VAEs.The paper is concerned with discontinuities in the latent space of Variational Autoencoders. There are three main contributions: A theoretical analysis of two existing algorithms for finding holes. An empirical analysis of the density of latent holes in different types of VAEs.This paper studies the holes within the latent space of text VAEs. The major contribution is a hole detection algorithm, which firstly projects the latent representations to a principle subspace, then performs tree-based BFS to detect holes. This paper suffers from its unclear presentation of the algorithm (with many mistakes), concerns regarding algorithm scalability	This paper studies discontinuities (i.e., holes) in the latent space of text VAE. Analysis of previous hole detection methods are conducted, and a new efficient hole detection algorithm is proposed. It is an interesting work, but the paper in its current form has a few weaknesses/flaws regarding the proposed algorithm, experiment designs and the resulting conclusions. Reviewers have made various constructive suggestions, which the authors acknowledged.
Below are multiple reviews of a paper. The paper mainly deals with two cases, end-to-end training efficiency and data-addition training efficiency. The major findings are as follows. Random search might lead to unnecessary training when loss does not converge.This work proposes two protocols for evaluating and comparing the quality of different optimizers. It points out that some existing, commonly used ways of comparing optimizers may over- or under-represent the amount of time that hyperparameter search can take. To fix this, it proposes using the Hyperband algorithm to guide the hyper Parameter searchThe paper proposes a new benchmarking protocol for optimizers in deep learning. The main argument for replacing random search with HyperBand is that HyperBand resembles human tuning behavior much more closely. However, the paper provides little detail on the nature of the study.The paper makes the argument that existing evaluation procedures either over emphasize the finding of optimal hyperparameters or under-evaluate the performance of an algorithm. The proposed procedure evaluates optimization algorithms by using the hyperband hyperparameter optimization algorithm.	This paper was referred to the ICLR 2021 Ethics Review Committee based on concerns about a potential violation of the ICLR 2021 Code of Ethics (https://iclr.cc/public/CodeOfEthics) raised by reviewers. The paper was carefully reviewed by two committe members, who provided a binding decision. The decision is "Significant concerns (Do not publish)". Details are provided in the Ethics Meta Review. As a result, the paper is rejected based Ethics Review Committee's decision .  The technical review and meta reviewing process moved proceeded independently of the ethics review. The result is as follows:  This paper studies the problem of evaluating optimiser's performance, which is important to show whether real progress in research has been made. It proposes several evaluation protocols, and used Hyperband (Li et al. 2017) to automate the tuning of each optimiser in the bench-marking study. Evaluations have been conducted on a wide range of deep learning tasks, and the paper reaches to a conclusion that none of the recently proposed optimisers in evaluation can uniformly out-perform Adam in all the tasks in consideration.  Reviewers agreed that the evaluations are extensive, however there are some shared concerns among reviewers. The paper argues that manual hyper-parameter tuning by humans is the right behavior to target for, which is the motivation to use Hyperband as an automating tool, and there is a human study to demonstrate that Hyperband tuning resembles human tuning behaviour. Some reviewers questioned about this desiderata choice that favours human tuning behaviour, also concerns on how the human study is conducted (and to what extend the human study itself is reflective enough for the human tuning behaviour in general).  Personally I welcome any empirical study that aims at understanding the real progress of a research topic, and I agree it is important to make rigorous automation tools in order to enable such a large scale study. Therefore, while the presented results are extensive, I would encourage the authors to incorporate the feedback from the reviewers to better examine their assumptions.
Below are multiple reviews of a paper. This paper presents UViM, a "unified modeling approach for vision using learned guiding codes" The model is trained on three different tasks (colorization, monocular depth estimation and panoptic segmentation) and achieves reasonable performance on all of these.The paper proposes UViM, a unified modeling approach for vision tasks with learned guiding codes. The approach has two stages. It first learns a discrete code from the GT to guide the prediction, and try to predict the code from input in the second stage.This paper presents an approach for computer vision tasks involving large output spaces overlaying the image. The paper proposes to learn a "guiding code" that represents the image overlay over a latent space of discrete tokens. The results are strong, especially for not being very optimized for these diverse vision tasks.	Three reviewers provided positive reviews which were further strengthened post discussion. They agreed that that the motivation was strong, the model was novel and the paper was well written. They appreciated the ablations provided by the authors and found the results compelling. The main concern by the reviewers was a missing experiment which was provided by the authors in their rebuttal, and was appreciated by multiple reviewers. In summary, the reviewers are unanimous in their support of this paper. I agree with their reviews and I recommend acceptance.
Below are multiple reviews of a paper. This paper studies the problem of task grouping by using an efficient and effective meta-learning framework. Experiment results conducted on multiple multitask datasets show significant improvement over state-of-the-art task grouping algorithms.The paper introduces a meta-learning method to learn to predict the transfer gains for each task grouping in a Multi-Task Learning problem. This is based on the assumption that, while the number of task combinations is huge, the data lies in a low-dimensional manifold (manifold hypothesis) and thus can be learned.This paper introduces a simple yet effective meta-learning framework for multi-task grouping. The main goal is to avoid computing the performance gains of multi- task learning (MTL) over single-task learning (STL) for all possible task combinations, which is intractable for a large number of tasks.The paper proposes a method for multi-task grouping. It trains a model that predicts performance gains as a function of task combinations. To save the training cost, the paper proposes an active learning algorithm that selects task combinations to use for training.This paper researches on the task grouping problem in Multi-task Learning (MTL) Task grouping matters MTL’s performance and has gained much attention recently. The proposed method has achieved superior performance.	The overall idea of using a meta-learning network with an active learner for grouped multi-task learning is interesting. The experimental results provided in the original submission and rebuttal are extensive to verify the effectiveness of the proposed method. A major limitation of the proposed method is the high computational cost, especially when each task has its own dataset.   Overall, this is a well-written paper that presents an interesting idea for multi-task learning.
Below are multiple reviews of a paper. This paper proposes a RecourseNet, which learns to instance-dependently recourse to environments so that the learner gets better samples at training time and the predictor is well informed which instance to recourse with which environments. The experimental results demonstrate the efficacy of Recourse net over simple baselines.The authors propose using a recourse mechanism that allows a model to recommend to its human users how they could improve the predictions of the model. One of my main concerns is around the idea of recourse/resampling. The authors state that this could be useful in medical settings. But is it really?The paper proposes a mechanism, termed RecourseNet, to identify and modify input instances so as to achieve a better classification outcome from a classifier. These modifications are performed in the latent space of environment-settings.The paper tries to improve the prediction accuracy through a different perspective: recourse on instance environment. The algorithm can be deployed on some online diagnosis platform and provides hints/tips to the user about how to take a clear image that can make the diagnosis more accurate.	The paper proposes a recourse approach that recommends how to improve performance on instances by modifying their environment. The paper is well motivated and provides a novel approach that is empirically demonstrated to be useful, though the empirical evaluation is limited. Reviewers agree that this paper addresses an important question that has more recently started to get attention, and that the contribution is novel, creative and significant. The quality of the write up could be improved, and I encourage the authors to do so for the camera ready version.
Below are multiple reviews of a paper. This paper investigate how to design simulation environments so the agent trained with them can master social rules. The paper is well written and easy to read and understand. The experiments are solid and well defined.The paper proposes to learn traffic rules via multi-agent RL (MARL) from observations rather than hardcoding the rules into the algorithms. Authors promise to release a suite of 2D driving environments for future MARL research in self-driving.This paper proposes a bilevel MARL method that can learn road rules and conventions implicitly without hard coding. It is quite interesting to see a simple and straightforward idea that is effective in this task setting. The clarity and completeness of writing could be significantly improved.The MDP that results from this work is very useful for future research. Currently, there are very few simulators that encode complex traffic rules. The possibility of new simulators resulting from this MDP is exciting and useful to encourage and promote research.	This paper shows how "road rules" (e.g., implicit designation of fast lanes on a highway) naturally emerge in a multi-agent MDP. The paper shows that interesting traffic rules do emerge, and it presents a detailed analysis of the factors that lead to this emergence. The paper is complemented by documented source code, with the aim to encourage the community to further work on the topic.  The reviewers agreed that this is original work, and appreciated its simplicity. Two concerns that were recurrently voiced were that 1) there is no algorithmic innovation and 2) there is no comparison to baseline models, or more generally a better placement in the context of existing literature.  The authors provided a detailed and, to my eyes, convincing response. With respect to the two concerns above, I would go as far as saying that 1) (no algorithmic innovation) is a feature, not a bug. The paper is interesting exactly because it studies emergent phenomena after framing multi-agent driving as a standard RL problem. Concerning 2) (lack of baselines), it seems to me somewhat besides the point: The paper is not claiming state of the art on some benchmark for a new algorithm, but studying how certain implicit rules emerge in a given setup. In this sense, as the authors point out, rather than looking at alternative baselines, it is informative to look at which aspects of the setup contribute to rule emergence, which is what the paper does.  Although I realize that in proposing this I am going beyond the reviewers' ratings, I found this to be an original and exciting paper, that I would strongly like to see accepted at the conference.
Below are multiple reviews of a paper. Open Set Learning is a task of classificing data over the known categories but that are OOD. There were no 3D dataset or benchmarks that attempt to solve the Open Set problems.The authors introduce a novel open set 3d learning testbed based on 3 existing 3D datasets, with several experiment settings. They also provide extensive comparisons on these benchmarks and give detailed analysis over them.This paper focus on building a benchmark on OOD detection task for point cloud. It is the first benchmark for open set 3D learning. The proposed benchmark considers two tracks: synthetic and real.The paper presents a benchmark for out-of-distribution detection on 3D point clouds. The authors benchmark multiple OOD methods and reveal room for future improvement. The paper tackles an important problem that has been largely ignored by the research community.	This work for the first time proposes to study the task of Open Set 3D Learning for 3D point cloud data. The authors have conducted extensive experiments under different settings with varied category semantic shifts and provided comprehensive experiments benchmarking the popular methods from 2D open set learning which leads to some important conclusions about the transferability of the 2D methods to the 3D settings. The contribution of the work is clear and novel. The AC believes the paper provides important findings for the community to be aware of.  During the rebuttal, reviewers raised up concerns regarding the lack of real-to-real setting and the missing of some evaluations/metrics. The authors have added the requested materials in the revised paper, which addressed most of the raised issues. While there are some minor questions asked by the reviewers, the authors have carefully addressed them and the AC does not think they are major issues preventing me from accepting this paper. The final scores are 3 accepts and 1 reject, and two reviewers confirmed their final decisions after rebuttal. The reviewer who gave the reject review didn't come back for responding to the authors' rebuttal and the AC think the authors have addressed his/her questions well.  Therefore, the AC is very confident in recommending an acceptance of this work to the track. But, please carefully revise the final paper for the camera-ready submission, based on the reviewers' suggestions. Congratulations!
Below are multiple reviews of a paper. This paper proposes to tackle unsupervised domain adaptation. It uses a Knothe-Rosenblatt transport approach which applies a one-dimensional optimal transport to all conditional marginals of one distribution into another. The method uses an autoregressive density estimation from the RNADE algorithm based on a Gaussian Mixture strategy.The authors consider the unsupervised domain adaptation (UDA) by using the Knothe-Rosenblatt transport. They propose to estimate the density of both source and target data via autoregressive modeling. The authors should discuss the experimental results in detail.A new KRDA method is proposed. It exploits autoregressive model using a mixture of Gaussians. Experiments on both synthetic and real-world datasets are done.The paper proposes Knothe-Rosenblatt Domain Adaptation (KRDA) for unsupervised domain adaptation with covariate shift. The authors evaluated the proposed model on synthetic data (mixture of Gaussians, Inter-twinning moons), and real data (Hepmass, Amazon dataset)	This paper proposes to address the problem of domain adaption using Knothe-Rosenblatt transport withe the method denoted as KRDA . The main idea is to perform density estimation of the different distributions with mixture of Gaussians and then estimate a  an explicit mapping between the distribution using  Knothe-Rosenblatt. Experiments show that the proposed method works well on toy and real life datasets.   The paper had low score during the reviews (3,3,3,3). While the reviewers appreciated the idea, they felt that the originality of the method is not well justified compared to a number of existing UDA approaches using OT. Also the reviewers noted several important references missing and that should also be compared during the numerical experiments. A discussion about the limits of the method in high dimension would also be very interesting.  The authors did not provide a reply to the reviewers' comments so their opinion stayed t same during the discussion. The paper is then rejected and the AC strongly suggests that the authors take into account the numerous comments from the reviewers before re-submitting ton a new venue.
Below are multiple reviews of a paper. Value-Driven Hindsight Modelling proposes a method to improve value function learning. Authors train the standard value function (which does not have access to future information) to predict the features which the highsight value function learns to summarize the value relevant parts of the future trajectory.The paper proposes a way to learn better representation for RL by employing a hindsight model-based approach. The authors claim that this extra information can be used to learn a better representation in some problems and lead to faster learning of good policies.The paper presents a new model-based reinforcement learning method, termed hindsight modelling. The method works by training a value function which, in addition to depending on information available at the present time is conditioned on some learned embedding of a partial future trajectory. A model is then trained to predict the learned embeddedding based on information at the current	I agree that it is an interesting idea and shows promise. However, given the current exposition and investigation done in the paper about the approach, I feel that a 'weak accept' is the right decision for this manuscript. I hope this doesn't deter the authors from working on this in the future, and I hope to see a more polished version of this manuscript out soon :)   Thanks!
Below are multiple reviews of a paper. This paper proposes a new reward shaping method, EAGER, in Language-guided reinforcement learning (RL) By extracting auxiliary Question Answering (QA) tasks, the agent is given intrinsic rewards based on how the generated trajectories could help answer these questions. The authors claim that such auxiliary tasks can be designed without engineer interventionsThis paper presents a simple but novel reward shaping method for language-conditioned RL. The paper mainly proposes the auxiliary objectives for question generation and question answering models. Then they calculate the intrinsic reward which is proportional to its confidence in its answer.The paper proposes an auxiliary reward scheme (EAGER) for instruction following RL (BabyAI framework) based on question generation (QG) and answering (QA) Concretely, QG is based on masked word modeling of the instruction, and QA is pre-trained with demo instructions and trajectories and fixed whenIn this paper, the authors proposed a reward shaping method for language-conditioned RL. The authors proposed to generate a set of questions based on natural language instructions, and then evaluate how likely the current trajectory answers the questions.	This paper presents a language-guided auxiliary reward mechanism based on generating Q&A pairs based on agent trajectories and rewarding the agent for producing trajectories that yield correct answers from an answering model. The reviewers broadly found the paper compelling and convincing, and thus I am happy to follow their general consensus in recommending acceptance.
Below are multiple reviews of a paper. This paper proposes a dynamic parameter sharing framework LDSA. LDSA divides the agents into up to $k$ groups according to their action-observation histories. Only the agents within the same group share the same parameters.Algorithm for efficiently training diverse abilities/policies in cooperative multi agent tasks. It learns to decompose a task into subtasks, match agents to a subtask based on their action-observation trajectory. It does better than QMIX, ROMA and RODE on the harder tasks on the StarCraft II microman LDSA assumes agents' skill specialisation is required to solve subtasks. LDSA learns to assign agents to subtasks by: Creating identically sized representations of subtasks and agents' abilities. Match agents and subtasks according to the similarity of their representations. Learning a policy that agents need to follow for each subtask.The paper proposes an algorithm to learn dynamic subtask assignment (LDSA) in cooperative MARL. It uses a subtask encoder to construct a vector representation for each subtask. Then, it proposes an ability-based subtask selection strategy to dynamically group agents into similar subtasks.	This paper proposes a method to dynamically group agents with similar representations and assign subtasks to each group so that they can effectively share parameters among agents within the same group while specializing across groups. The results on StarCraft Micromanagement benchmark and Google Research Football domain show that the proposed method outperforms relevant baselines including QMIX, ROMA, and RODE.  The reviewers found that the idea is interesting and technically sound, and the paper is very well-written. Although there were several concerns about the lack of baselines (CDC) and the lack of challenging benchmarks, the authors addressed most of them during the rebuttal period by updating the results with additional baselines, an additional benchmark (Google Research Football), and additional ablation studies. As a result, all of the reviewers agreed that the result is significant enough to be presented at NeurIPS. Thus, I recommend accepting this paper.
Below are multiple reviews of a paper. CNN.com will feature iReporter photos in a weekly Travel Snapshots gallery. Please submit your best shots of New York for next week. Visit CNN.com/Travel next Wednesday for a new gallery of snapshots.This paper builds a BERT classifier for word-level polysemy of Korean language. Adverbial positions such as -ey, eyes, and –(u)lo are involved in the investigation. There are three findings during the experiments, if there are more functions then the classification accuracy is lower.The paper presents a study of training a BERT-style model on the task of function identification for 3 different Korean adverbial postpositions(ey, eyse and (u)lo) Strengths of the paper: The task is novel and it is good to see an analysis on a lesser studied language. WeaknessesThe classification problem concerns polysemy in Korean: for each adverbial postposition (e.g. -eyse), classify the use of the postposition in a given sentence. The proposed method is to use BERT in replacement of static word embeddings.This paper introduces three Korean adverbial postpositions (-ey, -eyse, and –(u)lo) with examples. This paper presents a BERT-based classification to predict a function of an adverbials postposition. The paper also presents a visualization system to interpret the predicted results.	This paper presents a study on identifying word-level polysemy in Korean based on a language-specific BERT model.  It is always very good to see language-specific studies especially in non-English scenarios.  However, as the reviewers point out, there could be significant improvements to the experimental design of the paper (see comments from reviewer eqSx) and also the HCI aspects of the visualization setup (see comments from reviewer MV2W) to transform it to an acceptable ICLR paper.
Below are multiple reviews of a paper. The paper considers the construction of adversarial examples for a new learning paradigm which has practical relevance. A number of possible threat models under the few-shot learning paradigm are considered. The considered attack is found to be effective against a variety of models and on a benchmark datasets.The paper proposes a novel poisoning attack which is tailored for few shot learning classifiers. The main contribution of the paper is a poisoning attack, however authors talk quite a bit about adversarial examples.Recommendations on how to improve the paper: Add clear discussion of goals of the adversary.Adversarial Support Set Attack is an attack that perturbs the support set samples under the few-shot paradigm. It makes use of a seed query set to find adversarial samples that maximize the loss on this set, with the hope that it will generalize to any query sample. Empirical results show that this attack isThis work proposes adversarial attacks on few-shot learning systems. Evasion attacks are developed which can be viewed a simple applications of PGD/FGSM. The authors then apply evasion attacks to a support dataset, such that the n-shot classifier's loss is maximised.	This paper presents a method for attacking few-shot learners with poisoning a subset of support set. I believe this might be the first work to address adversarial examples for meta-learners (or few-shot learners), which is a timely issue. A common concern raised by most of reviewers is in the novelty of this work, in the sense that the method builds on a basic attack strategy (such as PGD) in the standard adversarial example setting. Authors responded to this, summarizing what's new in this paper. Episodic training for few-shot learners requires consuming support set (instead of single training data point). It is a nature of most meta-learning methods. Thus, it is easily expected that the adversarial attack for few-shot learners is naturally extended to poisoning a support set (or its subset) instead of a single data point. Certainly such extension may entail a new strategy. However, during the discussion period with reviewers, concerns on the novelty of such extension still remains. In particular, the few-shot learning algorithms do not allow big changes in the original model. The algorithms analyzed are prototypical networks that do not utilize fine-tuning, and MAML that fine-tunes for a small number of pre-fixed steps. So the transfer of adversarial samples may not be counted as a major contribution.
Below are multiple reviews of a paper. The paper proposes a mechanism to perform fairness aware feature selection. The critical assumption is that the sensitive attribute does not have any ancestors. The paper is easy to follow.This paper works within a structural causal modeling (SCM) framework for defining fairness of algorithms. Previous literature defining fairness this way assumes knowledge of the relevant SCM, which is a key limitation. The current paper relaxes this assumption to some specific contexts where the SCM is partially known.The paper is well-written and well-organized. The motivation is clearly described and the contribution is also clear. There is a technical lemma that seems flawed. The limitations of the paper have been addressed.	This paper has divergent views in the sense two reviewers have given positive assessments (6 and 7) while the other reviewer has given a negative assessment (score of 3). This paper also had very 'heavy' discussions between the reviewer with negative opinion and the authors.  First of all I would like to thank the reviewer involved in patiently discussing with the authors dedicating valuable personal time.  Let me start with the aspects all reviewers *more or less agree* on :  a) The main technical piece is an efficient algorithm and provable guarantees for identifying definite non-descendants and definite descendants from an MPDAG - maximum partially directed acyclic graph - the equivalence class of Causal DAGs one obtains after incorporating any arbitrary side information. Previous such results were known for CPDAGs and they don't carry over to MPDAGs. Therefore it is a non trivial result (specifically Lemma 4.4 ). So all reviewers agree that finding definite non descendants in Equivalence classes that also include side information is a very solid contribution.    b) The aspect in which reviewers had divergent opinion is this:  the paper's claim to be able to train counterfactual fair classifiers leveraging the result from [Kusner et. al 2017] that any function of non-descendants is counterfactually fair.  One of the reviewer's strong contention is that in most fairness datasets, most variables that are highly predictive of outcomes will also be downstream of sensitive attributes like race etc.. and therefore relying only on non-descendants is not exactly a realistic application. Authors cited their empirical structure learning results that show very few descendants and comments from Kusner et. al 2017 paper to bolster their case. Reviewer responded by citing alternate statements from the same paper etc..   *My opinion* is that in a specific context when fairness with respect to a specific sensitive attribute is desired, there are also often other features that has no causal relationship with the sensitive attribute but has a *correlation* (Examples include age and race, race and gender etc.. ).  To cite a recent reference please see Example 15 in https://arxiv.org/pdf/2207.11385.pdf (this reference is recent and I am *not* expecting authors or anyone else to have known this - it is just to demonstrate the point). The example shows *testable* correlations between sensitive attributes and non-descendants in COMPAS and Adult datasets.   This shows that a) neither causal sufficiency  nor b) the non-existence of non-descendants are realistic . In fact, spuriously related non-descendants give rise to spurious bias which may not be an object of correction for fairness (broadly speaking). This shows that causal sufficiency is a strong assumption (as authors have assumed) and also non-descendants do exist.  c) Another point to be noted is that Kusner et. al. 2017 do consider confounded models unlike the authors. Once you view exogenous, endogenous (observed) variables and sensitive attribute as one full deterministic system, their point is ALL exogenous + non descendant endogenous variables are "non-descendants" topologically and therefore could be used. They did not imply non-descendants endogenous 'only' as the authors contend in their discussions.  In fact, the algorithm section in Kusner et. al. 2017 - advocates for sampling Exogenous from some side information (level 2 and 3 information) and forming a predictor as a function of exogenous *and* non descendant endogenous variables.  Therefore, reviewer has a valid point on the discussed aspect as well. Authors may want to pay attention to this.   *In summary*: Authors' contention that Kusner et al 2017 paper advocates for non-descendant endogenous as their main sufficient criterion appears to be not exactly correct. However, non-descendants and their confounding with sensitive attribute is a more realistic model. However, authors core technical structure learning contribution is also noteworthy.   If this line of work is to be pursued where one could find non descendants even under limited confounding (between sensitive attributes and non- descendants - a mild violation of causal sufficiency) - it would be a step towards obtaining counterfactually fair classifiers (although even such a classifier would have to sacrifice a lot on accuracy depending on how many descendants one observes).  However, even positive reviewers have opined that main strength of the paper is a solid structure learning result that identifies non-descendants in a fully observational setting.  *Recommendation*: In the spirit of not blocking valid ideas that are fundamental and also the fact that one cannot always make the weakest set of assumptions to make progress, I tend to favor acceptance. A *very strong* suggestion to authors - I would place structure learning as the centerpiece and motivate it by a need to learn non-descendants (in the general sense) motivated by Kusner et al 2017. Authors also need to highlight Fair relax - a relaxation that they have proposed that uses possible descendants and definite non descendants to predict - it seems to be closer than other approaches to counterfactually fair one and therefore removing the singular focus on (as the discussions would have one believe) only observed definite non-descendants.
Below are multiple reviews of a paper. The paper studies how randomly initialized ReLU networks split the data into linear regions. It is based on Hanin and Rolnick [2019a] but focuses on data with low dimensional manifold structure. The experiments are insightful and support the intuitions of the theory.This work builds upon previous work by Hannin and Rolnick, which establishes the linear regions in deep networks. Bound on the number of linear regions and the distance to boundaries of these linear regions on the data manifold are derived.The paper is mainly an extension of the previous Hanin and Ronick paper onto the submanifold case. While the framework here is not new, I believe it is still a novel result. I am personally not a researcher in this field, and I would refer to other reviewers for further evaluation.The paper continues the work of Hanin and Rolnick [1,2] on the expressivity of PieceWise Linear (PWL) Deep Neural Networks (DNNs) The main contribution involves improving the theoretical bounds of both the number of linear regions and the average distance to the linear boundaries defined by a PWL	The paper studies the number of linear regions cut out by a randomly initialized deep network, for data with low-dimensional structure (manifold structured data). The main results pertain to the density of linear regions and the average distance to the boundary of a linear region: these results take the same form as in the Euclidean case (with distance inversely proportional to the number of neurons), but depend on geometric properties of the data manifold — in particular, its dimension and curvature. Reviewers generally appreciated the relevance of the paper’s setting: data arising in applications often have low-dimensional structure, and understanding how deep networks interact with the structure of data is an important research direction. At a technical level, the paper builds on techniques of [Hanin and Ronik 2019], but extends these results to manifold structured data. Questions raised by the reviewers include the role of curvature and input dimension in the results and the interpretation of real data experiments. After interacting with the authors, the reviewers considered their main concerns about the paper to be well-addressed. The AC concurs, and recommends acceptance.
Below are multiple reviews of a paper. The authors of the paper show that poisoned classifiers are broken in a fundamental way. They are vulnerable to attacks based on the original trigger image, and also to attacks by adversaries who do not know the originaltrigger. The paper is well written, all claims are easy to follow, and the authors incorporated user studies into the evaluation.The authors showed that with some post-processing analysis on a poisoned classifier, it is possible to construct effective alternative triggers against a backdoor classifier. The process of generating alternative triggers and finding effective triggers for each backdoor attacker is mainly manual and needs human intervention.Backdoor-poisoned machine learning models can also be vulnerable to alternative triggers. Two methods are proposed to generate alternative triggers that can cause the poisoned machine learning model to misbehave.The authors claim that "anyone with access to the classifier, even without access to any original training data or trigger, can construct several alternative triggers" Such a choice is unsual in the adversarial machine larening problem.	The paper argues that a successful backdoor attack on classifiers is connected with further fundamental security issues. In particular they demonstrate and not only an original backdoor trigger but also other triggers can be inserted by anyone with access to the classifiers. Furthermore, the alternative triggers may appear very different from the original triggers, which confirms the claim in the paper's title that such classifiers are "fundamentally broken".  The paper offers an interesting insight into the features of poisoned classifiers. However, such insight is diminished by the fact that the proposed attack requires a substantial manual interaction. The user must manually analyze the adversarial examples generated for robustified classifiers in order to determine the key parameters of alternative triggers. While manual intervention as such does not undermine the main observation of the paper, this makes an automatic exploitation of this idea hardly feasible and hence decreases the significance of the paper's main result.
Below are multiple reviews of a paper. The paper studies the personalized federated learning and makes a few contributions. It proves an information-theoretic lower bound on the sample complexity. It proposes an all-for-one algorithm that matches the lower bound.This paper studies the sample complexity of personalized federated learning with a large number of users (each holding a few samples) The mathematics in this paper appear to be correct, and the topic is interesting.This paper studies the issue of personalization in federated learning. An information-theoretic lower bound is established that reveals how much a client participating in the FL process can hope to benefit from collaboration. Overall, I think this is a very well-written paper.The paper shows an information-theoretic lower bound on the number of oracle calls for collaborative training on clients. Two optimal collaborative training algorithms are proposed, and convergence rates are presented.	This paper addresses an important issue related to sample complexities for a personalized federated learning (PFL) problem. Its focus is on the case where a large number of agents collaborate to train the PFL problem, and each agent can have local data from a slightly different data distribution. Author(s) provide both the lower and upper bound on the number of samples needed in order to achieve their goals. They also discuss techniques that allow for achieving an optimal bias-variance trade-off.  Note: please try to incorporate the suggestions and discussions into the camera-ready version.
Below are multiple reviews of a paper. The paper proposes an architecture-independent way of measuring distance between two models for the same type of input data. The method can be applied to help detect model stealing and inform unlearning verification. The paper is an empirical study on a topic that is not very popular.The paper presents a method (Zest) for measuring the distance or similarity between 2 supervised machine learning models. The method is demonstrated on 2 specific applications. The first is the detection of model stealing, where the input/output examples of a model are used to reproduce it and therefore steal the associated intellectual property. The second is the evaluationThe authors propose a novel approach for computing an architecture-independent distance metric to assess the similarity between ML models. They demonstrate the method by applying it on instances of the CIFAR dataset, focussing on the two tasks of model stealing and unlearning.The paper proposes a new method to calculate the distance between two machine learning models. By comparing using local approximations and compute the Cosine distance, this yields an architecture-independent method operating in weight space. It has proves effectiveness in applications including detecting model stealing and verifying machine unlearning.	This paper presents a method, called Zest, to measure the similarity between two supervised machine learning models based on their model explanations computed by the LIME feature attribution method.  The technical novelty and significant are high, and results are strong.  Reviewers had clarifying questions regarding experiments and suggestions to add experiments, which involve additional domains (text and audio) and different families of classifiers, and more contexts based on prior literatures. These were adequately addressed by the authors. Overall, this paper deserves borderline acceptance.
Below are multiple reviews of a paper. Inference of embedding vectors algorithms for three different exponential family distributions: Bernoulli, Poisson, and Gaussian. Considered two possible process prior: Dirichlet and Uniform. Experiments indicate their model outperforms previously known models.The proposed solution extends the Exponential family graph embedding model with two nonparametric prior settings: the Dirichlet process and the uniform process. The most interesting part is the study of the exploitation of the normal distribution in the proposed solution.The paper extends EFE to allow for a nonparametric prior (either Dirichlet or Uniform Process) over each vertices' embedding vector. The paper does not highlight the practical significant advantages of the extension or the technical challenges the paper overcomes.Judged from the results, we do see the variance in performance by different considerations. There are some great variations in the performance of the proposed model. How can you choose the best model? Please see above.	Meta Review: This is an interesting and well-written paper. Perhaps it it less obvious however, how it contributes to the existing literature. It clearly builds heavily on earlier work and only the rebuttal made it a bit clear (at least to me) what is innovative about the proposed approach. There was a consensus among the reviewers that the paper could be accepted if there is space. I ask the authors to incorporate the clarifying comments they sent to the referees - I think they are really crucial to improve the paper. I also realized that none of the referees pointed out that the "exponential family embeddings" are really just special generalized linear models. I think it is important to keep track of the original ideas and it would be good if the authors should mention generalized linear models explicitly (as the paper proposing "exponential family embeddings" does).
Below are multiple reviews of a paper. The paper proposes a framework for DP-SCO and DP-SMO, such that any non-private algorithm with a certain convergence guarantee can be plugged in. It achieves the first near optimal guarantee without for algorithms apart from SGD.The paper studies DP stochastic convex optimization (SCO) and stochastically minmax optimization (SMO) They provide near-linear time algorithms under (strong) convexity assumptions that attain optimal or near-optimal rates.The paper provides a general framework for solving smooth DP-SMO and smoothDP-SCO problems by utilizing the (phased) output perturbation mechanism. There is no need for modifying the algorithms themself to have a DP result.The paper is one more link in the ever growing chain of results on DP ERM-based optimization algorithms. While the novelty factor isn't that great, I still believe it is a problem worth mentioning in NeurIPS.	This work studies minimax optimization for convex-concave objective. It studies the population loss version of this question and shows linear time differentially private algorithms for this problem that achieve the optimal privacy utility trade-off. The algorithm is based on the phased ERM approach. The reviewers were in agreement that this problem is of interest and the paper makes a significant improvement on previous work to be interesting.  I would recommend acceptance.
Below are multiple reviews of a paper. This paper proposes a modified gradient descent algorithm by adding a chaotic component in the algorithm in a careful manner. The paper provides a comprehensive analysis on its SDE limit, the generalization bound and the regularization effect.The theoretical result makes sense to me, although I did not check the proof carefully. Compared to stochastic gradient descent (SGD), the advantage of the proposed method is not clearly addressed.Theoretically, the authors:. prove a generalization bound for their method that leverages recent generalization bounds for heavy-tailed SGD 2. prove that their method approximately follows gradient flow on a regularized loss functional which implicitly penalizes the Hessian trace. 3. Demonstrate that on CIFAR-10 classification withThe paper considers a family of deterministic fast-slow dynamical systems. This family includes GD and some of its variants. The authors show that, as the learning rate vanishes, the MDGD dynamics converge weakly to an SDE.	A recent line of work on the role of stochasticity in ML suggests that variants of GD which use non-traditional step size schedules (a) may perform relatively well in certain settings (b) due to an implicit chaotic behavior. The present paper studies a variant of GD (MPGD) augmented with an explicit chaotic component, implemented by means of an external deterministic dynamical system, as a theoretical model for investigating these hypotheses. Recent results are shown to imply generalization bounds for the limiting stochastic process. Numerical results are provided for comparing the performance of MPGD to existing methods.  The reviewers have generally found the use of a GD variant with an explicit chaotic term, as well as the proposed analytic framework, interesting and appreciated the clarity and rigor of the results given in the paper. In later discussions, concerns regarding the relevance of the theoretical model to (a) and (b) above were raised by the reviewers, questioning more broadly the significance of MPGD and the respective limiting SDE to the general understanding of SGD/GD. All in all, I think this is a reasonable paper to accept if there is room. The authors are encouraged to revise the paper according to the important feedback given by the reviewers.
Below are multiple reviews of a paper. This paper developed a generative model to perform simultaneous embedding/generation of images/texts, with application to zero-shot learning. The experiments are extensive. The novelty of this work is lacking.The paper suggests a new model incorporating deep topic model (text decoder),  VHE (image encoder), and GAN. The topic model and the VHE shares the topic parameters, and the GAN generate an image regarding the topic.This paper studies the zero-shot learning problem with deep generative models. It proposed a hybrid framework that combines VAEs and GANs all together. In the experiments, two benchmark datasets CUB and Oxford-Flowers are used.	The paper received borderline ratings due to concerns regarding novelty and experimental results/settings (e.g. zero shot learning). On my side, I believe that the proposed method would need more evaluations on other benchmarks (e.g., SUN, AWA1 and AWA2) for both ZSL and GZSL settings to make the results more convincing. Overall, none of the reviewers championed this paper and I would recommend weak rejection.
Below are multiple reviews of a paper. On the CIFAR-10 dataset, the drop in clean accuracy is >20% but only around 9 samples out of 50,000 can be certified robust.Data poisoning attacks deal with adversaries who change the training set, up to a certain degree (controlled in different ways) Previously methods were designed to tolerate adversarial perturbations while preserving low risk in the produced model. This paper proposes a general, simple, yet effective idea for certification in poisoning context.The paper proposes to solve two variants of adversarial poisoning attacks: 1) General Poisoning Attacks - where either the input is distorted or the label is flipped. 2) Label Flipping Poisoning attacks - where the input images are intact but only the labels are flipped.A paper studies how to enhance the robustness of classifiers in face of data poisoning attacks. The key insight of the paper is that adding or deleting one training point can at most change one of the k partitions of the training set.	The authors develop a novel strategy, Deep Partition Aggregation, to train models to be certifiably robust to data poisoning attacks based on flipping labels of a small subset of the training data or introducing poisoned input features. They improve upon existing certified defences against data poisoning and are the first to establish certified guarantees against general poisoning attacks.  Most reviewers were in support of acceptance. Reviewer concerns were raised in the rebuttal phase but were convincingly addressed in the rebuttal phase. One reviewer did raise concerns on the weakness of experimental results on CIFAR-10, but the fact that this method has established the first certified defence in the general poisoning setting and that the results are stronger on other datasets certainly warrant acceptance. I would encourage the authors to clarify this in the final version.
Below are multiple reviews of a paper. The idea is to interpret some regularization technics as a from of noisy bottleneck. I'd be interested to hear if the authors see a connection between their formalism and the one of Reference prior.This paper studies "Noisy Information Bottlenecks" The overall idea is that, if the mutual information between learned parameters and the data is limited, then this prevents overfitting. The paper gives an example of Gaussian mean field inference.This paper proposes a justification to one observation on VAE: "restricting the family of variational approximations can, in fact, have a positive regularizing effect, leading to better generalization" The explanation given in this work is based on Gaussian mean-field approximation.	The paper proposes a regularization method that introduces an information bottleneck between parameters and predictions.  The reviewers agree that the paper proposes some interesting ideas, but those idea need to be clarified. The paper lacks in clarity. The reviewers also doubt whether the paper is expected to have significant impact in the field.
Below are multiple reviews of a paper. The idea of using a transformer and a CNN in cross teaching semi-supervised paradigm is clever. Multiple techniques are used for comparison. The results seem to show good performance compared to baseline techniques.The code will be publicly released for reproduction. The novelty is limited by introducing the existing transformer (swin transformer) and U-net structure. The cross-teaching strategy is also simple and has not changed a lot compared with other semi-supervised learning.The method is compared only to other semi-supervised methods. The exclusive use of ACDC for such a simple and generally applicable approach leaves one wondering about other tasks.The public codebase of this work seems strong and comprehensive. The method is easy to follow and implement. The underlying motivation of the cross-teaching is clear.	This paper proposed a simple framework by combining CNN and Transformer by cross teaching for semi-supervised medical image segmentation. Experiments on cardiac application demonstrate better performance over other methods. Overall, this paper is well organized and the results are convincing. The majority of reviewers (3/4) has recommended weak accept. Based on own reading, I also recommend accept, although comparison results with other SOTA methods such as 3D models can be added in the final version.
Below are multiple reviews of a paper. This paper presents a representation learning method to optimize individual data representation vectors as well as an MLP encoder. The learned representation vectors can recover the features from multiple pre-trained self-supervised learning models. Experimental studies show that such learning method can outperform baselines including individual feature, concatenation and averaging.This paper proposes a framework to perform self-supervised model ensembling via a novel method of learning representations directly through gradient descent at inference time. The effectiveness of the proposed method is evaluated by k-nearest neighbors accuracy. The improvement is marginal considering the training and testing cost.This paper propose a new way to learn self-supervised model ensembling. Their novel approach learns representations via gradient descent directly at inference time after having pretrained feature extractors. The authors conduct a series of experiments to show the efficacy of their method.The paper proposes a new self-supervised ensembling method to get a better feature representation. Instead of using the conventional averaging or concatenating to ensemble multiple features, thisPaper proposes a different inference scheme where the backbone is also updated during the test time in a self supervised fashion.	The paper proposes a method to perform self-supervised model ensembling by learning representations directly through gradient descent at inference. The effectiveness is evaluated by k-nearest neighbors accuracy.  The reviewers agreed that the paper studies an important and interesting problem of leveraging model ensembling for self-supervised learning, which could improve both the performance and robustness of the learned representations. However, the reviewers also agreed that there were issues with the soundness of the empirical evaluation, which was a key reason for rejection.
Below are multiple reviews of a paper. The authors prove several statements about the expressiveness of different classes of graph neural nets. The results are based on a general Stone-Weierstrass-like theorem for equivariant functions. The paper and appendix are very well written and relatively well understandable for me.The paper describes the approximation power of certain types of graph neural networks. It considers Message Passing GNNs (MGNNs) and two GNN-type methods proposed by Maron et al., k-FGNN and k-LGNN.This paper compares the expressive power of three types of invariant and equivariant GNNs against the Weisfeiler-Lehman (WL) tests. The authors claim that 3-LGNN or 2-FGNN can count the number of 6-cycles, which is an improvement upon the result in [3The paper studies the expressive power of several classes of recently suggested models. The most widely-used models today, message-passing networks, are not universal. The paper also shows that folklore GNNs perform significantly better than other models in solving the quadratic assignment problem.	This paper is concerned with the ongoing research program of mapping the approximation power of different GNN architectures. It provides significant advances in the study of equivariant GNNs and nice extensions in the invariant case by closing existing gaps between distinct GNN families.  All reviewers agreed that this is a strong submission with substantial new theoretical results. The AC recommends a strong acceptance.
Below are multiple reviews of a paper. The paper introduces and describes Multi-LexSum: a benchmark for multi-document summarization and three levels of granularity (L, S, T) Summarizing legal texts is a non-trivial task which is a core task that many lawyers do. The experiments are well done and reasonable in light of the claims madeThe authors present a new dataset of 9,280 expert-authored summaries from large-scale civil rights lawsuits. They experiment with state-of-the-art models for abstractive summarization (BART, Pegasus, LED, and PRIMERA) on their new dataset.Multi-LexSum is a law-specific domain multi-document text summarization dataset. The summaries in this dataset vary from long, short, and tiny and derived from multiple documents. The paper conducted a good series of experiments to support their claim.This paper introduces Multi-LexSum, a multi-doc summarization dataset based on civil rights lawsuits from U.S. federal courts. The results indicate that exiting popular summarization models cannot achieve satisfying performances.The authors introduce a new set of summaries of long legal documents concerning civil rights cases. This data is focused on a subject area with high potential for social impact. The existence of multiple levels of granularity is a very nice feature.	This is a very high-quality dataset, which is especially noteworthy since legal NLP benchmarks are very difficult to build. The authors approached every aspect of the process with extreme care. It will likely have an impact on law practice and start interesting discussions about the use of ML in these settings. The paper is also very well written and enjoyable to read.  Most reviewers are heavily in favor of acceptance. Reviewer Aeqk brought up some weaknesses, but at least from the AC's perspective, these seem to be answered well by the authors.
Below are multiple reviews of a paper. DreamGrader is an automated fine-grained grading system for identifying known errors in interactive programs. It consists of an program-interaction agent and an error-classifier. The proposed system outperforms strong baselines and prior work by a significant margin.This paper proposes a meta exploration reinforcement learning algorithm, dreamgrader, that tries to provide feedback to student-authored interactive programs. The authors conducted experiments on a large, real dataset, not a synthetic one.The paper presents a novel approach called DreamGrader to give feedback on interactive student programs. In contrast to previous approaches which only gavebinary feedback (correct/incorrect), they assign more fine-grained feedback.	This work presents dreamgrader that aims to provide feedback to student-authored interactive programs. Reviewers all agreed that this paper presents a novel and original idea, solid experiments on real-world programs, as well as potential impact on MOOCs. There were some minor concerns and most got resolved during the discussion stage. Thus we recommend acceptance.
Below are multiple reviews of a paper. The paper tackles the problem of event data-based object tracking. Instead of using event frame/image representation, the authors chose to process raw event clouds. The proposed framework includes a downsampling strategy to extract key events from a raw event cloud.This paper make the first attempt to construct a new end-to-end learning-based paradigm that directly consumes event clouds. Considered the high temporal resolution and sparse characteristics in event clouds, it proposed key-event and graph-based network to extract irregular spatio-temporal information from raw data.A novel event processing method which first samples large amount of events into a subset of key events and then uses GNN to transform them into feature embeddings. In addition, motion-aware target likelihood is also computed to strengthen the matching process.The proposed method featured key-event embedding and motion-aware target likelihood prediction to take advantage of the unique characteristics of event data. Extensive experiments on both synthetic and real event datasets demonstrate the excellent performance of the proposed method in terms of tracking accuracy and speed.	The paper receives overall positive reviews and rebuttal has resolved the reviewer's concerns. The paper proposes a new framework that directly takes raw event clouds as inputs for object tracking. Reviewers agree that this innovation is inspiring. AC agrees and recommends accepting the paper.
Below are multiple reviews of a paper. The paper studies a problem of detections and localizations of changes using the discrepancies between the Nadaraya-Watson estimator on data before and after a time. The experiment results look interesting and promising.This paper addresses the problem of detecting abrupt changes in the conditional distribution of two (multivariate) random variables, using a finite time indexed data sample. The presented proposal entirely builds on a non-parametric approach.The paper discusses a nonparametric change-point estimation methodology. The synthetic results and real data analysis validate the performance of the proposed estimator. Yes they adequately addressed the limitations and potential negative societal impact.The paper presents a novel approach to detecting change points in conditional distributions. The method is empirically evaluated on synthetic data and two real-world use cases. The paper is sound, the presentation is clear, the method is novel and interesting.	This manuscript enjoyed universal recommendation of acceptance from the reviewers after the initial review phase. The reviewers did note several minor issues in these initial reviews, many of which were resolved by insightful responses from the authors. I encourage the authors to edit the manuscript to reflect the insights gained from this interaction when preparing an updated version.
Below are multiple reviews of a paper. The authors present an architecture to detect anomalies in multi-variate time series. Their approach compute correlation while taking into account periodicity of the signal through FFT. For me, the architecture is not clear.The paper presents GenAD, a DNN architecture for multivariate time-series anomaly detection. The key differences in comparison to existing approaches are two attention mechanisms tailored to capture patterns within time series.This paper proposes to better represent relationships between different variables within time series and use the result to perform anomaly detection. The experiments show reasonable results. The algorithm needs to be presented in a cohesive way to be able to understand what is actually being done.	The paper proposes an architecture of a model for multiple correlated time series that has application in anomaly detection.  The main idea is to use attention both along time to capture trends, seasonality, etc and along series types to capture their correlation.  Training loss attempts to reconstruct masked ranges of values, and thus the discrepancy between predicted and actual values can be used to flag anomalies.  While the ideas proposed in the paper are useful and lead to a well-engineered model while combining current architectural elements to best suit their task, the paper fails to impress as a research contribution.   The writing requires improvement, and the experiments on two datasets are not entirely convincing.  The authors have realized these limitations, as can be seen in the author feedback.  However, the changes entailed are too extensive to  revise the ratings across all reviewers. I hope these will help the authors submit a better next version to another conference.
Below are multiple reviews of a paper. DP-noise adds bias and has to be somehow corrected in the downstream tasks. Simply modifying DP-SGD in a way that Poisson subsampling is performed to the joint set of public and private data is quite obvious solution. There is something strange with the (eps,delta)-values in the experiments.The paper looks technically very sound, and the experiments seem well designed, but I have not checked the proofs in detail. The presentation of the evaluation metrics in page 7 is too concise and a bit difficult to understand.The proposed "privatized neural network" approach for learning weights is flexible and can be easily adapted to other architectures or models. The approach is not end-to-end, resulting in unbiased samples, but rather samples + IWs which downstream tasks must incorporate.The performance of various importance weight methods vary widely, and it's not clear what's driving it. In Proposition 3,  the claim is about differential privacy w.r.t. the full dataset.	Meta Review:  This paper proposes a sampling approach to correct bias in the synthetically generated data from a differentially private algorithm. Reviewers are in unanimous agreement that this paper has high technical quality and can be a significant contribution to the community.
Below are multiple reviews of a paper. Theorem 1 says that for $NU_ACDM < 3/7$ the algorithm is within a $7/4 + o(1)$ factor. In a regime where $n \approx $n$ very large, this would indicate that the algorithm would be almost as good as the best synchronous algorithm.This paper studies the combination of the asynchronous parallelization and the accelerated stochastic coordinate descent method. The proved convergence rate is claimed to be consistent with the non parallel counterpart. The linear speedup is achievable when the maximal staleness is bounded by n^{1/2}.The paper under review answers the question in the affirmative and does so very elegantly. I have only a few minor quibbles and a question.	The reviewers all agreed that this paper makes a strong contribution to ICLR by providing the first asynchronous analysis of a Nesterov-accelerated coordinate descent method.
Below are multiple reviews of a paper. The paper uses distances between the Persistent diagrams of states of neural networks and observe that during training there is a high correlation with the corresponding validation accuracy of the model. The authors tested their method on a variety of datasets. The contributions are not very novel in my opinion.The paper presents some empirical observations about the relationship of a persistent homology-based measure of learning dynamics and validation set error, during the training of deep neural nets. My main concern with the paper is that, unfortunately, the analyses presented are nowhere close to the standard of rigor and thoroughness one would expect.This paper analyses the training of neural networks from a topologicalperspective. It presents a pipeline that can measure (pseudo) distances between the network's weights during training. Such information is thenemployed to study the generalisation error of a neural network.This paper investigates the (cor)relation between the validation accuracy achieved by a neural network and a variation of a topological descriptor built on top of the network. The paper is well written overall (aside for few typos, see Minor comments). The methodology proposed by the paper is original and interesting.	This paper got uniformly strongly negative reviews.  The issue of estimating or bounding generalization accuracy from performance on the training set has a huge history and literature.  After considerable discussion the reviewers uniformly find this paper lacking in making a contribution to that literature.
Below are multiple reviews of a paper. This submission provides a more reasonable way to find the flatten minima rather than the heuristic way utilized in SAM. With negligible additional computation, this method improves the generalization performance. It is a good modification to the SAM method, which may further improve the performance.The paper presents a new method for improving generalization in deep learning called GSAM. It builds upon and extends recent works on adversarial weight perturbation and sharpness-aware minimization (SAM)This paper builds on the main idea of SAM. Namely, the authors noticed that minimizing the perturbed loss $f_p$ is insufficient for guaranteeing flat minima. The authors then defined the notion of surrogate gap $h$, which they propose to minimize. By using GSAM which consists of two gradient descent/ascent stepsIn this paper,the authors proposed a new method for sharpness aware training. The idea is to note a surrogate gap as a measure of sharpness, which motivates to minimize the perturbed loss and the surrogate gap simultaneously. The experimental results are comprehensive and seem to be convincing.	The paper proposes an interesting and well-motivated improvement of Sharpness Aware Minimization.  Overall the AC and reviewers are satisfied by the author feedback in improving the solidity and rigor of the theoretical results.   The points made by the authors in response to the reviewers initial concerns are essential, especially those regarding interpretation of Corollary 5.2.1, making the proofs rigorous, and fixing the potential for crude convergence bounds. It is therefore critical that the authors incorporate them into their manuscript.
Below are multiple reviews of a paper. The paper empirically studies the reason for the phenomenon that deep neural networks can memorize the data labels. New geometric measures by replica mean-field theory are applied in the analysis. I think this paper provides nice observations and initial analysis to the community.The authors apply MFTMA to DNNs trained on CIFAR with label noise to analyze their behaviors between generalization and memorization. They claim that what is involved in memorization are not lower layers but higher layers.This paper investigates memorization in deep neural networks (DNNs) Authors leverage mean field theoretic geometric analysis method (MFTMA) to analyze when and where memorization occurs in a DNN. Through empirical analysis, they show that generalizing feature are learned initially and that memorization happen later in training.This paper analyses memorization in DNNs, from the lens of memorization = fitting random labels, and finds that it seems to happen in later layers. These results are obtained using the MFTMA framework, a manifold analysis tool, testing geometric properties of individual layers.	The paper offers novel insights about memorization, the process by which deep neural networks are able to learn examples with incorrect labels. The core insight is that late layers are responsible for memorization. The paper presents a thorough examination of this claim from different angles. The experiments involving rewinding late layers are especially innovative.  The reviewers found the insights valuable and voted unanimously for accepting the paper. The sentiment is well summarized by R2: "The findings of the paper are interesting. It shows the heterogeneity in layers and training stage of the neural net".  I would like to bring to your attention the Coherent Gradients paper (see also R1 comment). This and other related papers already discusses the effect of label permutation on the gradient norm. Please make sure you discuss this related work. As a minor comment, please improve the resolution of all figures in the paper.   In summary, it is my pleasure to recommend the acceptance of the paper. Thank you for submitting your work to ICLR, and please make sure you address all remarks of the reviewers in the camera-ready version.
Below are multiple reviews of a paper. The authors propose extended batch normalization, called collaborative normalization. It normalizes features using domain-specific statistics and shifts the normalized features to gradually align their distributions between domains through the model.This paper proposes a novel normalization method termed Collaborative Normalization (CoN) to eliminate domain discrepancy for unsupervised domain adaptation. In practice, CoN firstly exploits domain-specific statistics to normalize features from source and target domain. Then it calculates the collaborative representations across domains and gradually aligns samples from one domain toThe paper proposes a normalization technique called collaborative normalization, which can substitute batch normalization in any neural network. The proposed method introduces an additional domain attention, collaborative translation, which calibrates the output of domain-specific batchNorm. It boosts performance without additional learning parameters.	Although all reviewers acknowledge that the paper has some merit, the work lacks in novelty. The idea of using normalisation techniques to reduce the domain discrepancy in UDA is well established in the DA and DG community. The theoretical analysis is an interesting first step in providing some insights on this class of approaches, but it still does not support an understanding on why some of these methods work better than others. Given all these considerations, the work is not ready for acceptance at ICLR.
Below are multiple reviews of a paper. Authors demonstrate how newly introduced dataset of diachronic Greek language with Parliamentary proceedings was created via crawling, parsing, cleaning, processing and verifying data. They discuss obstacles and deciisions made in the process.The paper provides a dataset of Greek parliament speeches. It also experiments on changes over time in word usage in those speeches. As the authors state, it can be useful for computational linguistics/NLP applications.This paper introduced a dataset of the Greek parliament proceedings. It included 1,280,918 speeches of parliament members from 5,355 parliamentary sitting record files with sufficient metadata. By applying the word usage change detection models and the proposed dataset, the authors analyzedword usage change in the context of Greek political environments.This work presents a large-scale greek parliament proceedings dataset ranging from 1989 up to 2020. The authors explored its potential in computational linguistics and computational political science research.This paper presents a dataset of Greek Parliament Proceedings covering 1989 to 2020. The temporal component makes it an interesting resource for studies in NLP and political analysis. The paper describes the creation of the dataset and presents several analyses focusing on stability of semantic change detection models."I learned many interesting things in the paper about Greek political history" "I do not think this paper meets the standards for acceptance at NeurIPS"	The authors have compiled a new dataset using data from the Greek parliament. The dataset is interesting because it is comprehensive data (over 30 years) in modern Greek. It is also a political speech database that accounts for modern greek politics. This data will be helpful for people working on NLP to test their models and political scientists working on political discourse.   Some of the reviewers (and me) complain about some of the preprocessing that the authors have done, like attributing sex to speakers or removing stop words, which are derivative results that obscure the quality of the data. Still, the authors have responded to the authors' criticism, and the reviewers have acknowledged the responses by the authors positively.
Below are multiple reviews of a paper. This work proposed a transfer learning method for GANs in the limited data domain. It borrows ideas from IMLE (to overcome mode-collapse) and conditional GAN (to improve training stability and generation quality) The model is claimed to be effective in preventing mode collapse and discriminator overfitting.This submission deals with transfer learning for training GANs with limited label data. The challenge is that training with limited data can result in mode collapse. This submission proposes to use data priors for each instance of the target distribution. A pre-trained feature extractor is used to provide the information to condition the GAN.Transfer learning is a good way to help GANs when sample size is limited. The paper is good and it can help data augmentation in other applications. I am just curious how the VGG pretrained network can also help.The paper focuses on improving the performance of training generative adversarial networks (GANs) with limited target data. The data prior is extracted by a pre-trained network /  self-supervised model, and then mapped into the embedding by G_emb and D_emb.	The paper proposes to use a feature extractor (encoder) $C(x)$, pre-trained with label supervision or contrastive learning on a large image dataset, to both regularize the discriminator's last feature layer $D_f(x)$ and encode the data $x$ itself as the conditional input of the generator $G(z|G_{emb}(C(x)))$. The main purpose is to help the training of GANs when there is a limited number of images in the target domain. A clear concern of this approach is that to generate a fake image, one will need to first sample a true image, making the model unattractive if the training dataset size is large (need to store the whole training dataset even after training). To mitigate this issue, the authors propose to fit up to 200k randomly sampled $G_{emb}(C(x))$ with a GMM with 1k components. To validate the practice of requiring a GMM (a shallow generative model) to help a GAN (a deep generative model) to generate, the authors have done a rich set of experiments under state-of-the-art GAN architectures or training methods (SNGAN, BigGAN, StyleGAN2, DiffAugment) to illustrate the efficacy of the proposed data instance prior and its compatibility with the state-of-the-art methods in a variety of settings. In the AC's opinion, the paper is missing references to 1) related work that combines VAE (or some other type of auto-encoder) and GAN, which often helps stabilize the GAN training [1,2,3], 2) VAE with a VampPrior [4], and 3) more broadly speaking, empirical Bayes related methods where the prior model is learned from the observed data (see [5] and the references therein). The potential advantages of using a VAE rather than a GMM to help a GAN to generate include: 1) there is no need to store 1k GMM components, which may require a large amount of memory; 2) there is no need to subsample the training set; and 3) the VAE and GAN can be jointly trained. The AC recommend the authors to discuss the connections to these related work in their future submission.  [1] Larsen, Anders Boesen Lindbo, et al. "Autoencoding beyond pixels using a learned similarity metric." International conference on machine learning. PMLR, 2016.  [2] Zhang, Hao, et al. "Variational Hetero-Encoder Randomized GANs for Joint Image-Text Modeling." International Conference on Learning Representations. 2019.  [3] Tran, Ngoc-Trung, Tuan-Anh Bui, and Ngai-Man Cheung. "Dist-gan: An improved gan using distance constraints." Proceedings of the European Conference on Computer Vision (ECCV). 2018.  [4] Tomczak, Jakub, and Max Welling. "VAE with a VampPrior." International Conference on Artificial Intelligence and Statistics. PMLR, 2018.  [5] Pang, Bo, Tian Han, Erik Nijkamp, Song-Chun Zhu, and Ying Nian Wu. "Learning Latent Space Energy-Based Prior Model." Advances in Neural Information Processing Systems 33 (2020).
Below are multiple reviews of a paper. The paper considers the question whether GKs and GNNs can approximate a fixed graph similarity. The chosen graph similarity is maximal when graphs are isomorphic. Its computation is intractable for most graphs (complexity in $n!$) Experiments are done on very small graphs (at most 9 nodes) Experimental results areThis paper proposes to study the expressiveness of some graph kernels and graph neural networks. To this aim, the authors build a synthetic dataset of graphs and compute the pairwise similarities, which are compared to an oracle function supposed to quantify how much two graphs are isomorphic.This paper provides an intensive empirical study on the expressiveness of graph kernels and graph neural networks. It defines an exact but computationally demanding similarity of graphs defined over all possible permutations for adjacency matrices.The paper deals with supervised graph classification comparing GNN and graph kernel approaches. The authors define an intractable graph similarity functions, which boils down to a normalized graph edit distance. In some settings, GNNs do not perform better than trivial baselines.	The reviewers liked the direction of the paper but unanimously agree that, in its current version, it is not strong enough to justify publication at ICLR. There was no rebuttal from the authors to consider.
Below are multiple reviews of a paper. The paper tried to answer an important question "when will the deep models benefit from data augmentation?" They proved (though I didn't check the proof) that "a deep model can benefit from augmented data when the data bias is small" Based on this, they developed two methods "AugDrop" and "MixLoss" TheThis paper illustrated two algorithms that correct bias in data augmentation. The authors illustrate their algorithms from a theoretical perspective. Authors' initial motivation can help the field significantly.This paper proposes a method to improve the generalization of deep networks when the input is applied strong augmentations, i.e. mixup, resulting in large data bias. The improvements on CIFAR10/CIFAR100 are very marginal. The paper has some typos and grammar mistakes.This paper theoretically analyzes the effect of bias in augmented data on the efficacy of data augmentation approaches. It proposes three new approaches that purport to limit the negative effects of data bias in the augmented data distribution, and both theoretically and experimentally analyze them.	This work presents a new theoretically motivated data augmentation technique. Reviewers agreed that the theory was interesting and has value, however raised concerns regarding the experimental evaluation which was limited to the Cifar datasets. There was some discussion over whether or not a comparison with AutoAugment would be fair, the proposed method is theoretically motivated whereas AutoAugment takes significant compute to train. I agree with the authors that if the method doesn't outperform AutoAugment on CIFAR, this would not necessarily invalidate their results. Nonetheless the work would be significantly strengthened if it included results. on additional datasets to stress test the theory. I recommend the authors add additional supporting evidence and resubmit.
Below are multiple reviews of a paper. This paper proposes a model for adaptive duration modification of an input signal. Model is a graphical model with neural components. Authors derived an upper bound for the likelihood (conditional probability of output sequence and estimated length given input) All the model parameters are updated, by minimizing this upper bound.This paper proposes a generative sequence-to-sequence encoder-decoder architecture. The bulk of the evaluation is on how accurate the target length is estimated. The introduction glosses over most of the prior work in this area.Speech rate, duration, and pitch modification is of interest in several practical audio applications. The paper proposes the use of an encoder-decoder framework with attention masking to estimate a candidate target utterance length.This work proposes a generative model to convert emotion by adaptively modifying the duration of speech components without the need for reference utterance. The proposed method looks interesting and novel, but there are several concerns over the evaluation and correctness.	This paper introduces a deep neural network sequence-to-sequence framework for modifying the length of a speech sequence.  It employs a convolutional encoder-decoder architecture optimized under a Bayesian formulation with variational inference.  The proposed framework is evaluated on a voice conversion task and three emotion conversion tasks. The results show that it can successfully change the duration of an utterance without accessing the target utterance.  Almost all reviewers raised concerns with some strong or inaccurate claims made by the authors in the paper.  The literature review on related work also needs to be significantly improved.  Another major concern is on experiments. Other than the DTW compared in the work, the proposed method should also be compared with existing duration modification techniques. The MOS evaluation seems to be limited and needs further improvement to make the results stronger and more convincing.  Since the authors did not provide a rebuttal, all these major concerns remain unanswered.
Below are multiple reviews of a paper. In offline RL, we can only use stored data, but it is too small for improving performance. For image based RL, they need observations as pixels. Authors generate image data from new states with recurrent generative model.This paper proposes S2P: a method for state-conditioned image synthesis for offline image-based RL. The authors motivate their method by the fact that offline RL suffers from distribution shifts in the low data regime.This work extends the distribution of the data generating policy in offline RL. They show that their data augmentation strategy improves SOTA algorithms like CQL, IQL and an offline version of SLAC. The paper has conducted experiments limited to only DMControl with reliable state transitions.This paper focuses on an offline reinforcement learning problem. A generative model S2P is proposed to generate image transition data by virtually exploring the state space. It shows significant performance improvement in 6 image-based DMControl tasks.	## Summary The performance of the offline RL methods can be limited by the amount of coverage in the dataset. Most real-world problems have limited coverage in the offline RL datasets and the sample efficiency of the pixel-based offline RL methods in general is often poor. Thus, it is an important direction of research to improve the sample-efficiency those continuous control pixel-based offline RL algorithms. This paper proposes a method called S2P which generates pixel based observations from the states by using a generative model. The paper shows improved results on offline DeepMind control datasets.  ## Decision  The paper in general is well-written and clear. The idea is simple and seems to be effective compared to other data augmentation approaches. The reviewers were in general positive about this paper. I think the NeurIPS and offline RL community *would benefit from the findings of this paper*.  However, I think a few clarifications in the final version of the paper would make the contributions of this paper more clear.   1. I found the improvements shown in the paper very encouraging. However, I found the choice of the dataset odd and confusing. In particular, I am curious why the authors did not decide to use the standards datasets published in RL Unplugged benchmark for offline RL. I think the authors should justify why they did not use those datasets in the camera-ready version of the paper, provide results on those datasets, and release the datasets that they used in this paper (perhaps contacting the RL Unplugged authors to see if it is possible to release them under RL Unplugged benchmark.) As it stands out, this paper only compares against baselines that the authors themselves implemented in the paper. Nevertheless, running experiments on the RL Unplugged would enable us to be able to compare S2P against other published offline RL baselines. 2. Authors should include the standard deviations in the camera-ready version of the paper as request by *reviewer i7hg*. 3. In general, I think the authors did a good job during the rebuttal and many of the reviewers raised their scores as a result of additional results and experiments that the authors have provided. The authors should include those results in camera-ready version of the paper including the clarifications about the questions that the reviewers asked in the rebuttal. 4. Currently the links and the references in the supplementary material are all broken. The authors should fix those in the camera-ready version of the paper.  **With the above points addressed in the camera-ready version of the paper, I think this paper would be ready for publication.**
Below are multiple reviews of a paper. The paper "Stochastic Adaptive Activation Function" successfully establishes a link between the statistics of feature selection and the recently proposed Swish-activation function. An ASH (Adaptive Swish) non-linearity appears in the theory part. The paper reports improved performance on every dataset and every network.In this paper, the authors present the Adaptive SwisH (ASH) activation function. They prove the baseline threshold of the ASH function is trainable during the training phase and that the threshold value adaptively changes according to the contexts of inputs. The ASH activation function outperforms other activation functions on classification, object detection,The authors propose a new trainable activation function. Unlike most activation functions that work element-wise, this one activates over complete layers. The activation criteria is whether the element is in the top k% of the elements in the layer. The threshold is then controlled by a learnable parameter.The paper proposes an activation function where the threshold is set to the upper k% of the input tensor values. The writing is at times difficult to follow and understand, but the mathematics appear sound. The paper would be much more significant with repeated runs and statistical significance tests.	Reviewers appreciated the novelty of the proposed activation function, the theoretical motivation and its connection to the SwisH activation. In terms of presentation and soundness of the results, Reviewers pointed out some weaknesses in the initial reviews for this paper. In particular, the reviews voiced some concerns with the clarity and formatting of some figures, the lack of clarity of a mathematical derivation, and most of all, issues in the presentation of the empirical results that didn't report confidence intervals allowing for an assessment of the statistical significance of accuracy differences. These weaknesses were however addressed in ways that satisfied the Reviewers in the rebuttals and subsequent versions of the paper. Thanks to these welcome changes the paper has now garnered unanimous consensus among Reviewers that it should be accepted.
Below are multiple reviews of a paper. The paper proposes a method to combine modeling based on graphs mapping electrode geometry and self-supervised pre-training for EEG-based seizure detection and classification. It also proposes an interpretation method using occlusion maps to demonstrate the model's ability to localize seizure.The paper presents a method for seizure detection and classification. In particular, the method is self supervised, based on graph neural network and use EEG signals. The results are shown to improve current state-of-the-art.The paper combines well-founded strategies for representing EEG data on non-euclidean spaces preserving spatial and temporal patterns. Authors propose a graph-based representation from thresholded  Gaussian and linear (correlation) kernels.	This work tackles an important clinical application. It is experimentally solid and investigates novel deep learning methodologies in a convincing way.  For these reasons, this work is endorsed for publication at ICLR 2022.
Below are multiple reviews of a paper. This paper considers the decentralized bilevel optimization problem. It proposes a gossip-based method which overcomes the challenges in computing the hyper-gradients. With a strongly-convex lower level problem, the method is provably convergent.The paper tackles the problem of Stochastic Bilevel Optimization (SBO) in a decentralized setting. It uses a gossip protocol for communication between the agents. Overall, the paper is very clear and easy to follow.Gossip-based distributed bilevel learning algorithm that solve both the inner and outer optimization problems in a single timescale. The sample complexities are optimal for $epsilon$ and $K$, and the method achieves linearly scaling in network size. The strength of the work is the theoretical analysis and proposed method for decentralized stochThis paper first develops a gossip-based distributed bilevel learning algorithm based on the stochastic gradient descent method. Then, the authors develop the convergence analysis to characterize the convergence behavior of the stated algorithm. The algorithm achieves an $O$ sample complexity for nonconvex objectives.	This paper proposed a fully decentralized algorithm for bilevel optimization. Although the techniques are a combination of existing ones from bilevel literature and the decentralized optimization literature, but the setting considered is considerably sophisticated (i.e., both levels are distributed). The algorithm is a single-timescale, and the rates are good for both nonconvex and convex settings. The reviewers all appreciate the contribution of this work. Therefore I recommend acceptance of the paper.
Below are multiple reviews of a paper. The paper proposes to make any neural network equivariant by symmetrizing over a subset of the group, rather than over whole group. Strengths: The universality proof helps convince the reader to use this method. Weaknesses: It is a bit unclear when the results apply to finite and infinite groups.The paper introduces a framework called Frame Averaging that can adapt existing backbone architectures to become invariant/equivariant to new symmetry types. It achieves this by averaging over an input-dependent frame which outputs a subset of groups. The results are impressive, which suggests that the FA framework can be very useful in practice.This paper proposes a general method for transforming existing models into invariant/equivariant models using Reynolds operators. The name "frame" is confusing with the concept of frame in differential geometry. Frame Averaging (FA) is a framework for adapting known architectures to become invariant or equivariant with respect to a general group. The idea of FA is to replace the averaging operator over the entire group by the averaging over a smaller set of group elements.	The submission proposes a method to make a pre-existing model equivariant to desired symmetries: frame averaging. The strategy relies on a significant reduction of the number of symmetries to average over (with respect to the Reynolds operator) and uniform subsampling. The paper also demonstrates the usefulness of this method theoretically (universal approximation result) and practically (competitive performance). The contributions are clear and the core idea is simple. I recommend this paper for acceptance with spotlight.
Below are multiple reviews of a paper. This paper proposes a cheap attention module that focuses on mobile settings. The module is mainly used to augment GhostNet and achieves improvements on ImageNet classification and downstream tasks, e.g. detection and segmentation.A "decoupled fully connected" (DFC) attention module can significantly improve the performance of image classification models. This is achieved by aggregating information on the horizontal and vertical axis (instead of over the entire image)Light-weight neural networks have weak ability to capture the global information, which is the bottleneck restricting the representation ability. The attention module is only constructed by fully-connected layers. Then a light-weight architecture is constructed, which achieves SOTA performance on various vision tasks, such as image classification and object detection.This paper improves a previous work, named GhostNet. The original GhostNet aims to eliminate the effect of those uninformative feature maps by introducing the ghost module. This paper is motivated by this and designs an edge device friendly attention mechanism.	This paper aims to augment efficient CNNs with self-attention. However, since the naive approach to self-attention is computationally expensive and would contradict the point of efficient CNNs, the authors introduce a new attention mechanism which captures long-range information without substantially added computation cost. The paper demonstrates that GhostNetV2 exhibits markedly better performance at various compute limits as compared to previously proposed efficient networks. Three of the reviewers were quite positive on this paper, noting the novelty of the approach and the strength of the empirical results. One reviewer had several concerns, primarily regarding comparison to NAS based approaches and the novelty of the approach. I agree with the other reviewers that it is not reasonable to compare NAS approaches to non-NAS approaches, and agree that there are marked differences between this work and the previous work cited. I therefore recommend acceptance. I think this will be a valuable contribution to the efficient network community.
Below are multiple reviews of a paper. The paper presents a dataset of mouse interactions, provided annotations include 7 keypoints of the mouse obtained using a pose estimation model. The benchmark models proposed are the winning methods of the Multi-Agent Behavior Workshop. Proposed tasks on the dataset are useful for real-world applications.This paper presents a video dataset consisting of pairs of socially interacting mice with 6 million frames of unlabeled tracked poses. Tracked poses are output from their pose tracker MARS [43]. Behavior annotations are designed for three different tasks; 1) classical closed-set supervised learning task. 2) task of mimicking one annotator�The CalMS21 dataset consists of 1 million video frames of tracked animal poses and behavioral annotations for mice. The dataset is primarily used for action recognition tasks with 3 and 10 actions, but also contains annotations in some cases from multiple annotators, making it useful for ‘style transfer’ across individuals.	The paper presents a dataset of 1M videos frames with tracked animal poses and behavior annotations. All reviewers agreed that the paper is well-written and that the dataset is useful -- as evidenced by the fact that it has already been used to organize a challenge. Reviewers raised some minor concerns including more details about annotators and the relationship between the proposed benchmark and prior work on human action recognition. The author response was satisfactory in addressing these concerns, and in the end all reviewers voted to accept the paper. Congratulations on having your paper accepted to the NeurIPS 2021 Track on Datasets and Benchmarks! The authors are encouraged to take the feedback from reviewers into account when preparing the camera-ready version of the paper.
Below are multiple reviews of a paper. For reinforcement learning agents learned in an offline setting, it is especially important to be able to quantify uncertainty. The paper builds off of theoretical findings from past work on deep generative models and applies it well to the offline RL domain.The authors propose a Riemannian metric that captures both uncertainty in dynamics and OOD data. Their offline RL algorithm GELATO learns an uncertainty-penalized reward function by learning the geodesic distance through a 'pullback' metric.The paper introduces a new pullback metric for such dynamic models, and verifies its performance on several RL benchmarks. Using Riemannian distance metrics instead of Euclidean metrics, the authors better estimate uncertainties for out-of-distribution (OOD) data.	Unanimous accept from 3 reviewers.  I'm uncertain about "accept" given reviewer's XJeV and  Jba5 reviews are on the short and vague side. Reviewer vqqM never responded, even though they would have been a great reviewer for this work (reminded them once and they confirmed, but forgot to follow up again). Reviewer TKTA's review was the most useful, a borderline accept. There is reviewer consensus on novelty, in addition to being well written, with convincing results on MuJoCo and a highway environment.  I myself am unfamiliar with Riemannian metrics/manifolds, however after reading up on the subject, I worried this paper might have been too close to "Latent Space Oddity: on the Curvature of Deep Generative Models" to learn (or compute) latent space metrics, however this works differs by (1) using a variational *forwards* model to consider dynamics, (2) using an ensemble of model to consider epistemic uncertainty, and (3) tying both these aleatoric and epistemic forms of uncertainty into an offline-RL setting, where rewards are pessimistically estimated under uncertainty. While it seems a little ad hoc to suggest this particular method _for_ a particular application (offline RL), which confuses the narrative and motivation a bit, it does seem to give better RL performance in these settings than L2 and ensembling/bootstrapping in Figure 4. This is the most borderline paper I've seen as AC this NeurIPS, but if forced to make a decision, I lean accept.
Below are multiple reviews of a paper. This paper introduces a novel cross-device federated dataset, FLAIR. The dataset consists in 429k images from 51k individual Flickr users. The task consists in classification, with 2 levels of granularity for the classes.This paper proposes a new benchmark for large-scale cross-device federated multi-class image classification problem. It seems FLAIR only supports TensorFlow, which I think is a huge disadvantage for PyTorch users.This paper builds a large-scale multi-label image classiﬁcation dataset FLAIR. FLAIR includes 429,078 images from 51,414 users, with 17 coarse-grained labels and 1,628 ﬁne- grained labels. FL AIR considers several important non-IID challenges in federThe paper presents FLAIR, a large-scale image dataset for federated learning. The images in the dataset are gathered and filtered in such a fashion that no faces are present to avoid any personally identifiable information. The dataset is collected from real Flickr profiles, which guarantees realistic user splits.The authors provide a large-scale classification dataset for cross-device Federated Learning with two tracks; fine-grained classification 1628 classes and coarse classification with 17 classes. The authors do not provide the NeurIPS checklist in the main article nor in the supplementary. I would advocate for not rejecting the article based on this.	The authors provide a benchmark for federated learning.   The commonly mentioned strengths: - there is a big need in the community for this type of work - easily accessible code - various levels of complexity with different granularity  Regarding the weaknesses, I see no showstoppers - some feedback about the experiments done on the datasets -> this point comes back consistently among all reviewers, in terms of the amount, settings and reproducibility.. The authors are adviced to address this in future work, to keep momentum for the use of the community on this dataset  - there was some discussion about tensorflow and pytorch, but based on the discussion both seem supported - some settings / image types could be better supported  None of these weaknesses seem serious, and quite frankly, we can not expect one dataset to cover all possible settings. Since the reviewers are in agreement about the quality of this work, I recommend them for an oral presentation.
Below are multiple reviews of a paper. The authors extend the Fourier features framework to non-Euclidean spaces, including S2, SO(3) and S2xS2.Spherical harmonics and Wigner basis can be put into appendix, as it is quite well-known. The authors did not mention anything regarding how to choose the scale of the basis, although they mentioned it as a limitation.This paper generalizes the positional encoding with Fourier features to non-Euclidean manifolds. The underlying method took degrees up to 10 in the paper. The theoretical basis of this paper is well supported, but to what degree this method is of practical needs further justification.The paper proposes a positional encoding scheme for coordinate-based learning. It achieves better performance than Euclidean coordinate encoding. The title appears to suggest learning on general manifolds, but the actual discussion is focused on manifolds with a spherical structure.The paper generalizes the commonly used sinusoidal position encoding scheme to inputs naturally residing in non-Euclidean manifold. It is not clear why achieving "shift-invariance" , "minimal parameterization" or even the orthonomality property matters for the purpose of positional encoding.	Positional encoding of the input coordinates using Fourier basis [as described in (1)] is a common tool in the context of multilayer perceptrons (MLP). The author propose to replace the Fourier basis with one on manifolds M (2), such as the classical spherical harmonics (M=S^2), the Fourier basis on M=SO(3) or on M=S^2 x S^2.  MLPs form an important tool of our times. Unfortunately, as it is elaborated by the reviewers the Fourier basis of the investigated manifolds are widely-studied and the presented results are well-known; the submission lacks novelty.
Below are multiple reviews of a paper. This paper studies the convergence of SGD with momentum under linear regression with covariate shift. The paper shows that the expected progress of SGC with momentum is a discretization of a second-order ODE.This paper analyses the phenomenon of resonance in momentum SGD (SGDm) under a time-dependent covariate shift. This setting is useful to depart from iid-sampling-based theory, and could have useful implications for continual learning and reinforcement learning.This paper studies the behavior of SGD with momentum when the training data are not iid. The insight is novel, the numerical experiments are extensive, while the theoretical study can be improved. The reviewer has some major comments listed below.The paper discusses conditions under which SGD with momentum (SGDm) would diverge. Theoretical predictions are tested empirically, and it is shown that the basic phenomenon (resonance or at least suboptimal convergence) is also present in setups with noise, non-harmonic oscillations, other optimizers (	This paper studies online learning using SGD with momentum for nonstationary data. For the specific setting of linear regression with Gaussian noise and oscillatory covariate shift, a linear oscillator ODE is derived that describes the dynamics of the learned parameters. This then allows analysis of convergence/divergence of learning for different settings of the learning rate and momentum. The theoretical results are validated empirically, and are shown to generalize to other settings such as those with other optimizers (Adam) or other models (neural nets). The reviewers praise the clear writing and the rigorous and systematic analysis.  3 out of 4 reviewers recommend accepting the paper. The negative reviewer does not find the main contribution interesting and significant enough for acceptance. Although I think this is a reasonable objection, it is not shared by the other 3 reviewers. Since the negative reviewer does not point out any critical flaws in the paper, I think the positive opinions should outweight the negative one in this case. I therefore recommend accepting the paper.
Below are multiple reviews of a paper. The paper tackes clinically and technically important problem. Detailed information for the implementation such as experimental setup and network structure were given. The final performance of the proposed method is inferiror to existing methods.Authors provide an ablation study against Faster RCNN with a VGG16 backbone. They show multiscale features from the proposed decoder help for high quality RPN targets.The results seem good, compared to certain comparable methods, although not compared to the best methods. The results are not as good as the 3D model (3DCE) as noted by the authors. The experimental setup notes that augmentations and normalisations are used.The paper uses the DeepLesion dataset, which includes a large number of pulmonary nodules. The presented combination of U-net-like backbone and the Faster R-CNN detection framework does not outperform the baseline.	The paper received unanimously negative reviewing comments from four independant reviewers, citing concerns about the limited novelty (mostly combination of known methods), possibly inappropriate choice of dataset, performances below SOTA ones, etc. The rebuttal does not sufficiently address the above concerns as most of the reviewers stick to the negative rating.
Below are multiple reviews of a paper. The benchmark provides the first two datasets to examine multimodal robustness in video-text settings. Through algorithmic perturbations to YouCook2 and MSRVTT, the work offers a lens to understand how both textual and visual alterations affect retrieval.The paper proposes two text-to-video retrieval datasets and conducts robustness experiments. The authors consider 90 visual and 35 textual perturbations in total. The paper points out the weakness in several multi-modal models and draws some conclusions useful for model design.This paper proposed two large-scale benchmark datasets by applying 90 visual and 35 different textual perturbations to the existing retrieval datasets MSRVTT and YouCook. The benchmark is evaluated using several SOTA baselines of different input features and training strategies and two proposed metrics.The submission is of full oringinality. The team performed enough of experiments, adopt reasonable metrics to evaluate the results. I think these contribution will act as benchmark for the future research in the robust multi-modal learning.The paper brings up a study on the robustness of multimodal models which uses text and video. It proposes a benchmark of video-caption pairs with different types and intensities of perturbations. The paper compares four different models and uses the text-to-video retrieval score.The paper addresses an important topic of evaluating multi-modal models with regards to their robustness against perturbations. The paper is well-written and easy to understand.	This paper proposes new benchmarks for probing video-text models' robustness, that include a multitude of visual/textual perturbations. All of the reviewers have acknowledged the usefulness and effort put into the benchmark construction and presented analysis. Some of their concerns centered around: lacking metric definitions, limited scope (video-text), detachment from real-world scenarios, issues with figure/table presentation, etc. After rather extensive discussions, many of the concerns have been resolved. Presently, 4 out of 6 reviewers argue for acceptance (3 of them strongly). The remaining 2 reviewers maintain their opinion on the limitations of the presented work, most importantly somewhat inconclusive takeaways, limited number of models compared (initially 5, the authors have added one more), mostly one task (video-text retrieval). I believe having 6 models is acceptable for the proposed study. Upon carefully examining the claims/arguments, I encourage the authors to "scale down" their claims/narrative (and perhaps even rename the paper) to **more explicitly acknowledge the emphasis on video-text retrieval**. But I still think the analysis as such is valuable and thus recommend acceptance.
Below are multiple reviews of a paper. This paper uses Variational Inference to query pre-trained flow-models. Authors first show that it is not trivial to conduct such queries exactly. The paper then proposes a framework that affords such querries by working in latent space.The paper proposes to solve the conditional inference problem by performing a relaxed version of variational inference in the prior space of the flow-based model. The key novelties (A and B) are incremental in nature given the above related works that are not cited.In this work, the authors propose a novel method of estimating conditional distributions over arbitrary partitions of variables $x = [x_1,x_2]$ Using an existing pre-trained flow model for $p(x)$. Their method fits a new *pre-generator* flow for each observation which maps from a baseThe paper is concerned with the approximation of conditional densities in trained normalizing flow models. Conditioning deep differentiable models is a standard domain of application of Bayesian inference. The main idea behind the method is to perform inference in the latent space.	This paper proposes a method for conditional inference with arbitrary conditioning by creating composed flows. The paper provides a hardness result for arbitrary conditional queries. Motivated by the fact that conditional inference is hard the paper therefore suggests a novel relaxation where the *conditioning* is relaxed.  There were various concerns from the reviewers regarding notation, comparison algorithms, and how the hardness result motivates the smoothing operation introduced. After careful study of the paper and all the comments I find that I am most concerned about the hardness result and how it motivates the smoothing operation that is done. Novel computational complexity results *as such* are not really in the scope of ICLR. There's nothing wrong with having such a result in a paper, of course, but a paper like this should be evaluated on the basis of the algorithm proposed.  Like R4, I do not follow how this hardness result is meant to motivate the smoothing that's applied. The paper is unambiguous that the goal is to do conditional inference. A hardness result is presented for conditional inference, and so a relaxed surrogate is presented. This has a minor problem that it's not clear the relaxed problem avoids the complexity boundary of the original one. There's a larger problem, though. The hardness result has not been sidestepped! The goal is still to solve conditional inference. The algorithm that's presented is still an approximate algorithm for conditional inference. R4 suggests that other approximation algorithms should be compared to. The authors responded to this point, but I am not able to understand the response. For the same reason, I think it is valid to ask for comparison to other approximate inference algorithms (e.g. without smoothing)  None of the above is to say that the smoothing approach is bad. It may very well be. However, I think that either the existing argument should be clarified or a different argument should be given.  Finally here are two minor points (These weren't raised by reviewers and aren't significant for acceptance of the paper. I'm just bringing them up in case they are useful.)  Is Eq. 3 (proof in Appendix B.1) not just an example of the invariance of the KL-divergence under diffeomorphisms?  Proof in appendix B.2 appears to just a special case of the standard chain rule of KL-divergence (e.g. as covered in Cover and Thomas)
Below are multiple reviews of a paper. The authors argue that uniform priors for the high-level latent representations improve transferability. The approach is evaluated on deep metric learning, zero-shot domain adaptation and few-shot meta-learning. The results show consistent improvement in the different tasks.The authors propose a regularization technique that maximizes the entropy of the learned representation. The uniformity prior is imposed via an adversarial objective function. The proposed regularization can be easily added to the existing frameworks to improve their generalization ability.The authors claim uniformity in embedding space if the key for good generalization. They propose an adversarial training based method to improve the uniformity of feature space. The authors provide no evidence on how the method works.The paper is overall well-written and easy to follow. The overall idea of using a uniform regularizer on manifold is interesting and supported by theoretical considerations coming from GAN and VAE-like formulations.	The authors argue that uniform priors for the high-level latent representations improve transferability, which is beneficial in a number of tasks involving transference. The approach is evaluated on deep metric learning, zero-shot domain adaptation and few-shot meta-learning.  Pro: - A simple yet effective method - Signifiant gains in experimental study  Cons: - Close variants of this approach were proposed in previous works, and so the novelty of the current work is limited. - There is no accompanying analysis which may shed new light on the advantages of the approach.
Below are multiple reviews of a paper. The paper provides a  end-to-end pipeline for time-series analysis fo the HiRID dataset an ICU dataset. It involves the preprocessing of data, proposing possible tasks where this dataset can be used, finally evaluating models.The authors present a number of contributions related to the HiRID-ICU database. The temporal resolution may also enable improved performance over other datasets. A major weakness of the paper is lack of clarity and details in the methods.This work provides a modular and standard pipeline to pre-process the public ICU time-series dataset. It creates six clinically relevant prediction benchmark tasks, and evaluates regular machine learning methods (LightGBM, Logistic Regression) and deep learning methods.	The reviewers all liked the paper.  The dataset will provide more information for the medical and machine learning community. The authors' response clarified some important points.  The authors are strongly invited to integrate these points in the final version.
Below are multiple reviews of a paper. Machines should be able to generalize in the same ways as children. The motivation is ambitious, interesting, and relevant. It pulls strongly from cognitive science. The paper is highly sylized and polished.This work proposes a benchmark for evaluating the task-solving capabilities of agents on three levels: perceptual, conceptual, and algorithmic. The tasks are procedurally-generated contextual 2D gridworld environments. The paper provides empirical evaluations of TD3 with various encoder/decoder architectures.The authors propose a task HALMA which involves a grid-world maze that is partially observed. The aim of this environment is to test three proposed 'levels of generalisation' I found the paper had an enjoyable positive style of discourse and built up the problem area quite nicely in the introduction.The paper introduces a new benchmark which measures agent reasoning abilities and their generalization. The paper extensively motivates this benchmark and shows experiments with training RL agents on it.	This paper proposes a new task domain for learning-based AI agents, HALMA, a game that is designed to bring together multiple areas of research in AI. Perception, in the form of recognition of MNIST digits, learning mathematics - in the form of arithmetic operations on the natural numbers, and navigation and planning. When combined into a game, these elements are argued to require various important properties of human cognition, such as abstraction, analogy and affordance.   I commend the ambitious goals of this work, and its multidisciplinary motivations. I believe the benchmark can indeed eventually be an important challenge for the community. I think that the dynamic testing aspect is particularly interesting, where the environment produces trials designed to go beyond the agent's experience to that point. However, having considered the views of the reviewers and read the (main body) paper entirely myself, I unfortunately cannot recommend acceptance in its current form.   The main reason for the decision is simply that it is prohibitively challenging for me to grasp exactly how the game actually works after a thorough reading and considerable thought. The authors spend two pages motivating the approach with (arguably excessively grandiose) allusions to Marr's levels of analysis, Gibson's affordances, Holyoak's analogy and various other famous works from the history of AI and philosophy of mind; as well as to the board game HALMA. But as a reader I can't myself start to make any of these connections because the game proposed by the authors has not been explained to me! It is finally introduced on the fourth page - with reference to Figure 2 which is too small to consult and very hard to interpret. After consulting the appendix (where the idea is a bit clearer) I was able to decipher the way in which the numbers related to the maze itself, but was (and am still) unclear on the actions available to the agent. These are explained as follows:   ""The direction set is t , , , u. The primitive action set, in terms of the numberof moves, is t , , , u; this design of primitive numbers with a maximum of three aligns withthe doctrine of core knowledge in developmental psychology (Feigenson & Carey, 2003; Dehaene,2011). If an option is selected, consecutive hops as in Halma are simulated; all observations fromintermediate states will be skipped, and only the observation of the final state is provided. A movewould fail if a wall stops the agent, leaving the agent’s position unchanged; failure moves bringpenalties to the agent. The agent would receive a positive reward when reaching the goal""  From reading this I am left with the following questions:  - Are directions primitive actions?  - How can a primitive action also be a number of moves?  - What does it mean to select an option?  - Can I select an option and an action at the same timestep?   Most importantly, I still don't really know how the game works.   This example is intended to illustrate the difficulty faced by readers of this paper in general.    I note that the reviewers awarded this work scores that place it on the borderline for acceptance, but with consistently low confidence. On consulting with the reviewers it is clear that this is not because they lack expertise but because they too did not understand the full details of how this domain/task works. This is also clear from the lack of detail in their reviews; only reviewer 3 engaged with any of the details of the task itself.   To summarise, I think there is potentially a very interesting and important contribution in this dataset. However, the work will only have impact in the community if it can be understood and adopted after a single read of the paper. I therefore recommend that the authors resubmit this work to a different venue taking account of the following:   - Explain how the game works *then* connect it to the literature on human learning *not* vice versa (from the concrete to the abstract) - Be very concrete, perhaps guide the reader through a single particular episode explaining the observations available to the agent and the options open to it at each important point-  Get to the point of your contribution. Tenuous connections to cogsci etc can go in the discussion - Make all diagrams and illustrations extremely simple to interpret and large enough to easily read - Avoid use of subjective adjectives, and particularly describing one's own contributions as "ingenious solutions" and "impeccable" - Avoid rhetorical flourishes and latin - Submission to a journal may allow the authors greater space to draw the desired connections to disparate fields without compromising on readability or exposition of their methods
Below are multiple reviews of a paper. The M-GAIL method is a variant of the GAIL method for adversarial training. In GAIL, the policy is optimized to minimize the ability to discriminate (classify) two classes: trajectories of the expert vs. trajectories from the policy. In the proposed method, the discriminator is forced to also discriminate aThis paper proposes M-GAIL, which performs imitation learning from expert as well as sub-optimal demonstrations. This work builds off of GAIL (Ho et. al 2016) but modifies the discriminator. The authors show empirically that including these sub-Optimal demonstrations into the training process leads to faster and improved learningThis paper is about adversarial imitation learning and how data from non experts can be used to improve representation learning of the discriminator function. They also change the training objective because minmax does not lead to an optimal policy.The paper proposes a modification of GAIL (Ho & Ermon, 2016) to make use of non-expert data. The general problem setting is interesting, but I think it is of rather little significance, because I do not see many clear applications. The paper mentions the game of Go, but learning a policy on such large	This paper proposes a variant of GAIL that can learn from both expert and non-expert demonstrations. The paper is generally well-written, and the general topic is of interest to the ICLR community. Further, the empirical comparisons provide some interesting insights. However, the reviewers are concerned that the conceptual contribution is quite small, and that the relatively small conceptual contribution also does not lead to large empirical gains. As such, the paper does not meet the bar for publication at ICLR.
Below are multiple reviews of a paper. The report contains a reproducibility summary incorporating their main findings and the overall replicability of the original paper. The report can significantly benefit from improved writing, especially by shedding motivation on the choice of extended experiments. The authors do not delve into veracity of the theoretical contributions made.The authors do a nice job of (a) providing an overview of the original work, (b) detailing their reproduction effort and (c) summarizing their findings. The decomposition fo what was /wasn't reproducible with hypotheses around why is particularly valuable.	A good reproducibility study with a detailed analysis of the original paper. The author's effort in writing the code from scratch in PyTorch is commendable. It would be great to work on some presentation issues that reviewers suggested.
Below are multiple reviews of a paper. This paper proposes a distributional Actor critic framework (GMAC) based on GMM, Actor critic and Cramer distance. The majority of the results presented show convincing improvements of GMAC over IQAC and the PPO baselines.This paper proposes to learn a Gaussian Mixture Model of the distribution of returns and use it as the critic in an actor-critic RL agent. However, this work has several problems that make it unpublishable at the moment.This paper proposed a Gaussian-mixture Actor Critic (GMAC) framework to address the problems of distributional RL. The framework uses Gaussian mixtures to represent the distribution of value functions, and learn the Gaussian distribution parameters.This paper proposes an actor-critic algorithm based on distributional RL. Distributions are approximated as mixtures of Gaussians, Bellman targets are computed using Lambda-returns, and the training loss is computed using an energy distance.	The paper proposes a distributional perspective on the value function and uses it to modify PPO for both discrete and continuous control reinforcement learning tasks. The referees had noticed a number of wrong/misleading statements in the initial version of the submission, and the AC had also pointed out several problematic statements in a revised version. While the authors had acknowledged these mistakes and made appropriate corrections, there are several places that still need clear improvement before the paper is ready for publication. The paper seems to introduce a novel actor-critic algorithm. However, the correctness of its key step, the  SR($\lambda)$ algorithm, has not been rigorously justified. For example, it is unclear how the geometric random variables would arise in that algorithm. For experiments, the AC seconds the comments provided by Reviewer 2 during the discussion: "The empirical comparisons are overall still lacking: for the smaller-scale experiments, whilst the authors have been actively engaged in improving these comparisons during the rebuttal, at present, they are still in need of updating to make a fair comparison, for example in terms of the number of parameters included. The authors have acknowledged this, although the rebuttal period ran out before they were able to post new plots. The large-scale empirical results are still lacking reasonable baselines against existing distributional RL agents."
Below are multiple reviews of a paper. In this paper, the authors proposed a new domain adaptation setting for adaptation between single source but multiple target domains. The proposed framework is quite similar to DSN. The presentation is in a quite poor quality, including many typos/grammatical errors.Multi-target domain adaptation is an unexplored scenario compared with adapting single/multiple source to single target. A mutual information-based loss is proposed to encourage part of the features to be domain-specific while the other part to beDomain-invariant.The biggest contribution is the setting part, where one seeks to adapt one source to multiple, but somewhat similar, target domains. It is interesting to explore such direction since in many real-world applications, applying the model to many different target domains are required.	The paper proposes the unique setting of adapting to multiple target domains. The idea being that their approach may leverage commonality across domains to improve adaptation while maintaining domain specific parameters where needed. This idea and general approach is interesting and worth exploring. The authors' rebuttal and paper edits significantly improved the draft and clarified some details missing from the original presentation.   There is an ablation study showing that each part of the model contributes to the overall performance. However, the approach provides only modest improvements over comparative methods which were not designed to learn from multiple target domains. In addition, comparison against the latest approaches is missing so it is likely that the performance reported here is below state-of-the-art.   Overall, given the modest experimental gains combined with incremental improvement over single source information theoretic methods, this paper is not yet ready for publication.
Below are multiple reviews of a paper. This work tackles the problem of learning linear sorting functions with bounded noise under Gaussian martingales. The proposed algorithms enjoy strong theoretical sampling guarantees and a polynomial runtime.This paper is the first to study the problem of learning linear label rankings in the presence of noise. They provide two algorithms, one improper and one proper, for learning with error bounds in the normalized Kendall tau distance.The algorithm is generalized to any k and is further used to obtain a proper learner using the ellipsoid method. When the error is measured by top-r disagreement loss, the proper Learner also achieves improved sample complexity.The paper studies two notions of closeness: kendal-tau distance, and top-r distance. The goal is the learn a matrix ~W which approximates the label ranking. The problems seem like natural extensions of learning halfspaces with Massart noise.	The reviewers are unanimous in their strong positive opinion on this paper.  The authors have given the first efficient algorithms for learning noisy linear sorting functions with theoretical guarantees a relevant and useful problems setup for the NeuRIPS community.  The reviewers consider the paper clear and well-presented and thus this is a natural accept.
Below are multiple reviews of a paper. The paper is very difficult to read, and lacks coherence in addition to several typos throughout the paper. The introduction talks only about theoretical background of reconstructing Diffusion Tensor Image from DWIs.The results shows the models ordered by prediction times are: VOX, NBH, CSD and NNLS. The differences between models are very significant. The techinical novelty seems limited.The article suffers from lack of motivation behind the proposed work, lack of novelty, as well as poor writing and missing results. In its current state, the article cannot be said to be ready for publication. The method is described as self-supervised.The paper proposes to use a self-supervised approach to estimate the local fiber orientations in diffusion data. The experimental setting of the work is unclear, with misleading explanations on the data used and the experiments performed on each dataset. The relevant literature using DL methods for the presented problem is missing.	All reviewers have brought up serious concerns and major issues of the submitted work. They all agreed that the current quality of the manuscript will need significant improvement, in terms of writing, model design, and quantitive analysis of experimental results, to publish at MIDL. Details are included in each reviewer’s feedback.
Below are multiple reviews of a paper. The goal is to maintain a near-optimal solution and simultaneously minimize the recourse, namely the number of facility openings/closings $+$ reassignments of clients to centers. In this setting, the paper gives a dynamic algorithm that maintains a constant approximation guarantee. There are some experimental results which I don't know how toDynamic Facility Location problem (with client insertions and deletions) is being considered in which modifying the solution involves additional cost (recourse) The authors provide an algorithm that maintains a constant factor approximation solution to the current instance.The paper studies fully dynamic facility location for general metric spaces. The main result is a dynamic algorithm which maintains a O(1)-approximate solution using O(log m) amortized recourse.The authors develop the first fully dynamic algorithm for facility location with constant approximation guarantee and polylogarithmic recourse per update. This guarantees that the current solution does not change ``too much'' after any update.	The paper considers facility location problem in a well-motivated fully-dynamic setting where clients can arrive and depart. The goal is to maintain a near-optimal solution and simultaneously minimize the amount of "recourse" (the number of facility openings/closings and reassignments of clients to centers). However, this algorithm only works when the ratio of maximum distance / opening cost to minimum distance / opening cost is bounded polynomially in the number m of given facility locations; the paper presents an algorithm that maintains a constant-factor approximation guarantee while using an O(log m)--amount of amortized recourse per change. The idea is to relax the classical greedy algorithm of Jain-Mahdian-Saberi for the static case.which picks repeatedly a cluster---a facility along with the clients assigned to it---of minimum average cost, and to show how to maintain such a solution dynamically with small recourse.   The paper was generally strongly appreciated by the reviewers.
Below are multiple reviews of a paper. The paper is driven by the challenge of modeling the ambiguities of certain tasks, like the RNA folding problem. The flow of this paper is clear. It introduces the motivation first and then its solution to the problem fits the motivation nicely. The experimental design supports their claims.The paper introduces a novel probabilistic layer into the transformer architecture that incorporates cVAE. It also introduces a training strategy ("kappa annealing") to effectively train models with such layers while reducing need for tuning. While the elements of the main ideas are present, they are presented in a mathematically unclear manner.The authors present a probabilistic Transformer dubbed ProbTransfomer that models hierarchical latent distributions by integrating the transformer structure with a conditional variational auto-encoder. The article reveals that the incorporation of generalized ELBO with limited optimization is advantageous for variational training.	This is a nice application-motivated paper that introduces and tests a novel stochastic variant of a transformer architecture.  All three reviewers recommend acceptance (albeit one is borderline). The borderline review focuses on the closeness of this to existing work, and the relatively incremental nature of the contribution. While I do see the potential concern, I think all in all the consensus is clearly to accept.  Interaction between reviewers and authors led to a number of beneficial changes to the paper during the review process.
Below are multiple reviews of a paper. The paper builds up on Carefl (Khemakhem et al 2021), which fits an autoregressive flow model using the variables' causal ordering. It does not provide any identifiability result, showing that the learnt graph is indeed causal.This paper proposes to combine the continuous optimization-based causal discovery approach from notears with flow-based function learning. An extension is given to data missing (completely) at random. I think this is a strong paper, both for the main result as well as for the unifying framework in section 5. My only concern is that theThe authors consider a fundamental problem of learning directed causal graphs with nonlinear continuous data. They propose a scale causal discovery method based on the flow, variational inference, GNN, and Notears. The method is a novel and interesting contribution to the continuous optimization literature.This paper proposes a general flow-based approach to learn DAGs from data. It provides a unified view of existing continuous optimization methods for structure learning. The paper is well written and easy to follow.The paper proposes a flow-based causal discovery method to learn nonlinear causal DAGs with potential missing values. The proposed approach is based on Variational Bayes and continuous optimization approach. Strengths: First paper to combine VB with NOTEARS.	This paper proposed a flow-based approach FCause to Bayesian causal discovery that is scalable, flexible, and adaptive to missing data. Reviewers were split on this paper and could not reach a consensus during the discussion, and no reviewer pushed for acceptance. After taking a closer look myself, I agree with several of the reviewers that while the core ideas here are interesting and novel, there remain too many unresolved issues that require another round of revision.  I encourage the authors to carefully take in account the reviewers' comments and re-submit this promising work to another ML venue.
Below are multiple reviews of a paper. This dataset includes daily living action data collected by two cameras and several IMUs from 51 stroke-impaired patients and 20 healthy subjects. The motivation is to facilitate the rehabilitation process after stroke that requires repetition of sub-second actions. The paper states that it introduces a multimodal dataset but the benchmark is done respectively.In this paper, authors introduce a new multimodal dataset called StrokeRehab. It includes inertial measurements and video data of several daily activities performed by 51 stroke impared patients and 20 healthy subjects. In addition, a novel approach dedicated to high resolution action identification is proposed.This article proposes a dataset for identifying short duration actions for physical rehabilitation that contains both video and IMU data. THe dataset includes data from stroke-impaired patients and healthy subjects performing activities of daily living, and labels at a high temporal resolution. The article also proposes a novel sequence-to-sequence approach to identify actions.This paper describes the StrokeRehab Dataset for action sequence recognition. The dataset consists of sub-second 3,372 trials (120,891 functional ‘primitives’) in 71 subjects. Data was recorded with 9 IMUs on the upper extremities, and featurized using the IMU acceleration, quA new dataset called StrokeRehab provides action information for multiple patients rehabilitating from strokes as well as healthy subjects performing similar actions. The paper also proposes a new algorithm to improve action recognition on this dataset.The authors introduce a large-scale action-recognition dataset called StrokeRehab. The dataset consists of 3,372 trials of rehabilitation activities and 120,891 functional primitives. It provides a benchmark for generalization in the presence of realistic distributional shift.	This submission receives reviews from 6 different reviews. Most reviewers (5/6) appreciate the contribution of the new dataset. They acknowledge that the problem setup is interesting and the dataset may be useful for different research communities: computer vision, time series analysis, medical. On the other hand, reviewer 38gN concerns about the novelty of the proposed dataset. AC reads all reviews and comments, and discussions, and is convinced that the proposed dataset will provide a useful benchmark for research, thus AC recommends to accept this submission as a poster. AC recommends the authors to incorporate all suggestions from reviewers for the final camera version.
Below are multiple reviews of a paper. The paper proposes a self-supervised deep-learning framework for image-to-image translation tasks, such as segmentation. The method provides a mechanism to impose consistency in output across multiple points from the same individual.This paper tackles self-supervised learning for longitudinal medical images by designing loss functions that consider the temporal evolutions of scans taken from the same subject. A U-net architecture is pre-trained via a combined loss function that maximizes the similarity between encoder features from corresponding local patches acquired at different times.The paper claims that prior works on self-supervised learning are ill-suited to handle typical longitudinal medical image sequences. The proposed solutions are evaluated on three datasets with longitudinal medical images.	The paper proposes a self-supervised deep-learning framework for image-to-image translation tasks, such as segmentation, that accommodates and fully exploits longitudinal data. Specifically the method provides a mechanism to impose consistency in output across multiple points from the same individual and simple regularisation terms to avoid some problems common with other methods, such as mode collapse. The authors compare the method against baselines in two distinct neuroimaging segmentation tasks, which nicely demonstrate the additional power afforded by imposing longitudinal consistency.  The reviews overall reported that the submission tackles an important problem, presents well formulated experiments, and shows a significant advance over the SOTA.   The reviews raised concerns raised included non-specialist accessibility, adding more related work, and questions w.r.t. the claims, presentation, and relevance of the results, and particularly about the mode collapse problem. The authors have addressed these concerns, in particular by adding a new section (Section E/Need for regularization) to the Supplementary Material which contains several new visualizations and quantifications of the mode collapse problem (from ablation experiments). The paper has been updated to reflect some  clarifications required by reviewer de4n. Some citations suggested by Reviewer r9Zh are now discussed in the submission.  As it is, the paper meets all conditions for acceptance at NeurIPS 2022.
Below are multiple reviews of a paper. IMV-LSTM can handle multi-variate time series data in a manner that enables accurate forecasting, and interpretation. The propose model outperforms popular interpretable models on three different datasets.This paper describes a recurrent model (LSTM) which can produce variable-wise hidden states. These states can be further used for two types of attentions: 1) variable importance for the importance of each variable (not accounting for time), and 2) temporal importance. The proposed NN model does not seem to directly provide suchThe contributions of this paper are in the field of LSTM, where the authors explore the interpretability of L STM with multivariate data. To this end, the authors endow their approach with tensorized hidden states.	The reviewers appreciated the clarity of writing, and the importance of the problem being addressed. There was a moderate amount of discussion around the paper, but the two reviewers who responded to the author discussion were split in their opinion, with one slightly increasing their score to a 6, and the other remaining unconvinced. The scores overall are borderline for ICLR acceptance, and given that, no reviewer stepped forward to champion the paper.
Below are multiple reviews of a paper. The authors identify 55 research papers and manually code them on the basis of location, data topic, application domain, and ethical risk type. The authors draw conclusions regarding the prevalence of different applications and risk types in the global south vs global north.A survey paper discusses an analysis of the application areas for computer vision technology in the Global South and their potential risks. The authors analyzed 55 research papers using open and axial coding to identify application ideas and used the moral compass framework.The paper presents insights from a literature review of computer vision and risk factors in the global south. I think the manuscript holds merit and the work would spawn interesting conversation at GI.	The paper received mixed scores from the reviewers (7, 7, 3). I believe that a survey paper is a valid contribution type for GI's HCI track, as it helps further our knowledge about designs that have been explored and highlights what can be done in the future. While the paper has shortcomings (addressed in the paper) and offers limited results (as acknowledged by all reviewers), the results are timely (R3) and interesting (R1, R3). Based on this, I recommend that the paper be accepted.     Below I summarize the key issues identified by the reviewers and encourage the authors to read through the individual reviews carefully to address other concerns.   - Address the methodological limitations early in the paper (R2, R3)  - More directly define the scope of this work (e.g., what does CV-systems encapsulate (R1), acknowledge that risks not identified in the analysis may still exist (R3))  - Provide more details about background literature (R1, R3)  - Clearly highlight the surprising and new results (R1)    Recommendation: Accept
Below are multiple reviews of a paper. This paper provides fine-grained solution for PAC reinforcement learning with the deterministic MDP setting. Proposed algorithm is based on the elimination rule and the resulting complexity is expressed in terms of min flow with linear program formulation. The experiment is motivate.This paper studies instance-dependent optimality of PAC reinforcement learning in tabular deterministic episodic MDP. It introduces a new notion of sub-optimality gap called deterministic return gap. The paper also proposes an algorithm based on maximum coverage sampling and confidence-based elimination.This paper studies PAC RL in tabular deterministic MDPs with known transitions but unknown (stochastic) rewards. A new algorithm is presented (EPRL) which is worst-case minimax optimal and matches the instance-dependent lower bound up to an H^2 term and logarithmic factors.This work studies the PAC RL problem in the tabular finite horizon setting for deterministic transition MDPs. The paper derives instance dependent lower bounds and an algorithm which nearly matches the lower bounds.	The paper studies PAC reinforcement learning in tabular episodic MDPs with deterministic transitions and provides upper and lower bounds on the sample-complexity that match up to horizon and log-factors. Overall, all reviewers rate this paper positively (after the authors' responses and discussion). They view the contribution of a fine-grained instance-dependent guarantees in this setting as significant and particularly appreciated the novel insights, e.g., relating the MaxCoverage function in Algorithm 1, to the StaticMaxCoverage in Algorithm 3 or the inclusion of graph-theoretical concepts in the lower bound analysis. There were also several limitations raised, in particular the deterministic transition assumption and the reward range assumption used in the lower bound. However, some of these can be addressed by clarification and more detailed discussion in the camera ready. All in all, this is a solid paper and is recommended to be accepted.
Below are multiple reviews of a paper. This paper proposes two variants of stochastic gradient algorithms without replacement. For smooth functions satisfying the PŁ condition, the proposed shuffling-based variants converge faster than their with-replacement counterparts. The majority of the manuscript is well-written and easy to understand.This work analyzes the convergence rate of local and mini-batch Random Reshuffling. It provides high probability upper bounds, and matching expected lower bounds. The analyzed problems have significant importance in practice and lack a thorough theoretical understanding yet.This paper studies two popular algorithms: local SGD and minibatch SGD using the data shuffling technique, which means sampling without replacement. Authors provide analysis under PL condition and show that in some cases these methods with shuffling outperform classical local SGC and minIBatch SGC. At the end of the paper, a	This paper analyzes local SGD under the random reshuffling data selection setting. As is the case for standard random reshuffling, better rates are shown for local SGD when random reshuffling is used. This would already be a nice contribution to a line of work on random shuffling methods—but the paper goes beyond that by showing a matching lower bound and designing a (theoretically) better variant algorithm. The reviewers were all in agreement that this paper should be accepted (as a result not much further discussion happened after the original reviews), and I agree with this consensus. The modification seems to improve the paper, although I did not look through it in detail.
Below are multiple reviews of a paper. The authors suggest a relationship between a leaky relu and a spiking integrate and firing neuron model. The findings are quite interesting but the paper is not well written. I don't think it would help the progress of the field to publish the article in the current form.The authors seek a mechanism to train a spiking neural net to duplicate the function of a non-spiking one. This is desirable for energy-efficient inference. The training process becomes challenging due to the discrete nature of the spiking process.Conversion to SNN actually improves rather than damage the accuracy on ResNet. Although the proposed method is much more efficient, it does not show obvious performance improvement.	The work tackles the task to convert an artificial neural networks (ANN) to a spiking neural network (SNN). The topic is potentially important for energy-efficient hardware implementations of neural networks. There is already quite some literature available on this topic.  Compared to these, the manuscript exhibits a number of strong contributions: It presents a theoretical analysis of the conversion error and consequently arrives at a principled way to reduce the conversion error. The authors test the performance of the conversion on a number of challenging data sets. Their method achieves excellent performances with reduced simulation time / latency (usually, in order to achieve comparable performance to ANNs, one needs to run the SNN for many simulated time steps- this simulation time is reduced by their model).  One reviewer criticized that the article was hard to read, but this opinion was not shared by other reviewers and the authors have improved the readability in a revision.  In summary, I believe that this manuscript presents a very good contribution to the field.
Below are multiple reviews of a paper. This paper proposes a task-grouping method and novel training algorithm for MTL. There are some flaws in the proposed method and the proposed methods seems not technically sound. The definition of the transference measure is problematic.Despite there are typos in a few places, the paper is good written and easy to follow. The empirical results are very weak. With considering the variance, I doubt any of the improvement in Table 2 is statistically significant.This paper studies the transferability in multi-task learning. They propose a metric, transference, to evaluate how tasks affect each other. They also propose a method called IT-MTL to compute and improve lookahead loss changes.This paper studies the problem of task relationship/transference in multi-task learning. A (nonsymmetric) task transference between task $i$ and task $j$ can be computed by measuring the relative change of training loss of the two tasks.	This paper proposes a method to quantify transference, which is a measure of information transfer across tasks, for multi-task learning framework. Specifically, the transference is measured as the change in the loss for a specific task after performing a gradient update for another. The proposed transference measure is used to both understand the optimization dynamics of MTL and improve the MTL performance, either by grouping tasks or combining task gradients based on the transference. The method is validated on multiple datasets and is shown to bring in some performance gains over the base MTL model (PCGrad, UW-MTL).   The majority of the reviewers were negative about this paper (4, 4, 5), while one reviewer gave it a positive rating (6). The reviewers in general agreed that the idea of measuring transference as the change in the loss with gradient updates is novel and intuitive. Yet, the reviewers had common concerns on the 1) weak performance improvements, and the 2) high-cost of computing the transference. While computing the transference requires additional computations with linear time complexity, which may be problematic with a large number of tasks, the performance gains using it were rather marginal (less than 0.5% over the baselines).  Another common concern from the reviewers was its insufficient experimental validation, as a comparative study against existing works that perform task grouping is missing. Both the authors and reviewers actively participated in the interactive discussion. However, the reviewers found that the two critical limitations persist even after the authors’ feedback, and in a subsequent internal discussion, they reached a consensus that the paper is not yet ready for publication.   Thus, although the proposed method is novel and appears to be promising, it may need more developments to make it both more effective and efficient. Moreover, there should be more in-depth analysis of its time-efficiency, and other benefits (e.g. interpretability) that could be achieved with the proposed transference measure. Finally, while there exist many works on learning both hard or soft task grouping, the authors do not reference or compare against them. To name a few, [Kang et al. 11] propose how to learn the discrete task groupings, [Kumar and Daume III 12] propose to learn a soft grouping between tasks, [Lee et al. 16] propose to learn soft grouping based on asymmetric knowledge transfer direction across the tasks, and [Lee et al. 18] proposes the extension of [Lee et al. 16] to a deep learning framework. I suggest the authors to discuss and compare against the above mentioned works, and fortify the related work section by searching for more classical works on multi-task learning.   - [Kang et al. 11] Learning with Whom to Share in Multi-task Feature Learning, ICML 2011 - [Kumar and Daume III 12] Learning Task Grouping and Overlap in Multi-task Learning, ICML 2012 - [Lee et al. 16] Asymmetric Multi-task Learning based on Task Relatedness and Confidence, ICML 2016   - [Lee et al. 18] Deep Asymmetric Multi-task Feature Learning, ICML 2018.
Below are multiple reviews of a paper. This paper explores the knowledge distillation problem in object detection. Extensive experiments are conducted on MS COCO and verify the effectiveness of the proposed method.The paper proposes a knowledge distillation method for object detection. The proposed modules provide consistent improvements in detection MAP across different architectures. The observation that a high-AP teacher is important for distillation is quite intriguing.The authors have made clear some of my concerns and made revisions accordingly. I am in a position now to recommend this paper, thus I update my initial recommendation from 5 to 6.	After the rebuttal stage, all reviewers lean positive (in final scores and/or in comments during the discussion phase). The AC found no reason to disagree. The benefit of the proposed method is demonstrated in many diverse settings, and the authors argue novelty in that no prior work addresses both fg/bg imbalance and relation distillation.
Below are multiple reviews of a paper. This paper proposes an operator splitting method which solves a convex relaxation of a learge-scale nonconvex optimization problem. The proposed method is modular, scalable and parallelizable. Experimentally, the authors demonstrate that the proposed method has tighter bounds on the worst-case performance of large CNNs in image classification and RL settings.The paper proposes a novel method for the neural network verification problem. The authors use variable splitting and Lagrangian relaxation to relax the verification problem, which is then solved with ADMM. The method is GPU friendly and claims to solve the relaxation to optimality.This paper proposes an efficient solver for computing the convex relaxation of Neural Networks. The method is based on ADMM, with the authors proposing a novel decomposition of the optimization problem. The authors give convergence guarantees and show good convergence empirically with the optimization curves.This paper proposes ADMM for neural network verification problems. Experiments are demonstrated to show its effectiveness and scalability. This paper has several limitations, which are discussed as follows. The novelty of this paper should be justified better.DeepSplit is an improvement on two closely-related dual solvers for the same relaxation (the convex hull of element-wise activation functions) The inner problems require the use of an iterative optimisation algorithm.	The authors propose a novel operator splitting method for solving convex relaxations of neural network verification problems, and develop and validate an optimized implementation of the same on large scale networks, focusing on the problem of verifying robustness to norm bounded adversarial perturbations.  The reviewers agree that the paper contains interesting ideas that are worthy of further development and that these ideas may prove useful eventually in pushing the envelope of what is possible in neural network verification. However, in its current form, the paper misses some key experimental evidence to rigorously evaluate the value of the contributions made: 1) Comparison against SOTA incomplete verifiers: The authors do not provide detailed and rigorous comparisons against well-known baselines (for example the incomplete verifiers from Fast-and-complete (Xu et al., 2021), Beta-CROWN(Wang et al. 2021))  2) Incorporating tighter relaxations: It would be valuable for the community to understand whether the proposed algorithm is compatible with tighter relaxations like those of (Tjandraatmadja et al., 2020). Even if they are not, it would be interesting to understand the comparison against standard solvers for these tighter relaxations compared against the advanced solver developed by the authors applied to the weaker relaxation. 3) Showing performance in the context of complete verification: While this is not a requirement, it would be great to see how the method performs in the conjunction with a branch and bound search, as this sometimes reveals surprising tradeoffs or weaknesses of incomplete verifiers (as observed in the results of Beta-CROWN(Wang et al. 2021)).  I encourage the authors to strengthen the paper adding these experiments and resubmit to a future venue.
Below are multiple reviews of a paper. The paper tackles an interesting issue, and the efforts of the authors are clear in investigating the problem and in writing the manuscript. The authors adequately addressed the limitations and potential negative societal impact of their work.The authors propose two defense algorithms to train a secure model from scratch. They train a backdoored model first then removing the backdoor from the model. They follow an approach similar to [29] Supervised Learning.The proposed methods outperform the existing backdoor defenses either in backdoor detection or backdoor removal. The defense solution including a secure training (ST) module and a backdoor removal (BR) module seems simple yet effective against various classical backdoor attacks.The authors observe that the features of poisoned samples are more sensitive to image transformations. They use this observation to filter out poisoned data from the training set. The experimental results are pretty strong, and the work compares to other defenses and a range of attacks.	The authors propose a new method for defending against backdoor attacks which is based on the observation that poisoned samples are more sensitive to transformations than clean samples. They design a metric called \textit{feature consistency towards transformations (FCT)} to distinguish poisoned samples from clean samples in the untrustworthy training set.  The paper received favorable reviews and has made substantial updates during the rebuttal phase to the general satisfaction of the reviewers. I thus recommend accept.
Below are multiple reviews of a paper. The authors propose a GAN-based approach to learning disentangled representations. They combine elements InfoGAN with recent Information-Bottleneck perspectives on variational auto-encoders. The results on d-Sprites are quite good, and the latent traversals in Figure 2 show a good degree of disentanglement.The new approach is based on the idea of using an information bottleneck. The idea is to leverage the strengths of the GAN framework to make it easier to do.This paper introduces the IB-GAN and information bottleneck inspired GAN variant. The ordinary GAN objective is modified to include a variational lower and upper bound on the generative mutual information.	Strengths:  This paper introduces a clever construction to build a more principled disentanglement objective for GANs than the InfoGAN.  The paper is relatively clearly written.  This method provides the possibility of combining the merits of GANs with the useful information-theoretic quantities that can be used to regularize VAEs.  Weaknesses:  The quantitative experiments are based entirely around the toy dSprites dataset, on which they perform comparably to other methods.  Additionally, the qualitative results look pretty bad (in my subjective opinion).  They may still be better than a naive VAE, but the authors could have demonstrated the ability of their model by comparing their models against other models both qualitatively and quantitatively on problems hard enough to make the VAEs fail.  Points of contention:  The quantitative baselines are taken from another paper which did zero hyperparameter search.  However the authors provided an updated results table based on numbers from other papers in a comment.  Consensus:  Everyone agreed that the idea was good and the experiments were lacking.  Some of the comments about experiments were addressed in the updated version but not all.
Below are multiple reviews of a paper. The paper proposes an approach for learning disentangled latent representation in the VAEs. They replace the total correlation regularization term of Chen2018 with more appropriate group- and property-wise KL terms. More importantly, they link the data property y with the latent space w by a learned mapping.The paper presents the new Property-controllable VAE (PCVAE) to inductively bias the latent representation to capture explicit data properties. The paper proposes group-wise and property-wise disentanglement terms. The presented work is evaluated on two datasets from two domains.The paper proposes property controllable VAE, with the aim to learn certain latent variables correlated to the property and are disentangled. The paper has several important details that are missing, and seems not self-contained enough to reproduce if the reader is not familiar with the disentanglement literature.The authors propose to learn two sets of latent z and w: the dimensions of w are independent of each other and each dimension w_i maps to a known ground truth generating factor y_i. The key difference from the previous approach is the use of invertible and Lipschitz smooth mapping to learn monotonic m	This paper proposes a new approach to learning deep generative models with induced structure in the latent representation. All four reviewers gave the same score of 6 to this paper, showing a consensus that the paper is above the bar for acceptance. The authors did a commendable job of detailed replies to reviewer comments, which as R1, R3, and R4 all note has improved the clarity and quality of the paper, addressing their concerns.
Below are multiple reviews of a paper. The BigScience corpus and the BLOOM model trained using it are a significant step towards democratizing access to large language models. The work has been value-driven and is inclusive of diverse language families.The paper describes BigScience Corpus, a very large (1.6TB)                multilingual dataset. It is a very interesting initiative due to (1) its multilinguality and (2) care taken as far as quality is concerned. The paper is lacking clear evidence for Big science Corpus being superior to other data sets.This paper presents the BigScience Corpus which can be used to train large language model. With the help of international collaboration between multidisciplinary researchers, it provides a massive multilingual corpus (including text and code)This paper described an international effort of collecting a large-scale high-quality open dataset for language processing. I believe this dataset could be of interest to a lot of people working on this topic and could be a solid ground for future research. The development of this dataset is highly collaborative and open access.The authors created a new, multilingual corpus for training large language models. They crowdsourced language corpora all around the globe. Filtering of each language was done by a person proficient in this language.The paper presents the 1.6TB multilingual dataset built for training the 176-billion-parameter BigScience large open-science open-access multilingual language model (BLOOM) The dataset contains both natural languages and programming languages, collected from two sources.	This paper describes the creation of the BigScience corpus used to train the BLOOM model. The paper describes steps taken to curate and construct the corpus as well as analysis of what it contains.  This is an impressive effort and blazes a trail among such data collection and governance efforts. Reviewers appreciate the democratization of a dataset of this size and generally appreciated the care taken in its construction, such as the filtering of data by native speakers of each language.  The authors convincingly rebut a few points about PII (criticisms which could be leveled against nearly any model at this scale, and which require whole lines of research to address in complete detail) and the aims of the corpus.  The most major point brought up is about the release process, particularly the decision to release a subset of the dataset. However, I am satisfied with the authors' responses, particularly to reviewer nTin.  I also agree with the ethics reviewer that significant care has been taken in this project, and although the data governance aspects of it are not discussed as much here, an accompanying publication describes them in detail. Taken together, these two papers are a model for how other efforts should proceed down the road.  Finally, in a similar vein, there are a few comments about different choices that could've been made (e.g., inclusion of source code, "toxic" content, etc.). However, unlike some NeurIPS papers, I don't think this project can be reasonably expected to jump through hoops for reviewers. The main question is: is the effort itself worthy of publication (yes), and is the documentation of the different parts of the effort clear and useful to the community in its present state (also yes). The decision-making process is laid out clearly (and elements from the rebuttal could be integrated to strengthen the paper further) and it seems clear that this effort is best-in-class in terms of transparency and other factors here.
Below are multiple reviews of a paper. The work studies the problem of collecting new data to learn outcome distribution of sensitive groups. The paper explores interesting ideas on controlled data collection to correct biased estimates. There are limitations like the restriction to single dimensional data.The paper presents a method for "data debiasing" in a sequential-data setting with one feature. The algorithm conducts a form of bounded-random exploration in this one-dimensional setting. It can be used to perform learning under fairness constraints.The paper considers an algorithm to debias datasets through adaptive and bounded exploration for classification. Their algorithm works by adaptively picking a lower bound corresponding to a function of the percentile of the estimated univariate distribution (with current parameters)	This paper has seen a lot of discussion between reviewers and authors. Reviewers are fairly positive after the discussion/rebuttal phase and there have been significant score revisions upwards.  Few concerns that were highlighted during rebuttal/discussion phase are:   1) Multiple reviewers have pointed out that amongst two sources of bias - data bias and model bias - the authors focus on assembling a dataset to avoid the first type of bias. It has been pointed out using terms like "social bias, unfairness" and "statistical bias" are very misleading . I strongly suggest the authors to better revise the paper according to reviewer comments using more precise terminology -data bias and/or model bias. Clarity has been a concern uniformly shared amongst all reviewers.  2) The authors principally reduce the data to a single dimension using dimension reduction techniques and use thresholded classifier. Authors responded to this concern saying -effective feature learning in general amounts to that and there are optimal data dimension reduction techniques. Further authors also experimentally demonstrate that losses in accuracy is not much due to these techniques.   In summary, concerns 1 and 2 are not severe enough (as acknowledged by reviewers raising scores) but important to keep in mind while preparing the camera ready.
Below are multiple reviews of a paper. This paper considers a regression setting in which the missing values are observed with lower values than the true values. Authors provided appealing application for this problem setting. They rewrote the risk and provided an unbiased gradient estimator. There is a gap between the estimator and the actual implementation.The authors study the problem of training a regression model when only for a subset of the datapoints (those for which their label lie above the current model prediction) the correct labels are available. It is unclear if the labels y can be noisy, because all the derivations seem to be under the assumption they are not.In this paper, the authors address a new weakly supervised regression problem. In this problem setting, upper-side data (labeled above the regression line) and unlabeled data are provided. Experiments demonstrate the advantages of the proposed algorithm.	The paper addresses regression in a weakly supervised setting where the correct labels are only available for examples whose prediction lie above some threshold. The paper proposes a method using a gradient that is unbiased and consistent.  Pros: - Problem setting is new and this paper is one of the first works exploring it. - The procedure comes with some unbiasedness and consistency guarantees.  - Experimental results on a wide variety of datasets and domains.  Cons: - Novelty and technical contribution is limited. - Motivation of the problem setting was found to be unclear. - Some gaps in the experimental section (i.e. needing the use of synthetic data or synthetic modifications of the real data).  Overall, the reviewers felt that as presented, the paper did not convincingly motivate the proposed upper one-sided regression problem as important or relevant in practice, which was a key reason for rejection. The paper may contain some nice ideas and I recommend taking the reviewer feedback to improve the presentation.
Below are multiple reviews of a paper. The architecture of the generative models allows generating the three physical parametric maps, T1, T2 and PD. This allows moderating conclusions that can be drawn from the performance of the network.The paper shows the strengths of using DL methods for domain transfer learning. The method is promising to extend on a broader range of TE and TR values and anatomies. The novelty of incorporating the signal acquisition equation and using unsupervised learning should be evaluated against relevant work.The proposed method learns the quantitative information from the input MR image, which theoretically enables reconstructing MR images of any contrasts given different set of TE and TR values. Leaning the quantitative maps does not require the ground truth of PD, T1 and T2.	This paper presents a deep generative models for  multi-contrast synthesis MRI. Th proposed unsupervised method uses knowledge of the MR physics models and is applied to radiotherapy. Most of the reviewers found this paper interesting. The technical choice and the validation could be improved, especially the choice of the baseline method.
Below are multiple reviews of a paper. The paper presents a method that uses a Neural Radiance Field representation as a state space for a reinforcement learning algorithm. This approach is evaluated in tasks where multiple views of the scene are available, and where the 3D information present in the NeRF representation is useful for determining shape and pose of objects.The authors proposed the first learned state representation through NeRF supervision for reinforcement learning purposes. The sample efficiency has greatly improved compared to other learned representations and a key-points representation selected by human experts. Only simplified simulation environments are used rather than real-world environments.The paper propose a Neural Radiance Fields-based RL (NeRF-RL) method. It makes use of supervision from NeRF to learn state representations describing the objects in the 3D scene. Several experiments involving robotic object manipulations were conducted.	The reviewers appreciated the detailed replies and the additional experiments. They are now all in favor of publishing the paper. The paper proposes to use the NeRF representation on RL, the benefits of this combination is shown in a wide variety of experiments. The last open points by iBq4 and aWEL were well addressed by author replies and additional experiments.
Below are multiple reviews of a paper. This paper presents a self-supervised video representation learning method (VideoMAE) based on transformer design. In VideoMAE, applying a high masking ratio and tube masking strategy lead to a challenging video reconstruction task. Empirical results demonstrate the effectiveness of approach on 4 different video datasets in different settings.This paper studies the Masked AutoEncoder in the context of video self-supervised learning. It adapts the MAE technique to the video domain and propose tube masking along with a high masking ratio for videos. The experiments are conducted on a set of standard video action recognition tasks.The paper presents a self-supervised learning method to learn representations of videos. The method is based on being able to decode masked elements from an encoded video, similar to the masked autoencoder approaches to image representation learning.	This paper studies application of masked autoencoders to video data. It is a very empirical paper with lots of ablations and experiments. All three reviewers lean toward the acceptance of the paper. Reviewer C915 has a slight concern regarding the novelty of the paper over concurrent works including [50,53]. The reviewers believe that the ablation study is exhaustive and the paper has a good reproducibility. The authors are encouraged to add new experiments with kinetics pretraining in the final version.
Below are multiple reviews of a paper. The authors investigate the impact of various training hyperparameters such as weight-decay, batch size, use of batch normalization in eval/ train mode during adversary generation, smooth activations, optimizer and learning rate schedule. The authors demonstrate that use of the right hyperparameter can bring TRADES back to the top ofThe paper systematically reviews different hyperparameter settings and training strategies used for PGD adversarial training on CIFAR-10. Based on that, it derives practical takeaways (“bag of tricks”) and puts forward a standard baseline setting for future work.The task of finding good hyper parameters for adversarial training is a challenge. This paper provides a comprehensive evaluations on the different hyper parameter settings of training adversarially robust models. I have a few concerns regarding consistency of the experiments performed here.The paper provides an evaluation of different hyperparameter settings for adversarial training. It evaluates combinations of warmup, early stopping, weight decay, batch size and other parameters on adversarially trained models. The paper does a very good job in identifying good hyperparameters.	The authors have conducted a thorough empirical study on the hyperparameters of representative adversarial training methods. The technical novelty of this paper might be insufficient.  But the empirical findings in this paper explain the strange and inconsistent reported algorithm results in the literature to some extent and remind the necessity and importance of a careful study on hyperparameters. The authors have actively interacted with the reviewers and through the discussions, many unclear issues have been fixed.
Below are multiple reviews of a paper. This paper considers learning a risk-sensitive policy based on CVaR via distributional RL. Experiments are executed on both synthetic and real-world data. The theoretical results are not solid enough to guarantee the convergence of the algorithm.The paper presents a new method for robust reinforcement learning that optimizes the dynamic and static CVaR. The proposed approach does better at the task of option trading than risk neutral and markov action selection startegies.The authors study the problem of learning risk-sensitive policies in the distributional RL setting. They adopt Conditional Value at Risk (CVaR) as the risk measure throughout the paper. It is then shown that a distributional Bellman operator employing the Markov action-selction strategy does not converge to a dynamic or static CVThe authors tackle the challenge of learning a risk averse policy (CVaR) in a distributional RL setting. They present a theoretically sound method for iteratively learning a CVaR maximizing policy and back these claims with experiments.	This paper proposes a new action selection approach for risk-averse distributional reinforcement learning optimizing CVaR. It first shows that the action selection schemes used in existing approaches do not converge to the desired policies and subsequently shows that the fixed-point of the Bellman operator with the new action selection scheme is the desired optimal CVaR policy as long as it is stationary. It finally provides empirical results showcasing the benefits of the proposed approach.  The reviewers had mixed initial views on this paper. On the positive side, they found the paper to be well written and appreciated the new insights into the convergence of the existing action selection scheme as well as the more principled proposed scheme. On the negative side, there were concerns that (1) the paper does not actually convergence of the algorithm, only a fixed point, (2) that the paper does not provide sufficient discussion of the implications of the presented results, e.g. in the form of a conclusion and (3) that a comparison to CVaR optimization approaches that are not based on distributional RL is missing.  The authors' response addressed serval of these concerns so that all reviewers view this paper positively. Although, this paper still remains borderline and some concerns remain, the AC concurs with the reviewers that this paper has sufficient merits to be accepted, hence a recommendation for acceptance.
Below are multiple reviews of a paper. This paper introduces a library that implements 1 infectious disease model and 3 agents in a gym environment. The authors provide analysis for a covid-19 lock down scenario using their library.This paper introduces OpenAI Gym environment for RL optimization of epidemic containment policies. The envirnoment currently contains an example SEIR model parameterized for COVID-19, along with a simple economic model to evaluate the lost productivity due to lockdowns.The paper presents an interesting study on the dynamics of the epidemic. In my opinion, the development of a tool is relevant for medical and decision-making studies but is not enough novel or significant for the ML field.	The reviewers agree that the contributions may not be relevant to the ML research community or perhaps are a poor fit for the venue, but otherwise find the work potentially useful and addressing a timely topic. Because the paper focuses on a simulation environment for existing epidemiological models, reviewers comment that the technical and methodological novelty is limited.
Below are multiple reviews of a paper. This paper propose the geodesic self-attention (GSA) module, which captures the long-range geometrical dependencies of point cloud objects by means of a Riemannian manifold. While the approach seems reasonable and the experimental results look promising, I have the following concerns(See Questions) about the paper.This paper proposes to leverage geodesic metrics for computing the self-attention weights for point cloud transformer architectures. The author conducted experiments on ModelNet and ScanObjectNN for object classification.The authors propose two ideas for the implementation of geodesic distance computation. The performance of the data manifold-based method is empirically verified on three tasks. The method proposed in this article is an incremental improvement on existing methods.	The paper addresses an issue of existing self-attention module that is mainly designed for data on Euclidean domain; for those on non-Euclidean domains, e.g., those on Riemannian manifold, the paper proposes a Geodesic self-attention counterpart. Experiments on tasks of 3D classification and segmentation show the efficacy. All reviewers acknowledge the problem importance and contributions made in the paper, although a few concerns are raised, including additional ablation studies and comparisons with other methods using geodesic metrics.   In the rebuttal, the authors clearly respond and address the reviewers’ concerns. Acceptance is recommended. Congratulations!
Below are multiple reviews of a paper. The paper presents a neural PDE solver based on adn encode-process-deode architecture that respects boundary conditions thanks to a novel GNN-based gradient operator. The idea seems to be very simple and based on existing methods but is effective. The paper is sometimes hard to read and not very clear.This work proposed to use E(n)-Equivariant Graph Neural Network to solve PDEs. Main differences compared to existing works include using a boundary node encoder and pseudoinverse decoder to enforce boundary conditions and achieve better long-term accuracy.The authors’ primary contribution is the development of neural network layers that enable the treatment of Dirichlet- and Neumann-type boundary conditions in encoded space. They claim that they have tested their model against classical solvers, but I found no evidence of this in the main paper or supplementary PDF.The paper is clear and well written. I enjoyed the writeup for the backgrounds section, which doesn't assume too much prior knowledge on the subject matter. The experimental evaluations are compelling. It would be interesting to see how the model generalizes to a different range of physical parameters.	The paper proposes a E(n)-equivariant neural PDE solvers that can satisfy boundary conditions provably. The reviewers acknowledged the importance of the studied problem setting and generally appreciated the results. The paper is nicely written and provides both strong experimental results and theory. Indeed, a range of interesting experiments demonstrate the effectiveness of the proposed method. I want to thank the authors for their detailed responses that helped in answering some of the reviewers' questions. (The reviewers have provided detailed feedback in their reviews, and we strongly encourage the authors to incorporate this feedback when preparing a revised version of the paper.) In summary, this paper is a clear accept. Well done!
Below are multiple reviews of a paper. The paper explores an interesting and novel application of flow based models to video compression. While I think the paper could be strengthened by more qualitative examples and a larger dataset, I think this could be a good contribution to the conference.This paper proposes improved version of Scale-Space Flow (SSF) model. Authors add two enhancements to SSF for improve Rate-Distortion performance. The paper also introduce a dataset for neural video compression that collected from youtube.com.The paper presents a lossy video coding scheme using autoregressive generative models. The evaluation should be conducted in YUV 4:2:0 domain for fair and reasonable comparisons.The proposed method shows favorable results when the bitrate is higher than 0.12 bits per pixel on the public benchmarks. They propose two new components: a learnable scaling transform for modeling motion estimation/compensation, and structured priors for modeling the entropy.	All reviewers recommend acceptance. The authors have addressed several of the reviewers' concerns in their comments, conducted additional experiments, and updated the manuscript accordingly.  A concern was raised regarding the size of the dataset introduced and used by the authors for this work. However, I agree with the authors that it doesn't necessarily make sense to compare this to datasets designed for training video classification and/or generation models; In the compression setting, the quality of individual data points matters much more than their quantity, as the authors argue.  Reviewer 2 was curious about the potential of a pre-trained optical flow module. I believe the authors have convincingly argued that end-to-end learning is likely to be more effective and practical (and indeed, there is plenty of evidence for this in other ML contexts where training data is not scarce). I agree that a direct comparison in the paper would have been interesting, but this would constitute a significant investment of time and effort on the authors' part (as they also point out, training such a module separately could actually be more difficult), and I think it would be unreasonable to make this a condition for acceptance.
Below are multiple reviews of a paper. This paper surveys various adversarial defense methods on their performance when the perturbation distortion epsilon is increased. The authors suggest a robustness curve as an evaluation metric. Please refrain from only using color to distinguish curves in figures as it may not be friendly to readers with color blindness.The authors advocate for the use of Robustness curves, plotting the adversarial accuracy as a function of the size of the neighbourhood region of allowed perturbation. The paper clearly describes the problem it deals with and reads easily, but I am not entirely convinced by the importance of the problem.This paper presents a theoretical scenario where point-wise measure of adversarial robustness falls short in comparing model robustness. Then conduct experiments to show that robustness curve is a more meaningful evaluation metric.The paper showed that point-wise measures fail to capture important properties that are essential to compare the robustness of different classifiers. The authors introduced the recently proposed robustness curves to provide a global perspective.	The authors study "robustness curves" which are plots of the robust error versus the radius used in the corresponding l_p-ball threat model.  Pro: I completely agree with the authors that the current evaluation purely based on evaluation for a single radius is insufficient and one should report the complete curve.   Con: The authors are overclaiming that they have come up with robustness curves. Very early papers e.g. even in the adversarial training paper of Madry there are plots of robust accuracy versus chosen threshold. Moreover, I agree with one of the reviewers that using PGD for the purpose of a robustness curve is inaccurate and in particular inefficient as several attacks for different radii have to be done. There have been several attacks developed which aim to find the adversarial sample with minimum norm and thus compute the robustness curve in one run.  The additional insights e.g. intersection of robustness curves are partially to be expected and I don't find them sufficient to move the paper over the bar for ICLR.  As these insights are additionally  only shown for relatively small models which seem far away from the state of the art, it is unclear if they generalize. However, I encourage to follow some of the reviewer's suggestions to improve the paper.
Below are multiple reviews of a paper. Reviewer: "I think overall that this paper is a good contribution and I recommend acceptance" reviewer: "The intro section is almost completely repetitive of section 3 and could be significantly shortened"This paper deals with the problem of catastrophic forgetting in lifelong learning. Authors propose the regularized learning strategies where we are given a fixed network structure without requiring additional memory increases.The work is thorough and some of my minor concerns have been addressed, so I am increasing my score to 6. I cannot go beyond because of the incremental nature of the work, and the very limited applicability of the used continual learning setup from this paper.	Two of the reviewers raised their scores during the discussion phase noting that the revised version was clearer and addressed some of their concerns.  As a result, all the reviewers ultimately recommended acceptance.  They particularly enjoyed the insights that the authors shared from their experiments and appreciated that the experiments were quite thorough.  All the reviewers mentioned that the work seemed somewhat incremental, but given the results, insights and empirical evaluation decided that it would still be a valuable contribution to the conference.  One reviewer added feedback about how to improve the writing and clarity of the paper for the camera ready version.
Below are multiple reviews of a paper. The paper is well-written and easy to follow. Performance is good. Conclusion is somehow not convincing. How about the comparison with some recently published weakly supervised learning?The multi-task learning paradigm reduces training times compared to the other state-of-the-art method. Data appears to be limited to patches of imaging data focused on tumor/lesion regions of interest (ROI)Multi-task learning results in improved segmentation performance. Improvement of 6%, 13%, and 70% for dice metric, averaged Hausdorff distance (AVD), and training time respectively is reported.The key idea of multi-task learning is clear and reasonable. The proposed method show improvements on three public lesion segmentation datasets. The improvement on NIH deeplesion dataset (8.7%) is not very convincing.	The authors have addressed all the points raised by the Reviewers to a different extent, including more experiments and discussion points to support the described method.  AnonReviewer1 indicated that a more extensive comparison with other recent and maybe more competitive baseline segmentation methods should have been included. I do agree that it would have been interesting to do so. However, all Reviewers agree that the paper represents a contribution as an application paper and, considering the rebuttal effort, I recommend to accept this work for publication.
Below are multiple reviews of a paper. This paper conducts an empirical analysis of the effect of training data size on the model robustness to adversarial examples. The authors compared four different NN architectures using four different datasets. Overall, the paper is easy to follow and clearly written.This paper empirically evaluates the effect of the training dataset size on accuracy and robustness against adversarial attacks. The methodology of the paper is generally easy to assess and the overall idea well communicated. For the motivation example I assume the following assessment holds true.The paper presents an empirical study of how accuracy and robustness vary with increasing training data for four different data sets and CNN architectures. The main conclusion of the study is that while training accuracy generally increases with increasing data, provided sufficient training data is available for training the network in the first place.	The reviewers conclude the paper does not bring an important contribution compared to existing work. The experimental study can also be improved.
Below are multiple reviews of a paper. The motivation behind this paper leaves from current limitations of fine-tuning. The authors propose a Dynamic Parameter Selection (DPS) algorithm, which fine-tunes pre-trained networks adaptively in two stages. On the GLUE benchmark, DPS gains range between 0.44-1.33 points.This paper proposed a new large-scale language model fine-tuning algorithm called Dynamic Parameter Selection (DPS) This algorithm essentially uses a two stage cyclic updating strategy, where in Stage-1 it accumulates in-batch gradients of updated parameters. In Stage-2, it derives a subnetwork based on the StageThis paper proposes a Dynamic Parameter Selection (DPS) algorithm to address the overfitting and catastrophic forgetting issues in fine-tuning pre-trained language models. The proposed DPS consists of a cyclic two-stage updating strategy.This paper introduces Dynamic Parameter Selection, which selects subnetworks to perform staging updates based on gradients. The GLUE benchmark is used for evaluation, and results are positive. Large pre-trained LMs form the baselines of many impressive results.	The reviewers were very positive about this paper, which proposes a method for selective fine-tuning of language models on downstream tasks. The method works well in various settings including realistic out-of-distribution and low-resource scenarios.   The main strengths are: * useful idea  * conceptually simple method * the choice of datasets * the use of competitive models * convincing experiments in multiple settings, including OOD generalization   The reviewers also noted some weaknesses, especially:  * the need for a first pass, computational bottleneck, --> author response seems satisfactory  * the choice of baseline to compare against  * need for theoretical guarantees  --> to me, this is not strictly necessary for an empirical paper  * experiments only with classification tasks --> to me, the choice of tasks (GLUE, NLI) is reasonable, as the authors argue  * uninformative discussion of limitations  The authors did a fine job addressing most of these issues in their response and they should update their paper accordingly. Concerning the last point: the authors did not address this point, and are strongly encouraged to do so in their revision.
Below are multiple reviews of a paper. This work addresses fine-grained entity typing by leveraging semantic relations of the mention with other words in the same sentence. Authors showed how to use hypernym relations and verb-argument relations. The proposed method significantly improves over baselines.The paper shows that semantic relations associated with mentions can be used to improve fine-grained entity typing. Experimental results show that the integrated semantic relation information improves the final performance. The submission is well suited to the akbc conference.The paper describes an approach that models linguistic features extracted from the entity context and applies them to the fine-grained entity type (FET) prediction task. Experiments show that incorporating models for hypernym relation detection and semantic role labelling improve the performance.	The paper make use of semantic relations (hypernym and verb-argument) to obtain the state of the art performance in entity typing, especially compared to strong baselines such as BERT. The paper presents an interesting message that linguistic features could be still important among the age of end-to-end methods. It is also clear that entity typing is crucial for constructing knowledge bases, making the paper quite appropriate for the proceedings of AKBC.
Below are multiple reviews of a paper. On balanced datasets and when using cross-entropy loss for learning, it is observed that the last layer features from the same class converge to their within-class means. The key question the paper asks is L58: "Do we really need to learn a linear classifier at the end of a deep neural network for classification?"The paper provides a theoretical analysis of the class imbalance problem with a fixed classifier inspired by the recent neural collapse phenomenon. The paper studies neural collapse in the case in which the final classifier is not subject to back-propagation and is initialized with the vertices of a simplex equiangular tight frame.The paper proposes a loss function which projects the features to a pre-defined simplex and computes the gradients w.r.t it. It claims that neural networks use linear classifiers at the end and this is not needed if features are computed for each class and projected to a simplex. A theoretical explanation for this approach	This paper examines the use of a random equiangular tight frame (ETF) as a replacement mechanism for the final classification layer in a deep neural network, and demonstrates experimental advantages in class-imbalanced training scenarios.  Reviewers gave drastically different assessments of this paper, with ratings ranging from reject to weak accept.  The authors provided extensive responses to all reviewers, and Reviewer amWi participated in an extended discussion with the authors.  Author responses directly addressing concerns raised by other reviewers, such as pointing to ImageNet results in response to Reviewer Nj4c asking for such experiments, appear not to have received subsequent engagement from reviewers.  The Area Chair has taken an detailed look at the paper and the entirety of the discussion, and agrees with Reviewer amWi's assessment.  The work provides an interesting examination of ETF as a novel mechanism to address class imbalanced training; the contributions meet the bar for acceptance to NeurIPS.  Reviewer amWi makes several suggestions regarding presentation of the main contributions as well as additional papers for citation and discussion, which the authors may want to take into consideration when preparing the final version of the paper.
Below are multiple reviews of a paper. First order methods on a pair of conditions; the restricted secant inequality lower bound and smoothness towards the optimum as the upper error bound. Results show that the worst-case convergence of gradient descent on the class of functions satisfying those assumptions is optimal.This paper studied the complexity of gradient descent (GD) in RSI- and EB+ settings. The paper provided linear convergence results of GD in this case, and further derived the interpolation conditions.The paper is well written and is a solid theoretical paper. It is remarkable that the authors can show rigorously that the gradient descent is optimal on the class of functions that satisfy a lower restricted secant inequality. The weakness of the paper is that even though the paper has a nice theoretical contribution, its practical importance and relevance is less clearIn this work, the authors considered applying the gradient descent algorithm to functions in the intersection of RSI- and EB+. A matching lower/upper bounds on the convergence rate is derived. I think the results are interesting to audiences in optimization and machine learning.	A solid theoretical paper with fine execution that establishes the optimality of the vanilla gradient descent method in a class of functions extending the well-studied class of smooth and strongly convex functions. Please make sure to take into account the insightful feedback given by the reviewers in the revised version.
Below are multiple reviews of a paper. The paper provides a novel theoretical explanation of the epoch-wise double descent phenomenon, which recently has gained some interest in the community. The theory also suggests a simple and effective mitigation strategy by adaptation of the different stepsizes corresponding to the different U-shaped curves.Double descent is caused by the superposition of multiple bias-variance trade-offs arising from the fact that different parts of the network are trained at different speeds. The risk of gradient descent is close to the sum of U-shaped curves (this is dubbed as the "risk of early stopped least squares").The paper provides an interesting analysis and direction to improve generalization capability by setting learning rates differently for each feature and using early stopping. My major concern is that supporting evidence is very week for a technical paper (although it is great for a talk) Theorem for neural network training is really theorem for shallow linear models with the fixed kernel,Double-descent phenomenon observed by Nakkiran et al. as a function of training time. Classical theory suggests test loss should follow a U-shaped curve, where the model initially learns but then overfits.	This paper provides a novel theoretical analysis of epoch-wise double descent for a linear model and a two-layer non-linear model in the constant-NTK regime. Some reviewers noted that these models may be too simple to offer a full explanation for the phenomenon in state-of-the-art practical models, for which the NTK is known to change significantly. While this may be true, I believe that the detailed understanding derived in these simple settings provides an important first step and will surely be of interest to the community. I therefore recommend acceptance.
Below are multiple reviews of a paper. This paper proposes a simple regularizer for RL which encourages the state representations learned by neural networks to be more discriminative across different observations. The experimental results on Atari games show that this regularizer improves A3C on most of the games.The paper aims at characterizing and discussing the impact of the expressivity of a state representation on the performance. It then discusses three possible ways of improving performance with a specific regularization on the state representation. Some parts in the paper are not well-supported and many important elements are lacking.The authors propose the notion of "expressiveness" of state representation by simply checking the effective rank of the state vectors formed by a sampled trajectory. Experiments on a large set of Atari games show that this regularizer can improve the performance of reinforcement learning algorithms.	The authors propose to define 'Expressiveness' in deep RL by the rank of a matrix comprising a number of feature vectors from propagating observations through the learnt representation, and show a correlation between higher rank and higher performance. They try 3 regularizers to increase rank and show that they improve the final score on Atari games compared to A3C or DQN. The AC and reviewers agree that the paper is interesting and novel and could have general significance for the RL field. Also, the authors were very responsive to the reviewers and added more details, plus several experiments and analyses to support their claims. However, the reviewers were concerned about a number of aspects and have recommended that the authors clean up their presentation and analysis a bit more. In particular, the fact that the regularization coefficient is tuned for each Atari game makes it very hard to compare to DQN/A3C which are very careful to keep the same hyperparameters across every game.
Below are multiple reviews of a paper.  PACMAC is a method for unsupervised domain adaptation tailored to vision transformer architectures (ViT) pre-trained using self-supervised approaches (SSL) The method works by 1) continued SSL training on the union of the labeled source domain and unlabelled target domain, and 2) joint fine-tuning on the sourceThe paper focuses on adapting self-supervised ViTs for unsupervised domain adaptation (UDA) The goal is the find reliable pseudo labels for unlabeled target domain images and then train the model using pooled source and target data. The main contribution of this paper lies in designing ViT-specific data augmentation.In this paper, the authors propose a new method for adapting Visual Transformers (ViT) with modern self-supervised learning (SSL) pretraining adapted to unsupervised domain adaptation (UDA) The proposed approach, named PACMAC, starts with a weights pretrained on Imagenet and follows of two steps.	This work looks at adapting ViT-like models for unsupervised domain adaptation, by cleverly finding pseudo-labels with 'attention-guided masking'. There's a weak consensus among the reviewers that this work has good empirical results, but somewhat limited novelty. I think the rebuttal discussion has helped improve this work quite a bit, and given the good results, ablations, and the importance of unsupervised domain adaptation, I am recommending acceptance.
Below are multiple reviews of a paper. This work simply applies the meta-learning method into the federated learning setting. The experimental results are not convincing because the data partition is not for federatedlearning. The title is misleading or over-claimed. Claiming the few round adaptations can reduce communication costs is misleading.This paper studied the combination of federated learning tasks in a meta-learning setting. With the assistance of the pre-trained meta-model, the new FL model's training can be completed within limited communication rounds. This paper proposed a few-round learning (FRL) algorithm and designed global prototype-assisted learning (GPAL)This paper proposes a new paradigm to train federated learning models. The proposed algorithm has the potential to redefine FL training paradigm. It would be great if the authors can evaluate their algorithm in a standard FL dataset.The proposed method relies on a strong assumption that there is a meta-training environment in federated learning. It is unclear how the proposed method provides any theoretical contribution rather than applied research. The proposed two-stage procedure is equivalent to: learn a global model in a standard FL setting, and then conduct personalized deployment for each device or a	This paper proposes a meta-learning based few-shot federated learning approach to reduce the communication overhead incurred in aggregating model updates. The use of meta-learning also gives some generalization benefits. The reviewers think that the paper has the following main issues (see reviews for more details): * Limited technical novelty - the paper seems to simply combine meta-learning with federated learning * Not clear whether the communication overhead is actually reduced because the meta-learning phase can require significant communication and computation. * The experimental evaluation, in particular, the data distribution, could have been more realistic.  I hope that the authors can use the reviewers' feedback to improve the paper and resubmit to a future venue.
Below are multiple reviews of a paper. The paper is proposing to evolve datasets of (inputs, outputs) in the context of programming by example. The goal is to infer a computer program that is consistent with the association of ( inputs, Outputs) The proposal is relatively straightforward, using an adversarial optimization loop to enhance the training set.Synthesis models trained on synthetic datasets of randomly generated programs often fail to generalize to real-world PBE problems. This work proposes a more principled adversarial approach to generate synthetic data. The training set is built iteratively by finding data distributions on which a given model performs poorly.The paper proposes an approach to develop synthetic datasets aimed at training DeepCoder-alike models. Authors claim that current approaches to generate synthetic datasets do not help coding algorithms to obtain a good generalization.This work mainly deal with the issue of I-O selection during training. Typical program synthesis training collects its dataset as follows. This work suggests that instead of picking a random set of I, this set of input should be chosen adversarially.	The paper uses adversarial data to improve generalization in Programming By Example (PBE). The reviews were somewhat mixed with some people finding this useful and interesting while others finding it straightforward and unsurprsing. The reviewers were not convinced of the ultimate usefulness of the approach since it is evaluated on toy or synthetic datasets. The clarity of the presentation could also be improved.
Below are multiple reviews of a paper. This paper applies transformer models to learning linear-time temporal logic (LTL) and propositional logic. The results show that, when trained on large datasets of random formulas, transformer models can perform quite well on within-distribution held out test tasks.The paper presents multiple dataset generation and testing procedures for linear temporal logic and propositional logic satisfiability. They are then used to train Transformers with tree positional encoding. The approach amounts to imitation learning based on existing solvers for satisfiability for the considered logics.The paper explores the application of modern learning techniques (transformers and tree positional encodings) to the task of producing valid traces for a given LTL specification. A series of experiments are conducted to explore the generalization power of the proposed approach.This paper presents a dataset of linear-time temporal logic (LTL) formulas, which are generated by conjoining popular LTL specification patterns. It then investigates the learning capability of the Transformer over these LTL formulas. The experimental evaluation shows that the Trans transformer predicts solution with high accuracy.	The paper shows that standard transformers can be trained to generate satisfying traces for Linear Temporal Logic (LTL) formulas. To establish this, the authors train a transformer on a set of formulas, each paired with a single satisfying trace generated using a classical automata-theoretic solver. It is shown that the resulting model can generate satisfying traces on held-out formulas and, in some cases, scale to formulas on which the classical solver fails.  The reviewers generally liked the paper. While the transformer model is standard, the use of deep learning to solve LTL satisfiability is novel. Given the centrality of LTL in Formal Methods, the paper is likely to inspire many follow-up efforts. There were a few concerns about the evaluation; however, I believe that the authors' comments address the most important of them. Given this, I am recommending acceptance. Please add the new experimental results (about out-of-distribution generalization) to the final version of the paper.
Below are multiple reviews of a paper. This paper proposes VXN, a large-scale 3D indoor dataset for multimodal, multitask navigation in continuous and audiovisual complex environments. It can conduct four embodied navigation tasks, including image-goal. navigation, audio-goal navigation, object-goal Navigation, and vision-language navigation.This paper proposed a new visual navigation benchmark that combines information from different modalities. The modular structure is designed via analyzing the task component. The paper should include more SOTA models on the four navigation tasks as baselines.The paper proposes a unified model for 4 popular navigation tasks. A Transformer based architecture is utilized to combine these 4 tasks. The experiment section provides results for single-task and multi-task settings.	This paper introduces a novel indoor navigation dataset that is both continuous and audio+visual.  Within this setting, they include popular tasks and their audio-generalizations (e.g. image-goal nav --> audio-goal nav).  Particularly of note is the leveraging of unification of these tasks during training for a better overall agent.  This is a necessary and important step for the community.  There are several minor concerns regarding exposition and claims which were addressed in responses/updates which will strengthen the final paper. This includes task/model variances and clarifying why the reported variances are smaller than typically seen in related EAI tasks.
Below are multiple reviews of a paper. The paper is not clear, not well-organized, and very hard to read. There is no definition about the probabilistic distribution of $e$ in Definition 1. The last sentence in page 3 says "Now we characterize the condition about the non-Gaussian distributions"The LiM model can incorporate more types of non-Gaussian distributions for the continuous variables. The method's applicability is severely limited by the causal sufficiency assumption. The paper is unfortunately pockmarked with writing errors, which hinder readability.The paper introduces a novel approach to discover causal structures in mixed (continuous/categorical) data. Such data occur across all empirical sciences. The presented approach can be considered of high relevance for the audience of causal machine learning and beyond.	The paper tackles the problem of causal discovery from mixed data, i.e. when continuous and discrete variables may be present, for both bivariate as well as multivariate settings. It introduces the so-called Linear Mixed (LiM) model and proves full identifiability under certain assumptions, including causal sufficiency, linear continuous functions with additive non-Gaussian noise, and a linear logistic model for the discrete variables. It also describes the associated LiM algorithm that can find this model, consisting of a global search optimisation phase (based on the so-called quadratic penalty method), followed by a local likelihood optimisation phase. The experimental evaluation shows that, when the assumptions hold, the method compares favourably to other approaches that are not designed to handle this setting.  Reviewers were initially fairly critical of the paper, in particular on clarity of the presentation and several errors / omissions in the text. However the authors made an excellent attempt at answering the points raised, clarifying some and promising to address / resolve others in the final version, so that ultimately all reviewers agreed on recommending acceptance, although insisting presentation could/should still be imporved.  I have to admit on reading the paper I am actually slightly more critical than the reviewers. I fully agree presentation should be improved, but I also notice a tendency to emphasise weaknesses of other methods while focussing on strong points of the proposed method, rather than trying to give a fair and balanced assessment of pros and cons. It is technically ok, but rather niche, relying on strong assumptions where the only ‘real-world’ application (Boston) leads to a questionable output model. Essentially the algorithm is likely to obtain the touted ‘full identifiability’ by overfitting on the data, even though for larger sample sizes the performance actually seems to decrease in some cases. That said, it does at least try to expand existing causal discovery methods to the important mixed data realm, and the proposed approach is new and sound in principle, so despite the caveat above I will follow the reviewers and recommend accept.
Below are multiple reviews of a paper. This paper aims at defining a new architecture, Dynamic Recurrent Neural Network. It would be based on discrete differential equations of basic linear system transfer functions known from dynamic system identifiation. They show also an application example.The paper has definitely technical merits, but I remain puzzled with the lack interpretability section (3.4). I do not see how I can use the methodology to reconstruct the underlying physical processes that drive the physical phenomena. Since the authors are claiming in the abstract that interpretability is a distinctive feature of the methodology, I was expecting toThis paper aims at proposing Dynamic Recurrent Network to understand the underlying system properties of RNNs. By first showing five basic linear transfer functions in dynamic systems theory, the paper formulates DYRNN units. It will be better to test the method on some benchmark datasets.The authors present a method for incorporating basic concepts from linear systems theory into the standard structure for training artificial neural networks. They compare results of their approach against standard approaches for 3 simple datasets. The work is quite unclear, and takes several passes over to have a basic sense of the approach. It does not seem ready for publication.	This paper proposes a new RNN architecture called Dynamic RNN which is based on dynamic system identification.  Reviewers questioned the expressivity of the proposed model, practical application/impact of the proposed model, and interpretability of the proposed model. Even though the authors attempted to convince the reviewers, 3 out of 4 reviewers think that this work is not ready for publication.   Specifically, R4 recommends 5 ways to strengthen the paper. I recommend the authors to incorporate this feedback and make a stronger resubmission in the future.
Below are multiple reviews of a paper. PROSPECT is a database for proteomics research based on a massive collection of LC-MS/MS datasets already available from the ProteomeTools project. The paper is well written, and the package adds some functionality to the original database. The primary weakness of the paper is the relatively limited original content.This paper presents a newly annotated and integrated protein MS dataset based on the ProteomeTools dataset. The authors then present what they consider to be a sort of "best practices" for evaluating and presenting analyses.This study curates and annotates the ProteomeTools Dataset. It can be used to train models in predicting properties for mass spectrometry (MS/MS) using experimental data. The paper highlights an area of research that is not as commonly represented in CS/ML conferences.This work is relevant in the field of proteomics analysis with Mass Spectrometry (MS) The current dataset, ProteomeTools consists of raw data. Current models to predict the retention time, spectra given a sequence, or both have been processing the data in many different ways. This makes it hard to compare these models.This paper presents a new deep-learning ready dataset for looking at protein mass spec data. Mass spec is a central instrument for much work across drug discovery and chemistry/biochemistry at large. This dataset is curated and ready for benchmarking where they aggregate and align the data.This paper presents a new annotated dataset for predicting proteomic properties from sequence data. The authors clearly define two relevant machine learning tasks that this dataset could be used for. The evaluation metrics are well suited for their specific tasks.	Reviews were split. Reviewers agreed on the importance of the domain but differed in how they valued the contribution over ProteomeTools, which the dataset builds upon. A primary concern was lack of baselines/benchmarking. The rebuttal argues that baselines would not add much value since strong methods have been published in prior work. However, my interpretation of the reviewers ask is not to invent new heuristic baselines but to evaluate the prior methods on the newly prepared dataset. The authors do add evaluation of one such model (Prosit) to the revision. Evaluating more models in the same way could strengthen the contribution, and could be part of the ongoing maintenance of the dataset / code.  Overall, however, the majority of reviewers felt the paper does provide significant value beyond ProteomeTools and other prior work, through the new annotations, tooling, and usage recommendations. The revision adds an appendix (G) to clarify these contributions, and it may be useful to move some of that text into the intro of the paper (as I think many readers will want to know what are the main contributions beyond the base dataset). I agree with the majority that there is significant value added and recommend acceptance.
Below are multiple reviews of a paper. This paper focused on adapting large-scaled pre-trained vision-language model (i.e., CLIP) to downstream datasets under the few-shot setting. Compared to the recent related work CoOp, this work (1) learns multiple prompts, (2) uses both local features and global features, and (3)The authors propose a new prompt learning method, which learns multiple prompts to describe diverse characteristics of categories. To optimize the model effectively, they apply optimal transport to match vision and language modalities.This paper focuses on the few-shot prompt learning for vision-language model CLIP. The experiment shows that PLOT can achieve better performance over CoOp in most of the datasets.	This paper presents a novel perspective of prompt tuning for few-shot visual recognition: a dynamic matching algorithm between the prompt candidate and the visual features. Compared to the existing CoOp and CoCoOp algorithm, the proposed "Optimal Transportation" idea definitely sounds better and indeed achieves better performance. All the reviewers acknowledge the merits of the paper.   Though AC also acknowledges the merits of the paper, there are two unaddressed demerits:   1) As the proposed method is essentially an ensemble method, comparisons with prompt ensemble should be conducted. Unfortunately, the reported "G" in Table 2 and Line 254-265 is not a proper ensemble, because the "G" baseline may degenerate into many duplicate single CoOp models with different random seeds. AC conjectures that this is the reason why G's performance is only slightly different from CoOp. By "proper ensemble", the authors may want to try initializations by "this is a photo"+"a picture of" + "there is an xx of" etc, or, augmenting each image by random crops, each of which corresponds to a "G", and then ensemble.   2) This paper lacks an important "Base to New" setting as proposed by CoCoOp. As the proposed PLOT in this paper has significantly more tunable parameters, AC doubts that it may lead to the overfitting of the training classes but ruins (or forgets) other classes which were used to have good zero-shot performance without training.  Unfortunately, AC regrets to recommend reject and wishes the best of luck in re-submitting the paper to other venues.
Below are multiple reviews of a paper. Soft pruning learns a binarization function based on a sigmoid. The paper claims the key is updating all the weights while maintaining the masks for inference. That seems ineffective compared to L1 or similar methods.The paper proposed a new method to prune a neural network. The method is interesting, innovative and effective. The work would be beneficial for others if the code is published open.A new type of soft threshold operator can be used in the context of neural network pruning to obtain sparse, performant networks from pre-trained, dense networks. The main idea is to replace the Heaviside step function that occurs in "hard threshold" pruning by a sigmoid function that can be differentiated.I like the approach of using the sigmoids to be able to learn the thresholds and the weight pruning. I feel the experiments section could be written a bit more clearly so as to make the assertions in the conclusion and introduction stand out as really obvious. Pacing very nice. Good exposition of related papers. Very easy to understand	This paper proposes a method for differentiable pruning that replaces the hard thresholding of standard pruning, with a soft version that permits taking the gradients of the pruning threshold. The proposed benefits are an accuracy that is better or competitive with alternative methods as well. Moreover, the paper suggests the technique to be efficient.  The pros of this paper are that it is working in an interesting setting of differentiable pruning, with the hope of -- in some sense -- simplifying the pruning process or at least unifying the process with standard training.  The technique is plausibly justified in its technical development. The paper also follows with a significant number of experiments.   The cons of this paper are that the conceptual framework -- beyond the initial idea -- is not fully clear. In particular, this paper does not elucidate a clear set of claims and hence, results in the difficulty on the Reviewers part in detangling the claims and identifying the appropriate comparisons.  For example, the paper doesn't take up a simple claim that it is state-of-the-art in accuracy vs parameter measures (and would seem not to given the results of Renda et al. (2020)).  It need not necessarily make this claim, but there are suggestions to such a claim early in the paper. If this is not an intended claim, then the paper can remove any suggestions to such (i.e., the claims around new SoTA for networks not evaluated in prior work).   The paper has a somewhat tentative claim that it is more efficient (in the total number of epochs of training) versus other techniques (Table 3).  However, the presented results are only at a single-point versus other methods.  Renda et al. (2020) directly consider accuracy versus retraining cost trade-offs. Appendix E of that paper provides one-shot pruning results for ResNet-50 showing accuracy on par with that presented here.  The number of retraining epochs is also similar to here. This paper, however, only compares against the most expensive iterative pruning data point in the other paper.  In sum, my recommendation is Reject. This is promising work that needs only (1) to include a few testable claims and (2) to re-organize the results (and perhaps run a limited set of new results) to thoroughly explore those claims. For example, if the most important claim is accuracy vs retraining cost, then it needs to show a more complete trade-off curve of the two results.  Of course, this, in principle, opens the door to comparisons to many other techniques in the literature.
Below are multiple reviews of a paper. The paper introduces a novel approach N-CODE, based on Neural Ordinary Differential Equations. The results suggest that the performance of the approach leads to significant improvements compared to the state-of-the-art. The limitations of the proposed method are not clear.The paper proposes to predict the required weights of a Neural ODE function from the input data. In the supervised part, has good visualizations of the decision boundaries induced. The unsupervised part shows good comparisons with previous methods.N-CODE is a technique for more expressive neural ordinary differential equations (NODE) flows. Instead of learning a fixed set of parameters, the proposed approach learns dynamic parameters that evolve over time. The method has certain overlaps with the control theory and maximum principle.The paper proposes a new class of neural ODE based models, called neurally-controlled ODEs (N-CODE) Instead of directly learning the weights of the neural network parameterizing the vector field f of the ODE, the paper instead proposes to learn a controller that takes as input the initial state and outputs the initial	This paper introduces a few variants of neural ODE architectures to improve their expressivity.  The motivation and method make sense, but are fairly incremental.  The tasks are also fairly low dimensional and as one reviewer pointed out, reconstruction isn't a good benchmark task.  However, the paper seems well-executed, and the rebuttals answered the expert rewiewers' concerns.
Below are multiple reviews of a paper. In this paper, the authors propose a framework to learn the query embeddings for hyper-relational KGs. The proposed problem outperforms most of the previous methods that only use triple-only graphs. Experiments show that qualifiers help their framework achieve more accurate results.The paper presents an approach for embeddings queries over hyper relation graphs. The work defines a new dataset on Wikidata because of reified triples/qualifiers. The paper is well written and is an important step in the direction of handling multiple representations.This paper studies the multi-hop logical reasoning problem with hyper-relational knowledge graphs. In hyper relational knowledge graphs, edges are associated with some key-value pairs used for describing contextual information. The goal of this paper is to incorporate such information in order to provide more fine-grained question answering.This paper studies how to embed and answer hyper-relational conjunctive queries based on recent advancements in Graph Neural Networks and query embedding techniques. The challenge of multi-hop logical reasoning is not clearly stated.This paper proposes a novel problem to embed query graphs with edge qualifiers. The proposed approach is compared with three baselines including the reification baseline. The overall performance shows the proposed approach shows benefit over the baselines.	This paper presents a query embedding approach for answering multi-hop queries over a hyper-relational knowledge graph (KG). The main contributions are a new dataset (WD50K-QE) for this task and a simple but sensible extension to an existing model for query embeddings to also handle relation qualifiers. Reviewers wJVm and Bute note that the reification and StarQE models perform similarly. While this is not a negative result, as the authors note, it does raise the question of the relative pros and cons of the two methods. I hope the authors can add a discussion of when one might prefer StarQE over the conceptually simpler reification method in the final version. The authors addressed Reviewer frRt’s concerns about faithfulness and backwards compatibility (though more evidence on purely triple-based tasks would be nice here). Reviewer GQAR also raised some concerns about writing, but the other reviewers mostly found the paper to be well written and well motivated and I tend to agree. Overall, while there are some very good suggestions on how the paper can be extended and improved, I find the current contributions to be substantial enough to warrant a publication.
Below are multiple reviews of a paper. The authors aim at solving an interesting problem for Granger causality. They propose a probabilistic implementation for modeling the graph structure with an encoder and the shared dynamics with a decoder.There is no novelty in the problem set addressed in this paper. This paper proposes a new method for an existing problem. However, it lacks the details of the method and the theoretical explanation to support the effectiveness.Proposed method significantly advances the state-of-the-art, although the relevance of this method depends very much on the assumption of "shared dynamics" The paper hinges on the Granger causality framework, therefore it may be more interesting for fields of studies with high frequency data. The motivation of the paper could be improved.	This paper tackles an interesting but specialized problem in causal discovery for multiple (or multivariate) time series.  The _exact_ nature of the problem set-up is not at all clear from the paper unless it is read _very_ carefully, and understandably confused at least one reviewer, so if this is accepted the final version should have a significantly revised abstract and introduction.  The setting, as I understand it, is as follows.  We have multiple data sets, each of which consists of $N$ univariate time series, all of length $T$, and assumed to be regularly, and simultaneously, observed.  Each data set is coming from an independent system.  (These systems or data sets are what the MS. confusingly calls "samples".)  Not only are they statistically independent, but the graph of effective connectivity among the $N$ univariate processes is different from one system to another.  However, there is a common functional form, shared across all the systems, for how the future of each of the $N$ nodes is generated from its own past and the past of its neighbors.  This differs from system to system only up to a finite-dimensional set of parameters, which represents graph structure as well as, e.g., connection strength.  Thus for instance we might be looking at neuronal firing rates, and saying that $x_i^t = \mathrm{logit}^{-1}\left(\alpha + \sum_{j \neq i}{w_{ji} x_j^{t-1}}\right)$, where the assumption of a common functional form is showing up in the additivity and the inverse-logit parts.  (This isn't a great model of neuronal response but you get the idea.) As the authors say in their replies to referees, and as the manuscript hints, an obvious application of this would be to multi-electrode-array neuronal recordings, where each data set from a different animal would be recording different neurons, with a different graph, but one might hope for a common neuronal response mechanism across experimental subjects.  (I can't come up with a second convincing application, especially not with fixed $N$ across "samples", which seems important to the encoding/decoding step.)  The innovation in this paper is to separate learning the common functional form of the vector autoregression from learning the graph, thereby allowing for pooling of information about the shared part of the model across data sets.  The reports agree that this is cleverly done, though it is not entirely clear what the limits on the expressive power of this method are, nor under what conditions it will converge on either the correct graph or the correct functional form.  Nonetheless, this is original and innovative work, and while text needs to clarify the intended application, the authors' replies to reviews make me fairly confident this can be done.
Below are multiple reviews of a paper. This paper provides a multi-stage solution to unsupervised, frame-wise segmentation in videos. The common fate heuristic is used to provide initial object detections and segmentations.The paper introduces an object-centric generative model for visual scenes. The model decouples the problem into three tasks: 1) modelling the 2D appearance and shape of individual objects with a variational auto encoder; 2) same thing for background; 3) sampling the position, size and appearance of individuals conditioned on the backgroundThis work proposes an object-centric generative model. It consists of motion segmentation, object model, background model, and scene model. Object model is trained to reconstruct an object as if it is not occluded.	This paper studies the challenging problem of object-centric generation of visual scenes. While the paper has some novel ideas that make it interesting, its (quantitative and qualitative) comparison with existing methods is currently premature to allow drawing conclusions with sufficient evidence.  Instead of claiming that existing models cannot do well for the more realistic datasets mentioned by reviewer dAqW, it would be more convincing to conduct a comprehensive experimental study by comparing the proposed method with existing methods on a range of datasets, from simple ones to more realistic ones. The synthetic Fishbowl dataset introduced in this paper can be one of them.  Moreover, the clarity of the paper could be improved to make it appeal better to the readers.  All three reviewers engaged actively in discussions (both including and not including the authors). Although one reviewer recommends 6 (weak accept), the reviewer also shares some of the concerns of the other reviewers. As it stands, the paper is not ready for acceptance. If the comments and suggestions are incorporated to revise the paper, it will have potential to be a good paper for future submission.
Below are multiple reviews of a paper. This work has twofold contributions, which are both theoretic and empirical. The theoretic contribution is the unification of existing algorithms using Shapley-Taylor indices. The empirical contribution is their proposed fast- kernel algorithm, which has been validated through quantitative experiments.This paper proposes an approach for explaining visual similarity models. It provides a general framework that enables them to adapt existing explanation methods to the similarity learning task. The experiments themselves do suggest their approach has merit, although lacking in several aspects.This paper proposes a explanation framework for retrieval/similarity/metric learning models. The proposed method relies on estimation of Shapley value, the authors then propose a kernel-based approximator. Experiments are conducted on PascalVOC and MSCoCo to show the faithfulness and quality of explanations.	The initial reviews for this paper were 6,6,6, the authors have provided a rebuttal and after the rebuttal the recommendation stayed the same. The reviewers have reached the consensus that the paper is borderline but they have all recommended keeping it above the acceptance threshold. Following the recommendation of the reviewers, the meta reviewer recommends acceptance.
Below are multiple reviews of a paper. The experiments are convincing. The authors solve a very reasonable problem in a general and compelling way. I was not sure why in the poker experiments the authors did not use deep learning to train an agent against which the colluding ones would play.The paper proposes an information-thoretic model to identify collusion among players in a multi-player game. The model seems too simple and relevant only for some classes of games (see more specific comments in the following)The approach to collusion detection is intuitive and accessible, and the experimental setup is very clear. I generally like the information-theoretic approach and think that this can be very fruitful, if developed further.	Meta Review: The paper introduces an information-theoretic measure to detect collusion (=cooperation between subsets of players) in multi-agent games. The measure is based on comparing distributions of joint actions of pairs of players against the marginal distribution over actions (which is motivated from a mutual information viewpoint and implies using the KL-divergence to compare distributions).  Pro: * A challenging theoretical problem tying into a line of research with significant downstream real-world applications (e.g. collusion in financial markets;) * A theoretically well motivated approach (taking into account the clarifications during the rebuttal) * Reviewers agree that the paper is well written * Compelling experimental results  Cons: * By far the main criticism (raised by two reviewers independently) before the rebuttal was that the measure is flawed, and could potentially mistake coordination between two players as collusion when instead their actions are correlated simply because they are in an adversarial relationship. The authors' response has clarified this as a misunderstanding.  After the clarification by the authors, aVDZ and DVsz have raised their score to a weak accept. To me personally, the main weakness of the paper has been successfully addressed by the authors and I am in favor of acceptance. There are still some open minor issues, and the paper is probably only highly relevant for a sub-community of UAI - that's why I currently do not see the paper as a candidate for an oral.
Below are multiple reviews of a paper. Proposed approach uses both structural connectivity and functional connectivity (via fMRI) to setup the graph edge information. The proposed network alternates between analyzing temporal information via gated temporal convolutional network layers and spatial information via GNN layers. A multi-resolution soft cluster smoothing is applied as the pooling operation in the GNNThis paper proposes a deep learning method for temporal data on graph nodes, specifically designed for brain imaging data. It can be deployed for classification of data where the time-varying data and graphs are individual specific.This paper proposes a Graph Neural Network model to estimate latent dynamics in the human brain. The model consists of four parts 1) estimating each sample's adjacency matrix by learning a shared projection matrix 2) gated temporal convolutional neural network for learning information from time-series data 3) graph neural network to get embeddingsThis paper proposes a method of graph neural network to jointly models dynamic functional signals and structural connectivities. In the experiment, the accuracy of this method is about 20% higher than other methods. The overall innovation of the article still needs to be improved.	This paper proposes a Graph Neural Network model to estimate latent dynamics in the human brain using functional Magnetic Resonance Imaging (fMRI) and Diffusion Weighted Imaging (DWI). The representation is tested on a classification task. While reviewers acknowledge the importance of this application, various concerns have been raised and partially addressed. The work focuses on graph deep learning and offers limited evidence of its superiority over more traditional ML or non graph based deep learning. Besides the methodological novelty is unclearly argued, which is not ideal for the audience of a conference like ICLR.  For all these reasons, this work cannot be endorsed for publication at ICLR 2022.
Below are multiple reviews of a paper. This paper presents a principled way of applying obfuscation transformation to create adversarial programs. A general mathematical formulation is presented to model the site locations and the transformation choice for each location in a perturbed program.This paper proposes an optimization problem to adopt insert/replace operations (program obfuscations) to generate adversarial programs. They apply it to the task of program summarization, and show that they outperform the existing baseline published in 2020.This work tackles the problem of adversarial attacks against ML models for code-understanding tasks, such as function summarization. It formulates the problem as the adversarial application of existing semantics-preserving program transformations (e.g., renaming variables)	This is a nice paper on generating adversarial programs. The approach is to carefully use program obfuscators. After discussion and improvements, reviewers were generally satisfied with the approach and evaluation. The problem domain was also found to be of interest.
Below are multiple reviews of a paper. This paper studies the problem of matrix completion using neural networks and deep matrix factorization as implicit and explicit regularization. The results are compelling, but some of the choices made are not fully justified or analyzed. The experiments are rather limited to a small set of test cases.This paper studies the matrix completion problem where the goal is to recover the matrix from partially observed elements. The proposed approach involves parameterizing the unknown matrix by deep matrix factorization and adaptive regularizers that are parameterized with deep neural networks.In this manuscript, the authors consider matrix completion problems. Leveraging recent advances on implicit regularization in (deep) matrix factorization problems, a new architecture for matrix completion is proposed. The underlying Laplacian matrix is parameterized by learnable weights.This paper proposes a generalization and extension to deep matrix factorization. The extension allows more complex model which include inverse problems. The generalization part is build on a "vanishing" regularization which leads to better dynamics and convergence. The experiments illustrate the advantage of the model compared to state-of-art methods.	There is a consensus that the contribution is not strong enough to effectively argue for an important novel lead which would justify publication at ICLR.   Authors have also not engaged with the reviewers.  For these rejections, this paper cannot be endorsed for publication at ICLR 2022.
Below are multiple reviews of a paper. This paper enhances transferability of vision transformers (ViT) by introducing two strategies specific to the architecture of ViT models. Self-Ensemble finds multiple discriminative pathways by dissecting a single ViT model into an ensemble of networks, leading to an explicit utilization of class-specific information at each ViT block. TheThe paper looks at Vision Transforms (ViTs) models and transferability of adversarial examples. The paper leverages the discriminative information stored in the lower layers' tokens. In general, I think it is a good paper, but also have some concerns about the generality of the work.The problem approached by the paper is interesting and the proposed approach is novel. The work is well-structured and written in a clear and concise manner with sufficient experimental verification. I like the idea of mining the relation between blocks and handle it by the proposed self-ensemble and token refinement method.'Self-Ensemble' implies it treats each transformer block of ViT as the 'last block' and apply a shared classifier to it. 'Token Refinement' tries to improve the classification ablity of shallow blocks by using extra non-shared module on each block's output tokens.	In this paper, the authors enhance the adversarial transferability of vision transformers by introducing two novel strategies specific to the architecture of ViT models: Self-Ensemble and Token Refinement method. Comprehensive experiments on various models (including CNN's and ViT's variants) and tasks (classification, detection, and segmentation) successfully verify the effectiveness of the proposed method.  In general, the problem studied is relevant and important. The paper is well-written and well-motivated with empirical findings. The proposed two strategies are novel, simple to implement, and effective in practice. Following the author's response and discussion, the average score increases from 6 to 7.5, with most concerns well addressed. AC believes that the paper should be highlighted at the ICLR conference.
Below are multiple reviews of a paper. This paper studies the generalization properties of Recurrent Neural Networks. The problem is important to understand in the theoretical machine learning community. The paper is written well overall, clearly explaining the results obtained.This paper refines the generalization bounds for vanilla RNNs in all cases. It fills the blank for RNN variants like MGU and LSTM. The paper focuses on generalization performance of RNN's and its variant in a theoretical perspective. In Lemma 2, the spectral norms of weight matrices and the numberThe authors provide new generalization bounds for recurrent neural networks. The main result is a new bound for vanilla RNNs, but they also have bounds for gated Rnns.	Some expert reviewers have raised novelty issues, that the authors have addressed in detail. Still, these expert reviewers are not entirely convinced. If this were a journal, I would recommend a major revision or reject-and-resubmit in order to allow the authors to anticipate the reviewers' concerns in the body of the paper and get some fresh reviews. I compliment the authors on the diligence they have put into the rebuttal stage, and look forward to reading the next version of the work. I will note that the bounds by Bartlett, Foster, and Telgarsky (and then the PAC-Bayes versions by Neyshabur et al.) are numerically vacuous empirically, and so whether those bounds or these bounds for RNNs explain generalization is up for debate.
Below are multiple reviews of a paper. Myriad is a JAX testbed written in JAX. It aims to benchmark imitation learning and reinforcement learning algorithms against trajectory optimization-based methods in challenging real-world environments. All environments, optimizers and tools are available in the software package.This paper proposed Myriad, which is a real-world testbed. It encorages the development of machine learning algorithms. Myriad is written in JAX, and both environments and trajectory optimization routines are fully differentiable.Myriad is a testbed consisting of 18 continuous-time, optimal control problems. It aims to enable comparisons between deep learning methods and optimal control methods. It also enables new algorithms like implicit planning over neural ODEs.This paper presents a suite of tasks inspired from real-world problems. It also provides implementations of 5 trajectory optimaiztion algorithms. The paper also demonstrates system identification and dynamcis learning via neural ODE on the presented tasks.This paper introduces a differentiable trajectory optimization library for use in optimal control and end-to-end learning of trajectory optimization modules. The library uses JAX to solve constrained continuous-time, continuous-control optimal control problems, particularly via a scalable form of gradient descent-ascent on an associated Lagrangian. To support system identificationThis paper develops a library that contains a suite of real-world continuous control problems and a collection of trajectory optimization implementations. It will be a great testbed for potentially huge RL advances in the continous control problems.	This paper provides a test-bed called Myriad for trajectory optimization and system ID in jax, with the hope of engaging RL practitioners to benchmark against the test bed. The proposed test-bed provides examples ranging from different domains (such as medicine, and biology) deviating from traditional domains that are usually the focus on RL benchmarks. Further, the focus is on continuous time settings. Limitations are clearly specified. Authors have done a good job of describing the testbed and comparing existing methods.  One challenge that remains to be addressed is how useful this testbed really is for RL practitioners. This concern has been raised because it seems like the dynamics of the proposed problems fall on the simpler end of the spectrum. Nonetheless, I am currently of the belief that having a JAX based test-bed for such domains is still valuable and I am hoping will contribute more to reproducible RL results in these domains. Currently it appears that the designer makes a lot of choices around the design and set up of the RL framework. It may be a real concern if the general RL community will not adopt the testbed for this precise reason. More importantly, it did strike me as odd that the contribution and abstract claim testbed for imitation learning and RL but do not provide a simple example of how this could be done. This was the main concern of tBG5. I also agree with CQCv's assessment that requiring dynamics equations to be explicitly provided by the user will significantly cost adoption of the test-bed. Reviewer vypE scored the paper very well but failed to justify the score for me to rely significantly on it.   My expectation is that the authors will genuinely deliver on all the asks. Further, continue to improve the library to make it more amenable to testing of RL algorithms with a more friendly API. Overall I want to note that significant effort seems to be required to put together the test-bed but also believe all above concerns are valid and authors are highly recommended to incorporate as many changes as possible. The lack of explicit examples of simple baseline rl testing on the test-bed is concerning, irrespective of the API and potential simplicity of the domains (which I believe is not a huge concern if it warrants RL testing in novel domains). I strongly encourage the authors to incorporate feedback and I believe it will make for a much stronger testbed in practice. Hoping authors deliver on this, to the extent possible by camera-ready deadline and after, I am recommending an accept since the testbed has some utility even in its current form (though I am less optimistic about widespread adoption in its current form).
Below are multiple reviews of a paper. This work proposes a new model class designed to make SHAP value calculations more efficient. The proposed method exploits sparsity and additivity among intermediate values to provide fast exact SHAP values for shallow ShapNets. This approach enables SHAP-based regularization during training and layer-wise explanations.The authors present a new type of network architecture where the each intermediate layer outputs the shapely contributions of the input. The core trick that the authors use to make their networks scalable is to aggressively limit the subset of features. The authors also extend this setup to work on computer vision tasks.The paper proposes to incorporate Shapley values as latent representations in deep models. The effectiveness of the proposed SHAPNETs is demonstrated through experiments on synthetic and real-world data. I have some comments as detailed below.	Shapley values are an important approach in extracting meaning from trained deep neural networks, and the paper proposes an innovative approach to address inefficiencies in post-processing to compute Shapley values, by instead incorporating their computation into training.  There was a robust discussion of this paper, and the authors' comments and changes substantially strengthened the paper and the reviewers' view of it, to the point that all reviewers now recommend acceptance.  Some lingering concerns remain that the authors should continue to work to address.  Is the method of computing Shapley values used as the baseline in the paper really state-of-the-art, or artificially weak?  The empirical results were methodologically sound but not as strong as one might expect or hope.  These concerns detract somewhat from enthusiasm, but nevertheless the paper yields an innovation to a widely-used approach to one of the most pressing current research problems.  The reviewers had a number of smaller suggestions that should also be incorporated including more significance testing and reporting of resulting p-values.
Below are multiple reviews of a paper. This paper proposes a method to train a machine translation system using weakly paired bilingual documents from Wikipedia. A pair of sentences from a weak document pair are used as training data if their cosine similarity exceeds c1. The model is also trained to minimise the KL divergence between the distribution of terms in the target language document and the distributionThe proposed method highly relies on the percentage of implicitly aligned data. The introduction needs to be rewritten with arguing the difference between existing methods.The method consists of a) mining documents that refer to the same topic, b) extracting from these documents parallel sentences, and c) training the usual unsup MT pipeline. The authors could further strengthen it by testing on low-resource language pairs.	This paper proposes a new method to mine sentence from Wikipedia and use them to train an MT system, and also a topic-based loss function. In particular, the first contribution, which is the main aspect of the proposal is effective, outperforming methods for fully unsupervised learning.  The main concern with the proposed method, or at least it's description in the paper, is that it isn't framed appropriately with respect to previous work on mining parallel sentences from comparable corpora such as Wikipedia. Based on interaction in the reviews, I feel that things are now framed a bit better, and there are additional baselines, but still the explanation in the paper isn't framed with respect to this previous work, and also the baselines are not competitive, despite previous work reporting very nice results for these previous methods.  I feel like this could be a very nice paper at some point if it's re-written with the appropriate references to previous work, and experimental results where the baselines are done appropriately. Thus at this time I'm not recommending that the paper be accepted, but encourage the authors to re-submit a revised version in the future.
Below are multiple reviews of a paper. The paper proposes a new way of prioritization in experience replay and Dyna-style planning methods. In particular, it proposes to exploit a learned model to actively search for states with high expected errors. The states are then prioritized proportional to theexpected errors.The paper shows how prioritized sampling from an experience replay buffer mirrors a cubic loss function. It uses this insight to show prioritized state selection for simulated policy rollouts via hill climbing ( gradient ascent)The paper investigates the search-control problem in Dyna-style reinforcement learning algorithms. It proposes a new sampling method based on gradient ascent. The suggested prioritization method is examined in various domains. It shows a better sample efficiency in most domains.	# Quality:  While the paper presents an interesting approach, Reviewer 2 raised relevant questions about the assumption of the theoretical justification that needs to be thoroughly addressed. Moreover, as noted by Reviewer4, the quality of the paper would also benefit from a more clear connection to existing model-based reinforcement learning literature, besides [Pan et al.]. For example, how much of the proposed approach and results can be applied in other algorithms?  # Clarity:  While the paper is generally well written and only minor suggestions from the reviewers should be implemented.  # Originality: The proposed approach is a small but novel improvement over existing algorithms (to the best of the reviewers and my knowledge).  # Significance of this work:  The paper deal with a relevant and timely topic. However, it is currently very difficult to gauge the significance of this work, and it unclear if the results can be extended beyond toy benchmarks and to other RL algorithms. Several reviewers suggested additional experiments to strengthen the paper.  # Overall: This paper deal with an interesting topic and presents new interesting results. However, the current manuscript is just below the acceptance threshold. Extending the experimental evaluation and improving the clarity of the paper would crucially increase the quality of the paper.
Below are multiple reviews of a paper. The paper is clearly written and all methods, experiments, etc. are well described. The authors conducted experiments on two datasets and reported results with correct patient/hospital level splits of the training, testing, and validation sets.The authors address an important problem of LSCC recurrence prediction. The experiments are well done, and improved results are observed with the proposed method. The authors report the performance of methods with the metrics ‘C-index’ and ‘Brier score’Proposed sampling mechanism is simple yet effective to learn unsupervised representations in histopathological whole-slide images. Paper presents a nice story of what are the missing parts/shortcomings in the previous works and how the proposed method addresses these shortcomings.	The paper proposes a simple and effective sampling approach to improve generalisation of survival modelling across different histopathology slides. The authors evaluate their multiple instance learning method on two separate datasets and show good performance.  Advancing self-supervised algorithms in histopathology and medical imaging in general is of great practical importance and is one of the keys to overcoming the data size bottleneck.  Overall the authors have answered reviewers concerns well and the paper reads clearly.  Pros * simple sampling approach with widespread applicability * use of open data, multiple datasets  Cons * Additional benchmarking with various competitive approaches using weak labels and/or transfer learning would be welcome, in particular with/without the sampling technique proposed
Below are multiple reviews of a paper. The paper showed a new approach for heterogeneous federated learning. It uses augmented dataset instead of a public dataset for knowledge transfer. The authors also suggested a lightweight additive secret sharing technique.This paper introduces a heterogeneous federated learning framework without requiring public datasets. The main strength of this paper is regarding the experimental results. Some aspects of the dataset expansion method and the secure querying protocol are unclear.PrivHFL is a protocol for collaborative learning that does not reveal the private data to the server or answering parties if they operate as honest-but-curious entities. It is not assumed that parties have new data or that there is a public pool of data to run inference on. The additional query data for knowledge transfer is obtained by	A heterogeneous federated learning framework is proposed which does not require auiliary public data sets, and does not reveal the private data to the server or answering parties if they operate as honest-but-curious entities. It builds a new protocol for private inference, which can run on GPUs, and proposes a dataset expansion method to not need an auxiliary data set. The paper presents extensive empirical experiments on the method.  The paper was extensively discussed with the authors. The concerns included both technical issues and more general issues on missing DP guarantees and realisticness of the threat model. Many of the issues were resolved by the clarifications provided by the authors, and as a result two reviewers increased their scores. However, all reviewers still place the paper to the borderline.  While the paper contains solid work, and improves efficiency compared to previous models, this is a borderline paper where the final judgement needs to be based on importance of the presented new contributions in advancing the field. The paper may not yet quite reach the bar, but I believe the reviewer comments have enabled the authors to improve the paper for further work.
Below are multiple reviews of a paper. For online learning with smoothed adversaries, optimal statisticalregret rates are known, but there are no efficient algorithms. Assuming access to an offline ERM oracle, the present paper develops new algorithms that are computationally efficient.This work provides so called oracle efficient algorithms for online learning, in the smoothed adversarial setting. The paper focuses in the setting of convex Lipschitz loses and binary cases separately.Online learning is a sequential setting in which in round $t = 1, \ldots, T$ a learner issues a prediction, suffers a loss corresponding to that prediction, and subsequently observes some feedback. The goal is to control the regret, which is the difference between the cumulative losses of the learner and the best fixed predictionThis paper considers the oracle-efficiency of smoothed online learning. In this setting, the output distribution of the nature is constrained to have a constant upper bound. The Poissonization technique is novel and may be of independent interest.	As summarized very well in the reviews, this is a well-written paper that makes a solid and elegant contribution to the recently active line of work on smoothed online learning.  The authors have successfully addressed the main concerns brought up in the discussion.  I genuinely agree the paper should be accepted.  As a side note to the authors: I honestly found your reaction to Reviewer gcMM’s comments rather aggressive and incongruous.  Disagreements naturally arise in a discussion and should not be automatically considered as an attempt to “greatly harm the review process and the community at large”.
Below are multiple reviews of a paper. This paper proposes a GAN-based approach to quantify both out-of-distribution and in-dist distribution uncertainty in image classification. The idea is interesting and can inspire others in this community. The presentation of this paper is clear and easy to follow.This paper proposes a method to estimate both aleatoric and epistemic uncertainties. It does so by training a conditional GAN in a latent space of a pretrained autoencoder. The provided toy dataset is illustrative.The paper presents UQGAN, a model for uncertainty quantification, including both OoD and FP detection. The proposed model contains a classifier C that outputs for a pair sample-label $x,y$ the probability that the pair is in-distribution.The generator is encouraged to generate features that lie in real distribution (evaluated by the discriminator) and out-of-class regions (assessed by the classifier) A low-dimensional regulariser is introduced to generate diverse features. Ablation studies verify the importance of the proposed regulariser.	The authors propose a new approach for training image classifiers with complete uncertainty quantification based on generative adversarial networks. The main idea is to use GANs to "shield" each class separately from the out-of-class (OoC) regime. This is done in combination with a one-vs-all classifier in the final DNN layer trained jointly with a class-conditional generator for out-of-class data in an adversarial framework. Finally, these classifiers are then used to model class conditional likelihoods. The empirical validation shows improved OoD detection and FP detection performance when compared to SOTA in this setting.  The reviewers appreciated the clarity of exposition and the positioning with respect to the related works. The unified approach applicable both to FP detection and OoD detection was deemed novel. On the negative side, the method seems to be extremely involved in terms of the required architectural pieces, distinction between low-dim and high-dim settings, primarily low-resolution data used for evaluation, and the number of hyperparameters. During the discussion the authors addressed the main questions raised by the reviewers. Nevertheless, given that all of the reviewers are leaning positive, I'll recommend the acceptance of this work. Please do a full pass in terms of formatting of the whole manuscript, including removing inline tables and figures, removing things like double parenthesis, bolding specific letters (e.g. L247), clarify the flow of information in figure 1 so that one can grasp the high-level overview of the algorithm, and incorporate the remaining points raised during the discussion.
Below are multiple reviews of a paper. The paper presents an image data set augmentation approach (4 variants+ original data set variant) in order to cater to the lack of sufficient data for learning purposes. The variations are all about extracting recognizable objects in images.The paper presents an object focused image based technique for CNN training. For every image in the training set, another image is generated where the labeled object is kept untouched and everything in the background is rubbed out. A simple comparison is made among five scenarios on using separately or combined the original and OFI.This work proposes to augment object focused image to improve image classification. It is more like a course project report than a scientific paper. It lacks rigorous experiment design and result analysis. The conclusion is not surprising or insightful.Authors propose an augmentation technique for image classification. The augmented image is obtained by segmenting the salient object and masking the background. Authors show an improved performance when using this augmentation on binary classification task.	The paper introduces an augmentation technique that, given an image with a detected object, keeps the object and removes the background.  The reviewers expressed numerous valid concerns about the paper's novelty, the setting (assumption that there's a single object), the scalability of the approach and the experimental setup, including the baselines used.  The authors have not addressed these concerns.
Below are multiple reviews of a paper. In this work, they do segmentation by three stages: global locating, organ locating and organ segmentation which reducing the resource consumption a lot. The RAM usage and GPU consumption are pretty low.	Please address the three reviewers' comments here  https://openreview.net/forum?id=WgYphAbJZS-&referrer=%5BProgram%20Chair%20Console%5D(%2Fgroup%3Fid%3DMICCAI.org%2F2022%2FChallenge%2FFLARE%2FProgram_Chairs%23paper-status)
Below are multiple reviews of a paper. The method is very simple: split the input into four pieces of size n/4 each, recursively solve each of them, then combine all four answers into a set and take a coreset of this set. The speed-up in running time is immediate (just because of how recursive formulas work)The paper proposes three reductions/ meta-algorithms to speed up existing distribution-compression algorithms while maintaining the error guarantee of the original algorithms. I believe the paper makes a good contribution to the field by proposing a general reduction scheme that improves the runtime of existing algorithms at cost of minimal increase in error.The paper introduces a new framework to improve on runtime of existing thinning procedures. The framework is quite simple and analysis is quite straight forward (except error analysis using Sub-Gamma) I am not sure how well "distribution compression" fits ICLR.	This paper proposes a simple meta algorithm to speed up data thinning algorithms with good theoretical guarantees. The method is both theoretically interesting and useful for practical applications.
Below are multiple reviews of a paper. In this work, the authors propose a recipe on how to build a general, powerful, scalable  graph Transformer with linear complexity and state-of-the-art results. The code is available and the performance of this work is good.The authors present a way how to efficiently use transformers on graph data. The paper is technically sound, and well structured and describes the problem well. The solid proof to use transformer block is missing.This paper provides a general, powerful, scalable (GPS) graph Transformer with linear complexity. The proposed definition of PE and SE is general, and the paper has a good presentation of writing logic. I have several problems about the methods and experiments.	This paper presents a powerful, general, scalable, and linearly complex graph Transformer. Positional encodings and structural encodings are redefined with local, global, and relative categories, and an attempt has been made to include  local and global focus attentions in a graph Transformer. All of the reviewers acknowledged the novelty of this work, particularly within the context of the domain, and therefore voted for its acceptance. Please take feedback from reviewers into account when preparing the camera-ready version.
Below are multiple reviews of a paper. The paper presents a new NN-search algorithm, that reaches the peak performance on TPUs. It is based on observations of hardware architectural properties and the so called roofline performance model. The evaluation is done on two TPU versions using two KNN datasets.This paper presents an ANN algorithm on TPU and analyzes the memory and instruction bandwidth of ANN algorithms. Strong Points: The problem is well-motivated, the related work is comprehensively studied and discussed.This paper presents a new algorithm implementation of K nearest neighbor search. The distances between all queries and entries in the database are calculated in L3 BLAS fashion. The adjustment of the bin size provides a simple method to balance recall and throughput.This paper studies using TPU for approximate nearest neighbor search. With careful analysis, it finds that search performance is bound by memory access and coefficient-wise operation instead of distance computation. Thus, it proposes to conduct partial reduce to reduce memory access such that search can reach peak FLOPs. Experiment results show that the proposed solution outperforms	The authors design an efficient implementation of nearest neighbor search on a TPU accelerator unit. The implementation is motivated by a refined roofline performance model that takes into account the memory and instruction bottlenecks that are found to be significant and that are not typically optimized for. Empirical results demonstrate that the proposed TPU solver outperforms state-of-the art GPU solvers. The package is available on Tensorflow.  The reviewers agree that the paper is well written, well structured and the proposed method can have significant practical impact.  Some concerns regarding the evaluation came up in the reviews but the additional experiments provided could address most of these concerns. What remains is a question on whether the performance gain over GPU comes from the algorithmic optimization itself or the higher efficiency of the TPU, and whether the algorithmic optimization would be similarly effective on other accelerators. The reviewers agree that performing such an analysis is outside the scope of this work. However, I want to encourage the authors to incorporate additional discussion to help the reader understand what parts of the work are specific to TPUs.  Overall this paper represents a well executed piece of work at the intersection between algorithm design and systems with an open source package that is available to the community. I recommend acceptance.
Below are multiple reviews of a paper. This paper exploring neighborhood memorization problem and proposes a neighbor-aware data augmentation method for node classification task. The work empirically indicates out that the learned node representations will be influenced by the neighbor label distribution.This paper addresses the class imbalance problem for node classification in a graph and points out some issues faced by existing GNNs and methods to address the same. It nicely depicts the problem of overfitting to minor classes and neighborhood memorization problem for class imbalance through experiments. The paper has multiple strong points and few weak points.The paper proposes an imbalanced classification strategy for GNNs. The proposed method alleviates the neighbor memorization problem by synthesizing ego networks. Extensive experiments are conducted to evaluate the proposed method.This paper investigates the problem of class-imbalanced node classification on graph. A model named GraphENS, which consists of two key components, is proposed to deal with the imbalance issue. Experiments on several datasets show that the proposed model can outperform the baselines.	Although reviews were initially a little polarized, they trend toward accepting the paper after rebuttal and discussion.  The most negative review raised issues of datasets, baselines, and experiments, and various details that they find confusing. These concerns were not shared by the other reviewers for the most part. Following a detailed rebuttal the most negative reviewer ended up siding with the more positive reviewers.
Below are multiple reviews of a paper. The manuscript proposes a new method of training neural RDEs with a pretrained autoencoder to reduce overhead of the log-signature transform when dealing with long time-series. The methods is compared to several different baselines, including neural CDE and ODE methods. These are tested on 6 real world datasets for bothThe paper seeks to improve upon the recently introduced "Neural Rough Differential Equation" (NRDE) model. The proposed autoencoder embeds "log-signature" information into a lower-dimensional space and can be trained prior to the main NRDE model. This approach is novel, easily understood, and intuitiveThe method performs competitively on a range of long time-series tasks. The writing of the paper is sometimes unclear and I am reluctant to recommend acceptance so long as there are (mathematical) statements that I cannot verify. The paper proposes an interesting extension to neural rough differential equations.This paper suggests hybridising neural rough differential equations (NRDEs) with nonlinear dimensionality reduction techniques (autoencoders) The experiments are very thorough, including all possible NCDE-derived benchmarks. The quality of the writing can be improved in general, as the mathematical constructions used are generally not too clear.	This paper proposes a novel method for training neural rough differential equations, a recent model for processing very long time-series data. The method involves a lower-dimensional embedding of the log-signature, which is obtained via pretrained autoencoder to reduce overhead. The results show significant and consistent improvements over previous methods on long time-series data.  Overall, the reviewers and I all agree that this paper offers a novel and impactful contribution leading to significant improvements over previous state-of-the-art methods for training neural rough differential equations. I recommend acceptance.
Below are multiple reviews of a paper. The authors propose and measure the performance of two SOTA methods such as Grad-cam and IRNet for the generation of weak-labels. Recent literature indicates that the use of semi-supervised methods in segmentation is not the most appropriate strategy.Fusion of weakly supervised with a fully supervised approach to address the challenge posed by the availability of annotated data is very interesting. This simple idea opens up the possibility of deploying CNN-based semi-supervised approach for semantic segmentation of Chest X ray.The paper tackles an interesting problem in how to train segmentation networks with limited pixel-level annotations. It builds on top of recent advances in weakly supervised and semi-supervised learning. The paper is mainly an application paper with limited methodological novelty.The results of this paper are promising as it clearly shows how global image labels can be leveraged in radiography. Main weakness of the paper relates to the lack of baselines. The idea of using grad-CAM to generate saliency maps as weak labels is not new.	The motivation for using semi-supervised learning in medical imaging is clear in order to reduce the cost of acquiring dense expert annotations. This paper presents an interesting study on applying recent semi-supervised learning methods to chest x-ray segmentation. There are some conflicting reviews here but in general, the reviewers find the work interesting enough to be presented but with too limited technical novelty to justify an oral presentation.
Below are multiple reviews of a paper. Neural nets (and sometimes other models) are shown to be susceptible to such attacks, due to their memorization. The strength is that the paper formally studies a well motivated question and is among the first to do it *formally*.This paper considers the problem of membership inference, i.e. guessing whether a given sample was in a model's training set. The authors propose to use the tools of random matrix theory in the asymptotic regime to analyze membership inference in the simple case of a linear model.This paper mathematically formalizes the existing empirical observation that larger models (linear regression) memorize more data. It provides some experiments on slightly more complicated models to further support the conclusion that having smaller models is better for privacy, even better than adding noise/ regularizing.	This paper considers the problem of membership inference. The authors propose to use the tools of random matrix theory in the asymptotic regime to analyze membership inference in the simple case of a linear model on Gaussian data. They start by deriving the explicit advantage of the attack in the asymptotic regime. Further derivations allow the author to analyze several interesting machine learning ingredients, starting from L2 regularization (ridge regression). There, the authors show that regularization has the counterintuitive effect of increasing the performance of membership inference attacks. The referees are leaning toward acceptance and I concur.
Below are multiple reviews of a paper. This paper studies the gradient descent-ascent optimization problem of GANs. It uses a novel framework called the Isolated Points Model. The theoretical results are then assessed experimentally on a toy dataset.This paper analyzes the dynamics of training GANs under the case that the true and generated samples are discrete, finite sets, and the discriminator is kernel-based. Strengths- This paper is well organized and well written.This article propose a simple theoretical model, called the Isolated Points Model. The article analyze the GAN's training problems from local stability and instability, approximate mode collapse and divergence three perspectives. Finally, this article argues a kernel based discriminator to explain the above three problems.	All reviewers agree this paper presents interesting analysis and results on GAN training dynamics. However they also note several limitations of the proposed setting, namely the assumptions of kernel width and the isolated points model, restrict directly applying results to practical settings. Authors in the response have done a good job of explaining how one can use the observations from the analysis to improve stability of real world training of GANs. Overall I think this work has some promising directions towards improving our understanding of training GANs, hence I suggest acceptance.
Below are multiple reviews of a paper. The proposed model is created by clubbing together GCN model for node classification and GAE model for link prediction. The loss function is a weighted combination of the two. The paper clubs together two earlier well known models and makes no additional theoretical contributions.The paper tackles a problem that is, in my opinion, very important and, so far, overlooked: cold-start node prediction using graph learning. The technique presented in the paper is simple, which I consider a plus. It works and it's simple. The experiments show a great improvement over the baseline.This paper is about the cold-start problem for representation learning on dynamics graphs. The proposed method (ColdExpand) uses convolutional networks and multi-task learning to learn embeddings for new unseen nodes in the graph. Such a problem is useful for applications of the link prediction problem and more specifically, recommendation tasks or graphColdExpand is a model that addresses learning tasks related to attributed graphs. Authors argue that this model is the first model able to deal with the cold-start problem, i.e. new nodes with no structure information. ColdExpand addresses the new node issue by using an architecture that combines a deep auto-encoder and a	The reviewers agree that the paper is addressing an interesting problem (cold-start for representation learning on dynamic graphs). However, the proposed methods can be improved by proposing more novel ideas. At the moment, the proposed methods is a combination of GCN model for node classification and GAE model for link prediction. In this case, some analysis or theoretical justification may make the paper more interesting. Furthermore, the reviewers think the experiments can be improved. For instance, results on more datasets, more comparison methods and a different setup will strengthen the paper.
Below are multiple reviews of a paper. This paper describes an approach to Incremental Semantic Segmentation (ISS) of images. The proposed approach demonstrates clear advantages over the state-of-the-art, both in terms of accuracy and memory efficiency. An extensive experimental evaluation is given on PASCAL VOC and ADE20K.The paper addresses the question of incrementally adding new categories in a semantic segmentation problem. This is a variant of the more standard class incremental learning problem. The approach is evaluated on two standard benchmarks in this field (PASCAL VOC and ADE20k)Replay-based methods propose to memorize a small set of images for previous categories. They achieve state-of-the-art performance at the cost of large memory footprint. Author propose a novel ISS method, dubbed ALIFE, that provides a better compromise between accuracy and efficiency.A new knowledge distillation loss dubbed adaptive logit regularizer (ALI) and a feature replay strategy are proposed. Experimental evaluation shows the superiority of ALI over previous (non-replay-based) approaches.	This work deals with incremental semantic segmentation. The authors propose a three-step incremental learning approach. They provide an in-depth analysis of the probability calibration methods widely used for the ISS, and introduce an interesting proposal for incrementally adapting the memorized features using global alignment by rotations. They show strong results on standard benchmarks for incremental segmentation, including the ablation study.    The rebuttal provides valuable insight, and the questions raised by the reviewers have been convincingly answered by the authors.   On the whole, the reviewers converged positively, the novelty and the interest of the proposal stand out clearly.   Authors are encouraged to consider all comments for their final version.
Below are multiple reviews of a paper. Wrt existing methods (SSE and IGNN), CGS learn multiple transition matrices instead of using a unique one. The underlying idea is to: (a) learn several linear operators whose iterations lead to a fixed point, (b) aggregate/combine the fixed points and (c) make the final prediction.The paper constructed a linear map on graph that is guaranteed to converge to a fixed point. By embeding such linear map into a graph neural network, it can be used to solve nonlinear problems. Experiments show that the proposed methods have good performance in various methods.The paper introduces the equilibrium GNN-based model with a linear transition map. The transition map is made contracting to ensure that the fixed point exists and is unique. The paper provides extensive comparisons with other equilibrium models.The paper is generally well-written, easy to follow, and contains enough technical details to understand the underlying principles. The proposed approach is technically sound and empirically evaluated on a range of experiments. The paper is well written and clearly explains the underlying assumptions and limitations.	The paper got four accepts (after the reviewers changed their scores), all with high confidences. The theories are complete and the experiments are solid. The AC found no reason to overturn reviewers' recommendations. However, the AC deemed that all the pieces are just routine, thus only recommended poster.
Below are multiple reviews of a paper. This paper proposed a model architecture for behavior cloning. The key element of the architecture is to feed region proposals from an RPN into a transformer. Results in simulation and real suggest this model works well.The paper presents VIOLA, an object-centric imitation learning method for manipulation. The idea is that object- and task-specific knowledge should be attended to for a manipulation policy. The paper introduces three simulated tasks (sorting, stacking, kitchen) and three real-world tasks.The paper presents an object-centric imitation learning approach to learning closed-loop visuomotor policies. The policy outperform naive baselines and several ablated methods in both simulation and the real world. The region proposals seem to make the network focus less on the irrelevant parts.The paper presents a transformer-based object-centric Visual Imitation Learning method. Ablations show that the method is able to effectively deal with perturbations, jitter and object placement variations.	Below is a summary of the strengths and weaknesses of the paper, according to the reviewers.  Strengths: - The use of transformers is interesting for attending to task-relevant parts of the image. - Results demonstrate robustness across viewpoints, initialisations, and distractors (although there is concern that the distractors are not that significant). - The ablation studies are very useful. - The real-world demos are interesting and impressive.  Weaknesses: - The paper appears to makes overly grand claims about introducing object-centric representations for imitation learning. - The baselines do not use the same data augmentations as the proposed method, making it an unfair comparison. - The use of pre-trained object detectors could make the method impractical for granular or deformable objects.  In the rebuttal, please address the above weaknesses, as well as the other concerns and questions raised by the reviewers.  ----------  Update after rebuttal:  Following the rebuttal, opinions were still divided on whether the paper should be accepted. There is a consensus that the overall idea is sensible and performs well, with strong real-world demos. But there is still concern about what we can really learn from this paper, other than the strength of transformers and region proposals. However, some of the questionable claims made in the original paper have now been rephrased in an updated paper. After a private discussion, the opinion amongst the reviewers is generally more positive than negative, and I believe that the simplicity of the method, together with the compelling real-world demo, would be appealing to the community.
Below are multiple reviews of a paper. The paper intends to contribute a novel task (Cache, as realized in AI2-THOR), the architecture of a strong Cache agent which learns reusable representations which allow significant transfer performance, and novel methods for evaluating the quality of dynamic image representations. The key strength of the paper is the very general core idea it advances.In this paper, the author's propose an embodied adversarial reinforcement learning agent that can play a variation of hide-and-seek called Cache. The authors argue that the agents are able to learn flexible representations of their observations which encode information such as object permanence, free space and containment.This paper examines the representations learned during adversarial gameplay, specifically a hide-and-seek game called Cache. The authors argue that the adversarial nature of the game shapes the representations. The paper is thorough, detailed, and well written.The task, Cache, seems extremely complicated to implement and train, since it involves five different stages of embodied exploration/action and adversarial reinforcement learning. While arguing that your agent successfully plays the game is important, it should take a backseat to the experiments which probe the properties of your static and dynamic image representations.	Motivated by the importance of gameplay in the development of critical skills for humans and other biological species, this work aims to explore representation learning via gameplay in a realistic, high fidelity environment. Inspired by childhood psychology, they propose a variant of hide-and-seek game called "Cache" built on top of AI2-THOR, where one agent must place an object in a room such that another agent cannot find it, and demonstrate that the adversarial nature of the game helps the agents learn useful representations of the environment. They examine the difference in representations learned via such a dynamic, interactive adversarial gameplay approach, vs other more passive approaches involving static images.  The paper is well written and motivated, and easy to follow. All reviewers agree that the paper will be a great contribution to the ICLR community. I believe this is an important work, because not only does it challenge the traditional way of training many components of our systems passively (via static image recognition models), it synthesizes ideas from various disciplines (psychology, embodiment, ML) and provides an excellent framework for future research. For these reasons I'm recommending we accept this work as an Oral presentation.
Below are multiple reviews of a paper. The paper proposes a graph neural network based forecasting algorithm for battery state of charge. The proposed algorithm is incremental over the existing ones and the corresponding impact on results is marginal. The paper does not meet the acceptance criteria for a top tier conference such as ICLR.This work proposes a new method based on graph neural network for Lithium-ion batteries parameters estimation. The proposed method, GAETS, essentially adds a graph autoencoding module on top of the previous GTS method.The paper proposes to incorporate a graph-autoencoder method from the field of causal structure learning for improving graph-based forecasting. The authors demonstrate empirically that the proposed method has an improved performance over the baseline considered.This paper studies a new problem of battery parameter estimation. The paper proposes a new graph autoencoder time series estimation approach that learns the underlying relationship between variables in battery measurements. Experimental results show that the new method outperforms the SOTA method.	The paper proposes to apply graph neural networks to predict battery state of charge. The main concern is the lack of technical novelty, since the main work is a straightforward application of existing works. The work could be better suited for a more application-oriented venue.
Below are multiple reviews of a paper. The authors proposed a 4D encoder-decoder CNN with convolutional recurrent gate units to learn multiple sclerosis (MS) lesion activity maps. The proposed architecture connects the encoder and decoder with GRU to incorporate temporal information.Authors present their work on identifying MS lesion change. The method uses GRU modules to include two or more images of the patient to identify lesion activity.The paper is well written. The idea of the paper is good. Results support the idea and gives an increase in the performance compared to baseline methods.The paper proposes to include recurrent layers in an encoder-decoder architecture to improve the segmentation of lesion activity. The method is clearly justified and introduced and shows clear improvements over a baseline that concatenates different time points.	The presented paper appears to be well written and presents interesting and promising results on an important problem. There is still room for improvement in the validation and clarification of the methods
Below are multiple reviews of a paper. The papers looks at the problem of using intrinsic rewards to help agent explore in sparse reward settings. The paper proposes combining multiple intrinsic rewards and proposes a meta- gradient based method to learning the fusion of these intrinsic rewards.This paper explores a model based intrinsic reward generation mechanism. The alpha-mean serves as the intrinsic reward, with the parameter alpha being co-optimized during training. The authors demonstrated that their proposed approach yields top performance in six augmented MuJuCo continuous control tasks.In this paper, the authors present a generalization of the model-prediction-error-based intrinsic reward method by fusing predictions from multiple models. I would like to understand the computational costs involved in using such a fusion approach.This paper proposes an intrinsic reward formulation to address the challenge of sparse reward in reinforcement learning. The key idea is to learn multiple models. The prediction error of each model is used as a component of the intrinsic reward.	The paper extends previous work on intrinsic reward design based on curiosity or surprise toward multiple intrinsic rewards based multiple model predictions and fuse the reward using meta-gradient optimization.  While most reviewers find the paper clearly written, several reviewers do bring up the concern on limited contribution of the work on top of existing ones. Reviewers also would like to see experiments conducted in environment with sparse reward rather than the delayed reward setting constructed from dense reward environments. More ablation studies on the different design choices will also be helpful.
Below are multiple reviews of a paper. The paper presents a maximally expressive parameter-sharing scheme for hypergraphs, and in general when modeling the high order interactions between elements of a set. Experimental results suggest that the proposed layer can outperform existing methods in supervised learning with graphs.The authors' model of G-NNs doesn't actually map to what is used in practice or what is interesting and useful. The aggregation operation in each layer is *not* linear, in the sense that it involves a product of the activations of the previous layer with the adjacency of the next layer.This paper explores maximally expressive linear layers for jointly exchangeable data. In doing so presents a surprisingly expressive model. I have given it a strong accept because the paper takes a very well-studied area (convolutions on graphs)	The paper provides a comprehensive study and generalisations of previous results on linear permutation invariant and equivariant operators / layers for the case of hypergraph data on multiple node sets. Reviewers indicate that the paper makes a particularly interesting and important contribution, with applications to graphs and hyper-graphs, as demonstrated in experiments.   A concern was raised that the paper could be overstating its scope. A point is that the model might not actually give a complete characterization, since the analysis considers permutation action only. The authors have rephrased the claim. Following comments of the reviewer, the authors have also revised the paper to include a discussion of how the model is capable of approximating message passing networks.   Two referees give the paper a strong support. One referee considers the paper ok, but not good enough. The authors have made convincing efforts to improve issues and address the concerns.
Below are multiple reviews of a paper. The paper proposes to subsample the computational graph to obtain an unbiased gradient estimator with less memory requirement. The experiments clearly demonstrate the effect of using SGD with randomized AD to train standard neural networks. The application on stochastic optimization of PDE is also very interesting and relevant.Memory is the main bottleneck for reverse mode autodiff for functions with lots of floating point operations. The authors suggest a way of producing the path sampling based on taking a chained matrix view of the computation graph.The authors proposed a general framework for randomized auto differentiation to achieve unbiased gradient estimators. This general framework allows randomization at different granularity such as layer level and individual neuron level. The memory saving is achieved by trading off gradient variance for activation memory saving.The paper proposes a novel approach to reduce memory in backpropagation by sampling the paths in DAG. The paper developed and proved the proposed method in a general framework. I feel that the explanation for applying this method to neural networks is somewhat lacking.	The reviewers agree that this is an interesting and original paper that will be of interest to the ICLR community, and is likely to lead to follow up work.
Below are multiple reviews of a paper. This paper proposes a model unfolding strategy that trains a series of models of increasing complexity for each stage. The proposed model leads to a reduction in both memory as well as inference time costs. Overall this paper studies an important area of model decomposition.The authors propose a cost-aware 2D prediction pipeline UnfoldML to solve multi-stage classification problem under the limited resources. In order to better find the optimal trade-off between model performance and cost, the author define a search space and three gate parameters.This paper aims to unfold a monolithic multi-class classifier to a series of single-stage classifiers for reducing deployment cost. The proposed method is a dynamic 2D projection pipeline which makes ICK predictions on sequential multi-stage classification tasks.This paper proposed a cost-aware prediction pipeline that "unfolds" a single multi-class classifier into a series of single-stage classifiers, reducing its deployment cost. Three classes of gate functions are learned to maximize the system-wise accuracy while minimizing the prediction cost.	The paper presents a method for transforming a multi-class multimodal classifier into a multi-stage classifier, increasing the efficiency at runtime and only using the necessary modalities for prediction. Most reviewers agree that this is an important problem for the community and has a high potential for impact. Reviewer f34b raised a question about uncertainty quantification, which the authors clarified successfully. The authors also introduced an appendix for policy selection and explanation on model predictions at the reviewer's request -- as these are tangential to the paper, the effort is appreciated. The authors also answered the questions about the optimization problem asked by reviewer cok9 - the reviewer did not comment on the author response, however the answers seem pertinent. An remaining issue is the lack of theoretical analysis of the work, though the experiments do support the authors' claims about the cost reduction. Reviewers 5CL8 and qEBg issued positive comments w.r.t the paper's strengths, specifically the real world experiments, the reduction in cost and the exploration of the cost-AUC trade-off space.
Below are multiple reviews of a paper. The proposed method shows 1-2% F1 score advantage over Stanford OpenIE on TAC KBP and Wikidata. The approach is interesting in that it is completely unsupervised, and is able to achieve a meaningful performance.This paper targets an ambitious question -- constructing a knowledge base from scratch using pre-trained language models. The proposed approach deals two problems: constructing facts from raw corpora and disambiguating the entities in the fact by linking them to WikiData entities.This paper presents an unsupervised approach for extracting OpenIE style triples from a corpus. The approach leverages the internal attention maps of pretrained transformers to identify paths which correspond to relations between a head entity and a tail entity.This paper is aimed at using pre-trained language models to create open-ended knowledge graphs. It seems like there's still some open questions about the types of improvements being made and what this implies about the LM's attention mechanism. There's also some missing related work in extracting knowledge from pretrained models that should probably be discussed.	We want to acknowledge that there has been a tremendous amount of work done during the discussion period on this paper for clarifying multiple points, adding multiple new comparison methods and new analysis. This is a very different draft than what was submitted and the reviewers acknowledged that. The draft is much closer from acceptance at ICLR than it was at submission time. However, despite all those additions, we do not support a publication at ICLR.   The main issues with the current draft are its positioning and motivations.  Right now the draft is in-between a paper about Knowledge Base Construction (KBC) and a paper analyzing the knowledge contained within a large language model. This in-between came up in multiple places during the discussion and is what causes the biggest confusion around this work. And, since there is no clear choice, the draft has limitation on either side.  * If the main point is around KBC to build general-purpose KBs, then one would expect experiments on downstream tasks powered by a KB, language understanding tasks for instance. Indeed, KBs are just a means to an end and the latest advances in very large language models have shown that KBs were not essential to be state of the art in language understanding tasks (GLUE, QA datasets, etc). So we would like to see whether these enhanced KBs could be beneficial. Or the KBs are studied as a way to encode commonsense like in (Bosselut et al., 2019) or (Davison et al., 2019), but this is not the point of the current draft. * If the main impact of the draft is around what the language models learn, bridging the deep language model and knowledge graph communities through enhanced model transparency, as it has been said in the discussion, then the discussion with (Petroni et al. 19) should be more prominent and the introduction, motivation and experiments of the draft should reflect that.  That's why, even if this work is of solid quality, the current draft can not be accepted.
Below are multiple reviews of a paper. This paper studies distributions that can be used as additive noise mechanisms, which tightly/exactly satisfy f-differential privacy. Such tight distributions are called canonical noise distributions (CDNs) for f-DP. The paper gives a sufficient and necessary set of conditions on f for the existence of log-concave CNDs forF-DP is based on the concept of tradeoff functions which give an order for the distinguishability of pairs of random variables. Canonical noise distributions 'fill' a given f-DP profile by giving a noise adding mechanism.CND is a family of distributions that satisfies $f$-DP with no loss in privacy budget. The authors prove the existence and infinite divisibility of log-concave CND and extend the notion of CND to high dimensions.	This paper provides conditions for the existence of log-concave multivariate distributions to satisfy f-differential privacy constraints. The results of the paper have the potential to be broadly applicable.
Below are multiple reviews of a paper. This paper proposes to decompose the Q-value as immediate rewards and residual returns. This decomposition makes the actor can leverage the gradient from the immediate rewards, which is likely to improve performance. The experimental results show a slight performance gain.Actor Residual Critics (ARC) is an alternative to the typical critic structure used in actor-critic RL. ARC-based imitation learning methods can outperform prior work in a number of continuous control tasks in both simulation and on real robots.In adversarial imitation learning (e.g. GAIL), the reward function is expressed in terms of the discriminator output and thus differentiable. When an actor-critic method is used for optimizing this reward, the analytic and differentiable form of this reward can be exploited. The paper presents a theorem to show convergence of policyThis paper proposes a method for updating policies using the gradient of the reward function in adversarial imitation learning. The Q function is represented as the sum of the immediate reward and the C function approximates the sum. of later rewards. Simulations verified the proposed method to outperform standard adversarial imitate learning.	While all reviewers appreciated the idea, there are severe concerns in particular from R3 concerning the validity of the statements and the contribution:  - In many standard RL settings, the  immediate reward might be misleading. The proposed algorithm seems only to have a benefit if a properly shaped reward signal is used (which is arguably the case for many standard RL benchmarks). Yet, this is not properly discussed in the paper. - The additional theorem for the new value iteration algorithm seems to unnecessary and an overcomplication - The contribution is mixed between RL and IRL, where in my opinion the paper makes a stronger case for the IRL setting as here the reward is always shaped. The contribution should be more focused to avoid "washing out the message". - More seeds are needed - Comparisons with GAIL need to be clarified (e.g. poor performance of GAIL in some environments).   The paper is currently borderline so all these issues need to be addressed very carefully. Rebuttal Update: The paper has been improved considerably after an intensive discussion with the reviewers in the rebuttal phase. All issues have been addressed and reviewers have now a positive opinion on the paper and think it should be published.
Below are multiple reviews of a paper. This paper introduces the idea of progressive training of deep networks for federated learning. Only some layer blocks are trained initially and the remaining blocks are progressively added. This can reduce both local computation cost and communication cost in the early stages.The authors adopt the progressive training technique to accelerate the training process federated learning. Extensive experiments demonstrate the efficacy of the proposed algorithm. The reviewer has several concerns about the current submission.ProgFed is a method that progressively trains neural network blocks of layers in $S$ “stages” Due to the specific nature of this form of training, the first $S-1$ stages of training require less compute. The authors prove that such a training procedure converges in a rate similar to the one ofProgFed is an algorithm designed for federated learning scenarios. Instead of training the neural network from end to end, it first trains the shallow layers, and then gradually train the deep layers. The ProgFed algorithm works not only for the feed-forward neural nets but also the U-nets, which consist of an encoder	As pointed out by some reviewers, the proposed method basically puts progressive training in the federated context. The theoretical analysis only concerns the centralized or non-federated setting and thus give no insight or guidelines for progressive training in federated learning. The main advantage of saving communication mainly comes from the simple observation that less parameters are computed and communicated during each round before the full end-to-end stage. However, this may cause extra overhead in hyper-parameter tuning including number of stage, learning rate schedules and stage-wise warmup. Despite its potential effectiveness in practice, the current version of the paper falls short of the acceptance bar due to the weakness in novelty and relevant theory for federated learning.
Below are multiple reviews of a paper. The paper proposes to use the distributionally robust learning (DRL) for unsupervised domain adaptation. The proposed approach — Distributionally Robust Self-Training (DRSL) — can provide competitive performance on the VisDA 2017 benchmark.This paper introduces distributional robust learning (DRL) for the unsupervised domain adaptation task. The proposed DRL based approach is claimed to better measure model prediction during self-training with an auxiliary discriminator.I find the paper to be well motivated. The individual components of Alg. 1 are well explained and shown theoretically. The overall approach well evaluated on 3 datasets and some of the components evaluated. On the negative side, clarity of the paper could be improved.	The paper proposes a rather complex algorithm for unsupervised doamin adaptation. While the paper provides detailed explanation, some motivation and some experimental resulst, it does not provide any theoretical guarantees for its performance. More concerning, since domain adaptation can only succeed when there is a close relationship between the source and target tasks, and only with algorithms  that take that relationship into account, any scientific proposal for domain adaptation should include a clear discussion of the assumptions driving the proposed algorithms and of the circumstances under which the proposed approach  may or may not work. This is missing in the current submission.   More specifically, a similar ocncern was voiced by Reviewer 3  Namely ".The generalization error (both theoretically and empirically) of the gradient approximation is unclear. It is necessary to analyze how effective and under what conditions the proposed approximation can work for the expected target loss optimization." Thsi point was not addressed in teh authors' rebuttal.  Anotehr key concerning point that was also brought up by reviewer 3 read: "It needs elaboration why the density ratios can be directly replaced as discriminator predictions, which seems not straight-forward and is the main difference to the conventional DRL." In response the authors cite the paper by Bickel et al 2007 but it falls short of addressing the well know fact that density ratio cannot be reliably estimated from samples of bounded size. The authors should have explained specific assumptions that can make this step of their algorithm og through.
Below are multiple reviews of a paper. The paper proposes a method to mitigate the difficulty of training deep adversarial auto-regressive generators in the ELECTRA self-supervised framework. The resulting model, named adversarial mixture of signals (AMOS), combined with the use of Gumble-Softmax relaxation, effectively stabilized GAN-style adversarial training.This paper present a method for pretraining language model using generator-discriminator training. Similar to ELECTRA model which used a MLM model as generator, which corrupts input text and replace some tokens with Masked token. Different from ELECTRA, they proposed to use multiple MLM generator models, which replace tokens at different difficultyThe paper presents an extension to Electra-like pre-training strategies that use MLM generator heads positioned at different layers throughout the networks. Mixture-weights for different MLM outputs are also learned end-to-end via the gumbel-softmax estimator. The authors make this mixture efficient by sharing the generator backboneThis work proposed a new framework AMOS to enhance ELECTRA-style pretraining. The new framework includes adversarial learning and curriculum learning. The overall performance outperforms ELECTRA and more-recent SOTA COCO-LM by a reasonable margin.This paper presents an adversarial learning framework for pre-training text encoders following ELECTRA-style architecture. Authors spent great deal of effort on the ablation study to show that the proposed framework and design choices perform better than existing state-of-art methods and other alternatives.The paper presents a framework for pre-training transformer based LMs a la ELECTRA-Generator-Discriminator style. The generator is modified to have multiple MLM heads specific to different layers. The replacement predictions from each of the layers are combined using learnable weights.	This paper received six reviews, consisting of three 8s two 6s and one 3. The reviewers generally felt that the proposed Electra-like pretraining provided fairly significant downstream improvements. Additional ablations were provided to during the author response period and other author responses were sufficient to cause scores to rise during the discussion period. The vast majority of reviewers recommended accepting this paper and the AC also recommends acceptance.
Below are multiple reviews of a paper. This paper studies estimation of process and observation noise variance in a subclass of linear dynamical systems. The approach revolves around forming variance estimators that exploit data-dependent operators. The resulting algorithm is simple.This paper provides novel finite-sample guarantees for parameter estimation in the dynamic linear regression setting. In an empirical example of predicting electricity consumption over time, the authors show that their estimator performs comparably to using maximum likelihood estimations as the inputs.The paper considers considers non-stationary linear regression with sub-Gaussian observation noise z. The approach is an alternative to maximum likelihood estimation (MLE)	The paper considers the estimation of process and observation noise variances in a subclass of linear dynamical systems and provides algorithms with finite sample guarantees. The math is novel and the results are interesting. I am happy to recommend acceptance.
Below are multiple reviews of a paper.  SPRT-TANDEM is an algorithm to train a sequential probability ratio test (SPRT) as a neural network. This network is then used to discriminate between two hypotheses as fast as possible (seeing the smallest number of observations in a sequence)The paper proposes a novel SPRT-TANDEM algorithm minimizing the divergence between estimated and true Log-Likelihood Ratios of SPRT. The paper is very well written, clear and scientifically sound.This work describes a new algorithm, SPRT-TANDEM, for classifying sequential data as early as possible. It builds upon several previous works (SPRT, KLIEP, and deep neural networks)The authors propose how to use the neural networks to estimate the posteriors for each label y for the log likelihood ratio (LLR) estimation. For LLLR training, there is no need for the sync of x^(t) for different ys.The paper proposes a new algorithm for early classification of sequential data. The algorithm is trained using a novel density ratio estimation loss alongside more standard cross-entropy. It shows strong performance on a number of provided benchmarks.	This paper presents a density ratio estimation approach to make the early decision for sequential data. The main contribution of this paper is the mathematical soundness of the proposed algorithm and all reviewers are unanimously positive about this paper with pretty good scores (7, 8, 6, 9, 7). However, despite the good scores, the verbal comments by the reviewers are not very strong except for one reviewer (R2); the reviewer with the highest score (9) did not provide detailed information about his/her rating. Also, the evaluation of this work is relatively weak because synthetic or simple datasets were employed for the experiment and the baseline methods are too straightforward. Also, it is not clear how the proposed algorithm can handle the data with sparse observations (data with idle times in the middle). Moreover, it does not provide rigorous stopping criteria although the authors proposed a simple method to determine the threshold, which is contradictory to the main objective of the proposed algorithm---making early predictions on sequential data---because the method requires "plotting the speed-accuracy tradeoff curve on the test dataset." This response implies that it at least requires a withheld dataset. Although this issue can be regarded as a separate problem, the paper could have provided an ablation study with respect to the criteria.  Considering all these facts--high scores but relatively low supports and confidences, and practical limitations, I would recommend accepting this paper as a spotlight presentation.
Below are multiple reviews of a paper. This paper proposes integrated gradient regularizer (IGR) for attribution protection. Incorporating IGR is to combine a standard (adversarial) loss function with a similarity function. Experiments show that IGR can both contribute to attribution protection and adversarial protection, surpassing previous baselines.The paper highlights some of the weaknesses in existing attribution robustness (attribution defense) methods such as l_p distance regularizers and Pearson correlation. The authors make a key observation about the Kendall's rank correlation metric. They propose a differentiable alternative based on cosine similarities.This paper theoretically demonstrates that Kendall’s rank correlation of two vectors is correlated to their cosine similarity. Then the authors propose an integrated gradients regularizer (IGR) to regularize the adversarial training methods and make them more robust.	Reviewers all find this paper presenting both good theoretical findings and empirical results for an important problem (feature attribution robustness). The approaches authors used in connecting the relationship between Kendall’s rank correlation and cosine similarity, as well as the geometric perspectives, are well received. The presentations are well written, with minor places for quick improvements.   Reviewers have raised various weakness points but we agreed most of them are minor, do not affect the contribution of this paper, and/or can be fixed without much effort.  Overall we recommend acceptance and would like to encourage the authors to further improve this paper presentation following reviewers’ suggestions in the next version.
Below are multiple reviews of a paper. This paper focuses on the online attack problem, where two elements are emphasized that attackers must operate under partial knowledge. To solve this problem, they propose VIRTUAL+ and give theoretical guarantee on competitive ratio. This may provide a new perspective why deep learning model is so fragile.This paper proposed a new threat model called online adversarial attacks. The experiment only evaluated on simple image datasets like MNIST and CIFAR. The motivation of the problem is not clear to me.This paper studies the online adversarial attacks on deep learning (DL) models. Since the data arrives as a stream, the attacker has to make an irrevocable decision on whether to attack when each data point comes. This setting aligns with the situation given in the k-secretary problem.This paper formulates an online threat model and use the VIRTUAL+ algorithm their proposed to solve this k-secretary problem. The proposed method is supported by theoretical justifications, and the numerical experiment shows a better performance of VITRUAL+ over other existing algorithms.	This paper opens the area of adversarial-attack research on streaming data (e.g., real-world settings such as self-driving cars and robotic visual tasks for a robot). For instance, online adversaries can focus their attack on a small subset of the streamed/online data, but still cause much damage to downstream models. This work highlights the need for stateful defense strategies. Connections to online algorithms and the k-secretary problem are made, along with improvements to some online-algorithms work of Albers and Ladewig.    Overall, the attack model introduced is important, and the bridge to online algorithms would be useful for the ICLR community. I also believe this topic lends diversity to the typical set of ICLR papers.
Below are multiple reviews of a paper. This paper proposes a method for the detection of adversarial examples based on identification of critical paths (called "effective paths") in DNN classifiers. Borrowing from the analysis of execution paths of control-flow programs, the authors use back-propagation from the neuron associated from the final class decision to identify a minimal subsetThe authors propose the notion of effective path, for the purpose of identifying neurons that contributes to the predictions and being able to detect adversarial images in the context of image classification. The paper could turn out to be a stronger paper but it is not ready yet.This paper proposes a measure (“effective path”) of which units and weights were most important for classification of a particular input or input class. Using the effective path, the authors analyze the overlap between paths across classes for CNNs and between adversarially modified and unmodified images. Finally, the paper proposes an adversarial	The paper presents an approach to estimate the "effective path" of examples in a network to reach a decision, and consider this to analyze if examples might be adversarial. Reviewers think the paper lacks some clarity and experiments. They point to a confusion between interpretability and adversarial attacks, they ask questions about computational complexity, and point to some unsubstanciated claims. Authors have not responded to reviewers. Overall, I concur with the reviewers to reject the paper.
Below are multiple reviews of a paper. The authors create (and make available) IndicLink, a dataset of multilingual fact linking in 5 Indian languages + English. The dataset is translated from English, from a portion of WebRED by annotators. The formalization for the task is difficult to parse.This paper studies the problem of fact linking -- linking facts from a knowledge graph (KG) to a given sentence where the fact is mentioned. A new test set for 6 Indian languages is created by manually translating sentences from WebRED with professional translators. The paper also proposes a model for this task based on the Dual Encoder -This paper considers the task of multilingual fact linking. The goal is to link abstract representations of facts to their language-specific representations in multiple languages. The paper proposes a retrieval + generation model (ReFCOG) that performs well.	This paper proposed a valuable resource in underrepresented languages, hence an exciting contribution for AKBC community. The new dataset presents a multi-lingual fact linking task for 5 indian languages in addition to English. The paper proposes a retrieval + generation model (ReFCOG) that performs well as compared to retrieval + reranking models, which provides a good starting point for the task. Reviewers have presented excellent list of suggestions to improve the paper further, especially, adding simple MT baseline (or a discussion if not possible in this setup), including systematic error analysis in the main paper, clarifying novelty of the proposed approach. I urge authors to address these in the updated draft of this paper.
Below are multiple reviews of a paper. Language models (LMs) have difficulty selecting the correct premise for a proof when the library of available premises is large. Authors use a data pre-processing step to train an LM to use an automatic theorem prover to improve premise selection.Thor combines the neural-based search heuristics with the Sledgehammer hammer in Isabelle. Thor achieves the new state-of-the-art result on the PISA dataset and performs comparatively with the best existing methods on the MiniF2F dataset.The paper presents a method to integrate language models and hammers for Interactive Theorem Proving. The authors train the language model to recognize an opportunity to invoke a hammer by transforming the training data.	The paper presents a method to integrate language models and hammers (Automated Theorem Provers) for Interactive Theorem Proving. The authors train the language model to recognize an opportunity to invoke a hammer by transforming the training data: they check whether the hammer can be applied at each proof state.   The approach is novel, while being simple. The reviewers are generally happy with the writing of the work. There were some concerns (such as obvious baselines, pointed out byuriH) that seem to be mitigated.  vtgR pointed out the slowness of preprocessing, which I think is an issue that should be explicitly acknowledged in the revision and addressed in future work.   Given the overall positive feedback of the reviewers, I am recommending an "accept" for this work.
Below are multiple reviews of a paper. This is an excellent analysis paper of a very interesting phenomenon in deep neural networks. In summary, the "harder" examples are more crucial to define the right decision boundaries. I argue strongly for this paper to be accepted to ICLR.This paper aims to analyze the extent to which networks learn to correctly classify specific examples and then “forget” these examples over the course of training. The paper is clearly written, and the work is novel -- to my knowledge, this is the first investigation of example forgetting over training. There are several experimental oversights which makeThis paper studies the forgetting behavior of the training examples during SGD. Empirically it shows there are forgettable and unforgettable examples, unforgettable examples are like "support examples" The paper also shows this phenomenon is consistent across different network architectures.	This paper is an analysis of the phenomenon of example forgetting in deep neural net training. The empirical study is the first of its kind and features convincing experiments with architectures that achieve near state-of-the-art results. It shows that a portion of the training set can be seen as support examples. The reviewers noted weaknesses such as in the measurement of the forgetting itself and the training regiment. However, they agreed that their concerns we addressed by the rebuttal. They also noted that the paper is not forthcoming with insights, but found enough value in the systematic empirical study it provides.
Below are multiple reviews of a paper. This paper proposes an empirical study of different mechanisms often set in place to prevent overfitting in Deep RL. It draws conclusions at what the challenges are and suggests future work directions. The authors point out the challenges and weaknesses but do not address them.This paper looks into why some of the recent methods for improving generalization in deep RL still do not perfectly generalize to new levels of a game. The authors also show that simple auxiliary tasks can improve generalization policies. The paper contains some interesting insights regarding some recently proposed algorithms.The paper studies generalization of several previously published visual RL SOTA algorithms with PPO as a baseline in ProcGen environment. Generalization is studied in terms of theme (colors and styles of objects and background) and tasks (levels with different layouts and specifics things to do) DrAC is shown to not be theme-invariThe paper studies generalization of policies trained for video games. More specifically, it analyzes transfer to new game situations via changing the theme (appearance) or the level (layout) of the game. The Procgen framework is used to procedurally generate new levels or themes.	This paper presents an empirical study of generalization in visual reinforcement learning. This study is carried out in the domain of video games and it addresses the benefits of techniques such as regularization, augmentation and training with auxiliary tasks. The reviewers for this submission were positive about the goal and setups in this paper. They agreed that understanding why present day methods that attempt to improve generalization continue to fall short, is an important problem. However, most reviewers were underwhelmed by the findings presented in the submission. As examples: Reviewer 185P mentions that "the paper does not seem to provide a clear and definite answer to the question" and " I am not convinced the experiments described in this paper support the claims made by the authors." and Reviewer SFef mentions that "Most of the conclusions are already known". Some reviewers also found a lack of clarity and several typos in the initial submission. The authors have provided detailed responses to the reviewers. In particular they have fixed most writing issues. They also detailed why certain algorithms and techniques were benchmarked in this submission and others were left out. I think this is reasonable. One cannot expect a paper to benchmark every algorithm out there, and choosing promising and representative ones is sufficient. My takeaway from detailed discussions about this paper are that: The paper is much improved from a writing point of view and the rebuttal addresses some concerns well. However, I do agree with the reviewers that the findings presented in the paper are for the most part expected. This reduces the value of the paper to readers. When this is the case, it may be beneficial to dig deeper into these findings and present a narrow but deep analysis. Please see Reviewer 185P's suggestions in this regard. Given the above, I am recommending rejection for this conference, but I encourage the authors to take into the reviewers suggestions and resubmit.
Below are multiple reviews of a paper. The paper proposes a new DSL language embedded in Julia that can represent reversible programs. Their language would allow reverse mode automatic differentiation to be implemented in lieu of the standard checkpointing schemes. The paper needs to be drastically improved in order to be accepted for publication.This paper draws connections between reversible programming and reverse mode automatic differentiation. It also introduces a reversible DSL in Julia that can be used to calculate first and second order gradients.The paper presents an embedded domain-specific language in Julia which enables reversible computation and automatic differentiation. The proposed system shows strong performance compared to the presented alternatives, especially when using GPU kernels.The paper adapts reversible computing techniques to compute gradients. The techniques presented are not new though the Julia based DSL is new. The results presented are for differentiating through a GMM.The paper presents a new approach to automatic differentiation (AD) It uses reversible programming to achieve memory-efficient function inverse and adjoint. The implementation is based on adding an embedded DSL to Julia called NiLang.	After reading the paper, reviews and authors’ feedback. The meta-reviewer agrees with the reviewers that the paper touches an interesting topic (reversible computing) but could be improved in the area of presentation and evaluation. Therefore this paper is rejected.  Thank you for submitting the paper to ICLR.
Below are multiple reviews of a paper. This paper introduces a new component to the unsupervised machine translation framework called cross-model back-translated distillation. Experimental results in several translation tasks show that the proposed approach improves the translation accuracy.This paper describes a method to enhance unsupervised machine translation through data augmentation. The idea is pretty straight-forward, if not altogether intuitive. The biggest knock against this paper is the relatively small data scenario.The paper proposes an additional stage of training for unsupervised NMT models. It uses synthetic data generated from multiple independently trained models. The generated synthetic data uses two stages of back-translation, with different models, to "diversify" the set of training data used for fine-tuning the models.The proposed method is quite simple yet effective, but it is also a kind of data enhancement. The evidence in this paper can not support the claim that the current performance bottleneck of UMT is due to the lack of diversity. The author adopts a variety of model structures, which is slightly redundant.	This paper proposed an additional training objective for unsupervised neural machine translation (UNMT). They first train two UNMT models and use these models to generate pseudo parallel corpora.  These parallel corpora are used to optimize the UNMT training objective. The experiments are conducted on several language pairs and they also compared with several alternative works.   All the reviewers admit that the proposed method is straightforward and effective. The authors claim that the new training objective is used to enhance the "data diversification". This point has been questioned by the reviewers. Some reviewers are convinced by the response and some still have different opinions.  From my point of view, the proposed method can also be considered as a kind of combination of  (pseudo) supervised NMT and unsupervised NMT.   The presentation and description of its key contributions seem unclear. However, we encourage the authors to modify their paper and we believe this proposed method can inspire the MT community for further research. At the moment, the paper is seen as not yet ready for publication at this time.
Below are multiple reviews of a paper. The paper presents MultiBERTs, a set of 25 model checkpoints, and the Multi-Bootstrap, a non-parametric method to estimate the model uncertainty. The experiments verified the proposed method on a case study of gender bias in coreference resolution.This paper releases MultiBERTs, a set of 25 BERT base checkpoints to facilitate studies of robustness. It also proposes the Multi-Bootstrap method to quantify the uncertainty of experimental results based on multiple pre-training seeds.Many tasks in contemporary NLP begin by building off of a large language model. This can cast the downstream task as a sort of fine-tuning experiment. In this work, the authors take BERT as an example. They ask how much a specific artifact as a draw from the distribution over affects downstream tasks built upon it.The paper presents MultiBERTs, a set of 25 model checkpoints to support robust research on BERT. The Multi-Bootstrap is a non-parametric statistical method to estimate the uncertainty of model comparisons across multiple training seeds. It demonstrates the utility of these resources by showing how to quantify the effect of an intervention to reduce a type	This paper is a resource and numerical investigation into the variability of BERT checkpoints. It also provides a bootstrap method for making investigations on the checkpoints.  All reviewers appreciate this contribution that can be expected to be used by the NLP community.
Below are multiple reviews of a paper. The paper is well written and clearly explained. The previous literature is adequately discussed and the experimental results are clear. The problem being solved does not seem to be particularly common or clinically relevant (see detailed comments below)The aim of the presented paper is a bit ambiguous and partially unclear. The claimed 264,198 samples in the training set do not match 90% of the full dataset. It is not clear why only subsamples of the validation and test data were used.There is substantial interest in encoding ordinal relationships between classes into the training process of neural networks. This paper shows that encoding prior knowledge about the order of the classes improves the performance.The paper addresses a common challenge faced when training models with labels which are coarse and could benefit from domain knowledge. The evaluations are not very convincing.	This is a borderline paper -- while the underlying idea is good and relevcant, the authors don't do a very good job of selling it; their experiments are performed on a very specific task with limited clinical relevance. The reviewers had a number of questions regarding experimental setup, which were largely answered in the rebuttal.
Below are multiple reviews of a paper. The paper investigates if invariances learned by the model transfer across classes. Using this approach, the authors are able to achieve a significant improvement on standard long-tail datasets.The paper investigates if robustness (or "invariance") to nuisance transformations are learned across all classes or if such robustness is sensitive to the class size. The paper demonstrates that such invariances seem not to transfer across classes: ie the classes with fewer examples suffer more.This paper works on long-tailed or class-imbalanced learning. The authors found that the learned classifier in such a setting cannot effectively transfer the class-agnostic (in)variance in a dataset from the head classes to the tail classes. The experimental results on several small-scale datasets demonstrate the effectiveness of the proposed methodThis paper studies the problem of how well do neural networks transfer class-agnostic invariances from head classes to tail classes. They found that the key to solving the long-tailed problem might be disentangling the class-specific features from class-shared features. Despite the good motivation of this paper, the technical details of the	This paper investigates how well properties invariant to changes such as lightening and background learned in the major class can be transferred to the minor class. In this paper, the authors reveal that invariances do not transfer well to small classes, and suggest that resolving this phenomenon can help increase the performance on imbalanced datasets. From this point of view, the authors propose a generative model-based augmentation technique.  Three reviewers suggested acceptance, and one reviewer judged borderline reject. It seems true that the method is not novel enough, but it is solid and well motivated. In particular, the finding of the paper is interesting and the design of the experiment is well done, so I think that it will have a great influence on research in this field in the future. As the negative reviewer mentioned, the lack of large-scale experiments is a major weakness of this paper. I strongly encourage the final version to supplement the promises made to the reviewer, including adding iNaturalist experiments.
Below are multiple reviews of a paper. The paper considers the problem of Multi-View Stereo reconstruction from images. It proposes a transformer-based approach, where specialized transformers are introduced for epipolar-guided stereo matching. The proposed approach represents the current state-of-the-art on both the intermediate and hard scenes of the Tanks & Temples dataset.The paper proposes a new learned MVS method based on MVSNet pipeline. The main contribution includes the introduction of window-based transformers to exchange the information among different views and a Geo Loss to consider the supervision signal of multiple views.This paper proposes a transformer-based architecture for multi-view stereo. Main contributions include inter- frame and inter-frame attention mechanisms designed to leverage epipolar constraints. The method is simple and performs very well on standard benchmarks.This paper presents WT-MVSNet, a deep learning based multi-view stereo method. It makes uses of Swin Transformer to aggregate global context in inter- and intra-feature attentions. For inter-attention, the authors propose Window-based Epipolar Transformer (WET) to reduce matching redundancy.	The paper is concerned with multi-View Stereo reconstruction from images with several transformers for specific subtasks. SOTA performance is attained. Reviewers acknowledge a technically sound pipeline. The writing is also clear and limitations are addressed. All reviewers recommend the paper for acceptance and so do I. Nevertheless, the authors must include the feedback provided by reviewers e.g. on possibly limited significance of 0.05 mm better results on DTU is significant or not given accuracy limitations of the ground truth. Also connections to pointed out related work must be discussed.
Below are multiple reviews of a paper. This paper proposes an architecture and training scheme for 3D shape reconstruction. It combines the generalizability of models that parameterize an entire shape family with the level of detail of models overfit to a single shape. As a result, it is possible to perform part-based edits where novel geometry is hallucinated where necessary.The paper presents a neural representation that combines the benefits of detail preservation of overfitted representations and edit-ability of generalizable representations. The model consists of a part mixing network, a part query network, and a global occupancy network. NEUFORM is evaluated on reconstruction, part based shape editing and shape mixing.This paper presents a shape editing method which works by combining generalized and overfit occupancy models. With this method they demonstrate superior shape reconstructions, shape edits and and shape mixing. I have no qualms with the methodology, presentation or results.	All the reviewers appreciated this work combining generalization capabilities of shape-space models and the fidelity achieved in a single shape overfit/optimization.
Below are multiple reviews of a paper. The paper develops a method for private neural-network-inference via utilization of Yao's garbled circuits (GC) protocol. The paper proposes utilization of a neural network architecture search, coupled with restricting weights to ternary alphabet and binary activation.The paper aims at developing an efficient neural network architecture with reduced computational cost under a cryptographic primitive where data on the client side and model on the server side are kept confidential. Garbled circuits are chosen as the cryptographic primitive due to its compatibility with a wide range of computations, including non-linear functions.This paper studies neural network designs for cryptographically secure inference. The paper uses the existing DARTS neural network architecture search algorithm to automatically a ternary neural network for secure inference based on garbled circuits.	The authors propose a new way of addressing the ML as a service problem through using garbled circuits. As the reviewers point out the novelty is limited and comparison to existing work is not complete. The authors have also not responded to the reviews.
Below are multiple reviews of a paper. This paper studies the problem of predicting item relevance to users, in a way that is robust to changes in the data distribution. The learning algorithm proposed requires minimal knowledge of the causal graph. The connection to economics and user behavior psychology by modeling the response y via an expected utility function is interesting.This paper proposes a learning framework that is robust to environment changes to predict the relevance of items to users. The proposed framework is novel and the paper is fairly well written. There are no comparisons with other exciting works.The paper considers a recommendation setting where we observe the attributes of users, of items, and aspects of the recommendation itself. The task is to use this information to predict the user's decision, whether or not they will interact with the item of interest. The decision is affected by the causal model by which a user reasons about features to make	This paper studies user-item relevance prediction and proposes a novel learning framework that is robust to distributional shifts in observed user-item attributes. All the reviewers appreciated the significance of the problem, the novelty of the solution, and the thorough empirical evaluation. The reviewers were confused by the exposition in some places, and the authors comprehensively addressed the questions during the feedback phase. Please include the extensive clarifying discussions with the reviewers in the revised paper, which will likely be of interest to the community.
Below are multiple reviews of a paper. The paper presents a novel neural architecture for the imputation task. The model is derived from the now classical GNN framework. A spatio-temporal cross-attention layer is proposed for the message passing between nodes.The paper proposes two variants of attention-based message-passing networks. The network learns representations that can reconstruct missing observations. The performance of SPIN and SPIN-H is compared empirically to multiple benchmarks in Section 5.In this paper, the authors propose an attention-based model for missing data reconstruction from spatiotemporal graphs. The proposed method outperforms existing approaches, especially when the missing rate is high.SPIN is a spatiotemporal graph network with a new spatiotsemporal attention for reconstructing missing data points in multivariate time series. The proposed attention mechanism consists of the inter-node cross-attention and the intra-node self-att attention.	The paper tackles the important problem of spatiotemporal data imputation via a novel GNN architecture and corresponding spatiotemporal attention mechanism that are both cogent and intuitive.   The author feedback satisfactorily addresses key concerns. In particular the ablation study is a great plus and the virtual sensing results further expand the relevance of the approach.   The AC finds the "auxiliary task learning" setting presented by the authors very interesting and strongly encourages the authors to explore such a setting as future work!
Below are multiple reviews of a paper. The authors present two online biologically plausible algorithms for the irreducible representation learning method. The first algorithm uses SVD to extract the subspace of maximal average rotation. The second is based on PCA of time difference vectors.This manuscript proposes biologically plausible algorithms for learning group transformations from sequences of observations. Two algorithms are proposed, one based on SVD and the other on PCA. Performance of these algorithms is evaluated in synthetic experiments.The present paper studied the neural implementation of learning irreducible representation of commuting group transformations. The whole paper is structure-wise but some presentation is not clear and the comparison with earlier studies was not done systematically.The authors depict two novel biologically plausible algorithms for online estimation of transformations using irreducible representations. Possible neural implementations are depicted which can be searched for in connectomics.	This manuscript presents novel biologically plausible algorithms for learning representations for Lie groups. The derivation of the algorithms and the networks are based on previously studied biologically plausible networks. Although there are some limitations, the reviewers agree that this work is sound, clearly presented, and represents a valuable contribution to both computational/theoretical neuroscience and machine learning.
Below are multiple reviews of a paper. The authors of this paper offer a method to compute the singular values (SVs) of convolutional layers efficiently. The assumptions of the lemma and theorems are not specified clearly. The experiments of computational complexity are too limited.The work proposed a less expansive approach to calculating the singular values of convolutional layers. The reviewer found that the title of the work is not well aligned with the actual content. The effect of the proposed approaches can be better demonstrated If more experiments can be added.This paper proposes an efficient method to compute eigenvalues of convolutional layers based on a sparsity-driven approach. Theoretical claims could be better explained/justified. Limitations are in section 6, assumptions are reasonable.This article proposed a framework based on the Tensor Train (TT) decomposition to decrease the complexity of computing a given convolutional layer's singular values. The main paper and supplementary materials give detailed proofs of the lemma and theorems.	This paper introduced a tensor decomposition, and associated theory, which allows for the control of singular values in convolutional layers.  Based upon the reviews, rebuttal, and reviewer discussion, I recommend paper acceptance. All reviewers recommend acceptance. The rebuttal was effective, with one reviewer who initially recommended rejection raising their score.  The authors should be sure to follow through, and update the paper to include changes discussed during the review period. Especially, it seems as if the framing of the paper shifted during the review period from centering on practically computing singular values to practically controlling singular values. From my understanding of the work, I agree this second framing makes more sense.
Below are multiple reviews of a paper. The paper proposes a generalization of Monge maps to the case where multiple pairs of labeled measures are to be matched by a single, global map. The paper starts by setting preliminaries and describing the objective, then provides a detailed account of implementation using partially input convex neural nets. It concludes with several experiments on treatment effects ofThe paper considers the problem of learning a map. The primary motivation is the following: suppose we observe unpaired biological data before and after treatment. The key aspects of the authors' approach to the problem is as follows.This work concerns the problem of learning the optimal transport (Monge) map that push-forwards between a given pair of measures coupled with a given context. They propose a framework that composes of an input convex neural network and a context embedding.This paper proposes to learn a single Monge map $T$ between different pairs of probability measures. The map is parameterized by a convex neural network with partial input from a context function. I find the idea of the paper well justified in terms of application.This paper proposes to learn a global map that is conditioned on the contexts. They achieve this by minimizing the Wasserstein-2 distance between the pushforward distribution and target distribution. The paper mainly applies their method to the biology data.	The paper considers the problem of learning a single Monge map between different pairs of probability measures such that the particular transport depends on a given context. The reviewers have found the paper well written and motivated. In addition the approach is novel and interesting. I therefore recommend acceptance.
Below are multiple reviews of a paper. The paper studies the problem of boosting test performance of the last layer by crafting random perturbations that are orthogonal to the train feature matrix. The claim that LLboost improves performance is very strong.This paper provides an innovative way to improve generalization performance. My major concern is about experiment part. Since the algorithm use valid data to tune the parameter, it should another held-out test data to show the result. However, the author only did experiment on test-data for model ResNet-18.The authors propose a method to adjust the last linear layer of a DNN without impacting the training accuracy. The condition that the last layer is over-parametrized is rarely satisfied in practical problems to which DNNs are applied. Because Alg. 1 uses validation labels as its input to select the best solution, it is	Though the method suggested in this paper is interesting, theoretically motivated, and resulted in some practical improvement, the reviewers ultimately had low scores. The reasons for this are: 1) The improvements obtained by this method were rather small, especially on the standard datasets (CIFAR, Imagenet). 2) In the main results presented in the paper, it seems that a proper validation/test split was not done (which seems quite important for demonstrating the validity of this method). In some of the results, presented in supplementary, such a split was done, but this seems to decrease the performance of the method even more. 3) The method requires that features in the last hidden layer approximately span a low dimensional manifold. This seems like a major limitation for the accuracy of this method, which becomes approximate in datasets where the number of datapoints is larger than the size of the last hidden layer (which is the common case).  Therefore, I suggest the authors try to improve all of the above issues and re-submit. For example, one simple way to address issue 3 and potentially improve the results (issue 1) is to use the same method on all the features in all the layers, instead of just the last layer. In other words, concatenate all the features and all the layers, and then add a linear layer from this concatenated feature vector directly to the network output, in a direction that is orthogonal to the data.
Below are multiple reviews of a paper. The problem has real research significance and economic value, especially for large-scale cloud system failure operation and maintenance. The efficiency advantage of the proposed solution makes it more adaptable to real system scenarios.A Root Cause Discovery algorithm inspired by existing FCI algorithm for detecting interventional targets is proposed. Additional node called F-node is introduced to represent the effect of the intervention. The proposed approach relies on the PC algorithm to learn causal graphs.The proposed algorithm treats a failure as an intervention on the root cause to learn the underlying causal structure. The authors compare their proposed solution with a modified version of the PC algorithm and some existing work on root cause analysis.	The paper provides a new approach for learning root causes of failures and is targeted to micro-services. One of the main shortcomings of the paper raised by reviewers was in the evaluation. On the one hand, reviewers pointed out a number of very relevant related works that are not compared with this work, and on the other hand, the bulk of the quantitative assessments are done using synthetic data, and there were some questions about the level of realism of the Sock-store experiment. That said, the rebuttal had a good analysis of the relationship with those related works and argued for why they are not entirely comparable. I do think the evaluation could be stronger; in fact, I think the paper could have more impact and more visibility in a systems conference, but that would require a more complete evaluation on more real systems (it is instructive to compare the evaluation of this paper with that of the Sage paper brought up by one of the reviewers). However, I think the combination of an interesting algorithmic contribution, strong results on simulated data and a compelling real-world case study puts this paper above the bar.
Below are multiple reviews of a paper. This paper revisits the traditional problem of approximating graph convolutional networks using Chebyshev polynomials. ChebNetII's performance improvement is significant, particularly for semi-supervised node classification tasks. This work is mostly well-written with informative content and new ideas that are worth publishing.A new GNN model called ChebNetII is proposed enhancing the Chebyshev polynomial approximation and reducing the Runge phenomenon. It can achieve the state-of- art performance on some open graph datasets.This paper proposes an extension to ChebNet by introducing Chebyshev Interpolation. The proposed methods are simple, yet provides theoretical support and improved performances.	The authors consider the traditional problem of approximating graph convolutional networks using Chebyshev polynomial, which is known as Chebnet. Then, the authors propose a new GNN model called ChebNetII enhancing for reducing the Runge phenomenon; this is an important contribution to GNN. Overall, the reviewers are positive about the paper. Thus, I also vote for acceptance.
Below are multiple reviews of a paper. The authors introduce a new type of state abstraction called model-invariance. The idea of combining the two concepts of sparsity and causal invariance is not new. In the linear settings, it is convincing that the learned model could generalize well to unseen environments. However, the proposed approach has no guarantees on that causal variables canThis work presents a method for learning representations for model based reinforcement learning by leveraging assumed sparsity in the causal graph. Authors propose a method which, at a high level, aims to utilize data collected under different conditions to extract a representation under which the transition model is approximately invariant.This paper points out that the causal structure is important for the generalization ability of a dynamics prediction model. The paper is also well-written, but the analysis and the experimental support are not strong enough, so I give 5 in this procedure. I am willing to increase my score if the authors fix the below problems in the rebuttalThis paper defines a novel model-invariant state abstraction for factored MDPs. It’s also shown that using invariant causal prediction significantly reduces transition prediction error in both toy example and several continuous control tasks. Inspired by theoretical results, this paper also proposes a novel method for learning model-Invariant representations using	This paper proposes a method to learn representations in MBRL by exploiting sparsity in the model to improve data efficiency. The key idea is to build a representation for which the model is invariant. The idea is quite interesting, but one weakness of the current draft is that there is a disconnect between the presented theory (linear case) and the relevant experimental setup (non-linear). The paper is overall well written but would still benefit from a revision to improve clarity as pointed out by the reviewers. The experimental results are inconclusive due to the choice of weak baselines.
Below are multiple reviews of a paper. The paper proposes to first predict a coarse (32^3) voxel grid by aggregating independent predictions from individual views. Then, it translate it into a mesh and refine it using deepMVS predictions (using each view in turn as a reference view) The pipeline presented in this paper is extremely complicated, and has many differentThis paper proposes a system of reconstructing 3D objects from multi-view images. The visual quality is reasonable, however from Figure 3 it seems like reconstructed local surface suffers from noises. Despite the results, the system is rather bulky and ad-hoc.The paper generally uses a mix of SoA techniques creatively woven together in a fairly sophisticated model. Oher novel aspects such as using the neural renderer to create the contrastive depth module was interesting.	This submission is an interesting case...  The method it presents appears to work quite well, achieving state-of-the-art quantitative reconstruction results (though qualitatively, the reconstructed surfaces are locally noisy).  The method is quite complex, which different reviewers saw as either a strength or a weakness ("a mix of SoA techniques creatively woven together in a fairly sophisticated model" vs. "bulky and ad hoc").  Most critically: it appears that the reasons for the method's significant (14%) improvement over the prior art for this problem (Pixel2Mesh++) are not due to the novel contributions that the paper focuses on (multi-headed attention, contrastive depth loss). Rather, it is other system design choices that are not novel research contributions that make up all but 1% of this difference (primarily, using a voxel grid predictor to get the initial mesh, as opposed to an initial ellipsoid mesh).  It might be possible for the authors to write a systems paper supporting these design decisions and showing how they lead to better results. However, this is not the paper the authors have written (the majority of the technical detail in the paper is focused on method components that make minimal impact). I would also argue that this hypothetical paper would not necessarily be appropriate for ICLR, since it does not focus on any new representations. It would be better suited to a venue such as CVPR, ICCV, or 3DV.  p.s. Reviewer 5 deserves all of the credit for noticing this major issue with the paper.
Below are multiple reviews of a paper. This paper introduces a new dataset called K-Radar. It includes three common sensors for autonomous driving applications, i.e., camera, radar, and lidar. The radar they are using is more advanced than the hardware in most existing datasets.The paper introduces a 4DRT-based 3D object detection dataset and benchmark, K-Radar. K-radar contains power measurements along the Doppler, range, azimuth, and elevation dimensions. The new dataset provides 3D bounding box labels and tracking ID for 93.3K objects.The authors collected and organized a new dataset with radar data. They introduce the radar sensor which is capable of penetrating snow or rain drops due to its longer wavelength. The calibration process for the sensor suite is not very clear.This paper presents a 4D Radar tensor (4DRT)-based dataset (K-Radar) for 3D object detection. It also provides diverse scenarios with challenging illumination, time, and weather conditions.This paper presents the first large-scale dataset containing four-dimensional radar tensor (4DRT), Lidar, stereo camera, IMU, and RTK-GPS data for the perception module in autonomous driving. The authors collected and annotated the actual driving data under various weather conditions and road types.This is the first dataset with 4DRT, including Doppler, range, azimuth, and elevation. It provides the baseline method for 3D object detection. The paper does not provide any experiments about tracking performance.	5 out of 6 reviewers are positive about accepting this work. The meta reviewer agrees with the reviewers that the K-Radar dataset is a clear contribution to the community and thus recommends acceptance. The meta reviewer believes that the authors have answered the negative reviewer's question in a fair enough way. The authors are suggested the authors polish their paper writing and exposition following reviewers' comments.
Below are multiple reviews of a paper. I find the paper well written and the idea well executed overall. The only question mark is on the performance of the proposed method. I have not found a convincing argument against the use of batch normalization in favor of Zero Init.The method is based on interesting observations regarding forward and backward explosion in such networks with the standard Xavier or (He, 2015) initializations. Experiments with the new method show that it is able to learn with very deep networks. The method includes 3 components, of which only one is justified in a principled manner.This paper shows that with a clever initialization method ResNets can be trained without using batch-norm (and other normalization techniques) The network can still reach state-of-the-art performance. This paper indicates that the role of normalization in training deep resnets might not be as important as people thought.	The paper explores the effect of normalization and initialization in residual networks, motivated by the need to avoid exploding and vanishing activations and gradients. Based on some theoretical analysis of stepsizes in SGD, the authors propose a sensible but effective way of initializing a network that greatly increases training stability. In a nutshell, the method comes down to initializing the residual layers such that a single step of SGD results in a change in activations that is invariant to the depth of the network. The experiments in the paper provide supporting evidence for the benefits; the authors were able to train networks of up to 10,000 layers deep. The experiments have sufficient depth to support the claims. Overall, the method seems to be a simple but effective technique for learning very deep residual networks.   While some aspects of the network have been used in earlier work, such as initializing residual branches to output zeros, these earlier methods lacked the rescaling aspect, which seems crucial to the performance of this network.  The reviewers agree that the papers provides interesting ideas and significant theoretical and empirical contributions. The main concerns by the reviewers were addressed by the author responses. The AC finds that the remaining concerns raised by the reviewers are minor and insufficient for rejection of the paper.
Below are multiple reviews of a paper. This paper proposes a new dataset for estimating robustness to distribution shift, in particular corruption robustness. They select corruptions that are "decorrelated" in a specific sense. The paper is missing key qualifiers.Robustness of computer vision models to image perturbations is a topic of great interest. Robustness properties depend significantly on model size and training procedure. At least one neural network needs to be trained for each candidate dataset.The proposed ImageNet-NOC dataset is balanced and covers a wider range of corruptions. The coverage (Sec 5.3) is a little bit confusing. The reviewer appreciates the analysis of the coverage and balance of the robustness benchmarks.ImageNet-C, the de facto standard for measuring robustness to natural corruptions for ImageNet classification models, contains correlated corruptions, so a mean robustness score is biased in favor of certain classes of corruptions. It proposes two metrics: robustness. score and overlapping score, and uses them to specify desirable characteristics of a	The authors propose a new dataset, namely ImageNet-NOC, for evaluating robustness of image classifiers to corruptions. The dataset may be viewed as an alternative to ImageNet-C which uses a different set of corruptions. To derive this set of corruptions, the authors first develop a notion of similarity between two corruptions, and then propose an iterative algorithm to build a set of corruptions which, intuitively, is sufficient to cover the larger set of corruptions (i.e., enjoys *high coverage*), and assigns a similar importance to each such corruption (i.e., is *balanced*). Then, the authors argue that ImageNet-NOC is superior to ImageNet-C as it achieves a higher degree of balance and coverage.  The reviewers found this to be a borderline paper. The reviewers appreciated the introduced metric and agree that there is no point in evaluating on corruptions which are perfectly correlated. In addition, the systematic approach for generating a set of relevant corruptions is seen as a step in the right direction. The reviewers appreciated the author response and were engaged in the discussion. As it currently stands the reviewers are not convinced that the paper is ready for acceptance. To improve the manuscript the authors could extend Tables 3 and 4 with a wider range of models and investigate qualitative differences between models robust on one dataset, but not on the other. Furthermore, there should be a more detailed discussion of stability and computational properties of algorithm 1. In addition, the authors should provide strong arguments as to why is it not sufficient to add additional corruptions to ImageNet-C and compute a weighted score instead. The latter suggestion could lead to an iterative improvement of the current set of benchmarks and place more emphasis on the methodology. I suggest the authors to incorporate the reviewer's feedback and place more emphasis on the methodology around algorithm 1, rather then on introducing another dataset which is likely to be superseded as soon as we add a couple more corruptions in the mix.
Below are multiple reviews of a paper. An upper bound is provided in Theorem 1, with interesting dependence on the second hidden layer width. The results the authors achieved contain enough caveats that I'm not sure if we can really draw strong conclusions.The authors showcase that in the case of having only the middle-layer trained, the test error of the setup in concern is upper-bounded by the sample complexity. The authors then subsequently put forth a novel bias choice in terms of the input vector norm which can alleviate the robustness issue of the two-layer model.The effect of noise is somewhat counterintuitive. It seems that generalization worsens as the number of samples increases in presence of noise. This might suggest that upper bound on generalization has some room for improvement.This paper studies the generalization performance of overparameterized 3-layer NTK models. The results provide insights into which hidden layer plays a more important role and how the bias affects the size of the learnable set. Overall the paper is good, especially in its excellent theoretical work.	This paper studies the generalization error of three-layer relu neural networks, when only the middle layer weights are trained.  The focus is the regression setting, and the goal is to capture the hidden layer interactions. The paper aims to determine how the (hidden) layer interactions influence the double-descent curve. The generalization error bound established depends on the layer width in an interesting manner, which may shed light on understanding deeper networks outside of the kernel regime.  All reviewers rated this work above the bar. As such, I recommend accepting this paper.  There were a few parts that the reviewers found unclear/needs improvement. In particular, some of the clarifications made by the authors in their rebuttal can help make this paper more clear for its future readers.
Below are multiple reviews of a paper. The method is on-chip and local, allowing SNNs to be learned directly on neuromorphic hardware. Experiments on image classification benchmarks demonstrate that the proposed LTL rule performs comparably to other ANN-to-SNN conversion methods. The method is not theoretically motivated, but this is not strictly necessary if there are good empiricalThis paper proposes a Local Tandem Learning (LTL) method to train spiking neural networks by distilling knowledge from a pre-trained ANN in a layer-wise way. Two versions of LTL, offline learning and online learning, are introduced and the on-chip implementation is discussed. Experiments on CIFAR-10Local Tandem Learning (LTL) is a spiking neural network (SNN) learning rule. It combines the teacher-student learning framework and a novel layer-wise local learning method for ANN-to-SNN conversions.This paper proposes a generalized learning rule called Local Tandem Learning. The SNN mimics the feature representation of a pre-trained ANN through local loss functions. This method has not only high accuracy but also fast convergence. It has two versions: offline and online and both versions have high performance.	This paper proposes a novel method of training spiking neural networks (SNNs) by matching the intermediate feature representations of SNNs with pre-trained ANNs. The method is on-chip and local, allowing SNNs to be learned directly on neuromorphic hardware.   All reviewers agreed that the problem that the paper target to solve is important, and the proposed method is novel. During the discussion period, the authors successfully addressed the concerns of the reviewers. Therefore, I recommend acceptance.
Below are multiple reviews of a paper. The manuscript presents a comprehensive benchmarking study in the terms of datasets, network backbone and training strategy. The authors analyzed the database characteristics, data enhancement strategy, network structure and loss function design by conducting vast experiments.The authors tackle the problem of extensively evaluating human mesh recovery model and training parameters to find the optimal parameters for a strong baseline. They perform extensive ablation studies on many components of the model, including data type, data augmentation, model choice, model initialization, and training strategy.This paper experimentally studies the task of 3D human pose and shape estimation from three aspect: dataset, backbone, and training strategy. Although the time and effort spent on the experiments is significant, no meaningful insight is given by the authors. The conclusions drawn from this experiment is ad-hoc.This paper studies various components of 3D pose and shape estimation, that are usually overlooked or heuristically addressed by relevant work. Authors demonstrate how commonly overlooked factors like dataset mixing, augmentation strategy and model initialisation can effect reported performance.This paper systematically varies several dataset, architecture, and training choices while keeping evaluations consistent. While many of the general findings are unsurprising, some of the findings aren’t obvious a priori so the evidence provided here is useful. It is quite useful to have the specific details of datasets and choices in one place.This paper gives a detailed analysis of 3D human recovery in datasets, backbones, and training policies. Inspiring and detailed discussions and sound-designed experiments are conducted. The results of the large-scale experiments reveal several important discoveries.	This paper presents a benchmark (in the sense of a large scale ablation and evaluation of existing works/datasets), considering the effects of dataset, "backbone" and training strategies for the problem of human pose and shape estimation. There is a consensus among reviewers that this paper's main limitation is the (over)emphasis on the human mesh recovery (HMR) framework. The forum discussions provide convincing arguments that despite this, the paper still offers with a major contribution to this albeit limited view of the problem. Another common issue raised by reviewers is whether this paper is suitable for the NeurIPS D&B track. I agree with the authors (and Reviewer BCuk) that this paper's premise is indeed well suited for this track, as described in the call for papers and FAQ. Therefore, I dismiss this as a limitation. Finally, there is a strong outlier review, whose exceptionally low score is obliterating this paper's average score. I have read the discussion in detail and while I find that this reviewer is making interesting points, I do not agree that any of them are serious enough to withhold publication of this work. I am content to see the reviewer's points as providing pointers for other future works that may be more influential than the presented one. The possible existence of superior future studies is not a reason to reject this paper. In conclusion, backed by the strong majority of reviewers, I recommend accepting this paper to the NeurIPS 2022 Datasets and Benchmarks program.
